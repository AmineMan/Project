Title:          Article-Action-ISIT.pdf
Author:         Administrator
Creator:        Adobe Acrobat 9.0.0
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Thu May 17 14:22:49 2012
ModDate:        Tue Jun 19 12:55:20 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      342220 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569564509

MAC with Action-Dependent State Information at
One Encoder
Lior Dikstein

Haim H. Permuter

Shlomo (Shitz) Shamai

Ben Gurion University of the Negev
liordik@post.bgu.ac.il

Ben Gurion University of the Negev
haimp@bgu.ac.il

Technion
sshlomo@ee.technion.ac.il

Abstract—We consider a two-user multiple-access channel,
where one of the encoders is allowed to take an action that
effects the formation of the channel states. The states are know
non-causally to the encoder. Two independent messages are
sent: a common message and a private message transmitted
by the informed encoder. We ﬁnd precise characterizations of
the capacity region. Our framework takes account of previously
evaluated settings regarding point-to-point channels with actions
and multiple-access channels with common messages. We obtain
the capacity of the Gaussian action-dependent point-to-point
channel.
Index Terms—Actions, Non-causal side information, Channel
capacity, Channel coding, Binning, Gel’fand-Pinsker Channel,
Dirty paper coding.

and identically distributed (i.i.d.) states available causally at
the encoder. Gel’fand and Pinsker [2], and later Heegard and
El Gamal [3], studied the case where the encoder observes
the channel states non-causally. They derived a single letter
formula for the capacity using a binning coding scheme. Costa,
in his famous “Writing on Dirty Paper” [4] used the results
obtained by Gel’fand and Pinsker and applied them to the
case where there are two additive Gaussian noise sources,
where one of the interferences takes the role of the channel
state. Somekh-Baruch, Shamai and Verdu, in their paper [5],
considered a MAC with common and private messages where
the encoder informed of the private message is additionally informed of the channel states non-casually. They characterized
the capacity region for the general ﬁnite alphabet case using
a generalized binning coding scheme. A MAC with private
messages at both encoders and state information known to one
encoder channel was examined in [6], where an inner bound
for the capacity region in the general discrete memoryless case
was found.
A novel idea of an action-dependent state scenario was
introduced in the work of Wiessman [7]. In his paper, he
looked at a point-to-point channel where the encoder is allowed to take an action that can effect the channel’s states
and characterized the capacity for the case where the channel
inputs are allowed to depend causally or non-causally on the
state sequence. In our paper, we generalize the previous results
presented in the works of Somekh-Baruch, Shamia and Verdu
[5] and of Wiessman [7]. We consider a MAC with a common
and private message and CSI at one encoder as in [5], but with
the addition of the fact that the encoder can effect the states
as in [7]. We further discuss the cases where our framework
reduces to one of the previous settings. Finally, we analyze
the Gaussian action-dependent point-to-point channel and ﬁnd
it’s capacity.
The remainder of the paper is organized as follows. In
Section II we formulate the problem of coding for a MAC with
a common and private message and with action-dependent
states available non-causally at the informed encoder. In Section III we state our main results, which include the capacity
region of the MAC with action-dependent state information at
one encoder, and discuss additional simple cases that provide
insight and show consistency with previous results. In Section
IV we examine the Gaussian action-dependent point-to-point

I. I NTRODUCTION
STATE-DEPENDENT channels characterize a signiﬁcant
collection of communication models, ranging from interfering
transmissions models to cases where the states are generated
by nature. Problems of coding for such channels have received
much attention due to the wide range of their potential
applications. Such applications vary from modeling communication links, such as fading, to interference in a wireless
network. Furthermore, problems relating to Multiple Access
Channels (MAC) with channel state information (CSI) have
been thoroughly studied due to their importance in wireless
communication systems. Most of the channels investigated
until now have been examined under the assumption that
the states affecting the channel cannot be inﬂuenced by the
communication system.
In our work, we consider a MAC where one of the encoders
is allowed to take an action that affects the formation of
the states. Speciﬁcally, we examine a MAC communication
system where two encoders have access to a common message
and only one has access to a private message. This encoder,
can generate an action sequence that, in turn, effects the
channel states. Furthermore, the states affected by the action
sequence are accessible non-causally to the informed encoder
when producing the channel input. We characterize the capacity region of the channel for the general ﬁnite alphabet case
with a single letter expression. This is done by using a random
coding scheme and a binning technique, where the encoding
of the message is done in two parts.
Shannon [1] ﬁrst introduced and characterized the capacity
of a state-dependent, memoryless channel with independent

1

2
n
X1 (M1 )

The code is deﬁned by the encoding functions:

M1
Encoder I

n
f1 : M1 → X1 ,

Channel
Yn
n
X2 (M1 , M2 , S n )
p(y|x1 , x2 , s)

M2

Decoder

f2 : M1 × M2 × S →

ˆ
M1
ˆ
M2

S

fA : M1 × M2 → An

n

ˆ
ˆ
g : Y n → (M1 × M2 ).

(5)

(n)
Pe =

channel and ﬁnd it’s capacity. We conclude in Section V with
a summary of this work.
AND

Throughout the paper, random variables will be denoted by
upper case letters, deterministic realizations or speciﬁc values
will be denoted by lower case letters and calligraphic letters
will denote the alphabets of the random variables. Let xn
denote vectors of n elements, i.e. xn = (x1 , x2 , ..., xn ) and
xj denote the i − j + 1-tuple (xi , xi+1 , ..., xj ) when j ≥ i and
i
an empty set otherwise. The probability distribution function
of X, the joint distribution function of X and Y , and the
conditional distribution of X given Y will be denoted by PX ,
PX,Y and PX|Y respectively.
We consider a channel coding MAC with action-dependent
states, where the states are known non-causally at one encoder,
as illustrated in Fig. 1. The MAC setting consists of two
transmitters (encoders) and one receiver (decoder). Let n
denote the block length and A, S, X1 , X2 and Y be ﬁnite sets
which denote the actions, states, Encoder 1’s inputs, Encoder
2’s inputs, and the outputs respectively. A state information
channel is described by a triple (A, PS|A , S) and is assumed
to be memoryless with transition probabilities:

Pr{g(Y n ) = (m1 , m2 )|(m1 , m2 )sent}.
m1 ,m2

III. M AIN R ESULTS

A. Capacity Region
The following theorem provides an expression for the
capacity region of the “MAC with action-state information at
one encoder” channel, for ﬁnite alphabets A, S, X1 , X2 :
Theorem 1: The capacity region of the MAC with actionstate information at one encoder, as shown in Fig. 1, is the
closure of the set that contains all the rates that satisfy
R2
R1 + R2

≤

≤

I(U ; Y |X1 ) − I(U ; S|A, X1 )

I(X1 , U ; Y ) − I(X1 , U ; S|A),

(8)

for some joint probability distribution of the form
P (a, s, u, x1 , x2 , y) =P (x1 )P (a|x1 )P (s|a)P (u|s, a, x1 )
× P (x2 |x1 , s, u)P (y|x1 , x2 , s), (9)
and |U | ≤ |A||S||X1 ||X2 | + 1.
A detailed proof is provided in [8]. Here we only provide the main ideas of the achievability and converse. The
achievability proof is based on a random coding scheme,
where the encoding of the messages is done in two parts.
For a joint probability distribution in the form of (9) the
uninformed user transmits at a rate R1 , where it’s codebook
consists of 2nR1 codewords. Now, the informed user uses
it’s additional knowledge to transmit it’s message using a
binning coding scheme. Encoder 2 generates 2n(R1 +R2 ) action
sequences an (M1 , M2 ) ∼ p(a|x1 ), and 2n(R1 +R2 ) bins. Next
˜
we randomly generate 2nR codewords un ∼ p(u|a, x1 ) and
distribute them uniformly into the bins. Therefore there are
˜
2n(R−(R1 +R2 ) codewords in each bin. Encoder 1 transmits
x1 (m1 ) and Encoder 2 transmits un (k) from bin (m1 , m2 )
such that it is jointly typical with xn , an , and sn . For decoding
1
the message, we look for m1 , m2 such that an , un , xn and
ˆ ˆ
1
y n are jointly typical.

(1)

Deﬁnition 1: A ((2nR1 , 2nR2 ), n) code for the channel in

Fig. 1 consists of two sets of integers M1 = {1, 2, ..., 2nR1 }
and M2 = {1, 2, ..., 2nR2 } called message sets. An index is
chosen uniformly and independently by the senders out of
the message sets. Encoder 1 selects a channel input sequence
n
n
X1 = X1 (M1 ). Given the messages M1 , M2 , an action
sequence denoted An = An (M1 , M2 ) is selected by Encoder
2. A state sequence, S n , is then selected by the channel,
with An being the input chosen by the Encoder 2. Next, a
n
n
channel input sequence, X2 = X2 (M1 , M2 , S n ), is selected.
The output of the channel is denoted Y n . The channel is
characterized by conditional probability p(yi |x1,i , x2,i , si ) and
is assumed to be memoryless:
p(yi |xi , xi , si ) = p(yi |x1,i , x2,i , si ).
1
2

1
2n(R1 +R2 )

(7)
A pair rate (R1 , R2 ) is achievable if there exists a sequence
(n)
of codes (2nR1 , 2nR2 , n) s.t. Pe → 0.
The capacity region is the closure of all achievable rates.

P ROBLEM S ETUP

p(si |ai , si−1 , m1 , m2 ) = p(si |ai ).

(6)

We deﬁne the average probability of error for the
((2nR1 , 2nR2 ), n) code as follows:

MAC with action-state information at one encoder.

II. N OTATION

(4)

and a decoding function

p(s|a)

Fig. 1.

n
X2 ,

an action encoder

Encoder II

An (M1 , M2 )

(3)
n

(2)

2

3

In the converse, we combine ideas presented by Gelfand and
Pinsker [2] regarding the non-causal stated information and
ideas used by Wiessman [7] concerning the identiﬁcation of
the auxiliary random variable. The auxiliary random variable is
n
chosen as Ui = (M1 , M2 , Si+1 , Y i−1 , An ). Finally, we show
that the Markov relation S − A − X1 holds.
Corollary 2: The following region is equivalent to the one
presented in Theorem 1:
R2
R1 + R2

≤

≤

point-to-point action-dependent states channel introduced in
[7].
Case 2: MAC with common message known to one encoder,
i.e., |S| = 1. For this case, we take U = X2 and we have
I(U ; S|A) = 0 and I(X1 , U ; S|A) = 0. Furthermore, there is
no point in allocating resources to the action sequence. As a
result, we obtain the following region:
R2

I(A, U ; Y |X1 ) − I(U ; S|X1 , A)

R1 + R2

I(X1 , A, U ; Y ) − I(X1 , U ; S|A). (10)

≤

I(X2 ; Y |X1 )

I(X1 , X2 ; Y ),

(13)

for some joint probability distribution of the from
P (x1 )P (x2 |x2 )P (y|x1 , x2 ).
Case 3: “MAC with common message and state information
known to one encoder”. Assume that we have a malfunction at
the action encoder, i.e. we cannot choose an action that effects
the formation of the states, but the Encoder 2 still knows
the states noncausally. For this case A = ∅; therefore, the
following expressions I(U ; S|A) and I(X1 , U ; S|A), become
I(U ; S) and I(X1 , U ; S) respectively. Hence we have the
following capacity region

It is clear that the region (10) contains the one in (8)
since I(U ; Y |X1 ) ≤ I(A, U ; Y |X1 ) and I(X1 , U ; Y ) ≤
I(X1 , A, U ; Y ). For the converse, we have:
I(A, U ; Y |X1 ) − I(U ; S|X1 , A) =
I(A, U ; Y |X1 ) − I(A, U ; S|X1 , A) =
˜
˜
I(U ; Y |X1 ) − I(U ; S|X1 , A),

≤

(11)

˜
˜
taking U = (A, U ), where (X1 , S, A, U , X2 , Y ) satisﬁes the
same joint distribution relations as (X1 , S, A, U, X2 , Y ) .
Furthermore, notice that we can express the capacity region
as:

R2
R1 + R2

≤
≤

I(U ; Y |X1 ) − I(U ; S|X1 )
I(X1 , U ; Y ) − I(X1 , U ; S),

(14)

where
the
probability
distribution
I(A; Y |X1 ) + I(U ; Y |X1 , A) − I(U ; S|X1 , A)
P (x1 )P (a|x1 )P (s|a)P (u|s, a, x1 )P (x2 |x1 , s, u)P (y|x1 , x2 , s)
I(A; Y ) + I(X1 , U ; Y |A) − I(X1 , U ; S|A).
reduces to P (x1 )P (s)P (u|s, x1 )P (x2 |x1 , s, u)P (y|x1 , x2 , s).
(12) This is indeed the result of the Generalized Gel’fand and
Pinsker channel, introduced in [5].
This result provides intuition and makes immediate sense.
IV. T HE G AUSSIAN C HANNEL
The informed encoder transmits information using the action
sequence, A, which is decoded and used at the decoder to
Weissman [7] ﬁrst introduced the Gaussian channel model
decode a second transmission, hence the conditioning. Namely, for the action-dependent point-to-point channel, illustrated in
we can look at the conditioned expressions of the region as Fig 2. He derived an achievable scheme for a lower bound
standard expressions of a “MAC with common message and on the capacity of the channel. We would like to show that
state information known to one encoder” channel presented in the lower bound achieved in [7] is indeed the capacity of
[5], i.e.,
the point-to-point channel. In order to do so, we look at the
Gaussian channel model presented in [5], namely the Gaussian
R2 ≤ I(U ; Y |X1 ) − I(U ; S|X1 )
Generalized Gel’fand and Pinsker (GGP) channel, illustrated
R1 + R2 ≤ I(X1 , U ; Y ) − I(X1 , U ; S, )
in Fig 3. In this setting, the states are known non-causally to
one encoder and are unknown to the second encoder and the
with a supplement of side information A.
decoder. The capacity region for this model was solved in [5].
We examine the case where only a common message is sent
B. Examples of special cases
over the channel. In this section we use the result obtained
Before proving the theorem, let us examine some special
in [5] to prove the capacity of the action-dependent point-tocases in order to get some intuitive perception and persuade
point channel. Similar results where obtained simultaneously
ourselves that the following region is consistent with previous
and independently by Choudhuri and Mitra in [9].
results.
Case 1 Point-to-point with action-dependent states, i.e., A. Channel Model
R1 = 0, P (a|x1 ) = P (a), P (u|s, a, x1 ) = P (u|s, a),
The Gaussian action-dependent point-to-point channel setP (x2 |x1 , s, u) = P (x2 |s, u). For this case, the region in ting is given by the following parameters:
Theorem 1 becomes:
the relation between Xi , Si and Yi is:

R2
R1 + R2

≤
≤

R2

≤

I(U ; Y ) − I(U ; S|A)

Yi = Xi + Si + Ni ,

for
a
probability
distribution
of
the
form
P (a)P (s|a)P (u|s, a)P (x2 |s, u)P (y|x2 , s). This is the

•

3

n

(15)

N is an i.i.d Gaussian noise process with zero-mean and
E[Ni2 ] = N , independent of X and S.

4
S n = An (M ) + W n
Action

M

We brieﬂy recall the channel model presented in [5]. The
channel is given by:

p(s|a)

Encoder

Yi = X1,i + X2,i + Wi + Ni .
Gaussian

ˆ
Decoder M

channel

X n (M )

Here, the states are denoted as W , where the noise processes
Wi and Ni are zero-mean Gaussian i.i.d. with E[Ni2 ] = N and
2
E[Wi2 ] = σW . Individual power constraints are considered:

Channel
Encoder
Y

Fig. 2.

n

n

n

=X +A +W

N

+N

1
n

n

Point-to-point channel with action-dependent states.
n
X1 (M )

Encoder I
Gaussian
channel

Decoder

ˆ
M

Encoder II

n
n
Y n = X1 + X2 + W N + N n

Sn

P1
 σ12
 0
0


Fig. 3. MAC with state information at one encoder and a common message

•

•
•

•

(16)

W n is an i.i.d Gaussian noise process with zero-mean
2
and E[Wi2 ] = σW , independent of N n .
The actions are constrained by
1
n

n

i=1

Ai (M ) ≤ PA .

(17)

The power constraint on the channel input is:
1
n

i=1

≤P

(18)

B. Capacity of the point-to-point channel
Theorem 3: The capacity of the Gaussian action-dependent

σ12
P2
σ2W
0

0
σ2W
2
σW
0

1

point-to-point channel under the power constraints is given
in (19) at the top of the next page, for some ρXA ∈ [0, 1],
ρXW ∈ [−1, 0] such that
ρ2 + ρ2
XA
XW ≤ 1.

i=1

1
≤ P1 ,
n

n

i=1

2
X2,i ≤ P2 .

(22)



0
PA
0 
 σ
⇔  XA
0 
0
2
σN
0

σXA
PX
σXW
0

0
σXW
2
σW
0


0
0 
.
0 
2
σN

In conclusion, we obtained a one-to-one correspondence
between the Gaussian action-dependent point-to-point channel
and the Gaussian GGP channel, with only a common message.
The capacity region for the Gaussian GGP channel was found
in [5] and is presented in (23) at the top of the next page,
where ρ12 = √σ12 , ρ2W = √σ2W 2 and ρ2 + ρ2 ≤ 1.
12
2W
P P

n

Xi2

2
X1,i

Conversely, we show that the Gaussian GGP channel, with
only a common message, is a special case of the Gaussian
action-dependent point-to-point channel. Let us take An (M )
n
as X1 (M ) and X(M ) as X2 (M ). So, we can look at the
“Encoder I” block as the “Action Encoder” and the “Encoder
II” block as the “Channel Encoder”.
Action-dependent
GGP channel
point-to-point channel with common message
n
An
X1
n
n
X
X2
n
n
fA : M → A
fX1 : M → X1
n
n
n
n
fX : M × S → X
fX2 : M × S → X2

The process S n is combined out of An (M ) and W n ,
i.e. S n = An (M ) + W n . Therefore, we can look at the
channel output Yi :
Yi = Xi + Ai (M ) + Wi + Ni .

n

Now, we would like to show that setting of the Gaussian
action-dependent point-to-point channel, illustrated in Fig 2 ,
is a special case of the Gaussian GGP channel, with only a
n
common message, illustrated in Fig. 3. Let us take X1 (M )
n
as A (M ), and X2 (M ) as X(M ). We can look at the block
of the “Action Encoder” as “Encoder I” and the “Channel
Encoder” as “Encoder II”.
Notice that we don’t lose any of the properties of the setting
by looking at the action-dependent point-to-point channel as
a Gaussian GGP MAC. Both the “Channel Encoder” and
“Encoder II” have knowledge of S n and the channel inputs
and the channel outputs are the same. The covariance matrix
ΣX1 ,X2 ,S,N becomes ΣA,X,W,N :

M

n
X2 (M )

(21)

n

P2 σW

2

Hence, the capacity for the Gaussian point-to-point channel
can be achieved by substituting the following associations in
the Gaussian GGP capacity expression. Here we have M2 = 0,
thus R2 = 0, P1 → PA , P2 → PX , ρ12 → ρXA and ρ2W =
ρXW . Substituting the expressions into (23) we get (19).

(20)

C. Remarks

The main idea of the proof is to show we can obtain a oneto-one correspondence between the action-dependent pointto-point channel introduced in [7] and the MAC with state
information known to one encoder channel, presented in [5].

Recall the result for the achievable rate introduced in
Weissman’s paper [7] for the Gaussian point-to-point channel
with action-dependent states

Proof:

CG =

4

1
log
2

max

(α,γ):α2 PA +γ 2 σ2 ≤PX
W

5

C =

PX (1 − ρ2 − ρ2 )
1
XA
XW
log 1 +
2
N

R2

≤

R1 + R2

≤

+

√
√
1
( PA + ρXA PX )2
.
log 1 +
√
2
PX (1 − ρ2 − ρ2 ) + (σW + ρXW PX )2 + N
XA
XW

P2 (1 − ρ2 − ρ2 )
1
12
2W
log 1 +
2
N
2
1
P2 (1 − ρ12 − ρ2 )
2W
log 1 +
2
N

+

√
√
1
( P1 + ρ12 P2 )2
log 1 +
,
√
2 − ρ2
2
P2 (1 − ρ12
P2 )2 + N
2W ) + (σW + ρ2W

2
2
[(1 + 2α)PA + PX + 1 + (1 + 2γ)σW ][1 + (PX − (α2 PA + γ 2 σW ))]
.
2
PX − α2 PA + 1 + σW (1 + 2γ)
(24)

2
γ 2 σW

(23)

the capacity formula of the Gaussian GGP channel in [5]. The
advantage of this technique is that we don’t need to calculate
the expressions directly as in [5], instead we present the region
as a function of the channel variables.

We would like to show that our result, obtained in (19), is
consistent with the result obtained in [7]. Here, X is deﬁned
as:
X = αA + γW + G
(25)
2

(19)

VI. ACKNOWLEDGMENT
This work has been supported by the CORNET Consortium
sponsored by the Chief Scientist of the Israel Ministry for
Industry and Commerce.

2

where α PA +
≤ PX and G ∼ N (0, PX − (α PA +
2
γ 2 σW )). Therefore we have:
√
PA
σXA
= α√
σXA = αPA , ρXA = √
PA PX
PX
σXW
σW
2
σXW = γσW , ρXW =
= γ√
. (26)
2
PX
PX σW

R EFERENCES
[1] C. E. Shannon. Channels with side information at the transmitter. IBM
J. Res. Dev., 2(4):289–293, October 1958.
[2] S. I. Gel’fand and M. S. Pinsker. Coding for Channel with Random
Parameters. Problems of Control Theory, 9(1):19–31, 1980.
[3] C. Heegard and A. A. El Gamal. On the capacity of computer memory
with defects. IEEE Transactions on Information Theory, 29(5):731–739,
1983.
[4] M. Costa. Writing on dirty paper (Corresp.). Information Theory, IEEE
Transactions on, 29(3):439–441, May 1983.
[5] A. Somekh-Baruch, S. Shamai, and S. Verd. Cooperative multiple-access
encoding with states available at one transmitter. IEEE Transactions on
Information Theory, 54(10):4448–4469, 2008.
[6] S. Kotagiri and J. N. Laneman. Multiple access channels with state
information known at some encoders. CoRR, abs/cs/0607102, 2006.
[7] T. Weissman. Capacity of channels with action-dependent states. IEEE
Trans. Inf. Theory, 56(11):5396–5411, 2010.
[8] L. Dikstein, H. H. Permuter, and S. Shamai. Mac with action-state
information at one encoder. In preperation.
[9] C. Choudhuri and U. Mitra. How useful is adaptive action? In
Globecom2012, December 2012.

Notice that now the constraint (20) becomes
2
α2 PA + γ 2 σW ≤ PX .

Now, substituting the expressions in (26) into the capacity
region of Theorem 3, i.e. in(19), we achieve the lower bound
(24) found in [7] and have shown that it is indeed tight.
Therefore, the capacity expression in (24) is equivalent to the
expression in (19).
V. C ONCLUSIONS
In multi-user communication systems today the demand for
high rates is constantly rising. Therefore, it is essential to ﬁnd
the fundamental limits of channel models in order to beneﬁt
from the channel structure. As a result of this motivation, we
extended the study of MAC with states known at one encoder
to the case where the encoder can take an action to effect the
formation of those states. We found the fundamental limits of
the channel model and characterized the capacity region. In the
process, we developed a two stage binning coding scheme. We
found the capacity of the Gaussian action-dependent point-topoint channel.
In the full paper [8], we obtain a closed formula for the
capacity region of the Gaussian action-dependent MAC. The
capacity is achieved by taking a Gaussian auxiliary random
variable and we show it sufﬁces to consider only jointly
Gaussian random variables. We observe that the capacity
formula found contains previously known results, particularly
the capacity found in the former section. Moreover, we we can
use the same techniques presented to give alternative proof to

5

