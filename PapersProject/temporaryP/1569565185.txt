Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Sat Apr 28 02:02:34 2012
ModDate:        Tue Jun 19 12:56:03 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      388201 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569565185

How Fast Can Dense Codes Achieve the
Min-Cut Capacity of Line Networks?
Anoosheh Heidarzadeh and Amir H. Banihashemi
Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada

In this paper, we study the coding delay and the average
coding delay of dense codes over the ﬁeld of size two (F2 ).
The analysis however can be generalized to ﬁnite ﬁelds of
larger size. We consider both lossless networks and networks
with Bernoulli losses. We also study both deterministic regular
and Poisson transmission schedules.
The main contributions of this paper are:
• For networks with deterministic regular transmissions and
Bernoulli losses, we derive upper bounds on the average
coding delay of dense codes (as a function of the message
size, the network length and the trafﬁc parameters) tighter
than what were presented in [4], [5] in the asymptotic
regime as the message size goes to inﬁnity.
• We show that, for such networks, the coding delay may
have a large deviation from the average coding delay in
both cases of identical and non-identical links. For nonidentical links, our upper bound on such a deviation is
smaller than what was previously shown in [5]. It is worth
noting that, for identical links, upper bounding such a
deviation has been an open problem (see [5]).
• We generalize the results to the networks with Poisson
transmissions for both lossless networks and networks
with Bernoulli losses.
The proofs are omitted due to the lack of space, and can be
found in [6].

Abstract—In this paper, we study the coding delay and the
average coding delay of random linear network codes (dense
codes) over line networks with deterministic regular and Poisson
transmission schedules. We consider both lossless networks and
networks with Bernoulli losses. The upper bounds derived in
this paper, which are in some cases more general, and in some
other cases tighter, than the existing bounds, provide a more
clear picture of the speed of convergence of dense codes to the
min-cut capacity of line networks.

I. I NTRODUCTION
Random linear network codes (dense codes) achieve the
capacity over various network scenarios, in particular, unicast
over line networks. Lun et al. [1] showed that dense codes
achieve the capacity of networks with transmission and loss
schedules speciﬁed by stochastic processes with bounded
average rate. They however did not discuss the speed of
convergence of such codes to the capacity.
The speed of convergence of dense codes to the capacity of
networks with arbitrary deterministic transmission schedules
was studied in [2] and [3]. It is not, however, straightforward to
apply the results to the networks with probabilistic schedules.
The coding delay or the average coding delay is often used
to measure the speed of convergence of a code to the capacity
of a network. The coding delay of a code over a network with
a given schedule of transmissions and losses, referred to as
trafﬁc, is the minimum time that the code takes to transmit
all the message vectors from the source to the sink over the
network. The average coding delay of a code over a network
with respect to a class of trafﬁcs is the average of the coding
delays of the code with respect to all the trafﬁcs.1
Pakzad et al. [4] studied the average coding delay of
dense codes over the networks with deterministic regular
transmissions and Bernoulli losses, where the special case of
two identical links in tandem was considered. The analysis
however did not provide any insight about how the coding
delay (which is random with respect to both the codes and the
trafﬁcs) can deviate from the average coding delay (which is
random with respect to the codes but not the trafﬁcs).
More recently, Dikaliotis et al. [5] studied both the average
coding delay and the coding delay over networks similar to
those in [4], under the assumption that all the packets are
innovative.2 This is not however a valid assumption in practice,
where the ﬁeld size is ﬁnite and can be as small as two.

II. N ETWORK M ODEL AND P ROBLEM S ETUP
We consider a line network of length L, where the L + 1
nodes {vi }0≤i≤L are connected in tandem. The underlying
problem is unicast: The source node v0 is given a message of
k vectors from a vector space over F2 , and the sink node vL
demands to have all the message vectors.
Each node transmits a (coded) packet at each transmission
opportunity in discrete-time where the number of transmissions per transmission opportunity is one. The points in time at
which the transmissions occur over each link follow a stochastic point process. The processes specifying the transmissions
over different links are considered to be independent.
Each packet transmission is either successful or fails. In the
latter case, the packet is erased. We consider two scenarios:
(i) lossless, where all packet transmissions are successful,
and (ii) lossy, where all packet transmissions are subject to
independent erasures over the same link or different links. The
trafﬁc over a link is fully described by the processes describing
the schedule of transmissions and by the loss model.
The links are assumed to be delay-free, i.e., the arrival time
of a successful packet at a receiving node is the same as the
departure time of the packet from the transmitting node.

1 The coding delay of a class of codes over a class of trafﬁcs is a random
variable due to the randomness in both the code and the trafﬁc. The average
coding delay is the coding delay averaged out over the trafﬁcs but not the
codes, and hence is a random variable due to the randomness in the code.
2 A collection of packets is “innovative” if their global encoding vectors are
linearly independent.

1

The goal in this paper is to upper bound the coding delay
and the average coding delay of dense codes over networks
with two types of transmission schedules and two types of loss
models speciﬁed below.3
The transmission schedules are described by (i) a deterministic process where at each time unit there is a transmission
opportunity at each node (such a schedule is referred to as
deterministic regular), or (ii) a Poisson process with parameter
λi : 0 < λi < 1, over the ith link, where λi is the average
number of transmission opportunities per time unit.
The loss models are described by (i) a deterministic process
where each packet transmission is successful (such a model
is referred to as lossless), or (ii) a Bernoulli process with
parameter pi : 0 < pi < 1, over the ith link, where pi is the
average number of successes per transmission opportunity.

The global encoding vectors of the received packets at a node
form the rows of the decoding matrix at that node. Let Qi+1
and Qi be the decoding matrices at the (i + 1)th and ith
nodes, respectively, and Ti be a matrix over F2 such that
Qi+1 = Ti Qi . The rows of Ti are the local encoding vectors
of the packets transmitted by the ith node, i.e., (Ti )n,j = λn,j ,
∀n ∈ Oi and ∀j ∈ Ii , where λn is the local encoding
vector of the nth packet. Let Qi be Qi restricted to its dense
rows, i.e., Qi is dense and has d rows (D(Qi ) = d). We
can write Qi+1 = Ti Qi , where Ti , the transfer matrix at
the ith node, is a matrix over F2 with d columns: (Ti )n,j =
λn,j +
∈Ii \Di λn, γ ,j , ∀n ∈ Oi , ∀j ∈ Di and {γ ,j } are
in F2 satisfying j∈Di γ ,j λj,k = λ ,k , ∀k ∈ Ii .
The nth row of Ti indicates the dense packets at the ith node
which contribute to the nth packet sent by the ith node, and
the j th column of Ti indicates the packets sent by the ith node
(n)
(j)
to which the j th dense packet contributes. Let Tirow (Ticol )
th
be the set of labels (indices) of i.u.d. entries in the n row
(n)
(j th column) of Ti . Thus, |Tirow | ≥ max{n − r + d, 0} (in
particular, the ﬁrst max{n − r + d, 0} entries of the nth row
(j)
are i.u.d.). Similarly, |Ticol | ≥ d − j + 1 (in particular, the last
d − j + 1 entries of the j th column are i.u.d.).
Let rank(T ) denote the rank of a matrix T over F2 . The
following result is then useful to lower bound the density of
the decoding matrix Qi+1 in terms of rank(Ti ).4
Lemma 1: Let Q be a dense matrix over F2 , and T be a
matrix over F2 , where the number of rows in Q and the number
of columns in T are equal. If rank(T ) ≥ γ, then D(T Q) ≥ γ.
The rank of a matrix T similar to that of the transfer matrix
T speciﬁed earlier can be lower bounded as follows.
Lemma 2: Let T be an n × d (d ≤ n) matrix over F2 such
that for any 1 ≤ j ≤ d, at least d − j + 1 entries of its j th
column are i.u.d.. For every integer 0 ≤ γ ≤ d − 1,

III. D ETERMINISTIC R EGULAR L OSSLESS T RAFFIC
In a dense coding scheme, the source node, at each transmission opportunity, transmits a packet by randomly linearly
combining the message vectors, and each non source nonsink (interior) node transmits a packet by randomly linearly
combining its previously received packets. The vector of
coefﬁcients of the linear combination associated with a packet
is called the local encoding vector of the packet, and the
vector of the coefﬁcients representing the mapping between
the message vectors and a coded packet is called the global
encoding vector of the packet. The global encoding vector of
each packet is assumed to be included in the packet header.
The sink node can recover all the message vectors as long as
it receives an innovative collection of packets of the size equal
to the number of message vectors at the source node.
The entries of the global encoding vectors of a collection
of packets are independent and uniformly distributed (i.u.d.)
Bernoulli random variables as long as the local encoding
vectors of the packets are linearly independent. Such packets
(with linearly independent local encoding vectors), called
dense, are of main importance in our analysis.
The ﬁrst step is to lower bound the size of a maximal
collection of dense packets at the sink node until a certain
decoding time. We, next, lower bound the probability that the
underlying collection includes a sufﬁcient number of packets
with linearly independent global encoding vectors.
Let Q be a matrix over F2 . A maximal collection of rows in
Q with i.u.d. entries is called dense. The matrix Q is called a
dense matrix if all its rows form a dense collection. We refer
to the number of rows in a dense collection of rows in Q as
the density of Q, denoted by D(Q), and refer to each row in
such a collection as a dense row.
Let Oi (Ii ) be the set of the packets transmitted (received)
by the ith node and let Di be the set of the dense packets at the
ith node. Let r and d be the size of Oi and Di , respectively.

Pr{rank(T ) < d − γ} ≤ (d − γ)2−(γ+1) .
Let (0, NT ] be the period of time over which the transmissions occur. The decoding matrix at the ﬁrst internal node (v1 )
is dense and its density is equal to the number of packets at
the node until time NT , i.e., D(Q1 ) = NT . The density of
the decoding matrix at the other non-source nodes is bounded
from below as follows by applying the preceding lemmas.
Lemma 3: For every 1 < i ≤ L, the inequality
D(Qi ) ≥ D(Qi−1 ) − log D(Qi−1 ) − log(1/ )
fails w.p. b.a.b. .
By combining the result of Lemma 3 with D(Q1 ) = NT ,
we can derive the following result.
Lemma 4: Suppose that a dense code is applied over a line
network of L links with deterministic regular lossless trafﬁcs
until time NT . Then, the inequality

3 For some ﬁxed 0 <
< 1, the coding delay of a class of codes over
a network with a class of trafﬁcs is upper bounded by N with probability
(w.p.) bounded above by (b.a.b.) , so long as the coding delay of a randomly
chosen code over the network with a randomly chosen trafﬁc is larger than
N w.p. b.a.b. . The average coding delay of a class of codes over a network
with respect to a class of trafﬁcs is upper bounded by N w.p. b.a.b. , so long
as the average coding delay of a randomly chosen code over the network with
respect to the class of trafﬁcs is larger than N w.p. b.a.b. .

D(QL ) ≥ NT − L log(NT L/ )
fails w.p. b.a.b. .
4 The

2

proofs of the lemmas in this section can be found in [3].

and j. We start off with lower bounding the number of packets
in Iij . Let ϕij be the number of packets in Iij . The length
of the partition Iij is NT /w. Thus, ϕij is a binomial random
.
variable with the expected value ϕ = pNT /w.
Hereafter, for the ease of exposition, let us denote x/2 by
x, for every x ∈ R. By applying the Chernoff bound, one can
˙
show that the inequality
.
ϕij ≥ r = (1 − γ ∗ ) ϕ

Now, we lower bound the probability that the collection of
dense packets at the sink node includes an innovative subcollection of size k. This itself lower bounds the probability
that a dense code succeeds.
Lemma 5: Let M be an n × k (k ≤ n) dense matrix over
F2 . For every 0 < < 1,
Pr{rank(M ) < k} ≤ ,
if k ≤ n − log(1/ ).
The following result upper bounds the coding delay by
putting together the results of Lemmas 4 and 5.
Theorem 1: The coding delay of a dense code over a line
network of L links with deterministic regular lossless trafﬁcs
is larger than

fails w.p. b.a.b. ˙, so long as γ ∗ is chosen such that r is an
integer, and γ ∗ goes to 0 as NT goes to inﬁnity, where
∗

γ ∼

2 2
ln
ϕ

1
2

.

(1)

We focus on the set of all packets over the ith link in the
active partitions: Iij is ‘active’ if i ≤ j ≤ w − L + i. Such
a partition is active in the sense that (i) there exists some
other partition over the upper link so that all its packets arrive
before the departure of all the packets in the underlying active
partition, and (ii) there exists some other partition over the
lower link so that all its packets depart after the arrival of all
the packets in the underlying active partition.
Let wT denote the total number of active partitions. It is easy
to see that wT = L(w − L + 1). We select r packets in each
active partition and ignore the rest. This method of selection
fails if the number of packets in some active partition is less
than r. Clearly, the failure occurs w.p. b.a.b. wT ˙.
We shall lower bound the number of dense packets in active
partitions. Before explaining the lower bounding technique,
let us ﬁrst state two lemmas which will be useful to lower
bound the rank of the transfer matrix at each node (depending
on whether the number of dense packet arrivals at the node
in a partition is larger or smaller than the number of packet
departures from the node in the same partition).
For given integers w, r and {rj }1≤j≤w (0 ≤ rj ≤ r), let
Ti,j be deﬁned as follows: Ti,j is an r × rj dense matrix over
F2 , if 1 ≤ j ≤ i ≤ w; or an arbitrary r × rj matrix over F2 ,
.
otherwise. Let T = [Ti,j ]1≤i,j≤w , and n = 1≤j≤w rj .
Lemma 6: Let T be deﬁned as above. For every integer
0 ≤ γ ≤ n − 1,

k + L log(L/ ) + log(1/ ) + L + 1
w.p. b.a.b. .
IV. D ETERMINISTIC R EGULAR T RAFFIC WITH B ERNOULLI
L OSSES
A. Identical Links
In this case, the Bernoulli parameters {pi }1≤i≤L are all
the same, and equal to p. Similar to the analysis of the
previous case, in the case of the deterministic regular trafﬁc
with Bernoulli losses, we need to track the number of dense
packets through the network.
The density of the decoding matrix at the receiving node
of a link depends on the density of the decoding matrix and
the rank of the transfer matrix at the transmitting node of the
link. The rank of a matrix is a function of its structure, and
the structure of the transfer matrix at a node depends on the
number of dense packet arrivals at the node and the number of
packet departures from the node before or after any given time.
Such parameters depend on the transmission schedule and the
loss model of the link, and are therefore random variables. It
is however not straightforward to ﬁnd the distribution of such
random variables. We rather adopt a probabilistic technique to
lower bound the rank of the transfer matrices as follows.
We split the time interval (0, NT ] into a number of disjoint
subintervals (partitions) of the same length. The arrivals in the
ﬁrst j partitions occur before the departures in the (j + 1)th
partition. Thus the number of arrivals before a given point in
time within the (j + 1)th partition is bounded from below by
the sum of the number of arrivals in the ﬁrst j partitions. Such
a method of counting is however suboptimal since there might
be some extra arrivals in the (j + 1)th partition before some
points in time within the same partition. To control the impact
of suboptimality, the length of the partitions thus needs to be
chosen with some care.5
Let w be the number of partitions of the interval (0, NT ].
Let Iij be the j th partition pertaining to the ith link for all i

Pr{r(T ) < n − γ} ≤ u 1 − 2−rmax 2−γ+n−wr+(r−rmin )(u−1) ,
where rmax = maxj rj , rmin = minj rj , and u =
(n − γ)/rmin .
For given integers w, r and {rj }1≤j≤w (r ≤ rj ), let Ti,j
be deﬁned as follows: Ti,j is an r × rj dense matrix over F2 ,
if 1 ≤ j ≤ i ≤ w; or an arbitrary r × rj matrix over F2 ,
.
otherwise. Let T = [Ti,j ]1≤i,j≤w , and n = wr.
Lemma 7: Let T be deﬁned as above. For every integer
0 ≤ γ ≤ n − 1,
Pr{r(T ) < n − γ} ≤ u 1 − 2−r 2−γ+n−wrmin +(rmin −r)(u−1) ,

5

On one hand, the length of the partitions needs to be sufﬁciently small
such that there is not a large number of arrivals in one partition with respect
to the total number of arrivals in all the partitions. This should be the case
because ignoring a subset of arrivals in one partition should not cause a
signiﬁcant difference in the number of arrivals before each point in time
within the same partition. On the other hand, the partitions need to be long
enough such that the deviation of the number of arrivals from the expectation
in one partition is negligible in comparison with the expectation itself.

where u = (n − γ)/r .
For every 1 < i ≤ L, and 1 ≤ j ≤ w −L+1, the number of
dense packets in the ﬁrst j active partitions over the ith link can
be lower bounded as follows: For every 1 ≤ l ≤ j, suppose
that the number of dense packets in the ﬁrst l active partitions

3

over the (i − 1)th link is already lower bounded. Let T be
the transfer matrix at the ith node, restricted to the successful
packet transmissions within the ﬁrst j active partitions over
the ith link (the number of such packets in each partition is
already lower bounded). Then, it can be shown that T includes
a sub-matrix T with a structure similar to that in Lemma 6
or the one in Lemma 7.6 By applying the proper lemma, the
rank of the transfer matrix at the ith node, and consequently,
by applying Lemma 1, the number of dense packets in the ﬁrst
j active partitions over the ith link can be lower bounded.
Note that, because of its recursive nature, the above algorithm lower bounds the number of dense packets in the ﬁrst j
active partitions over the ith link as a function of the number
of dense packets in the active partitions pertaining to the ﬁrst
link. Further, the packets over the ﬁrst link are all dense (by
the deﬁnition of the dense packets), and hence by using the
recursion, the following results can be derived.
Let D(Qj ) be the number of dense packets in the ﬁrst j
i
active partitions over the ith link. Clearly, D(Qj ) ≥ rj, ∀j :
1
1 ≤ j ≤ w − L + 1 (since r packets are selected in each
partition). For any other values of i and j, D(Qj ) is lower
i
bounded as follows.
Lemma 8: For every 1 < i ≤ L,

inequality. Thus, kmax ∼ pNT , as nT ∼ pNT and log(1/ ˙) =
o(nT ). The following result can be shown by replacing NT
with k/p in the right-hand side of the latter inequality.
Theorem 2: The coding delay of a dense code over a line
network of L identical links with regular trafﬁcs and Bernoulli
losses with parameter p is larger than
1
p

k w log

wL

+ w log

wL

1

1
p

fails w.p. b.a.b. ˙.
Lemma 9: For every 1 < i ≤ L, and 1 < j ≤ w − L + 1,

k + (1 + o(1))

wL
kL
+ w log
w
1

w.p. b.a.b. , where w ∼ (kL/ log(kL/ )) 2 .

≥ rj − Lij

B. Non-Identical Links
The preceding results regarding the identical links immediately serve as upper bounds for the case of non-identical
links with arbitrary parameters {pi }1≤i≤L , by replacing p with
min1≤i≤L pi . The results however might not be very tight, e.g.,
for the case where, for some 1 ≤ i ≤ L, pi is much larger than
p. Thus the actual values of parameters {pi } need to be taken
into consideration to derive tighter bounds. In particular, for
every 1 ≤ i < L, depending on whether the ith or the (i + 1)th
link has a larger parameter, Lemma 6 or 7 is useful to lower
bound the rank of the transfer matrix at the ith node. The rest
of the analysis remains the same.
In the following, we present the main results (without
proof) for a special case of non-identical links with “unequal”
parameters {pi }, where no two parameters are equal.
Theorem 4: Consider a sequence of unequal parameters
{pi }1≤i≤L . The coding delay of a dense code over a line
network of L links with deterministic regular trafﬁcs and
Bernoulli losses with parameters {pi } is larger than

fails w.p. b.a.b. ˙, so long as log(wT / ) = o(r), where Lij =
j(1+o(1))(log(ij/ )+1)+log((j(1+o(1))+1)/ )+log(ij)+
1, and the o(1) term is (log(ij/ ) + 1)/r.
The result of Lemma 9 lower bounds the number of dense
packets at the sink node as follows.
Lemma 10: The inequality
˙
D(QL ) ≥ wT ϕ/L − wT ϕ/L (1/ϕ) log(wT / ˙)−
− (wT /L) log(wT / ˙) − (wT /Lϕ) log2 (wT / ) −
−(wT /Lϕ) log(wT / ) − log(wT / ) −
− log(wT /L) − 1

kL
+
w

w.p. b.a.b. , where w ∼ kL2 / log(kL/ ) 3 , and the o(1)
term goes to 0 as k goes to inﬁnity.7
It is worth noting that Theorem 1 is not a special case of
Theorem 2 with p = 1. In fact, Theorem 1 provides a tighter
bound compared to the result of Theorem 2 with p = 1.
We now study the average coding delay of dense codes with
respect to the trafﬁcs with deterministic regular transmissions
and Bernoulli losses. It should be clear that, in this case, the
deviation of the number of packets per partition should not be
taken into account. Thus, by replacing r with ϕ in Lemmas 8
and 9, and redeﬁning w as pNT L/log(pNT L/ ), we have
the following result.8
Theorem 3: The average coding delay of a dense code over
a network similar to Theorem 2 is larger than

D(Q1 ) ≥ r − log(1/ ) − log i − 1
i

D(Qj )
i

k + (1 + o(1))

(2)
1
3

fails w.p. b.a.b. , where w ∼ pNT L2 / log(pNT L/ ) .
Let nT be equal to the right-hand side of the inequality
(2). Thus, QL fails to include an nT × k dense sub-matrix
w.p. b.a.b. . By applying Lemma 5, the probability of
{rank(QL ) < k} is b.a.b. , so long as k ≤ nT − log(1/ ).
We replace with ˙ everywhere. Then, a dense code fails
to transmit k message vectors w.p. b.a.b. , so long as
k ≤ nT − log(1/ ) − 1.
In the asymptotic setting as NT goes to inﬁnity, nT can be
written as pNT −(1+o(1))(pNT L/w+ pNT w log(wL/ )+
w log(wL/ )). We rewrite the last inequality as k ≤ pNT −
(1 + o(1))(pNT L/w + pNT w log(wL/ ) + w log(wL/ )) −
log(1/ ) − 1. Let kmax be the largest integer k satisfying this

1
p

k + (1 + o(1))

kL
+
w

k w log

wL

1
.
w.p. b.a.b. , where w ∼ γe kL2 / log(kL/ ) 3 , p =
.
.
min1≤i≤L pi , γe = min1<i≤L γei , and γei = |pi − pi−1 |.

7 Similarly,

in the following, the o(1) term is deﬁned with respect to k.
that the latter choice of w is much larger than that in Lemma 10.
This is because, in this case, there is no gap between the lower bound on
the number of packet transmissions in each partition and the expectation, and
hence, the partitions do not need to be sufﬁciently long (see Footnote 5).

6 In

8 Note

the case of identical links, the transfer matrix at each node includes a
sub-matrix similar to that in Lemma 6. However, in the case of non-identical
links, depending on the trafﬁc parameters, the transfer matrix at a node might
include a sub-matrix similar to that in Lemma 6 or the one in Lemma 7.

4

Theorem 5: The average coding delay of a dense code over
a network similar to Theorem 4 is larger than
1
p

k + (1 + o(1))

In [5], the average coding delay of dense codes over the
networks of length L with deterministic regular transmissions
and Bernoulli losses with parameters {pi } was upper bounded
1−p
by k + i=ν pi −p , where p = mini pi is the unique minimum
p
and ν = arg mini pi . This result was derived under the unrealistic assumption that all the coded packets are innovative.
Related to this result, Theorem 3 or Theorem 5 indicates that
the average coding delay of dense codes over line networks
with trafﬁcs as above, but with arbitrary or unequal parameters,
1
is upper bounded by p (k + (1 + o(1))( kL log(kL))), or
1
p (k + (1 + o(1))(f (k)L log(kL))), respectively, where f (k)
goes to inﬁnity sufﬁciently slow, as k goes to inﬁnity.10 It is
important to note that both Theorems 3 and 5 do not have
the limiting assumption of the result of [5] regarding the
innovation of all the packets. The bounds of Theorems 3 and 5
are larger than that of [5], which is expected, since the former,
unlike the latter, are derived based on the realistic assumption
of operating over a ﬁnite ﬁeld, which has the consequence that
not all the coded packets are innovative.
The results of Theorems 2 and 4 indicate that for both
trafﬁcs with arbitrary or unequal parameters, the coding de1
1
lay is upper bounded by p (k + (1 + o(1))(k 2 L log(kL)) 3 ).
This is while, in [5], the coding delay is upper bounded
3
1
by p (k + O(k 4 )). This bound is looser than the bound in
Theorem 2, or the one in Theorem 4, although it is derived
under the same limiting assumption as the one used in [5]
for the average coding delay. Such an assumption makes the
bound appear smaller than what it would be at the absence of
the assumption. This demonstrates the strength of the bounding
technique used in this work.
By combining Theorems 2 and 3, or Theorems 4 and 5,
it can be seen that the coding delay might be much larger
than the average coding delay. This highlights the fact that
the analysis of the average coding delay does not provide a
complete picture of the speed of convergence of dense codes
to the capacity of line networks.

kL
w

w.p. b.a.b. , where w ∼ γe k/ (f (k) log(kL/ )), and f (k)
goes to inﬁnity, as k goes to inﬁnity, such that f (k) =
o(γe k/ log(kL/ )).
V. P OISSON T RAFFIC : L OSSLESS OR B ERNOULLI L OSSES
In the following, we discuss how to generalize the preceding
results to the case of identical links with Poisson transmissions. The generalization of the results to the case of nonidentical links should be straightforward and hence omitted.
In the case of the lossless Poisson trafﬁc with parameter λ,
the number of packets in each partition of length NT /w is a
Poisson random variable with the expected value λNT /w. By
applying the Chernoff bound to the Poisson random variable
(see [7, Theorem A.1.15]), the main results in Section IV are
applicable to this network scenario, where p is replaced by λ.
In the case of Bernoulli losses over a Poisson trafﬁc with
parameters p and λ, respectively, it can be shown that the
points in time at which the arrivals/departures occur follow a
Poisson process with parameter λp, and hence the number of
packets in each partition has a Poisson distribution with the
expected value λpNT /w. Thus the main results in Section IV
apply by replacing p with λp.
VI. C OMPARISON WITH THE E XISTING L ITERATURE
The upper bounds on the coding delay and the average
coding delay, derived in this paper, are valid for any arbitrary
choice of . However, in the following, to compare our results
with those of [4] and [5], we focus on the case where goes
to 0 polynomially fast, as k goes to inﬁnity. For such a choice
of , the upper bounds on the coding delay and the average
coding delay hold w.p. 1, as k goes to inﬁnity.
In [4], the average coding delay of dense codes over the
networks of length 2 with deterministic regular transmissions
and Bernoulli losses with equal parameters (p) is shown to be
√
1
upper bounded by p (k + O( k log k)). The result of Theorem 3 indicates that the average coding delay of dense codes
over the networks of length L with similar trafﬁcs as above
(i.e., identical links with equal parameters)9 is upper bounded
1
by p (k + (1 + o(1))( kL log(kL))). This is consistent with
the result of [4], although the bound presented here provides
more details (about the O(.) term in the former bound).
The result of Theorem 2 suggests that the coding delay of
dense codes over network scenarios as above is upper bounded
1
1
by p (k + (1 + o(1))(k 2 L log(kL)) 3 ). One should note that
there has been no result on the coding delay of dense codes
over identical links in the existing literature. In fact, this was
posed as an open problem in [5]. It is also noteworthy that
unlike the analysis of [5], our analysis does not rely on the
existence of a single worst link, and hence is applicable to the
special case of identical links.

R EFERENCES
[1] D. Lun, M. M´ dard, R. Koetter, and M. Effros, “On Coding for Reliable
e
Communication over Packet Networks,” Physical Communication, vol. 1,
no. 008542, pp. 3–20, 2008.
[2] P. Maymounkov, N. Harvey, and D. Lun, “Methods for Efﬁcient Network
Coding,” in Proc. 44th Annual Allerton Conference on Communication
Control and Computing, 2006, pp. 482–491.
[3] A. Heidarzadeh and A. Banihashemi, “Network Codes with Overlapping
Chunks over Line Networks: A Case for Linear-Time Codes,”
Submitted to IEEE Trans. Info. Theory, May 2011. [Online]. Available:
http://arxiv.org/abs/1105.5736
[4] P. Pakzad, C. Fragouli, and A. Shokrollahi, “Coding Schemes for Line
Networks,” in Proc. IEEE Int. Symp. Info. Theory, ISIT’05, 2005.
[5] T. Dikaliotis, A. Dimakis, T. Ho, and M. Effros, “On the Delay of
Network Coding over Line Networks,” in Proc. IEEE Int. Symp. Info.
Theory, ISIT’09, 28 2009-july 3 2009, pp. 1408–1412.
[6] A. Heidarzadeh and A. Banihashemi, “How Fast Can Dense Codes
Achieve the Min-Cut Capacity of Line Networks?” Submitted to IEEE
ISIT’12, Jan. 2012. [Online]. Available: http://arxiv.org/abs/1202.0343
[7] N. Alon and J. Spencer, The Probabilistic Method.
3rd ed. Wiley
Interscience, 2008.
10 The special case of success parameters with a unique minimum can fall
into each category of arbitrary or unequal success parameters. For example,
aside from the uniqueness of the parameter with the minimum value, some
other parameters might be equal, and hence such a case does not belong to
the category of unequal parameters but the arbitrary parameters.

9 One should note that Theorems 2 and 3 are not restricted to the special
case of identical links, and hold true for any arbitrary sequence of parameters.

5

