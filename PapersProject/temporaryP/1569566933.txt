Title:          ISIT2012.pdf
Author:         Tondar
Creator:        Adobe Acrobat 9.1.2
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Sat May 19 01:54:46 2012
ModDate:        Tue Jun 19 12:55:56 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      501019 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569566933

Key Agreement over Gaussian Wiretap Models with
Known Interference at the Transmitter
Ali Zibaeenejad
Department of Electrical and Computer Engineering,
University of Waterloo, Waterloo, ON, Canada
Email: azibaeen@uwaterloo.ca

Abstract—We investigate the (forward) key capacity of a
Gaussian state-dependent wiretap channel (G-SWC) paralleled
with a public channel having capacity CP ∈ [0, ∞). This model
consists of a sender, a main receiver, and a wiretapper. The
channel state information (CSI) is an additive white Gaussian
interference (AWGI) which is non-causally known at the sender.
A lower bound (LB) on the key capacity is achieved by using
a generalized version of the dirty paper coding (DPC) in which
the transmitted signal is correlated with the interference. The
correlation coefﬁcient is to be determined by CP . The achievable
scheme is asymptotically optimum as CP → ∞. This optimum
key capacity is also asymptotically achievable for any CP ≥ 0 in
high signal to interference ratio (SIR) regime. In this regime,
the public channel has negligible contribution in key generation.
Generally, the CSI enhances the key capacity such that it exceeds
the main channel capacity of the G-SWC in low SIR regime.

In this paper, we examine if the results of the DM model
[9] can be extended to the Gaussian model. In the DM
model, the strong typicality [13, Sec. 10.6] is applied to the
achievable coding scheme. However, this typicality is not
valid for continuous signals. Hence, we require to use the
generalized version of Markov lemma [14], which is only
valid for Gaussian distributions based on weak typicality [13,
Sec. 3.1]. Further, as alphabets of the CSI and auxiliary
random variables (RVs) are ﬁnite in the DM model, the proofs
of the LB and UB of the DM model have to be retreated for
the Gaussian model.
We develop a novel achievable coding scheme in which the
key is generated based on a random (vector) quantization of
the interference at Alice. As CP grows, a ﬁner quantization at
Alice improves the key capacity. For the key agreement, the
interference can be helpful, and so our strategy is to enhance
the additive interference of Bob’s received signal through the
transmitted signal (subject to the model parameters) such that
the achievable key rate is maximized. Hence, we exploit a
generalized version of the dirty paper coding (DPC) [11] in
which correlation coefﬁcient between the transmitted signal
and the interference is ρ. ρ is an increasing function of CP .
When CP → ∞, CK (∞) is asymptotically achievable by
an amplify-forward coding scheme in which the transmitter
ampliﬁes the interference according to its maximum available
power and forwards it to the channel, i.e., ρ → 1. Using
simulations, we also show that the LB on CK (CP ) is a strictly
increasing function of CP . This fact is an essential difference
between the Gaussian model and the DM model [9].
In an independent and parallel work to [7], we learnt that
Khisti et al. [6], [8] studied the key agreement problem over
the Gaussian model for two special cases: no public channel,
i.e., CP = 0, and a two-way public channel with unlimited
capacity. Regarding the former which is related to this paper,
they achieved an LB on CK (0) when SNR at the main channel
is not negative (in dB). In high SIR (and high SNR) regime,
this LB coincides our result in Corollary 1 when CP = 0 is
relaxed. Our achievable scheme is a generalized form of their
work as it is established for any SNR/SIR and CP ∈ [0, ∞).
The authors [6], [8] also derived a UB on CK (0). This UB
equals CK (∞), which is achieved in this paper. However,
they [6], [8] directly extended/calculated the results of the DM
model for their Gaussian model.
The rest of this paper is organized as follows. In Section II,
we will present the problem deﬁnitions. In Section III, we will
state our main results. We will justify the sketch of the proofs
in Section IV. In Section V, we will simulate and compare
the results for a sample Gaussian model. In the last section,
we will conclude this paper.

I. I NTRODUCTION
In a wireless network, key agreement [1] between intended
nodes is a challenging problem as propagated signals are
accessible by unauthorized antennas. Using the wiretap coding
strategy [2], the key agreement problem was formulated by
Maurer [1] as well as Ahlswede and Csisz´ r [3] for a discrete
a
memoryless (DM) channel-type model which consists of a DM
wiretap channel and a parallel public channel [1]. Ahlswede
and Csisz´ r [3] proved that the forward key capacity [3] of the
a
DM channel-type model equals the secrecy capacity [2] of its
wiretap channel, and thus the public channel is useless.
The key agreement problem from correlated Gaussian
sources is studied in [4], [5]. In [4], a two-way public channel
with unlimited capacity and rate limited quantization at the
sources are modeled; while in [5], a rate limited public
communication is considered, and the forward key capacity
is calculated as a function of the public channel capacity.
The key agreement problem over a discrete memoryless
state-dependent wiretap channel (DM-SWC) with non-causal
channel state information (CSI) at the transmitter (Alice)
was studied in [6]–[10]. Zibaeenejad [9] assumed a discrete
memoryless (DM) model in which the DM-SWC is parallel
with a forward (authenticated) public channel [3] having
capacity CP ∈ [0, ∞). He [9] investigated the (forward) key
capacity of the DM model as a function of CP , i.e., CK (CP ).
The author [9] established a lower bound (LB) and an upper
bound (UB) on CK (CP ), where the LB is asymptotically tight
as CP → ∞; further, for any DM-SWC there exists a ﬁnite
∗
∗
capacity CP such that CK (CP ) = CK (∞) for CP ≥ CP .
In this paper, we study the key agreement problem over a
Gaussian model: A Gaussian state-dependent wiretap channel
(G-SWC) paralleled with a one-way public channel. Following
[11], [12], the CSI is assumed to be an additive white Gaussian
interference (AWGI), which is non-causally known at Alice.
We explore the key capacity as a function of CP , i.e., CK (CP ).

1

II. P RELIMINARIES

AND

P ROBLEM S TATEMENT

Interference

A. Notations

S ∼ N (0, Λ)

N and R are reserved for the set of natural numbers
and that of real numbers, respectively. A subset of R which
contains its positive elements is denoted by R+ . Other sets
are also represented by blackboard bold letters, e.g., A. The
cardinality of a set is denoted by |.|, e.g., |A|; however, |.|
returns the absolute value of a real-valued argument. Deﬁne
Aℓ A × . . . × A, where ℓ ∈ N and A is an arbitrary set.

K

Alice’s
Encoder

x = W(Q, s)
1
t
n xx

1
n I(K; z, P )

P
One-Way Public Channel with Capacity CP

Fig. 1.

Key agreement over the Gaussian model.

where P is the set of public messages from which a message
is sent over the public channel during n-time instants.
Deﬁnition 3. An admissible code (⌈2nRK ⌉, n), where RK ∈
R+ ∪ {0} and code block length n ∈ N, for the Gaussian

model consists of the following components:
1) A key set K = {1, . . . , ⌈2nRK ⌉}, which is publicly known;
2) A randomization RV Q, which is drawn according to
arbitrary distribution PQ on set Q at Alice such that
Q is independent of s;
3) A key generator function K : Q × Rn → K . Observing
s, Alice computes her key K = K(Q, s);
4) A wiretap channel encoding function W : Q×Rn → Rn .
Alice generates x = W(Q, s) subject to power constraint
(1), and then she transmits x over the wiretap channel in
n successive transmissions;
5) A public channel encoding function F : Q × Rn → P,
where P is assumed to be the range of function F which
is subject to constraint (3). Alice transmits the public
message P = F (Q, s) over the public channel.
6) A decoding function D : Rn × P → K . At the end of
ˆ
receiving y and P , Bob decodes his key K = D(y, P ).
Deﬁnition 4. Let (⌈2nRK ⌉, n) be an admissible code which reˆ
turns the key pair (K, K) ∈ K2 . The reliability, security level,
and randomness of the key pair are respectively measured by
ˆ
average probability of error Perror (n) = P{K = K} ,

Deﬁnition 1 (G-SWC). A G-SWC with non-causal CSI at the
2
2
transmitter is determined by (Γ, Λ, σ1 , σ2 ) ∈ R+ 4 , where
n
• transmission signal x ∈ R , which is the channel input
(from Alice), is subject to average power constraint
(1)

y = x + s + g1 ,
z = x + s + g2 ;

g2

P = F(Q, s)

As depicted in Fig. 1, a Gaussian model consists of two
parallel channels from Alice to Bob and Eve: A G-SWC and
an (authenticated) public channel according to the following
deﬁnitions.

•

Bob’s Decoder

Eve’s Receiver

B. Problem Deﬁnitions

•

ˆ
K

y = x + s + g1

x+s

≤Γ

ℓ times

1 t
xx ≤ Γ ;
n

s

z = x + s + g2

n is reserved for the length of block codes. Greek letters are
reserved for publicly known parameters, e.g., Λ is interference
power. Random variables (RVs) are represented by capital
narrow Latin letters as well, e.g., X. An element of a vector
is speciﬁed by its time instant shown by a subscript, e.g., X1 .
Random vectors with length n are represented by small bold
Latin letters for simplicity, e.g., x = (X1 , . . . , Xn ). Superscript “t” above a random vector stands for its transposition.
P{.} and are reserved for the probability (of an event)
and the differential entropy function [13], respectively. Other
functions are denoted by calligraphic letters, e.g., functions I,
N , and E represent the mutual information, the (multivariate)
normal distribution, and the expectation [13], respectively. Any
other symbols will be deﬁned as they appear in the paper.

•

g1

s

(2a)
(2b)

random vector s ∈ R , which is known as interference,
is drawn independent and identically distributed (i.i.d.)
according to N (0, Λ);
random vectors g1 ∈ Rn and g2 ∈ Rn are additive
1
leakage rate
RL (n) = I(K; z, P ) ,
white Gaussian noise (AWGN) of Bob’s channel and that
n
of Eve’s channel, respectively. The components of g1 and
log(|K|) − H(K)
2
those of g2 are drawn i.i.d. according to N (0, σ1 ) and
(uniformity) randomness
X (n) =
.
2
2
2
n
N (0, σ2 ), respectively, where σ2 ≥ σ1 (with arbitrary
Deﬁnition 5. For a given public channel capacity CP ∈
correlation).
y ∈ Rn and z ∈ Rn are the channel outputs to Bob and [0, ∞), a key rate RK (CP ) is said to be achievable if there
exists an admissible code (⌈2nRK ⌉, n) such that2
Eve, respectively, such that
n

Reliability Condition :
Security Condition :

lim Perror (n) = 0 ,

(5a)

lim RL (n) = 0 ,

(5b)

n→∞

n→∞

vector s is known at Alice at time instant i = 1.
Randomness Condition : lim X (n) = 0 ,
(5c)
n→∞
Deﬁnition 2 (Public Channel). A noiseless channel from Alice
H(K)
≥ RK . (5d)
The Key Rate :
lim inf
to Bob is called a (forward) public channel if any signal sent
n→∞
n
over this channel is publicly known. The capacity of the public For a given capacity C , the supremum of all achievable key
P
channel is given by CP , i.e.1,
rates is called (forward) key capacity of CP , and it is denoted
log(|P|)
lim sup
≤C ,
(3) by function CK (CP ).
•

n→∞

1 In

n

P

2 If |K| is ﬁnite and K satisﬁes all the conditions given in Deﬁnition 5,
ˆ
then K satisﬁes them too due to Fano’s inequality [3], [10, Appendix A].

this paper, all logarithms are in base 2.

2

Then, from equations (13), we have

III. S TATEMENT OF M AIN R ESULTS
Theorem 1.
O(CP )

Deﬁne the set

(γ, ρ) : γ ∈ [0, 1], ρ ∈ (−1, 1),
√
2
(1−ρ2 )(1−γ)2 ΓΛ+σ1 (Γ+γ 2 Λ+2ρ γ ΓΛ )
√
CP ≥ 1 log
2
(1−ρ2 )Γ(Γ+2ρ ΓΛ+Λ+σ 2 )
1

Then, the key rate
1
RK (γ, ρ, CP ) = log
2

√
2
Γ + 2ρ ΓΛ + Λ + σ1
√
2
Γ + 2ρ ΓΛ + Λ + σ2

E (U 2 )E (S 2 )
E (U 2 )E (S 2 ) − (E (U S))2
√
Γ0 + γ 2 Λ + 2ρ γ Γ0 Λ
,
(14)
(1 − ρ2 )Γ0
E (U 2 )E (Y 2 )
2 )E (Y 2 ) − (E (U Y ))2
E (U
√
√
2
2
(Γ0 + γ Λ + 2ρ γ Γ0 Λ )(Γ0 + 2ρ Γ0 Λ + Λ + σ1 )
√
,
2 )(1 − γ)2 Γ Λ + σ 2 (Γ + γ 2 Λ + 2ρ γ Γ Λ )
(1 − ρ
0
0
0
1
(15)

1
log
2
1
= log
2
1
I(U ; Y ) = log
2
I(U ; S) =

.
(6)

+

=

1
log
2

√
2
(1 − ρ2 )(1 − γ)2 ΓΛ + σ2 (Γ + γ 2 Λ + 2ρ γ ΓΛ )
√
2
and I(U ; Z) is the same as I(U ; Y ) if σ1 is replaced by σ2 .
(1 − ρ2 )(1 − γ)2 ΓΛ + σ1 (Γ + γ 2 Λ + 2ρ γ ΓΛ )
The key generator, encoding and decoding functions of the
(7)
Gaussian model are similar to those of the DM model [9] with
is an achievable key rate of the Gaussian model for any the difference that the strongly typical property [13, Sec. 10.6]
(γ, ρ) ∈ O(CP ). Also, let
used in those functions is to be replaced by the weakly typical
RK (CP )
sup
RK (γ, ρ, CP ).
(8) property [13, Sec. 3.1]. On the other hand, the proof of [9,
(γ,ρ)∈ O(CP )
Thm. 1] relies on the Markov lemma [13, Sec. 15.8.1], which
The forward key capacity of the model is lower bounded by is only valid for strong typicality. However, if we prove that
the channel input is a Gaussian signal which satisﬁes power
CK (CP ) ≥ RK (CP ) .
constraint (1), the generalized version of the Markov lemma
Theorem 2. If CP → ∞, the key capacity of the model is
[14], which is based on the weak typicality, guarantees the
√
extension of the proof of [9, Thm. 1] to the Gaussian model.
2 2
1
(Γ + Λ + 2 ΓΛ + σ1 )σ2
√
Now, we revise the achievable coding scheme of the
.
(9)
CK (∞) = log
2 2
2
(Γ + Λ + 2 ΓΛ + σ2 )σ1
DM model [9, Thm. 1] for the Gaussian model in this
paper. Codebook C consists of N = 2n(I(U;S)+ǫ0 ) codeAlso, for any CP ≥ 0, CK (CP ) ≤ CK (∞) is a UB.
words u generated i.i.d. according to U ∼ N (0, Γ0 +
Γ
Corollary 1. In high SIR regime, i.e., Λ → ∞, the (forward) (α2 − β 2 )Λ). The codewords are uniformly partitioned into
key capacity of the Gaussian model is
2n(I(U;S)−I(U;Y )+ǫ0 +ǫ1 ) enumerated bins such that each bin
2
1
σ2
contains 2n(I(U;Y )−I(U;Z)−ǫ1 +ǫ2 ) enumerated sub-bins, where
∀CP ∈ [0, ∞) :
lim CK (CP ) = log( 2 ) .
(10)
Γ
0 < ǫ2 < ǫ < ǫ1 < ǫ0 < 1.
2
σ1
Λ →∞
A revealed vector s is ǫ-weakly typical [13, Sec. 3.1] with
IV. T HE S KETCH OF P ROOFS
high probability if n ≥ n0 (ǫ). Hence [10, Appendix B]
1
The detailed proofs can be found in [10, Sec. 3.4.2]. The
| sst − Λ| ≤ ǫ′ ,
(16)
n
sketch of the proofs is as follows.
′
˜
1) The Proof of Theorem 1: For any ǫ ∈ (0, 1), select real where ǫ = 2 ln(2)Λ ǫ. Having s, u is selected randomly from
sequences u ∈ C such that (u, s) is ǫ-weakly typical for n ≥
numbers Γ0 = Γ − ǫ, γ ∈ [0, 1], and ρ ∈ (−1, 1). Let
n1 (ǫ). This typicality leads to [10, Appendix B]
Γ0
1
β ρ
,
(11a)
(17)
| tst | ≤ ǫ′′
Λ
n
α γ+β.
(11b) where t = u − αs and ǫ′′ = ǫ ln(2) [3(Γ − β 2 Λ) + 2α2 Λ].
˜
0
α
2
Once codeword u is selected, the index of its bin is sent
˜
Also, assume auxiliary Gaussian RV T ∼ N (0, Γ0 − β Λ)
over the public channel, and the index of its sub-bin (within
such that E(T S) = 0, where S ∼ N (0, Λ). Let
the bin) is kept as key K. Also, signal x is generated by
X = T + βS ,
(12a)
x = t + βs = u + γs ,
˜
(18)
U = T + αS .
(12b)
where (18) follows from (11b). From equations (12) and (18),
From (11b) and (12), we have U = X + γS, where the we conclude that x is an i.i.d. Gaussian vector according to
˜
correlation coefﬁcient between X and S is ρ. Also, let X ∼ N (0, Γ0 ) as u and s are i.i.d. Gaussian vectors. Further,
2
Y = X +S+G1 , Z = X +S+G2 , where both G1 ∼ N (0, σ1 ) x is 2ǫ−weakly typical with high probability for n ≥ n1 (ǫ),
2
and G2 ∼ N (0, σ2 ) are independent of (X, S). Hence, from and [10, Appendix B]
1
[13, Thm. 8.4.1], we have
(19)
| xxt − Γ0 | ≤ ǫ′′′
2
2
n
(13a)
E(U ) = Γ0 + γ Λ + 2ρ γ Γ0 Λ ,
′′′
where ǫ = 2 ln(2)Γ0 ǫ. Because Γ0 = Γ−ǫ, power constraint
E(U S) = ρ Γ0 Λ + γΛ ,
(13b) (1) is met due to (19). From equations (11), (16), (17), and
2
E(Y 2 ) = Γ0 + 2ρ Γ0 Λ + Λ + σ1 ,
(13c) (18), we also have
1
(13d)
E(U Y ) = Γ0 + ρ(1 + γ) Γ0 Λ + γΛ ,
(20)
| xst − ρ Γ0 Λ| ≤ ǫ′′′ ,
n
2
E(Z 2 ) = Γ0 + 2ρ Γ0 Λ + Λ + σ2 ,
(13e) which shows an essential difference between our strategy with
E(U Z) = Γ0 + ρ(1 + γ) Γ0 Λ + γΛ .
(13f) that of [11] in which x and s are asymptotically orthogonal.
1
log
2

3

Now, the proof of [9, Thm. 1] can be applied to the Gaussian
model.
The security condition (5b) can be also justiﬁed as follows.
At the end of the transmissions, both Alice and Bob know
˜
the bin index of u. Now, the bin can be considered as a
Gaussian wiretap codebook, which is designed for a Gaussian
wiretap channel with no interference [15], with 2n(I(U;Y )−ǫ1 )
codewords. Hence, (5b) can be concluded from [15].

where
• (23) follows from [9, Eq. 29], which is also valid for
the Gaussian model, where Ui = (K, Wi ) and Wi =
((Y1 , . . . , Yi ), (Zi+1 , . . . , Zn ), P );
• (24) follows from Markov chain Wi → Ui → (Xi , Si ) →
Yi → Zi and data processing inequality [13, Thm. 2.8.1];
2
• (25) follows from equations (2), where G1i ∼ N (0, σ1 )
2
and G2i ∼ N (0, σ2 ) are independent from (Xi , Si );
• (26) follows from [13, Thm. 8.4.1] and entropy power inequality [13]; also, the forward key capacity is unchanged
if Eve receives a physically degraded version of Bob’s
signal Zi = Yi + G′ (similar to [13, Sec. 15.1.3]), where
i
2
2
G′ is independent of Yi such that G′ ∼ N (0, σ2 − σ1 );
i
i
1
2 (G′ )
i +
• (27) follows from the fact that (Yi ) − 2 log(2
22 (Yi ) ) is an increasing function of (Yi ) as (G′ ) =
i
1
2
2
2 log(2πe(σ2 − σ1 )) [13, Thm. 8.4.1]; it also follows
from (Yi ) ≤ 1 log(2πeE(Yi2 )) due to [13, Thm. 8.6.5]
2
with the equality when Yi ∼ N (0, E(Yi2 ));
2
2
• (28) holds due to E(Yi ) = Υi + E(G1i );
• (29) holds by applying Jensen’s inequality [13,
Thm. 2.6.2] and using Lemma 1 for some −1 ≤ ρ ≤ 1;
Hence, the UB is proved as equation (29) is an increasing
2
2
function of ρ provided σ2 ≥ σ1 .

2) The Proof of Theorem 2:
a) The Direct Part: Let γ = 1 and ρ = 1 − δ, where

δ ∈ (0, 1). Then, (1, 1 − δ) ∈ O(CP ) holds only if condition
√
2
1
σ1 (Γ + γ 2 Λ + 2(1 − δ) γ ΓΛ )
√
CP ≥ log
2
2
(2 − δ)δ Γ(Γ + 2(1 − δ) ΓΛ + Λ + σ1 )
(21)
is met. To satisfy this condition, select CP large enough such
that condition (21) is met for any given δ ∈ (0, 1). In other
words, (1, 1 − δ) ∈ O(CP ) with δ → 0 as CP → ∞. Hence,
√
2
2
σ2 (Γ + Λ + 2(1 − δ) ΓΛ + σ1 )
1
√
RK (1, 1−δ, CP ) = log
2 (Γ + Λ + 2(1 − δ) ΓΛ + σ 2 )
2
σ1
2
is an achievable key rate according to equation (7).

b) The Converse Part: Let i ∈ {1, . . . , n} be the time
instant and Υi E((Xi + Si )2 ). First, let state the following
lemma which is proved in [10, Lem. 3.5].

V. S IMULATIONS
σ2

1
Assume a Gaussian model with parameters Λ = 0.1 and
2
2
Λ = 0.4. In our simulations σ1 , σ2 , Λ are ﬁxed, and the
Γ
desired plots are sketched as a function of SIR, i.e., ( Λ )dB .
• Fig. 2: Recalling Theorem 1, the LB on CK (CP ) is simulated
in this ﬁgure for 5 different values of CP . The UB on the key
capacity is also sketched in this ﬁgure according to Theorem 2.
This UB is the maximum achievable key capacity over the
Gaussian model for a given G-SWC which acquires for CP →
∞. According to this simulation, inequality
RK (0) < RK (.25) < RK (.5) < RK (1) < RK (2) < CK (∞)
(30)
Γ
holds for any SIR. When Λ = 1, we have RK (0) = .9478
and CK (∞) = .9491. Hence, we observe that RK (0) is just
.137% less than CK (∞), which is the maximum achievable
key capacity for the given G-SWC. This difference is even less
for other values of CP according to equation (30). Moreover,
Γ
|RK (0) − CK (∞)| → 0 as Λ → ∞. In other words, the LB
on CK (CP ) for any CP ≥ 0 asymptotically achieves
σ2
1
lim CK (CP ) = log( 2 ) = 1 bit/trans. .
(31)
2
Γ
2
σ1
Λ →∞
This fact is established in Corollary 1. Hence, the public
channel has negligible contribution in key generation in high
SIR regime.
• Fig. 3: Assume the Gaussian model with CP = 0 (the
G-SWC alone). In this ﬁgure, we compare the (ordinary)
capacity of the main channel [11] (CM ), the known LB on the
secrecy capacity [12] (RS ), and the LB on the key capacity
given in Theorem 1 (RK (0)). As it is illustrated in this
ﬁgure, RK (0) exceeds the ordinary capacity of the G-SWC
Γ
when ( Λ )dB < −8.5 dB. In this region, this means that
RS ≤ CS ≤ CM < RK (0) ≤ CK (0) , where RS , CS , and CM
are the LB on the secrecy capacity, the secrecy capacity and
the main channel capacity of the G-SWC, respectively. In other
words, the key capacity in low SIR regime is generally greater
2
σ2

Lemma 1. Assume the G-SWC with average power constraint
(1). Then, there exists a real number ρ ∈ [−1, 1] such that
n
√
1
Υi ≤ Γ + Λ + 2ρ ΓΛ ,
(22)
n i=1

where the equality holds if and only if (iff) Xi ∼ N (0, Γ) for
any i.
nRK (CP ) ≤ H(K) + n

ǫ
3

n

≤
≤

i=1
n
i=1
n

=
i=1

[I(Ui ; Yi |Wi ) − I(Ui ; Zi |Wi )] + nǫ

(23)

[I(Xi , Si ; Yi ) − I(Xi , Si ; Zi )] + nǫ

(24)

[ (Yi ) − (G1i ) − (Zi ) + (G2i )] + nǫ

(25)

n

≤

σ2
n
1
log( 2 ) +
[ (Yi ) − log(22
2
2
σ1
2
i=1

(G′ )
i

+ 22

(Yi )

)] + nǫ
(26)

n

σ2
n
1
≤ log( 2 ) +
[ log(2πeE(Yi2 ))
2
2
σ1
2
i=1
′
2
1
− log(22 (Gi ) + 2log(2πeE(Yi )) )] + nǫ
2
n
σ2
1
n
2
[ log(2πe(Υi + σ1 ))
= log( 2 ) +
2
2
σ1
2
i=1

1
2
2
2
− log(2πe(σ2 − σ1 ) + 2πe(Υi + σ1 ))] + nǫ
2
n
2
Υi + σ1
σ2
1
n
log
= log( 2 ) +
+ nǫ
2
2
2
σ1
2 i=1
Υi + σ2
√
2
2
σ2 (Γ + Λ + 2ρ ΓΛ + σ1 )
n
√
+ nǫ
≤ log
2
2
2
σ1 (Γ + Λ + 2ρ ΓΛ + σ2 )

(27)

(28)

(29)

4

σ2

σ2

1
2
Achievable key rate vs. SIR for ﬁxed ( Λ )dB = −10 dB and ( Λ )dB = −3.98 dB

Optimum γ vs. SIR for ﬁxed (

1.1
1
2

1

log

1+ Λ
σ2
1
1+ Λ
σ2
2

1
2

UB on CK (CP )

log(

2
σ2
2
σ1

2
σ1
d
Λ )B

= −10 dB and (

2
σ2
d
Λ )B

= −3.98 dB

)
1

0.9
0.8

0.8

0.6

0.6

γ∗

RK , bits/trans.

0.7

0.5

CP = 0 bit/trans.

CP = 0 bit/trans.
0.4
0.3

CP = .25 bit/trans.

CP = .25 bits/trans.
CP = .5 bits/trans.

0.4

CP = .5 bit/trans.
CP = 1 bit/trans.

CP = 1 bit/trans.
0.2

CP = 2 bit/trans.

0.2

CP = 2 bits/trans.
CP → ∞ bits/trans.

0.1
0
−30

−20

Fig. 2.

−10
Γ
SIR ( Λ ), dB

0

0
−30

10

The LB on key capacity of the model with capacity CP .
σ2

Fig. 4.

1.6

−10
Γ
SIR ( Λ ), dB

0

10

Coefﬁcient γ ∗ for the Gaussian model with capacity CP .
σ2

σ2

1
2
Optimum ρ vs. SIR for ﬁxed ( Λ )dB = −10 dB and ( Λ )dB = −3.98 dB

(1) LB on the secrecy capacity
1

(2) LB on the forward key capacity
1.4

−20

=1

σ2

1
2
Rate vs. SIR for ﬁxed ( Λ )dB = −10 dB and ( Λ )dB = −3.98 dB

1.8

(3)

(3) The main channel capacity

0.8
1.2
1

0.6

ρ∗

Achievable Rate, bits/trans.

CP = 4 bit/trans.
Γ
2
σ1

(1)

0.8

CP = 0 bit/trans.

0.4

CP = .25 bit/trans.

0.6

CP = .5 bit/trans.

(2)

CP = 1 bit/trans.

0.4
0.2
Γ
2
σ1

0.2
0
−30

−20

−10

0
−30

0

−20

CP = 2 bit/trans.

=1

−10

CP = 4 bit/trans.

0

10

Γ
SIR ( Λ ), dB

Γ
SIR ( Λ ), dB

Fig. 5. Correlation coefﬁcient ρ∗ for the Gaussian model with capacity CP .

Fig. 3. Comparison of the forward key capacity, secrecy capacity and main
channel capacity of the G-SWC.

[3] R. Ahlswede and I. Csisz´ r, “Common randomness in information theory
a
and cryptography — Part I: Secret sharing,” IEEE Trans. Inf. Theory,
vol. 39, no. 4, pp. 1121–1132, 1993.
[4] S. Nitinawarat, “Secret key generation for correlated Gaussian sources,”
in Proc. IEEE Int. Symp. Information Theory (ISIT), Toronto, Canada,
2008, pp. 702–706.
[5] S. Watanabe and Y. Oohama, “Secret key agreement from vector
Gaussian sources by rate limited public communication,” in Proc. IEEE
Int. Symp. Information Theory (ISIT), Austin, Texas, USA, 2010, pp.
2597–2601.
[6] A. Khisti, “Secret key agreement on wiretap channel with transmitter
side information,” in IEEE European Wireless (EW) Conf., Lucca, Italy,
2010, pp. 802–809.
[7] A. Zibaeenejad and A. K. Khandani, “State-dependent wiretap models
with side information,” Dept. of Elec. and Comp. Eng., University of
Waterloo, Waterloo, ON, Canada, Tech. Rep. 2010-08, July 2010.
[8] A. Khisti, S. Diggavi, and G. Wornell, “Secret-key agreement with
channel state information at the transmitter,” IEEE Trans. Inf. Forensics
and Security, vol. 6, no. 3, pp. 672–681, 2011.
[9] A. Zibaeenejad, “Key agreement in state-dependent channels with noncausal side information,” in IEEE Information Theory Workshop (ITW),
Paraty, Brazil, 2011, pp. 658–662.
[10] ——, “Key agreement over wiretap models with non-causal side information,” Dept. of Elec. and Comp. Eng., University of Waterloo,
Waterloo, ON, Canada, Tech. Rep. 2011-07, Dec. 2011.
[11] M. Costa, “Writing on dirty paper,” IEEE Trans. Inf. Theory, vol. 29,
no. 3, pp. 439–441, 1983.
[12] C. Mitrpant, A. J. Han Vinck, and Y. Luo, “An achievable region for
the Gaussian wiretap channel with side information,” IEEE Trans. Inf.
Theory, vol. 52, no. 5, pp. 2181–2190, 2006.
[13] T. M. Cover and J. A. Thomas, Elements of information theory, 2nd ed.
New Jersey, USA: John Wiley & Sons Inc., 2006.
[14] Y. Oohama, “The rate-distortion function for the quadratic Gaussian
CEO problem,” IEEE Trans. Inf. Theory, vol. 44, no. 3, pp. 1057–1070,
1998.
[15] S. K. Leung-Yan-Cheong and M. Hellman, “The Gaussian wire-tap
channel,” IEEE Trans. Inf. Theory, vol. 24, no. 4, pp. 451–456, 1978.

than both the main channel capacity and the secrecy capacity
as it can be generated with assistance of the interference.
• Fig. 4 and Fig. 5: Assume (γ ∗ , ρ∗ ) is the optimum value
of pair (γ, ρ) in the sense that the supremum of equation (8)
is obtained. Fig. 4 and Fig. 5 exhibit γ ∗ and ρ∗ versus SIR,
respectively, for 6 values of CP . According to these ﬁgures,
both γ ∗ and ρ∗ are increasing functions of CP for any SIR.
Γ
Moreover, both γ ∗ and ρ∗ are increasing functions of SIR ( Λ )
∗ ∗
for any CP ≥ 0, i.e., lim (γ , ρ ) = (1, 1).
Γ
Λ →∞

VI. C ONCLUSIONS
We have shown that the positive effect of the interference
on the key capacity is generally more than that of the secrecy
capacity, because the interference, which is independent of
messages in a secrecy problem, is a valuable resource in key
generation. Hence, the key capacity of a Gaussian wiretap
channel with interference is generally larger than its secrecy
capacity. As CP grows, contribution of the interference in key
generation is intensiﬁed specially in low SIR regime because
a ﬁner quantization of the interference, which enhances the
forward key capacity, can be applied.
R EFERENCES
[1] U. Maurer, “Secret key agreement by public discussion from common
information,” IEEE Trans. Inf. Theory, vol. 39, no. 3, pp. 733–742, 1993.
[2] A. D. Wyner, “The wire-tap channel,” Bell Syst. Tech. J., vol. 54, no. 8,
pp. 1355–1387, 1975.

5

