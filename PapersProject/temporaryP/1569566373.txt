Title:          main.dvi
Creator:        dvips(k) 5.98 Copyright 2009 Radical Eye Software
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Thu May 17 16:41:42 2012
ModDate:        Tue Jun 19 12:56:16 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      355405 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569566373

From Glauber Dynamics To Metropolis Algorithm:
Smaller Delay in Optimal CSMA
Chul-Ho Lee,

Do Young Eun

Se-Young Yun,

Dept. of ECE, NC State University, Raleigh, NC, USA
Email: {clee4, dyeun}@ncsu.edu

Yung Yi

Dept. of EE, KAIST, Daejeon, Korea
Email: syyun@comis.kaist.ac.kr, yiyung@kaist.edu
by such a “negative” result, Shah and Shin [16] proposed a
modiﬁed CSMA requiring coloring operation that achieves
O(1) delay with throughput-optimality for networks with
geometry (or polynomial growth). Lotﬁnezhad and Marbach
[9] proved that a reshufﬂing approach, which periodically
reshufﬂes all on-going schedules under time synchronized
CSMA† , leads to both throughput-optimality and O(1) delay
for torus (inference) topologies. Jiang et al. [3] proved that a
discrete-time parallelized Glauber dynamics achieves O(log n)
delay for a limited set of arrival rates.
Despite these nice results on the delay asymptote for largescale networks, it still remains questionable how to improve
the delay performance of (standard) Glauber-dynamics based
CSMA for unscaled, ﬁxed networks without loss of other
important metrics such as throughput and complexity. It is
also unclear which tools to use for such purpose. While mixing
time has been a popular toolkit for delay analysis [16], [3], it
was shown very recently [18] that mixing time based approach
may not be the right way to capture delay dynamics even in
the asymptotic sense. On the other hand, the development of
optimal CSMA, in principle, is equivalent to constructing a (reversible) Markov chain to achieve a given, desired stationary
distribution under some constraints due to the interference. We
note that Glauber dynamics is just one such instance. There
can be many other Markov chains with the same stationary
distribution (thus leading to throughput-optimality) and no
additional complexity, but potentially higher efﬁciency for
smaller delay under the same constraints.
In this paper, we propose, as extensions of the Glauber
dynamics, a class of algorithms with a tunable parameter
β ∈ [0, 1], named generalized Glauber dynamics, ranging from
the Glauber dynamics (β = 0) to the Metropolis algorithm
(β = 1). We then show that the generalized Glauber dynamics
or corresponding reversible Markov chain achieves the same
stationary distribution regardless of the choice of β, while
the Markov chain, when β ∈ (0, 1], is more efﬁcient than that
under the Glauber dynamics (β = 0) in the sense of Peskun
ordering, i.e., a partial order between off-diagonal elements
of transition matrices of different Markov chains. Due to
the invariant stationary distribution property, the generalized
Glauber dynamics, when it comes into play for the problem
of optimal CSMA, guarantees the same long-term throughput
and also achieve throughput-optimality under mild conditions.
Despite the same long-term throughput, their ‘second-order’
behavior can be quite different. This in turn leads to different

Abstract—Glauber dynamics, a method of sampling a given
probability distribution via a Markov chain, has recently made
considerable contribution to the MAC scheduling research, providing a tool to solve a long-standing open issue – achieving
throughput-optimality with light message passing under CSMA.
In this paper, we propose a way of reducing delay by studying
generalized Glauber dynamics parameterized by β ∈ [0, 1], ranging from Glauber dynamics (β = 0) to the Metropolis algorithm
(β = 1). The same stationary distribution is sustained across
this generalization, thus maintaining the long-term optimality.
However, a different choice of β results in a signiﬁcantly different
second-order behavior (or variability) that has large impact on
delay, which is hardly captured by the recent research focusing
on delay in the large n (the number of nodes) asymptotic. We
formally study such second-order behavior and its resulting delay
performance, and show that larger β achieves smaller delay. Our
results provide new insight into how to operate CSMA for large
throughput and small delay in real, ﬁnite-sized systems.

I. I NTRODUCTION
Since the seminal work by Tassiulas and Ephremides
on throughput-optimal scheduling [19], referred to as MaxWeight, a huge array of research has been made to develop
distributed MAC scheduling with high performance guarantee
and low complexity. The tradeoff between complexity and
efﬁciency has been, however, observed in many cases, or even
throughput-optimal algorithms with polynomial complexity
have turned out to require heavy message passing (see, e.g.,
[20]). A breakthrough has been recently made, where just
locally controlling the classical CSMA parameters, which
is modeled by Glauber dynamics∗, is enough to achieve
throughput-optimality, see e.g., [4], [8], [12], [17]. We call
this “optimal CSMA” for brevity.
In addition to throughput or utility, delay is another key
performance metric in MAC scheduling. Delay research in
MAC scheduling with performance guarantee has been studied
with mathematical tools such as large deviation theory, heavy
trafﬁc approximation, and Lyapunov bound (see, e.g., [20]
and references therein). However, delay in Glauber-dynamics
based CSMA (or optimal CSMA) has been under-explored,
where only a small set of work has been published with
emphasis on the asymptotic results. Shah et al. [15] showed
that it is unlikely to expect a simple MAC protocol such as
CSMA to have high throughput and low delay. Motivated
This work was supported in part by National Science Foundation under
grants CNS-0831825 and CNS-0545893, and by Basic Science Research
Program through the National Research Foundation of Korea (NRF) funded
by the Ministry of Education, Science and Technology (2012-0003580).
∗ Glauber dynamics is a Markov Chain Monte Carlo (MCMC) method for
sampling a given probability distribution by constructing a Markov chain
achieving the desired distribution as its unique stationary distribution [7].

† Thus,

1

this is not a Glauber-dynamics based CSMA.

Algorithm 1 Glauber Dynamics (at Time Slot t)
1:
2:
3:
4:
5:
6:
7:
8:
9:

σv = 1

Choose a node v ∈ N uniformly at random
For node v:
if w∈Nv σw (t−1) = 0 then
λv
σv (t) = 1 with probability 1+λv
1
σv (t) = 0 with probability 1+λv
else
σv (t) = 0
end if
For any node w ∈ N \ {v}: σw (t) = σw (t−1)

σu = 0

σz = 0

σw = 0

σx = 1

σy = 0

Fig. 1. Illustration of a wireless multihop scheduling driven by the Glauber
dynamics over a conﬂict graph G with |N | = 6. Links v, x are active while
all others are silent, forming one instance of independent set on G.

a link as an (ordered) transmitter-receiver pair. It is said that
two links conﬂict with each other if they cannot be “active”
for communication at the same time due to the interference.
Consequently, we can deﬁne a conﬂict graph G = (N , E) in
which each node represents a link, while an edge between two
nodes (or links) exists if they conﬂict with each other. Given
a graph G, the scheduling governed by Glauber dynamics
determines which nodes to be active or available for communication, forming one instance of independent sets (feasible
conﬁguration) over G at each time t in a distributed manner.
For each node v ∈ N , if σv (t) = 1, then node v is active, i.e.,
the transmitter of link (or node) v can transmit a packet to its
receiver pair, and node v should be silent, if otherwise. See
Fig. 1 for an illustrative example. Throughout this paper, the
graph G refers to a conﬂict graph.
The Glauber dynamics in the context of scheduling is
typically considered under continuous-time (or asynchronous)
setting as used in [17], [16], which is also our target scenario.
Speciﬁcally, each node is equipped with its own Poisson
clock of rate 1, leading to the uniform node selection in
Algorithm 1, and then decides its transmission schedule (or
updates its status) accordingly. Here, the ‘master’ clock is
Poisson with rate n and each (master) clock tick corresponds
to a discrete-time slot in Algorithm 1. It is not difﬁcult to
see that the Glauber dynamics captures the following CSMA
features: 1) random back-off : the transmitter of link v waits an
exponentially distributed period of time with mean (1+λv )/λv
before transmitting (provided that the channel is sensed ‘idle’);
2) channel holding time: once the transmitter of link v grabs
the channel for transmission, it keeps the channel for an
exponential distributed period of time with mean 1 + λv . It
is worth noting that in the continuous-time setting, since the
master clock rate is n, the time scale is scaled down by
a factor of 1/n, implying the similar parallel-update effect
to the discrete-time parallel Glauber dynamics in [12], [3].
Although our target scenario is such continuous-time update
for scheduling, in our subsequent analysis, time unit of interest
is the unit of master clock ticks (so discrete time).

queueing delay performance, especially under the network of
a reasonable size, which is hardly captured by any asymptotic
order-wise analysis. However, thanks to the Peskun ordering
and its relationship with efﬁciency ordering, we are able
to demonstrate, in theory and simulation, that the original
Glauber dynamics (β = 0) in fact gives the worst queueing
delay performance among the generalized Glauber dynamics,
and there are inﬁnitely many different variants that have the
same long-term throughput, but with better queueing delay
performance as β increases, culminating in the ‘Metropolised’
version with β = 1 for any ﬁnite-sized networks.
II. P RELIMINARIES
A. Glauber Dynamics for the Hard-core Model
Consider a connected, undirected graph G = (N , E) with a
ﬁnite set of nodes (or vertexes) N = {1, 2, . . . , n} and an edge
set E. Let Nv = {w ∈ N : (v, w) ∈ E} be the set of neighbors
of node v. We deﬁne by σ a conﬁguration of the nodes in G,
which is given by σ = {σv , v ∈ N } with σv ∈ {0, 1} for all v. A
conﬁguration is said to be feasible if the set {v ∈ N : σv = 1}
is an independent set of G where no two nodes in the set
are adjacent (or neighbor of each other), i.e., if σv + σw ≤ 1
for all (v, w) ∈ E. Let Ω ⊆ {0, 1}n also be the set of all
feasible conﬁgurations on G. This model under the constraint
of independent sets is called the hard-core model [7].
The (single-site update) Glauber dynamics for the hard-core
model with heterogeneous fugacities {λv , v ∈ N }, deﬁned in
Algorithm 1, leads to a (discrete-time) Markov chain achieving
the following stationary distribution π = {π(σ)} over Ω:
1
π(σ) =
λσv ,
(1)
v
Z
v∈N

with a normalizing constant Z = σ∈Ω v∈N λσv . Note that
v
λv > 0 for all v, ensuring that π(σ) > 0 for all σ ∈ Ω.
Speciﬁcally, σ(t) = {σv (t), v ∈ N } denotes the state of the
Markov chain (or a feasible conﬁguration by the Glauber
dynamics) at time slot t. It is known that {σ(t)}t≥0 is an
irreducible, aperiodic Markov chain achieving the stationary
distribution π in (1) on the ﬁnite state space Ω [7], [17], [16].
The Markov chain {σ(t)} is also reversible with respect to π,
i.e., π(σ)Q(σ, σ ′ ) = π(σ ′ )Q(σ ′ , σ) for all σ, σ ′ ∈ Ω, where
Q(σ, σ ′ ) is the transition probability from state σ to state σ ′ .

III. C OMPARING R EVERSIBLE M ARKOV C HAINS
There are potentially many other (discrete-time) reversible
Markov chains with the same π in (1), all of which translate
into distributed algorithms just like the one in Algorithm 1, as
will be shown later. One important question would be how to
compare these reversible Markov chains. As these algorithms
have the same π, they all guarantee the same long-term
throughput, while their ‘second-order’ behavior can be quite
different, leading to different queueing delay performance.

B. CSMA and Glauber Dynamics
We present how CSMA in wireless multi-hop networks
can be modeled by the Glauber dynamics. In the context of
wireless multihop scheduling (or, simply scheduling), deﬁne

2

Algorithm 2 Generalized Glauber Dynamics with β ∈ [0, 1] (at

Mixing time has been a popular criterion to compare
competing reversible Markov chains with the same stationary
distribution. The mixing time of a (reversible) Markov chain
indicates the speed of convergence to its stationary distribution
and is mainly determined by the second largest eigenvalue
modulus (SLEM) of its transition matrix [7]. Note that smaller
SLEM leads to smaller (faster) mixing time. In this paper,
however, we look at the comparison of reversible Markov
chains from a different, but important perspective. This is done
based on the following Peskun ordering and its relationship
with efﬁciency ordering.
Deﬁnition 1 (Peskun ordering): [13] For two irreducible
Markov chains on a ﬁnite state space S with transition matrices
˜
˜
P = {P (i, j)}i,j∈S and P = {P (i, j)}i,j∈S , it is said that
˜ dominates P off the diagonal, written as P
˜
P
P, if
˜ (i, j) for all i, j ∈ S (i = j).
P (i, j) ≤ P
✷
˜
Let {X(t)}t≥0 and {X(t)}t≥0 be irreducible Markov
chains on a ﬁnite state space S = {1, 2, . . . , n} with transition
˜
matrices P and P, respectively. Suppose that the Markov
˜
chains {X(t)} and {X(t)} have the same stationary distribution π = {π(1), π(2), . . . , π(n)}. For a function f : S → R,
m
deﬁne an estimator µm
ˆ
t=1 f (X(t))/m for µ = Eπ (f ) =
f (i)π(i). It is well known that limm→∞ µm = µ for
ˆ
i∈S
any function f with Eπ (|f |) < ∞ [5], [7]. The asymptotic
variance of the estimate µm is deﬁned as
ˆ
ν(P, f )

lim m · VAR (ˆm ) ,
µ

m→∞

Time Slot t)
1: Choose a node v ∈ N according to a given {qv }
2: For node v:
3: if
w∈Nv σw (t−1) = 0 then
4:
if σv (t−1) = 0 then
1 β
−

5:
6:
7:
8:
9:
10:
11:
12:
13:
14:

λv
σv (t) = 1 with probability 1+λv
min 1, λβ
v
σv (t) = 0, otherwise.
else
1 β
−
1
min 1, 1/λβ
σv (t) = 0 with probability 1+λv
v
σv (t) = 1, otherwise.
end if
else
σv (t) = 0
end if
For any node w ∈ N \ {v}: σw (t) = σw (t−1)

IV. G ENERALIZED G LAUBER DYNAMICS FOR S MALLER
D ELAY IN O PTIMAL CSMA
We now introduce a class of algorithms with a controllable
parameter β ∈ [0, 1], named generalized Glauber dynamics, as
extensions of the (standard) Glauber dynamics in Algorithm 1.
As shall be shown below, this generalization indicates that
the Glauber dynamics is nothing but one of many possible
ways to achieve the desired stationary distribution in (1) under
the independent set constraints, while its extensions lead to
more efﬁcient reversible Markov chains in the sense of Peskun
ordering (and efﬁciency ordering).
The generalized Glauber dynamics is summarized in Algorithm 2. This is achieved by judiciously employing a generalization of the procedures by Hastings [2] for constructing
a reversible Markov chain with a given, desired stationary
distribution, which was originally introduced for the development of an MCMC sampler. The details are omitted owing
to space constraints but can be found in [6]. As a special case,
if β = 0, then Algorithm 2 becomes identical to Algorithm 1 –
the original Glauber dynamics for the hard-core model. Also,
if β = 1, then it means that the Metropolis algorithm [10] is
applied properly for the hard-core model. The only difference
between the generalized Glauber dynamics with β ∈ (0, 1] and
the original Glauber dynamics (β = 0) is that for a randomly
chosen node v, if σu (t−1) = 0 for all u ∈ Nv , then σv (t) is
decided based on σv (t−1) for any β ∈ (0, 1], while σv (t) is
determined independently of σv (t−1) for β = 0. Note also that
the node-selection probability distribution {qv } in Algorithm 2
can be arbitrary as long as qv > 0 for all v and v∈N qv = 1.
For any given {qv }, let σ(t, β) be a conﬁguration at time
t by the generalized Glauber dynamics with β ∈ [0, 1]. One
can see that {σ(t, β)}t≥0 is a ﬁnite Markov chain with a
transition matrix Qβ = {Qβ (σ, σ ′ )}σ,σ′ ∈Ω . We say that the
Markov chain is ergodic if π(σ ′ ) = limt→∞ Qt (σ, σ ′ ), where
β
Qt (σ, σ ′ ) is the t-step transition probability from state σ
β
to state σ ′ . We then have the following properties of the
generalized Glauber dynamics.
Theorem 1: For any given {qv } and β ∈ [0, 1], the Markov
chain {σ(t, β)} with Qβ is ergodic and reversible with respect
to π in (1). In addition, for any given {qv } and 0 ≤ β1 ≤ β2 ≤
1, Qβ1 Qβ2 .
✷

(2)

which is independent of the distribution of the initial state
˜
˜
X(0) [13]. We similarly deﬁne ν(P, f ) for the chain {X(t)}
˜
with P. As mentioned before, the estimate µm based on
ˆ
any ﬁnite, irreducible Markov chain with the same π always
becomes µ, as m goes to inﬁnity. However, since the asymptotic variance decides approximately how many samples are
required to achieve a certain accuracy of the estimate µm ,‡ it
ˆ
has been an important criterion to rank the efﬁciency among
competing Markov chains with the same π, especially for
˜
the MCMC samplers [13], [11]. It is also said that {X(t)}
˜ f ) for
is at least as efﬁcient as {X(t)} if ν(P, f ) ≥ ν(P,
any f with VARπ (f ) < ∞ [11]. In particular, this efﬁciency
ordering is still in effect even when both chains are already
in their stationary regimes (already mixed). The efﬁciency
ordering will be the key component in the delay analysis later
in the paper. It is known that the Peskun ordering between
˜
two reversible P and P with the same π provides a sufﬁcient
condition for the efﬁciency ordering as follows.
˜
Lemma 1: [13] If P and P are reversible with respect to
˜ then ν(P, f ) ≥ ν(P, f ) for any f with
˜
π, and P
P,
VARπ (f ) < ∞.
✷
It is worth nothing that efﬁciency ordering does not imply
mixing time ordering in general, although there are related
with each other [11]. (See more review on mixing time, Peskun
ordering, and efﬁciency ordering in our technical report [6].)
‡ This is formally captured by the Central Limit Theorem for an ergodic,
√
ﬁnite Markov chain under VARπ (f ) < ∞, saying that m(ˆm − µ)
µ
converges to a Gaussian random variable with zero mean and variance ν(P, f )
as m → ∞ [5].

3

of ‘throughput-optimal’ algorithms with better queueing delay
performance as β increases, culminating in the ‘Metropolised’
version with β = 1. We also support our analytical ﬁndings
for the dynamic fugacity case through extensive simulations
under various network topologies and arrival rates.
Fix {qv } and β ∈[0, 1]. Since we are interested in the longterm behavior of the queueing delay performance, without loss
of generality, we can assume that the system is in its stationary
regime.§ Thus, the Markov chain {σ(t, β)}t≥0 is in the steadystate, i.e., P{σ(t, β) = σ} = π(σ) for all t ≥ 0. We consider
that a packet arrives in each node v at the beginning of each
time slot according to a stationary 0–1 process {Av (t)} with
rate µv in which Av (t) = 1 if there is a packet arrival to node
v with probability P{Av (t) = 1} = µv at time t, and Av (t) = 0,
otherwise.¶ On the other hand, whenever node v is available
for communication, i.e., σv (t) = 1, it transmits one packet
backlogged in its FIFO queue (if any) during time slot t. The
communication (or service) availability at node v is modeled
as a 0–1 valued process governed by the generalized Glauber
dynamics. That is,

Proof: See our technical report [6].
A. Throughput Optimality

While our focus in this paper is to analyze the performance
of each queue per node (in a conﬂict graph) when the
generalized Glauber dynamics comes into play for the problem
of optimal CSMA, we here brieﬂy explain the throughputoptimality of the generalized Glauber dynamics. Theorem 1
says that the stationary distribution π of the Markov chain
{σ(t, β)} is invariant with respect to β ∈ [0, 1] and {qv }.
Thus, if the fugacity of each node λv can be chosen so that
the long-term service rate (or capacity) at each queue is larger
than its packet arrival rate, which is the typical case for delay
analysis [3], [18], then ‘throughput-optimality’ or ‘per-node
stability’ is achieved irrespective of the choice of β ∈ [0, 1]
and {qv }. However, in reality, it may not be possible for each
node v to adjust its fugacity λv based on the measured arrival
and service rates. Hence, in the literature, the throughputoptimality has been deﬁned and shown under the following
setting, especially for the original Glauber dynamics (β = 0):
the fugacity is now a function of time t, which is given by
1 if node v is available for service, i.e., σv (t) = 1
λv (t) = exp(f (Wv (t))) where f is some weighted function Sv (t) =
0 otherwise
and Wv (t) is the queue-length at node v at time t.
= 1{σ(t,β) ∈ Bv }
(3)
Even in this dynamic fugacity set-up, one can establish the
throughput-optimality of the generalized Glauber dynamics for t = 0, 1, . . ., where B
{σ ∈ Ω : σv = 1} ⊆ Ω.
v
with any given β ∈ [0, 1] and {qv }. There are two different We deﬁne π
π(σ), the long-term proportion of
Bv
σ∈Bv
ways to prove the throughput-optimality in the literature. communication availability at node v or its ‘service rate’.
The ﬁrst (and most popular) way is based on the time-scale From the stationarity of the Markov chain {σ(t, β)}, we
decomposition under which the system quickly converges to its have P{S (t) = 1} = P{σ(t, β) ∈ B } = π
v
v
Bv for all t.
stationary regime before its dynamics changes (see, e.g., [4], Thus, {S (t)}
v
t≥0 is a stationary 0–1 process. Also, {Sv (t)}
[12]). Under this condition, Theorem 1 immediately implies is independent of {A (t)}. As mentioned before, we assume
v
that the generalized Glauber dynamics is throughput-optimal. that π > µ for all v ∈ N , ensuring that utilization is strictly
Bv
v
On the other hand, the second approach in [17] is done without less than one at each queue.
the time-scale decomposition when qv = 1/n for all v and
Without loss of generality, we below examine the queueing
β = 0, but by choosing a proper weighted function f such as delay at an arbitrarily chosen node v. From now on, our
f (·) = log log(·+ e), so that f (Wv (t)) changes much slower exposition will be all about the queue in node v. So, for the
than the system dynamics. The proof technique in [17] can sake of notational simplicity, we drop the subscript v and use
be similarly used to establish the throughput-optimality of the µ, A(t), S(t), B, and π instead of µ , A (t), S (t), B and
B
v
v
v
v
generalized Glauber dynamics. A rigorous treatment on the π , respectively, unless stated otherwise. We ﬁrst evaluate
Bv
throughput-optimality without the time-scale decomposition is the time interval between the two successive communication
another research topic beyond the scope of this paper.
availabilities at node v, which corresponds to the service time
of a single-server queueing model. To this end, we deﬁne
B. Delay Analysis
T1

While not much is known yet about the queueing delay
performance of optimal CSMA algorithms, we emphasize that
the time-varying behavior of λv (t) (in the dynamic fugacity
set-up) makes the analysis even more intractable. So, as used
in [3], [18], we here focus on the following case for delay
analysis: the fugacity of each node λv is given and ﬁxed, but
possibly heterogeneous over v ∈ N , such that the long-term
service rate at each queue is larger than its packet arrival rate.
We then demonstrate that higher efﬁciency in the extensions
of Glauber dynamics, the choices of β ∈ (0, 1], give rise
to better queueing delay performance, while maintaining the
same long-term throughput. Speciﬁcally, the original Glauber
dynamics with β = 0 in fact gives the worst queueing delay
performance, and there are inﬁnitely many different variants

min{t ≥ 0 : S(t) = 1}, Ti+1

min{t > Ti : S(t) = 1},

and τi
Ti+1 − Ti (i ≥ 1). Here, {τi }i≥1 are such time
intervals, all identically distributed from the stationarity of
S(t), and also called the recurrence times to the state 1 for
{S(t)}. Then, we have the following.
Theorem 2: For a given {qv }, E{τi } = 1/πB for all β, and
E{(τi )2 } is decreasing in β ∈ [0, 1].
✷
§ Any initial transient ﬂuctuation will disappear when computing steadystate metrics for queueing dynamics. For instance, the initial queue-length
doesn’t matter for the analysis of M/G/1 queue in the steady-state.
¶ We assume very general class of arrival processes {A (t)}, satisfying the
v
usual conditions for the large deviation (large buffer) asymptotic to hold [1].
Such processes include not only Bernoulli arrivals, but correlated arrivals such
as auto-regressive processes whose autocorrelation functions are summable.

4

Proof: See our technical report [6].
For a ﬁxed {qv }, the average recurrent time, E{τi }, remains
the same for all β due to the invariance property of π with
respect to β in Theorem 1, while the variance of the recurrence
time is decreasing in β. In the standard queueing literature, the
variance of the service time plays a major role in queueing
performance. For example, it is well-known that, for M/G/1
queue, the variance of the service time solely determines the
average queueing delay if the average service time is kept the
same. Similarly, even for G/G/1 queue, more ‘variable’ service
time leads to larger queueing delay [14]. However, our system
is far more complicated than these standard queueing systems;
the recurrence times {τi } can be possibly correlated over i for
|B| > 1, as the time instant Ti+1 depends on the conﬁguration
σ(Ti , β) ∈ B at time Ti . Such dependency, thus, makes the
exact analysis of queueing delay performance intractable.
Nonetheless, for a given {qv }, the ‘marginal’ distribution of
the service time τi has smaller variance as β increases (with
the same mean regardless of the choice of β), suggesting that
larger β would lead to better delay performance.
In addition, we demonstrate that the efﬁciency ordering of
Qβ for different β can still order the performance of queueing
dynamics by directly taking into account the dependency
structure in {τi } sequence. To proceed, let W (t) be the queue
length (or workload) at time t, satisfying Lindley recursion:
W (t+1) = max{0, W (t) + A(t+1) − S(t+1)}.

node needs to be an appropriate function of its (time-varying)
queue-length. Nonetheless, if the corresponding temporal dynamics is relatively slow or is in ‘almost-stationary’ regime,
from Theorems 2 and 3, we expect that the average queueing
delay per node decreases in β ∈ [0, 1] for a given {qv }, which is
also supported by simulation results. Due to space constraints,
all simulation results are omitted and can be found in [6].
V. C ONCLUSION
We took a different direction, instead of relying on asymptotic delay analysis prevalent in recent studies, to achieve
smaller delay in Glauber-dynamics based CSMA (or optimal
CSMA) for ﬁnite-sized networks. By carefully exploring all
possible variants of the traditional Glauber dynamics, we
proposed generalized Glauber dynamics with no additional
complexity, maintaining the same stationary distribution and
thus rendering the long-term optimality unchanged in the
context of scheduling. We then showed that our extensions
lead to better queueing delay performance, by directly taking
into account the second-order system behavior via a notion of
Peskun (or efﬁciency) ordering and large deviation techniques.
R EFERENCES
[1] P. W. Glynn and W. Whitt, “Logarithmic asymptotics for steady-state tail
probabilities in a single-server queue,” Journal of Applied Probability,
vol. 31, pp. 131–156, 1994.
[2] W. K. Hastings, “Monte Carlo sampling methods using markov chains
and their applications,” Biometrika, vol. 57, no. 1, pp. 97–109, 1970.
[3] L. Jiang, M. Leconte, J. Ni, R. Srikant, and J. Walrand, “Fast mixing
of parallel Glauber dynamics and low-delay CSMA scheduling,” in
Proceedings of IEEE Infocom, 2011.
[4] L. Jiang and J. Walrand, “A distributed CSMA algorithm for throughput
and utility maximization in wireless networks,” IEEE/ACM Transactions
on Networking, vol. 18, no. 3, pp. 960 –972, June 2010.
[5] G. L. Jones, “On the Markov chain central limit theorem,” Probability
Surveys, vol. 1, pp. 299–320, 2004.
[6] C.-H. Lee, D. Y. Eun, S.-Y. Yun, and Y. Yi, “From Glauber dynamics to
Metropolis algorithm: smaller delay in optimal CSMA,” North Carolina
State University, Tech. Rep., May 2012, available at http://www4.ncsu.
edu/∼dyeun/pub/techrep-csma12.pdf.
[7] D. A. Levin, Y. Peres, and E. L. Wilmer, Markov chains and mixing
times. American Mathematical Society, 2009.
[8] J. Liu, Y. Yi, A. Proutiere, M. Chiang, and H. V. Poor, “Towards utilityoptimal random access without message passing,” Wireless Communications and Mobile Computing, vol. 10, no. 1, pp. 115–128, Jan. 2010.
[9] M. Lotﬁnezhad and P. Marbach, “Throughput-optimal random access
with order-optimal delay,” in Proceedings of IEEE Infocom, 2011.
[10] N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth, A. H. Teller, and
E. Teller, “Equation of state calculations by fast computing machines,”
The Journal of Chemical Physics, vol. 21, no. 6, pp. 1087–1092, 1953.
[11] A. Mira, “Ordering and improving the performance of Monte Carlo
Markov chains,” Statistical Science, vol. 16, no. 4, pp. 340–350, 2001.
[12] J. Ni, B. Tan, and R. Srikant, “Q-csma: Queue-length based CSMA/CA
algorithms for achieving maximum throughput and low delay in wireless
networks,” in Proceedings of IEEE Infocom, 2010.
[13] P. H. Peskun, “Optimum Monte-Carlo sampling using Markov chains,”
Biometrika, vol. 60, pp. 607–612, 1973.
[14] S. M. Ross, Stochastic processes, 2nd ed. John Wiley & Son, 1996.
[15] D. Shah, D. N. C. Tse, and J. N. Tsitsiklis, “Hardness of low delay network scheduling,” IEEE Trans. on Information Theory, 2009, submitted.
[16] D. Shah and J. Shin, “Delay optimal queue-based CSMA,” in Proceedings of ACM Sigmetrics, 2010.
[17] J. Shin, D. Shah, and S. Rajagopalan, “Network adiabatic theorem: An
efﬁcient randomized protocol for contention resolution,” in Proceedings
of ACM Sigmetrics, 2009.
[18] V. Subramanian and M. Alanyali, “Delay performance of CSMA in
networks with bounded degree conﬂict graphs,” in IEEE ISIT, 2011.
[19] L. Tassiulas and A. Ephremides, “Stability properties of constrained
queueing systems and scheduling for maximum throughput in multihop
radio networks,” IEEE Transactions on Automatic Control, vol. 37,
no. 12, pp. 1936–1949, December 1992.
[20] Y. Yi and M. Chiang, Next-Generation Internet Architectures and
Protocols. Cambridge University Press, 2011, chapter 9: Stochastic
network utility maximization and wireless scheduling.

(4)

From the large deviation theory, in considerable generality,
the tail distribution of the steady-state queue length W is
asymptotically exponential [1] with the asymptotic decay rate
η given by
1
η = lim − log P{W > x} > 0.
(5)
x→∞
x
Let I(t) = A(t)−S(t) be the net input into the queue at time
t
t
t
t. Let It
i=1 I(i), At
i=1 A(i), and St
i=1 S(i).
Clearly, E{It } = E{At } − E{St } = t(µ − πB ) < 0. In this
setup, we have the following:
Theorem 3: Suppose that the distribution of It is Gaussian
for large t with limt→∞ VAR{At }/t = ν ∗ < ∞. Then, η in
(5) is increasing in β ∈ [0, 1].
✷
Proof: See our technical report [6].
t
Since It =
i=1 (A(i) − S(i)) is the sum of t random
variables, as long as their dependency over i is not so strong,
it is reasonable to assume that It is roughly Gaussian for large
t. Then, Theorem 3 tells us that larger β leads to faster decay
of the tail distribution of the steady-state queue-length, again
suggesting better queueing performance while preserving the
throughput-optimality. The Gaussian approximation and Theorem 3 are also corroborated by simulation results.
As mentioned before, it may not be possible for each node
v to choose its fugacity λv based on the measured arrival and
service rates for per-node stability. Instead, the fugacity of each
If |B| = 1, the exact analysis is possible, as {τi } forms an i.i.d. sequence
due to the strong Markov property. For example, if the arrival process is an
independent Bernoulli process, the system is simply the discrete-time case of
M/G/1 queue.

5

