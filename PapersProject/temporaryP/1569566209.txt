Creator:         TeX output 2012.05.16:0748
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Wed May 16 07:49:03 2012
ModDate:        Tue Jun 19 12:55:47 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      290996 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569566209

Worst-Case Expected-Rate Loss of Slow-Fading
Channels
Jae Won Yoo and Tie Liu

Shlomo Shamai (Shitz)

Dept. of Electrical and Computer Engineering
Texas A&M University
College Station, TX 77843, USA

Dept. of Electrical Engineering
Technion–Israel Institute of Technology
Haifa 32000, Israel

the power gains as a user in an L-parallel Gaussian broadcast
channel and coding over different sub-channels [5]. In the limit
as L → ∞, by the ergodicity of the power-gain process each
“typical” realization of the power gains can support a reliable
rate of communication which is arbitrarily close to

Abstract—For delay-limited communication over block-fading
channels, the difference between the ergodic capacity and the
maximum expected rate for coding over a ﬁnite number of
coherent blocks represents the penalty incurred by the delay
constraint. This paper introduces a notion of worst-case expectedrate loss. Focusing on the slow-fading scenario (one block delay),
the worst-case expected-rate loss is precisely characterized for
the point-to-point fading channel and is characterized to within
one bit for the fading-paper channel.

Cerg = EG [log(1 + G · SNR)] .

(2)

Thus, Cerg is both the Shannon capacity (usually known as
the ergodic capacity) and the maximum expected rate in the
limit as L → ∞.
As such, the difference between the ergodic capacity and
the maximum expected rate that can be achieved by coding
over L coherent blocks represents the penalty incurred by the
delay constraint of LTC . In this paper, we are interested in the
worst-case expected-rate loss, where the worst case is over all
transmit signal-to-noise ratio SNR and all possible power-gain
distribution FG (·) with a ﬁxed sample-space size K.

I. I NTRODUCTION
Consider the discrete-time baseband representation of the
single-user ﬂat-fading channel:
√
Y [m] = G[m]X[m] + Z[m]
(1)
where {X[m]} is the channel input which is subject to an
average power constraint SNR, {G[m]} are the power gains
which are unknown at the transmitter but known to the receiver,
{Z[m]} is the additive white circularly symmetric complex
Gaussian noise with zero mean and unit variance, and {Y [m]}
is the channel output. As often done in the literature, we shall
consider the so-called block-fading model, where {G[m]} are
assumed to be constant within each coherent block of length
Tc and change independently across different coherent blocks
according to a given distribution FG (·). The coherent time Tc
is assumed to be large so that the additive noise {Z[m]} can
be “averaged out” within each coherent block.
We shall focus on the delay-limited regime, where the block
length of communication T = LTc for some ﬁnite positive
integer L. In this case, Shannon capacity is a very pessimistic
measure, as it is dictated by the worst realization of the power
gains. An often-adopted measure in the literature is expected
rate [1], which is deﬁned as the expected reliably decoded rate
where the expectation is over the power-gain process.
The problem of characterizing the maximum expected rate
is closely related to the problem of broadcasting over Gaussian
channels. The case with L = 1 represents the most stringent
delay requirement and is usually known as slow fading. For
the slow-fading scenario, the problem of characterizing the
maximum expected rate is closely related to the problem of
scalar Gaussian broadcast channel. It is known [2] that the
broadcast strategy of sending a degraded message set [3],
[4] maximizes the expected rate. For L > 1, the maximum
expected rate can be improved by treating each realization of

II. P OINT- TO -P OINT FADING C HANNEL
A. Worst-case expected-rate loss
Consider the point-to-point fading channel (1), which can
be identiﬁed by the transmit signal-to-noise ratio SNR and
the power-gain distribution FG (·). Denote by Cerg (SNR, FG )
and Cexp (L, SNR, FG ) the ergodic capacity and the maximum
expected rate that can be achieved by coding over L coherent
blocks, respectively. We deﬁne the worst-case expected-rate
loss A(L, K) as
A(L, K) := sup [Cerg (SNR, FG ) − Cexp (L, SNR, FG )] (3)
where the supreme is over all SNR > 0 and all power-gain
distribution FG (·) with a ﬁxed sample-space size K.
B. Main result
The main result of this section is a precise characterization
of A(L, K) for L = 1 and arbitrary ﬁnite K, as summarized
in the following theorem.
Theorem 1. For any positive integer K,
A(1, K) = log K.

(4)

Note that the above result is very pessimistic, as the worstcase expected-rate loss grows unboundedly (albeit slowly) as
the number of different possible realizations of the power

1

gain in each coherent block K tends to inﬁnity. This is due
to the following two facts. First, the slow-fading scenario
that we consider here is subject to the most stringent delay
requirement. Hence, the pessimistic result here calls for the
need of coding over multiple coherent blocks should the delay
requirement allow. Second, here we consider the worst-case
scenario over all possible transmit signal-to-noise ratio and
all possible power-gain distribution. Note that for Raleigh
fading channels, the expected-rate loss is bounded regardless
of the transmit signal-to-noise ratio [4] even though the fading
distribution in this case is continuous. This example illustrates
the importance of considering the worst-case scenario, as the
result of a speciﬁc fading distribution may lead to unwarranted
optimism for other fading distributions.

Kuhn-Tucker (KKT) conditions are sufﬁcient and necessary:
Fk + µk − λ

(nl − nl−1 )2

∑K

∗
rj

(K
∑

=

0

(10)

=

0

(11)

= 0
≥ 0

(12)
(13)

µk ≥ 0
λ ≥ 0

λ

(14)
(15)

j=l

l=1

)

∑K

∗
j=l rj

(nl − nl−1 )2

− nK − SNR

l=1

∗
µk rk
∗
rk

for all k = 1, . . . , K. Note that if λ = 0, by the KKT condition
(10) we have µk = −Fk < 0, which contradicts the KKT
condition (14). Thus, λ must be strictly positive, and by the
KKT condition (11) we have

C. Sketched proof of the main result
Let {g1 , . . . , gK } be the collection of K different possible
realizations of the power gain in each coherent block and let
pk := Pr(G = gk ). Without loss of generality, we may assume
that
g1 > g2 > · · · > gK > 0.

k
∑

K
∑

∑K

(nl − nl−1 )2

j=l

∗
rj

− nK − SNR = 0.

(16)

l=1

(5)

˜
Further let Fk = Fk + µk . We can rewrite the KKT conditions
(10)–(15) as

The maximum expected rate of the block-fading channel (1)
for coding over one coherent block, Cexp (1, SNR, FG ), is
given by [3], [4]
(
)
∑K
1+βk g
Fk log 1+βk−1k SNR
max
k=1
gk SNR
(6)
subject to 0 = β0 ≤ β1 ≤ β2 ≤ · · · ≤ βK ≤ 1

˜
Fk − λ

k
∑

(nl − nl−1 )2

∑K

∗
rj

=

0

(17)

− nK − SNR =

0

(18)

0

(19)

≥ 0
˜k − Fk ≥ 0
F
λ > 0

(20)
(21)
(22)

j=l

l=1
K
∑

∑K

(nl − nl−1 )2

j=l

∗
rj

l=1

∑k
where Fk := j=1 pj .
Note that for the above optimization program, not only
the optimal solutions cannot be written in a closed-form, the
objective function is also non-convex with respect to the power
allocation vector (β1 , . . . , βK ). Following [6], we shall rewrite
the optimization program (6) using the rate vector (r1 , . . . , rK )
where
(
)
1 + βk gk SNR
rk := log
.
(7)
1 + βk−1 gk SNR

∗
˜
(Fk − Fk )rk

=

∗
rk

for all k = 1, . . . , K. It follows that the expected-rate loss
Cerg (SNR, FG ) − Cexp (1, SNR, FG )
K
K
∑
∑
∗
=
pk log(1 + gk SNR) −
Fk rk

Note that for any given nonnegative rate vector (r1 , . . . , rK ),
one can solve for a unique power allocation vector
(β1 , . . . , βK ) where
( k
)
∑k
∑
−1
rj
βk = SNR
(nl − nl−1 )e j=l − nk .
(8)

k=1

=

k=1

K
∑

K
∑

pk log(1 + gk SNR) −

k=1

=

l=1

k=1

K
∑

K
∑

k=1

nk := 1/gk for k = 1, . . . , K, and n0 := 0. Thus, the
optimization program (6) can be equivalently written as
∑K
max
Fk rk
∑K
∑k=1
K
j=l rj − n
(9)
subject to
K ≤ SNR
l=1 (nl − nl−1 )e
rk ≥ 0, ∀k = 1, . . . , K.

=

K
∑

pk log(1 + gk SNR) −

k=1





(23)

k
∑


∗
pj  rk

j=1

pk

K
∑

(24)


∗
rj 

(25)

j=k

(
)
∑K
∗
pk log (1 + gk SNR)e− j=k rj

(26)

k=1
∗
∗
for any rate vector (r1 , . . . , rK ) that satisﬁes the KKT conditions (17)–(22).
To show that A(1, K) ≤ log K, we shall need the following
proposition.

Unlike the original optimization program (6), the new
optimization program (9) is convex, so the following Karush-

2

∗
∗
Proposition 1. For any rate vector (r1 , . . . , rK ) that satisﬁes
the KKT conditions (17)–(22) and any k = 1, . . . , K,

(1 + gk SNR)e−

∑K
j=k

∗
rj

≤

1
.
pk

is assumed to be non-causally known at the transmitter but
not to the receiver. Note here that the instantaneous power
gain G[m] applies to both the channel input X[m] and the
known interference S[m], so the model is particularly relevant
to the problem of precoding for multiple-input multiple-output
fading broadcast channel.
As for the point-to-point fading channel (1), we are interested in characterizing the worst-case expected-rate loss for
the slow-fading scenario. However, unlike the point-to-point
fading channel (1), the ergodic capacity of the fading-paper
channel (33) is unknown. Below, we ﬁrst characterize the
ergodic capacity of the fading-paper model (33) to within in
one bit. As we will see, this will also lead to a characterization
of the worst-case expected-rate loss to within one bit for the
slow-fading scenario.

(27)

The proof of the above proposition is fairly lengthy (and
technical) and is omitted from the paper due to the space
limitation. By Proposition 1, for any SNR > 0 and any powergain distribution FG (·) with sample-space size K we have
Cerg (SNR, FG ) − Cexp (1, SNR, FG )
K
∑
1
pk log
= H(G) ≤ log K.
≤
pk

(28)

k=1

We thus conclude that A(1, K) ≤ log K for any positive
integer K.
To show that A(1, K) ≥ log K, let us ﬁx SNR and K and
consider the power-gain distribution FG (·) with pk = 1/K
∑K−k+1 j
(so Fk = k/K) and gk =
d for some d >
j=1
(K − 1)/SNR and k = 1, . . . , K. Consider the rate vector
∗
∗
(r1 , . . . , rK ) where

(
)
 log nk+1 −nk ,
k = 1, . . . , K − 1
∗
( nk −nk−1
)
(29)
rk =
nK +SNR
 log
, k = K.
K(nK −nK−1 )

A. Main results
fp
Denote by Cerg (SNR, INR, FG ) the ergodic capacity of the
fading-paper channel (33). We have the following theorem.

Theorem 2. For any transmit signal-to-noise ratio SNR, any
transmit interference-to-noise ratio INR, and any power-gain
distribution FG (·), we have
fp
Cerg (SNR, FG ) ≥ Cerg (SNR, INR, FG )
≥ Cerg (SNR, FG ) − log 2

∗
∗
It is straightforward to verify that (r1 , . . . , rK ) satisﬁes the
KKT conditions (17)–(22) with λ = d/(1 + d · SNR) and
˜
Fk = Fk for all k = 1, . . . , K. Further note that for any
k = 1, . . . , K,
∑K

(34)

where Cerg (SNR, FG ) is the ergodic capacity of the point-topoint fading channel (1).

∗

(1 + gk SNR)e− j=k rj
(
∑K−k+1 j ) K−k+3
d d
K 1 + SNR j=1
(∑
) (∑
)
=
K−k+1 j
K−k+2 j
(1 + d · SNR)
d
d
j=1
j=1
(
)
SNR · d2(K−k+2) + O d2(K−k)+3
(
)
= K·
SNR · d2(K−k+2) + O d2(K−k)+3

fp
Next, denote by Cexp (L, SNR, INR, FG ) the maximum
expected rate of the fading-paper channel (33) for coding over
L coherent blocks. We have the following theorem.

(30)

Theorem 3. For any transmit signal-to-noise ratio SNR, any
transmit interference-to-noise ratio INR, and any power-gain
distribution FG , we have

(31)

which tends to K in the limit as d → ∞. By (26),
Cerg (SNR, FG ) − Cexp (1, SNR, FG )
∑K
→ k=1 (1/K) log K = log K

fp
Cexp (1, SNR, INR, FG ) = Cexp (1, SNR, FG )

(32)

(35)

where Cexp (1, SNR, FG ) is the maximum expected rate of the
point-to-point fading channel (1) for coding over one coherent
block.

in the limit as d → ∞. This proves that A(1, K) ≥ log K.
Combining the facts that A(1, K) ≤ log K and A(1, K) ≥
log K completes the proof of Theorem 1.

Finally, let
[ fp
Af p (L, K) := sup Cerg (SNR, INR, FG )− ]
fp
Cexp (L, SNR, INR, FG )

III. W RITING ON FADING PAPER
Consider the problem of writing on fading paper [7]–[9]:
√
Y [m] = G[m] (X[m] + S[m]) + Z[m]
(33)

(36)

be the worst-case expected-rate loss of the fading-paper channel (33) for coding over L coherent blocks, where the supreme
is over all SNR > 0, all INR > 0, and all power-gain
distribution FG (·) with a ﬁxed sample-space size K. We have
the following theorem.

where {X[m]} is the channel input which is subject to an
average power constraint of SNR, {G[m]} are the power
gains which are unknown at the transmitter but known to the
receiver, {S[m]} and {Z[m]} are independent additive white
circularly symmetric complex Gaussian interference and noise
with zero means and variance INR and 1 respectively, and
{Y [m]} is the channel output. The interference signal {S[m]}

Theorem 4. For any positive integer K,
log K ≥ Af p (1, K) ≥ log(K/2).

3

(37)

B. Sketched proof of the main results

Codebook 1

+

= Cerg (SNR, FG ) − log 2.

Bin eLTc R

...

.
.
.
Bin eLTc R

is not always within one bit of Cerg (SNR, FG ). Next, motivated by the secure multicast code proposed in [12], we shall
consider a variable-rate coding scheme that takes advantage
of the block-fading feature to boost the the achievable ergodic
rate from (48) to (38).

(42)

Fix ϵ > 0 and let U be chosen as in (44). Consider
communicating a message W ∈ {1, . . . , eLTc R } over L
coherent blocks.

To prove the achievability of the ergodic rate (38), we shall
consider a communication scheme which is motivated by the
following thought process. Note that with ideal interleaving,
the block-fading channel (33) can be converted to a fastfading channel, where the power gains {G[m]} are independent across different time index m. Now that the channel is
memoryless, by the well-known result of Gel’fand and Pinsker
[10] the following ergodic rate is achievable:
[
]
√
R = max I(U ; G(X + S) + Z|G) − I(U ; S)
(43)

Codebook generation. Randomly generate L codebooks,
each for one coherent block and consisting of
eTc (LR+I(U ;S)+ϵ) codewords of length Tc . The codewords are
independently generated (across different codewords within
each codebook and across different codebooks) according
T
to the product distribution PU c . Randomly partition each
LTc R
codebook into e
bins, so each bin contains eTc (I(U ;S)+ϵ)
codewords. See Fig. 1 for an illustration of the codebook
structure.

(X,U )

where U is an auxiliary variable which must be independent
of (G, Z). An optimal choice of the input-auxiliary variable
pair (X, U ) is unknown [7], [8]. Motivated by the recent work
[11], let us consider the auxiliary variable

Encoding. Given the message W and the interference signal
{S[m]}, the encoder looks into the W th bin in each codebook
and tries to ﬁnd a codeword that is jointly typical with SlTc ,
where SlTc represents the interference signal {S[m]} within
the lth coherent block. By assumption, Tc is sufﬁciently large,
so with high probability such a codeword can be found in each
codebook. Denote by UlTc the codeword chosen from the lth
codebook. The transmit signal XlTc over the lth coherent block
is given by UlTc − SlTc .

(44)

where X is circularly symmetric complex Gaussian with zero
mean and variance SNR and is independent of S. For this
choice of the input-auxiliary variable pair (X, U ), we have
√
I(U ; G(X + S) + Z|G) − I(U ; S)
(45)

Decoding. Let Gl be the realization of the power gain during
√
the lth coherent block and let L := {l : I(U ; Gl (X +
S) + Z) − I(U ; S) ≥ 0}. Let C(L) be a codebook formed by
the union of eLTc R sub-codebooks, where sub-codebook i is
formed by the product of the ith bins over the coherent blocks
in L. Given the received signal {Y [m]}, the decoder looks
into C(L) and tries to ﬁnd a codeword that is jointly typical
with {Y [m]}. If such a codeword can be found, the estimated
ˆ
message W is given by the index of the sub-codebook that
contains the decoded codeword. Otherwise, a decoding error
is declared.

(46)
(47)

This proves that
+

.
.
.

Fig. 1. The codebook structure for achieving the ergodic rate (38). Each bin
in the codebooks contains eTc (I(U ;S)+ϵ) codewords.

(41)

R = (EG [log(G · SNR)])

Bin 2

(39)

≥ EG [log(1 + G · SNR)] − log 2

= EG [log(1 + G(SNR + INR))] −
(
)
SNR + INR
log
SNR
≥ EG [log(G · SNR)] .

Bin 2

Bin eLTc R

(40)

U =X +S

Bin 1

.
.
.

for every possible realization of G, we will have
fp
Cerg (SNR, INR, FG )
[
]
+
≥ EG (log(G · SNR))

Bin 1

Bin 2

is an achievable ergodic rate for the fading-paper channel (33),
where x+ := max(x, 0). Since
(log(G · SNR)) ≥ log(1 + G · SNR) − log 2

Codebook L

Bin 1

1) Proof of Theorem 2: To prove the ﬁrst inequality in
(34), let us assume that the interference signal {S[m]} is also
known at the receiver. When the receiver knows both the power
gain
√ G[m] and the interference signal S[m], it can subtract
G[m]S[m] from the received signal Y [m]. This will lead
to a “clean” point-to-point fading channel (1), whose ergodic
capacity is denoted by Cerg (SNR, FG ) and is an upper bound
fp
for Cerg (SNR, INR, FG ).
To prove the second inequality in (34), we shall show that
[
]
+
R = EG (log(G · SNR))
(38)

Codebook 2

(48)

is an achievable ergodic rate for the fading-paper channel (33).
Note that even though the achievable ergodic rate (48) is
independent of the transmit interference-to-noise ratio INR, it

Performance analysis. Note that the total number of code-

4

words in C(L) is given by
∏
eLTc R ·
eTc (I(U ;S)+ϵ)
l∈L

3) Proof of Theorem 4: Note that
Af p (1, K)
[ fp
]
= sup Cerg (SNR, INR, FG ) − Cexp (1, SNR, FG ) (58)
≤ sup [Cerg (SNR, FG ) − Cexp (1, SNR, FG )]
(59)

(49)

∑

= eTc (LR+ l∈L I(U ;S)+(|L|/Tc )ϵ)
∑
≤ eTc (LR+ l∈L I(U ;S)+ϵ/2) .

(50)

= A(1, K)
= log K

(51)

for sufﬁciently large Tc . Hence, the transmit message W
can be reliably communicated (with arbitrarily small error
probability for sufﬁciently large Tc ) as long as
∑
∑
√
ϵ
ϵ
I(U ; Gl (X +S)+Z)− (52)
I(U ; S)+ ≤
LR+
2
2

where (58) follows from (35), (59) follows from the ﬁrst
inequality in (34), and (61) follows from (4). On the other
hand, following (58) we have
Af p (1, K)

l∈L

l∈L

≥ sup [Cerg (SNR, FG ) − log 2 − Cexp (1, SNR, FG )] (62)
= A(1, K) − log 2
(63)
= log(K/2)
(64)

or equivalently
) ϵ
√
1 ∑(
R≤
I(U ; Gl (X + S) + Z) − I(U ; S) − .
L
L
l∈L
(53)
Further note that
)
√
1 ∑(
I(U ; Gl (X + S) + Z) − I(U ; S)
L

where (62) follows from the second inequality in (34), and
(64) follows from (4). Combining (61) and (64) completes the
proof of Theorem 4.
ACKNOWLEDGMENTS
This research was supported in part by the National Science
Foundation under Grant CCF-08-45848 and by the Philipson
Fund for Electrical Power, Technion Research Authority.

l∈L

L
)+
√
1 ∑(
I(U ; Gl (X + S) + Z) − I(U ; S)
=
L

≥

1
L

l=1
L
∑

(60)
(61)

(54)

R EFERENCES
+

(log(Gl · SNR)) .

(55)

[1] M. Effros and A. Goldsmith, “Capacity denitions and coding strategies
for general channels with receiver side information,” in Proc. IEEE Int.
Symp. Inf. Theory, Cambridge, MA, Aug. 1998, p. 39.
[2] S. Verd´ and S. Shamai (Shitz), “Variable-rate channel capacity,” IEEE
u
Trans. Inf. Theory, vol. 56, pp. 2651–2667, June 2010.
[3] S. Shamai (Shitz), “A broadcast strategy for the Gaussian slowly fading
channel,” in Proc. IEEE Int. Symp. Inf. Theory, Ulm, Germany, June–July
1997, p. 150.
[4] S. Shamai (Shitz) and A. Steiner, “A broadcast approach for a singleuser slowly fading MIMO channel,” IEEE Trans. Inf. Theory, vol. 49,
pp. 2617–2635, Oct. 2003.
[5] P. A. Whiting and E. M. Yeh, “Broadcasting over uncertain channels with
decoding delay constraints,” IEEE Trans. Inf. Theory, vol. 52, pp. 904–
921, Mar. 2006.
[6] D. N. C. Tse, “Optimal power allocation over parallel Gaussian broadcast
channels,” U.C. Berkeley Tech. Rep., UCB/ERL M99/7, 1999. Available
online at http://www.eecs.berkeley.edu/Pubs/TechRpts/1999/3578.html
[7] A. Bennatan and D. Burstein, “On the fading paper achievable region of
the fading MIMO broadcast channel,” IEEE Trans. Inf. Theory, vol. 54,
no. 1, pp. 100–115, Jan. 2008.
[8] W. Zhang, S. Kotagiri and J. N. Laneman, “Writing on dirty paper with
resizing and its application to quasi-static fading broadcast channels,” in
Proc. IEEE Int. Symp. Inf. Theory, Nice, France, June 2007, pp. 381–385.
[9] S. Borade and L. Zheng, “Writing on fading paper and causal transmitter
CSI,” in Proc. IEEE Int. Symp. Inf. Theory, Seattle, WA, July 2006,
pp. 744–748.
[10] S. I. Gelfand and M. S. Pinsker, “Coding for channel with random
parameters,” Probl. Contr. Inf. Theory, vol. 9, pp. 19–31, 1980.
[11] M. El-Halabi, T. Liu, C. Georghiades, and S. Shamai (Shitz), “Secret
writing on dirty paper: A deterministic view,” Preprint. Available online
at http://arxiv.org/abs/1101.1688
[12] A. Khisti, A. Tchamkerten, and G. W. Wornell, “Secure broadcasting
over fading channels,” IEEE Trans. Inf. Theory, vol. 54, pp. 2453–2469,
June 2008.

l=1

By the weak law of large numbers,
[
]
1∑
+
+
(log(Gl · SNR)) → EG (log(G · SNR))
L
L

(56)

l=1

in probability in the limit as L → ∞. We thus conclude that
(38) is an achievable ergodic rate for the fading-paper channel
(33). This completes the proof of Theorem 2.
2) Proof of Theorem 3: Consider the K-user memoryless
Gaussian broadcast channel:
Yk =

√

gk (X + S) + Zk ,

k = 1, . . . , K

(57)

where X is the channel input which is subject an average
power constraint, S and Zk are independent additive white
circularly symmetric complex Gaussian interference and noise,
and gk and Yk are the power gain and the channel output of
receiver k, respectively. The interference S is assumed to be
non-causally known at the transmitter but to the receivers.
Through successive precoding at the transmitter, it can be
shown that the degraded message set capacity region of this
channel is the same as if the interference S is also known at
the receivers. Based on this fact, it can be further shown that
the maximum expected-rate for coding over one block is the
same as if the interference S is also known at the receivers,
which is given by Cexp (1, SNR, FG ). The details of the proof
are omitted from the paper due to the space limitation.

5

