Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Fri May 18 17:05:06 2012
ModDate:        Tue Jun 19 12:54:43 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      410820 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569566939

Penalized Maximum Likelihood Methods
for Finite Memory Estimators
of Inﬁnite Memory Processes
Zsolt Talata
Department of Mathematics
University of Kansas
Lawrence, Kansas 66045–7523
Email: talata@math.ku.edu

error of the estimation of the parameters of the Markov chain
from a sample.
Model selection methods in various settings seek a tradeoff
between the bias and the variation. There are classical results
aiming at identifying the balance, see for instance the indices
of resolvability in the work by Barron [2], [3], [4].
In this paper, the order kn of the Markov estimator process is estimated from the sample. The penalized maximum
likelihood (PML) is a natural generalization of the Bayesian
information criterion, that is often regarded as an approximation of the criteria derived from the minimum description
length principle (see Section III for the formal deﬁnition).
For the order estimation, PML with general penalty term is
used. The resulted Markov estimator process ﬁnds a tradeoff
between the bias and the variation as it uses shorter memory
for faster memory decays of the process X. If the process X is
a Markov chain, the PML order estimation recovers its order
asymptotically with a wide range of penalty terms.
Not only an asymptotic rate of convergence result is obtained but also an explicit bound on the probability that the
¯
d-distance of the above Markov estimator from the process
X is greater than ε. It is assumed that the process X is nonnull, that is, the conditional probabilities of the symbols given
the pasts are separated from zero, and that the continuity rate
of the process X is summable and the restricted continuity
rate is uniformly convergent. These conditions are usually
assumed in this area [7], [12], [13], [16]. The summability
of the continuity rate implies that the process is isomorphic to
an i.i.d. process [5].
To provide additional insight into the asymptotics of Markov
order estimators, the notion of consistent Markov order estimation is generalized for inﬁnite memory processes. A Markov
order estimator is compared to its oracle version, which is
calculated based on the true distribution of the process instead
of the empirical distribution. The oracle concept is used in
various problems, see, e.g., [2], [6]. If the decay of the
continuity rate of the process is faster than exponential, the
ratio of the PML Markov order estimator with sufﬁciently
large penalty term to its oracle version is shown to converge
to 1 in probability.

Abstract—Stationary ergodic processes with ﬁnite alphabets
are estimated by ﬁnite memory processes from a sample, an
n-length realization of the process. Both the transition probabilities and the memory depth of the estimator process are
estimated from the sample using penalized maximum likelihood
(PML). Under some assumptions on the continuity rate and the
¯
assumption of non-nullness, a rate of convergence in d-distance is
obtained, with explicit constants. The results show an optimality
of the PML Markov order estimator for not necessarily ﬁnite
memory processes. Moreover, the notion of consistent Markov
order estimation is generalized for inﬁnite memory processes
using the concept of oracle order estimates, and generalized
consistency of the PML Markov order estimator is presented.

I. I NTRODUCTION
This paper is concerned with the problem of estimating
stationary ergodic processes with ﬁnite alphabet from a sample, an observed length n realization of the process, with
¯
the d-distance being considered between the process and the
¯
estimated one. The d-distance was introduced by Ornstein
[17] and became one of the most widely used metrics over
¯
stationary processes. Two stationary processes are close in ddistance if there is a joint distribution whose marginals are the
distributions of the processes such that the marginal processes
are close with high probability (see Section IV for the formal
¯
deﬁnition). The class of ergodic processes is d-closed and
¯
entropy is d-continuous, which properties do not hold for the
weak topology [22].
Ornstein and Weiss [18] proved that for stationary processes
isomorphic to i.i.d. processes, the empirical distribution of the
k(n)-length blocks is a strongly consistent estimator of the
¯
k(n)-length parts of the process in d-distance if and only if
k(n) ≤ (log n)/h, where h denotes the entropy of the process.
Csisz´ r and Talata [11] estimated the n-length part of a
a
stationary ergodic process X by a Markov process of order kn .
The transition probabilities of this Markov estimator process
are the empirical conditional probabilities, and the order kn →
+∞ does not depend on the sample. They obtained a rate of
¯
convergence of the Markov estimator to the process X in ddistance, which consists of two terms. The ﬁrst one is the
bias due to the error of the approximation of the process by
a Markov chain. The second term is the variation due to the

1

decreasing function of k, therefore its limit exists as k → +∞.
The entropy rate of the process is

II. I NFINITE M EMORY P ROCESSES
Let X = {Xi , −∞ < i < +∞} be a stationary ergodic stochastic process with ﬁnite alphabet A. We write
j
Xi = Xi , . . . , Xj and xj = xi , . . . , xj ∈ Aj−i+1 for
i
j ≥ i. If j < i, xj is the empty string. For two strings
i
j
j
xi ∈ Ai and y1 ∈ Aj , xi y1 denotes their concatenation
1
1
i+j
x1 , . . . , xi , y1 , . . . , yj ∈ A . Write

1
¯
H = lim hk = lim
Hk .
k→+∞
k→+∞ k
¯
Note that hk − H ≥ 0 for any k ≥ 0.
The process X is a Markov chain of order k if for each
n > k and xn ∈ An
1

j
P (xj ) = Pr(Xi = xj )
i
i

P (x−1 )
−m

and, if

n

> 0,

where P (xk ) is called initial distribution and
1
P (a|ak ), a ∈ A, ak ∈ Ak is called transition probability
1
1
matrix. The case k = 0 corresponds to i.i.d. processes. The
process X is of inﬁnite memory if it is not a Markov chain
for any order k < +∞. For inﬁnite memory processes,
¯
hk − H > 0 for any k ≥ 0.
In this paper, we consider statistical estimates based on
n
a sample X1 , an n-length part of the process. Let Nn (ak )
1
denote the number of occurrences of the string ak in the
1
n
sample X1

For m = 0, P (a|x−1 ) = P (a).
−m
The process X is called non-null if
pinf = min

inf

a∈A x−1 ∈A∞
−∞

P (a|x−1 ) > 0.
−∞

The continuity rate of the process X is
P (a|x−1 ) − P (a|x−1 ) .
−∞
−k

sup
x−1 ∈A∞ a∈A
−∞

∞

If
k=1 γ(k) < +∞, then the process X is said to have
summable continuity rate.
x−1
−k

Remark 1. Since for any
m ≥ k,

k

∈ A and

−k−1
z−m

∈ A

m−k

Nn (ak ) =
1

,

and the empirical conditional probability of a ∈ A given ak
1
is
k+1
Nn (a1 )
ˆ
.
P (ak+1 | ak ) =
1
Nn−1 (ak )
1

the above deﬁnition of continuity rate is equivalent to
i>k x−i

∈Ai

P (a|x−1 ) − P (a|x−1 ) .
−i
−k
a∈A

The restricted continuity rate of the process X is
γ(k|m) =

P (a|x−1 ) − P (a|x−1 ) ,
−m
−k

max

x−1 ∈Am
−m

ˆ
ˆ
For k = 0, P (ak+1 | ak ) = P (ak+1 ). The k-order empirical
1
entropy is

k < m.

n
ˆ
Hk (X1 ) = −

a∈A

Similarly to Remark 1, note that the above deﬁnition is
equivalent to
γ(k|m) = max

k<i≤m x

max
−1

−i ∈A

i

n
ˆ
hk (X1 ) = −

a∈A

0 ≤ k ≤ n − 1.
III. P ENALIZED M AXIMUM L IKELIHOOD

The k-order entropy of the process X is

An information criterion assigns a score to each hypothetical
model (here, Markov chain order) based on a sample, and the
estimator will be that model whose score is minimal.

k ≥ 1,

ak ∈Ak
1

Deﬁnition 2. For an information criterion

and the k-order conditional entropy is
P (ak+1 ) log P (ak+1 |ak ),
1
1

ˆ
ˆ
P (ak+1 ) log P (ak+1 | ak ),
1
1
ak+1 ∈Ak+1
1

γ(k)θ1 ≤ γ(k | θ2 k ) if k ≥ kθ , for some θ1 ≥ 1, θ2 > 1.

hk = −

1 ≤ k ≤ n,

and the k-order empirical conditional entropy is

P (a|x−1 ) − P (a|x−1 ) .
−i
−k

P (ak ) log P (ak ),
1
1

ˆ 1
ˆ 1
P (ak ) log P (ak ),
ak ∈Ak
1

Hence, limm→+∞ γ(k|m) = γ(k) for any ﬁxed k. We say that
the process X has uniformly convergent restricted continuity
rate with parameters θ1 , θ2 , kθ if

Hk = −

.

Nn (ak )
1
ˆ
P (ak ) =
1
n−k+1

−k−1
x−∞

γ(k) = sup −1
max

i+k
i : Xi+1 = ak , 0 ≤ i ≤ n − k
1

For k ≥ 1, the empirical probability of the string ak is
1

−k−1
inf P (a|x−1 ) ≤ P (a|z−m x−1 ) ≤ sup P (a|x−1 ),
−∞
−∞
−k

x−k−1
−∞

(1)

i=k+1

−1
P (a|x−1 ) = Pr(X0 = a | X−m = x−1 ).
−m
−m

γ(k) =

P (xi |xi−1 ),
i−k

P (xn ) = P (xk )
1
1

n
ICX1 ( · ) : N → R+ ,

k ≥ 0.

the Markov order estimator bounded by rn < n, rn ∈ N, is

ak+1 ∈Ak+1
1

Logarithms are to the base 2. It is well-known for stationary
processes that the conditional entropy hk is a non-negative

n
ˆ
n
kIC (X1 | rn ) = arg min ICX1 (k).
0≤k≤rn

2

Remark 3. Here, the number of candidate Markov chain
orders based on a sample is ﬁnite, therefore the minimum is
attained. If the minimizer is not unique, the smallest one will
be taken as arg min.

IV. S TATISTICAL E STIMATION OF P ROCESSES
The problem of statistical estimation of stationary ergodic
processes by ﬁnite memory processes is considered, and the
following distance is used. The per-letter Hamming distance
n
between two strings xn and y1 is
1

A popular approach to choosing information criteria is the
minimum description length (MDL) principle [19], [4]. In
particular, the normalized maximum likelihood (NML) [23]
and the Krichevsky–Troﬁmov (KT) [15] code lengths are
natural information criteria because the former minimizes the
worst case maximum redundancy for the model class of korder Markov chains, while the latter does so, up to an additive
constant, with the average redundancy. The Bayesian information criterion (BIC) [20] can be regarded as an approximation
of the NML and KT code lengths. The family of penalized
maximum likelihood (PML) is a generalization of BIC.
n
The likelihood of the sample X1 with respect to a korder Markov chain model of the process X with some transition probability matrix Q(ak+1 |ak ), ak+1 ∈ A, ak ∈ Ak ,
1
1
by (1), is
Q(ak+1 | ak )
1

n
k
P (X1 ) = P (X1 )

Nn (ak+1 )
1

n
dn (xn , y1 ) =
1

if a = b
if a = b,

n
¯
and the d-distance between two random sequences X1 and
n
Y1 is deﬁned by

¯ n
˜n ˜
d(X1 , Y1n ) = min EP dn (X1 , Y1n ),
P

.

where the minimum is taken over all the joint distributions P
˜n
˜
of X1 and Y1n whose marginals are equal to the distributions
n
of X1 and Y1n .
The process X is estimated by a Markov chain of order
k = kn from the sample in the following way.

k+1
ˆ
P (ak+1 | ak )Nn (a1 ) .
1

Deﬁnition 6. The empirical k-order Markov estimator of
n
a process X based on the sample X1 is the stationary
ˆ
Markov chain, denoted by X[k], of order k with transition
ˆ
probability matrix P (ak+1 | ak ), ak+1 ∈ A, ak ∈ Ak . If the
1
1
initial distribution of a stationary Markov chain with these
transition probabilities is not unique, then any of these initial
distributions can be taken.

ak+1 ∈Ak+1
1
n
n
ˆ
Note that log MLk (X1 ) = −(n − k)hk (X1 ).

Deﬁnition 4. Given a penalty function pen(n), a nondecreasing function of the sample size n, for a candidate order
0 ≤ k < n the PML criterion is

=

I(xi = yi )
i=1

1
0

I(a = b) =

For 0 ≤ k < n, the maximum likelihood is the maximum in
Q(ak+1 |ak ) of the second factor above, which equals
1

n
PMLX1 (k) =

n

where

ak+1 ∈Ak+1
1

n
MLk (X1 ) =

1
n

ˆ
The order k of the empirical Markov estimator X[k] is
estimated from the sample, using the PML criterion. The
estimated order needs to be bounded to guarantee an accurate
assessment of the memory decay of the process.
The optimal order can be smaller than the upper bound if
the memory decay of the process is sufﬁciently fast. Deﬁne

n
− log MLk (X1 ) + (|A| − 1)|A|k pen(n)
n
ˆ
(n − k) hk (X1 ) + (|A| − 1)|A|k pen(n).

The k-order Markov chain model of the process
X is described by the conditional probabilities
Q(ak+1 |ak ), ak+1 ∈ A, ak ∈ Ak , and (|A| − 1)|A|k
1
1
of these are free parameters.
The second term of the PML criterion, which is proportional
to the number of free parameters of the k-order Markov chain
model, is increasing in k. The ﬁrst term, for a given sample, is
known to be decreasing in k. Hence, minimizing the criterion
yields a tradeoff between the goodness of ﬁt of the sample to
the model and the complexity of the model.

Kn (rn , γ, f (n)) = min { rn , k ≥ 0 : γ(k) < f (n)} ,
where f (n)
0 and rn
∞. Since γ is a decreasing
function, Kn increases in n but does not exceed rn . It is less
than rn if γ vanishes sufﬁciently fast, and then the faster γ
vanishes, the slower Kn increases.
The process estimation result of the paper is the following.

Remark 5. If pen(n) = 1 log n, the PML criterion is called
2
Bayesian information criterion (BIC), and if pen(n) = 1,
Akaike information criterion (AIC) [1].

Theorem 7. For any non-null stationary ergodic process with
summable continuity rate and uniformly convergent restricted
continuity rate with parameters θ1 , θ2 , kθ , and for any µn > 0,
the empirical Markov estimator of the process with the order
ˆ
estimated by the bounded PML Markov order estimator kn =
√
1
n
ˆ
kPML (X1 | η log n), η > 0, with 2 log n ≤ pen(n) ≤ O( n)

3

bias term is smaller as well. The result, however, shows the
optimality of the PML Markov order estimator in the sense
that it selects an order which is small enough to allow the
variance to decrease but large enough to keep the bias below
a polynomial threshold.

satisﬁes
n ˆ ˆ
¯
Pr d X1 , X[kn ]n
1

>

β2
max γ
p2
inf
+

η
θ2

log n

,n

1
− 4θ

1−4η log

1

|A|4
pinf

1
n1/2−µn

V. D IVERGENCE OF M ARKOV O RDER E STIMATORS

≤ exp −c4 4µn log n−| log pinf | (Kn (η log n,γ, n pen(n))+
c

+ exp −

c5 η 3 η 2 log |A|
n
log n

log log n
log |A|

The BIC Markov order estimator is strongly consistent [8],
that is, if the process is a Markov chain of order k, then
n
ˆ
kBIC (X1 ) = k eventually almost surely as n → +∞. Increasing the penalty term, up to cn, where c > 0 is a sufﬁciently
small constant, does not affect the strong consistency. It is not
known whether or not the strong consistency holds for smaller
penalty terms but it is known that if the candidate orders are
upper bounded by c log n, where c > 0 is a sufﬁciently small
constant, that is, the estimator minimizes the PML over the
orders 0 ≤ k ≤ c log n only, then pen(n) = C log log n still
provides the strong consistency, where C > 0 is a sufﬁciently
large constant [14].
The NML and KT Markov order estimators fail to be
strongly consistent because for i.i.d. processes with uniform
distribution, they converge to inﬁnity at a rate O(log n)
[8]. However, if the candidate orders are upper bounded by
o(log n), the strong consistency holds true [9].
If the process is of inﬁnite memory, the BIC and KT Markov
order estimators diverge to inﬁnity [10], [26]. In [24], results
on the divergence rate of the PML, NML and KT Markov
order estimators are presented. Bounds on the probability that
the estimators are greater and less, respectively, than some
order are obtained, with explicit constants. The ﬁrst implies
that under mild conditions, the estimators do not exceed
the O(log n) rate eventually almost surely as n → +∞.
The second bound implies that the rate O(log n) is attained
eventually almost surely as n → +∞ for the processes whose
continuity rates decay in some exponential range.
In this section, the notion of consistent Markov order
estimation is generalized for inﬁnite memory processes. If
the continuity rates decay faster than exponential, the PML
Markov order estimator is shown to be consistent with the
oracle-type order estimate.
In the previous section, non-nullness is assumed for the
process. In this section the process X is assumed to be only
weakly non-null, that is,

)

+ 2−sn pen(n)

if n ≥ n0 , where c > 0 is an arbitrary constant, sn → ∞
and β2 , c4 , c5 , n0 > 0 are constants depending only on the
distribution of the process.
Remark 8. If the process X is a Markov chain of order k,
then the restricted continuity rate is uniformly convergent with
parameters θ1 = 1, θ2 > 1 arbitrary (arbitrarily close to 1),
kθ = k + 1, and if n is sufﬁciently large, Kn = k and
max γ
=n

1
− 4θ

1

η
θ2

log n

1−4η log

|A|4
pinf

,n

1
− 4θ

1

1−4η log

|A|4
pinf

.

An application of the Borel–Cantelli lemma in Theorem 7
yields the following asymptotic result.
Corollary 9. For any non-null stationary ergodic process with
summable continuity rate and uniformly convergent restricted
continuity rate with parameters θ1 , θ2 , kθ , the empirical
Markov estimator of the process with the order estimated by
n
ˆ
ˆ
the bounded PML Markov order estimator kn = kPML (X1 | rn )
√
1
with 2 log n ≤ pen(n) ≤ O( n) and
5 log log n
≤ rn ≤ o(log n)
2 log |A|
satisﬁes
1
β2
n ˆ ˆ
¯
d X1 , X[kn ]n ≤ 2 max γ rn , n− 4θ1
1
θ2
pinf
c
(log n)c6 | log pinf |Kn (rn ,γ, n pen(n))
2
+ √
n

eventually almost surely as n → +∞, where c > 0 is an
arbitrary constant, and β2 , c6 > 0 are constants depending
only on the distribution of the process.

inf

a∈A

Remark 10. In Corollary 9, in the upper bound the ﬁrst term
is the bias due to the error of the approximation of the process
by a Markov chain. The second term is the variation due to
the error of the estimation of the order and the parameters of
the Markov chain based on a sample. If the memory decay of
the process is slow, the bias is essentially γ( rn /θ2 ), and the
variance is maximal. If the memory decay is sufﬁciently fast,
ˆ
then the rate of the estimated order kn and the rate of Kn
are smaller, therefore the variance term is smaller while the

x−1 ∈A∞
−∞

P (a|x−1 ) > 0.
−∞

Moreover, the PML Markov order estimator does not need to
be bounded. Therefore, let
n
n
ˆ
ˆ
kPML (X1 ) = kPML (X1 | n − 1).

Deﬁnition 11. For a candidate order 0 ≤ k < n the oracle
PML criterion is
PMLo,n (k) = (n − k) hk + (|A| − 1)|A|k pen(n),

4

ACKNOWLEDGMENT

and the oracle PML Markov order estimator is

In this research, Talata is supported by the NSF grant DMS
0906929.
R EFERENCES

kPML,n = arg min PMLo,n (k) .
0≤k<n

Remark 12. For Markov chains of order k, kPML,n = k if n
is sufﬁciently large, with any pen(n) = o(n).

[1] H. Akaike, “Information theory and an extension of the maximum likelihood principle,” 2nd International Symposium on Information Theory,
(Tsahkadsor, 1971), pp. 267–281, Akad´ mia Kiad´ , Budapest, 1972.
e
o
[2] A. R. Barron, L. Birg´ and P. Massart, “Risk bounds for model selection
e
via penalization,” Probab. Theory Related Fields, vol. 113, no. 3, pp. 301–
413, 1999.
[3] A. R. Barron, T. M. Cover, “Minimum complexity density estimation,”
IEEE Trans. Inform. Theory, vol. 37, pp. 1034–1054, Jul. 1991.
[4] A. R. Barron, J. Rissanen, and B. Yu, “The minimum description length
principle in coding and modeling,” IEEE Trans. Inform. Theory, vol. 44,
pp. 2743–2760, Oct. 1998.
[5] H. Berbee, “Chains with inﬁnite connections: uniqueness and Markov
representation,” Probab. Theory Related Fields, vol. 76, no. 2, pp. 243–
253, 1987.
[6] L. Birg´
e and P. Massart, “Gaussian model selection,”
J. Eur. Math. Soc. (JEMS), vol. 3, no. 3, pp. 203–268, 2001.
¯
[7] X. Bressaud, R. Fernandez, and A. Galves, “Speed of d-convergence for
Markov approximations of chains with complete connections. A coupling
approach,” Stochastic Process. Appl., vol. 83, pp. 127–138, 1999.
[8] I. Csisz´ r and P. C. Shields, “The consistency of the BIC Markov order
a
estimator,” Ann. Statist., vol. 28, pp. 1601–1619, 2000.
[9] I. Csisz´ r, “Large-scale typicality of Markov sample paths and consistency
a
of MDL order estimators,” IEEE Trans. Inform. Theory, vol. 48, pp. 1616–
1628, Jun. 2002.
[10] I. Csisz´ r and Zs. Talata, “Context tree estimation for not necessarily
a
ﬁnite memory processes, via BIC and MDL,” IEEE Trans. Inform. Theory,
vol. 52, pp. 1007–1016, 2006.
[11] I. Csisz´ r and Zs. Talata, “On Rate of Convergence of Statistical
a
Estimation of Stationary Ergodic Processes,” IEEE Trans. Inform. Theory,
vol. 56, pp. 3637–3641, 2010.
[12] D. Duarte, A. Galves, and N. Garcia, “Markov approximation
and consistent estimation of unbounded probabilistic sufﬁx trees,”
Bull. Braz. Math. Soc, New Series, vol. 37, no. 4, pp. 581–592, 2006.
[13] R. Fern´ ndez and A. Galves, “Markov Approximations of Chains of
a
Inﬁnite Order,” Bull. Braz. Math. Soc, New Series, vol. 33, pp. 295–306,
2002.
[14] R. van Handel, “On the minimal penalty for Markov order estimation,”
Probab. Th. Rel. Fields, vol. 150, pp. 709–738, 2011.
[15] R. E. Krichevsky and V. K. Troﬁmov, “The performance of universal
encoding,” IEEE Trans. Inform. Theory, vol. 27, pp. 199–207, Mar. 1981.
[16] K. Marton, “Measure Concentration for a Class of Random Processes,”
Probab. Theory Relat. Fields, vol. 110, pp. 427–439, 1998.
[17] D. S. Ornstein, “An Application of Ergodic Theory to Probability
Theory,” Ann. Probab. vol. 1, no. 1, pp. 43–58, 1973.
[18] D. S. Ornstein and B. Weiss, “How sampling reveals a process,”
Ann. Probab. vol. 18, no. 3, pp. 905–930, 1990.
[19] J. Rissanen, Stochastic Complexity in Statistical Inquiry. Singapore:
World Scientiﬁc, 1989.
[20] G. Schwarz, “Estimating the dimension of a model,” Ann. Statist., vol. 6,
pp. 461–464, 1978.
[21] R. Shibata, “Asymptotically efﬁcient selection of the order of the model
for estimating parameters of a linear process,” Ann. Statist., vol. 8,
pp. 147–164, 1980.
[22] P. Shields, The ergodic theory of discrete sample paths. Providence, RI:
American Mathematical Society, 1996.
[23] J. Shtarkov, “Coding of discrete sources with unknown statistics,” in
Topics in information theory (Second Colloq., Keszthely, 1975), pp. 559–
574. Colloq. Math. Soc. J´ nos B´ lyai, vol. 16, North-Holland, Amstera
o
dam, 1977.
[24] Zs. Talata, “Divergence of information-criterion based Markov order
estimators for inﬁnite memory processes,” IEEE Intl. Symposium on
Inform. Theory, pp. 1378–1382, 2010.
[25] Zs. Talata, “Divergence Rates of Markov Order Estimators and Their
Application to Statistical Estimation of Stationary Ergodic Processes,”
manuscript.
[26] Zs. Talata and T.E. Duncan, “BIC context tree estimation for stationary
ergodic processes,” IEEE Trans. Inform. Theory, vol. 57, pp. 3877–3886,
2011.

The consistency result of the paper is the following.
Theorem 13. For any weakly non-null stationary ergodic
process with
log γ(k)
→ −∞,
k

k → ∞,

n
ˆ
the PML Markov order estimator kPML (X1 ) with pen(n) =
κ 1
n , 2 < κ < 1, is consistent in the sense that
n
ˆ
kPML (X1 )
→1
kPML,n

in probability as n → +∞.
VI. P ROOF I DEAS
The proof of Theorem 7, the process estimation result,
relies on two bounds. First, an upper bound on the probability
that the bounded PML Markov order estimator is less than
some order is derived using non-nullness, summability of the
continuity rate and uniform convergence of the restricted continuity rate. Then, for any non-null stationary ergodic process,
an upper bound on the probability that the bounded PML
Markov order estimator is greater than some order is derived
using the relationship between the maximum likelihood and
the Krichevsky–Troﬁmov distribution. The proof is completed
by the result established in [11].
The proof of Theorem 13, the consistency result, is based
on the following observation. As the order of the estimator
process increases, a penalty term growing sufﬁciently fast can
control the increasing variance to prevent overestimation. On
the other hand, a large penalty term requires fast decay of the
continuity rate to prevent underestimation.
The proofs provide explicit constants in all bounds. The full
proofs can be found in [25].
VII. D ISCUSSION
In this paper, stationary ergodic processes have been estimated by ﬁnite memory processes from a sample, where
the memory depth of the estimator process is also estimated
from the sample using PML. Under some assumptions on
¯
the process, a rate of convergence in d-distance has been
obtained. The results show an optimality of the PML Markov
order estimator for not necessarily ﬁnite memory processes.
Moreover, the PML Markov order estimator has been shown
to be consistent with the oracle-type order estimate under some
assumptions on the process. Notice that the consistency result
requires larger penalty terms for PML than the process estimation result. This reﬂects the expectation that the estimation
of the structure parameter needs larger penalty terms than the
estimation of the sampling distribution; see, for example, [21]
and [20].

5

