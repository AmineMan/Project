Title:          PoltyrevExpurgation.pdf
Subject:        
Keywords:       
Author:         Amir
Creator:        PDFCreator Version 0.9.8
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Thu May 17 15:31:19 2012
ModDate:        Tue Jun 19 12:54:12 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      595 x 842 pts (A4)
File size:      344340 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569566901

Expurgated Inﬁnite Constellations at Finite Dimensions
Amir Ingber

Ram Zamir

Dept. of Electrical Engineering,
Stanford University
ingber@stanford.edu

Dept. of EE-Systems,
Tel Aviv University
zamir@eng.tau.ac.il

to Gallager’s error exponents in the classical channel coding
setting [5], and to the error exponents of the power-constrained
AWGN channel [6], [5]. Recently, Poltyrev’s setting was
revisited with an emphasis on ﬁnite-dimensions [7], where
explicit bounds (both upper and lower) on the error probability
were derived. Those bounds can be used to derive reﬁnements
for the random coding and sphere packing error exponents
for the setting, as well as to derive a channel dispersion result
[7][8]. The main interest and strongest results of [7] are above
the critical NLD δcr which plays the same role of the critical
rate in classic channel coding [5].
In this paper we consider the expurgation technique as a tool
to obtain achievability bounds for low NLD values, namely below the rate termed δex [4], a rate below which the expurgation
technique gives a better error exponent than the random coding
technique. We particularize the expurgation technique for ﬁnite
dimensions and obtain an achievability bound that is explicit
for any dimension n (where the expurgation exponent is only
an asymptotic result). For ﬁnite dimensions, we demonstrate
numerically that the expurgation technique improves upon the
random coding technique also for rates that are above δex
(and not only below δex , as in the error exponent case). In
addition, the bound is evaluated asymptotically (for ﬁxed δ),
and the exponential form of the bound is re-derived. We also
ﬁnd the sub-exponential terms in the approximation, and it
turns out that they are polynomial, with degree that depends
on the distance from capacity.

Abstract—We revisit the setting of a Gaussian channel without
power constraints, proposed by Poltyrev, where the codewords
are points in Euclidean space and their density is considered
instead of the communication rate. We reﬁne the expurgation
technique (proposed by Poltyrev for the derivation of the error
exponent) to the ﬁnite dimensions case and obtain a ﬁnitedimensional achievability bound. While the expurgation exponent
improves upon the random coding exponent only for certain rates
(below a rate known as δex ), we show that for ﬁnite dimensions
the expurgation technique is useful for a broader range of rates.
In addition, we present precise asymptotical analysis of the
expurgation bound and ﬁnd the sub-exponential terms, which
turn out to be non-negligible.

I. I NTRODUCTION
Communication schemes over the Gaussian channel are
traditionally limited by the power of the transmitted signal
[1], as without such limitation the channel capacity becomes
inﬁnite, since one can space the codewords arbitrarily far apart
from each other and achieve a vanishing error probability.
However, many coded modulation schemes take an inﬁnite
constellation (IC) and restrict the usage to points of the IC that
lie within some n-dimensional ’shaping’. A main example for
an IC is a lattice [2], and examples for the shaping regions
include a hypersphere in n dimensions, and a Voronoi region
of another lattice [3].
In 1994, Poltyrev [4] studied the model of a channel
with Gaussian noise without power constraints, where the
codewords are simply points in the n-dimensional Euclidean
space. The analog to the number of codewords is the density
γ of the constellation points (the average number of points per
unit volume) and the analog of the communication rate is the
1
normalized log density (NLD) δ
n log γ (since rate cannot
be deﬁned here in its usual meaning as the log of the number of
codewords per dimension). The error probability in this setting
can be thought of as the average error probability, where
all the points of the IC have equal transmission probability.
Poltyrev showed that the NLD δ is the analog of the rate in
classical channel coding, and established the analog term to
the capacity, the highest achievable NLD for coding on the unconstrained Gaussian channel with vanishing error probability,
denoted δ ∗ . Random coding, sphere packing and expurgation
error exponent bounds were also derived, which are analogous

II. BACKGROUND
A. Notation
We adopt most of the notations of Poltyrev’s paper [4]: Let
Cb(a) denote a hypercube in Rn :
Cb(a)

x ∈ Rn s.t. ∀i |xi | <

a
.
2

(1)

Let Ball(y, r) denote a hypersphere in Rn and radius r > 0,
centered at y ∈ Rn :
Ball(y, r)

{x ∈ Rn s.t. x − y < r},
n/2

(2)

π
and let Ball(r) denote Ball(0, r). Vn
Γ(n/2+1) denotes the
volume of an n dimensional hypersphere with radius 1 [2].
Let S be an IC. We denote by M (S, a) the number of points
in the intersection of Cb(a) and the IC S, i.e. M (S, a)

This work was supported in part by the NSF Center for Science of
Information.

1

|S Cb(a) |. The density of S, denoted by γ(S), or simply
γ, measured in points per volume unit, is deﬁned by
γ(S)

lim sup
a→∞

M (S, a)
.
an

bounds are available. In his paper [4], Poltyrev showed that
the following exponent is achievable:
 1 2(δ∗ −δ)
,
δ ≤ δex ;
 8e
e
δ ∗ − δ + 1 log 4 ,
δex < δ ≤ δcr ;
EU (δ) =
 1 2(δ∗ −δ) 2 1
− 2 − δ ∗ + δ, δcr < δ ≤ δ ∗ ,
2e
(10)
where

(3)

The normalized log density (NLD) δ is deﬁned by1
1
log γ.
(4)
n
It will prove useful to deﬁne the following:
Deﬁnition 1 (Expectation over a hypercube): Let f : S →
R be an arbitrary function. Let Ea [f (s)] denote the expectation
of f (s), where s is drawn uniformly from the code points that
reside in the hypercube Cb(a):
δ

Ea [f (s)]

1
M (S, a)

f (s).

δex = δ ∗ − log 2,
δcr = δ ∗ −

(5)

s∈S∩Cb(a)

sup Pe (s),

C. The MHS ensemble
The MHS theorem states that there exists a random ensemble of lattices with density γ, denoted L, with the following
property [9, Theorem 5, p. 205] (see also [10]):
Let f : Rn → R+ be a real nonnegative integrable function
with bounded support. Denote f (Λ)
λ∈Λ\{0} f (λ). Then
the following holds:

(6)

s∈S

and the average error probability is deﬁned by
Pe (S)

lim sup Ea [Pe (s)].

EL [f (Λ)] = γ

(7)

a→∞

(8)

f (Λ) ≤ γ

for all lattice points λ ∈ Λ.
1
1
It is known [4] that whenever δ < δ ∗
2 log 2πeσ2 , a
vanishing error probability can be achieved. In other words, δ ∗
is the capacity for the setting (and also known as the “Poltyrev
Capacity”).
The error exponent function of the setting is deﬁned as 2

f (λ)dλ.

(12)

Rn

III. A N E XPURGATION B OUND

FOR

F INITE D IMENSIONS

Before we present the expurgation bound, it is pedagogical
to ﬁrst review a simpler bound which is based on a union
bound. The expurgated bound is best understood as a modiﬁcation of this bound.

1
(9)
log Pe (S),
n
for the best IC S (assuming the limit exists).
As in classical channel coding, the exact value of the error
exponent E(δ) is not known for all NLD values δ, but only
lim −

n→∞

A. An achievability proof using the union bound
Theorem 1 (Union Upper Bound): For any NLD δ and any
ξ > 0, there exists a lattice Λ with density γ and error
probability upper bounded by

1 Throughout
2 Boldface

(11)

This is the main tool used in the achievability proof. We
shall later on prove that most of the lattices in L have a good
minimum distance, a fact that will facilitate the new result.

B. Error Exponent Bounds in the Poltyrev Setting

E(δ)

f (λ)dλ,
Rn

where EL denotes expectation w.r.t. the random ensemble L.
An immediate corollary is that there must exist at least one
lattice Λ that satisﬁes

Our achievability results are based on lattices where all
Voronoi regions are congruent. Therefore for a lattice Λ,
max
Pe (Λ) = Pe (Λ) = Pe (λ),

log 2.

Poltyrev initially used a random coding-like argument in
order to derive the achievability exponent bounds. This bound
e
yields a value of δ ∗ − δ + 1 log 4 for all rates below δcr .
2
For rates below δex , an expurgation method was used in order
to improve the exponent. It should be noted that only above
δcr the upper bound for the exponent (the sphere packing
exponent [4]) coincides with the lower bound. In the current
paper we reﬁne the expurgation technique, and obtain better
error probabilities even for δex ≤ δ ≤ δcr . Before we present
the new bound, we review the main tool used in such bounds,
namely the Minkowski-Hlawka-Siegel (MHS) theorem and the
MHS ensemble.

Throughout the paper, an IC will be used for transmission
of information through the unconstrained AWGN channel with
noise variance σ 2 (per dimension). The additive noise shall be
denoted by Z = [Z1 , ..., Zn ]T . An instantiation of the noise
vector shall be denoted by z = [z1 , ..., zn ]T .
For s ∈ S, let Pe (s) denote the error probability when s
was transmitted. When the maximum likelihood (ML) decoder
/
is used, the error probability is given by Pe (s) = Pr{s + Z ∈
W (s)}, where W (s) is the Voronoi region of s, i.e. the convex
polytope of the points that are closest to s than to any other
point s′ ∈ S (in the Euclidean sense). The maximal error
probability is deﬁned by
max
Pe (S)

1
2

the paper logarithms are taken w.r.t. the natural base e.
E denotes an error exponent function, where E denotes statistical

UUB
(n, δ) + ξ,
Pe ≤ Pe

expectation.

2

(13)

B. Expurgation Bound

where
UUB
Pe
(n, δ)

σ n enδ π

n−1
2

2

3n−1
2

Γ( n+1 )
2
.
Γ( n + 1)
2

The minimum distance of a lattice Λ, denoted dmin (Λ), is
given by the minimal distance of any two lattice points. It
appears that most of the lattices in the ensemble L have good
minimum distance:
Lemma 1 (Most lattices in L have good dmin ): Let reﬀ =
(γVn )−1/n (reﬀ is the radius of a sphere with the same volume
as a Voronoi cell of the lattice). Set a value for 0 ≤ α < 1.
Let Λ be drawn from the random ensemble L. Then,

(14)

Proof: The proof follows by taking the union bound of
all pair-wise error events: Let Λ be an arbitrary lattice, and
assume w.l.o.g. that the zero codeword was sent. Let r0 be a
given noise radius. Then the error probability is upper bounded
(using the union bound) by
Pe ≤

λ∈Λ\{0}

Pr{ z − λ ≤ z } + Pr{ z > r0 }.

Pr{dmin (Λ) < αreﬀ } ≤ αn .

(15)

Proof: For a set S, denote by NS (Λ) the number of
nonzero lattice points in S ∩ Λ.

λ ≤2r0

Consider the left term of the expression:

λ∈Λ\{0}

Pr{ z − λ ≤ z } =

λ ≤2r0

Q
λ∈Λ\{0}

Pr{dmin (Λ) < αreﬀ } =EL [1{dmin (Λ) < αreﬀ }]

λ
2σ

(a)

≤ EL NBall(αreff ) (Λ)

(b)

n
= γVn αn reﬀ

λ ≤2r0

˜
Q

=
λ∈Λ\{0}

λ
2σ

(c) n

.

=α ,

(a) follows from the fact that for any Λ s.t. dmin (Λ) < αreﬀ ,
then NBall(αreff ) (Λ) ≥ 1. (b) follows from the MHS theorem
used with the characteristic function of Ball(αreﬀ ). (c) follows
from the deﬁnition of reﬀ .
Deﬁnition 2 (Expurgated ensemble): The ensemble Lx
contains all the lattices in L whose minimum distance is at
least αreﬀ .
Lemma 2 (MHS theorem for the expurgated ensemble):
For any bounded-support nonnegative function f : Rn → R+ ,
the following holds:
1
ELx [f (Λ)] ≤
(18)
EL [f (Λ)].
PrL {dmin (Λ) ≥ αreﬀ }

2
∞
˜
where Q(x) = √1 x e−t /2 dt and Q (x) is deﬁned to be
2π
Q(x) when x ≥ r0 /σ and zero elsewhere.
˜
Since Q(·) has a bounded support, we may use the MHS
theorem and conclude that there exists a lattice Λ s.t.

˜
Q

λ
2σ

˜
Q

λ
2σ

dλ

Q

λ
2σ

dλ

λ∈Rn

≤γ

λ∈Λ\{0}

≤γ

λ∈Rn
∞

r
nVn rn−1 dr
2σ
r=0
1 n−1
n+1
= γVn (2σ)n √ 2 2 Γ
2
2π

=γ

(17)

Q

Proof: Denote by A the event where a lattice drawn from
L satisﬁes dmin (Λ) ≥ αreﬀ . Therefore an average of f (Λ)
w.r.t. Lx can be written as EL [f (x)|A].
We start with:

.

The last step (which follows by elementary algebraic manipulations of the integral) leads to (14). r0 can be arbitrarily large
to ﬁt ξ that is arbitrarily small so the proof is concluded.
Theorem 2 (Union Upper Bound Asymptotics): Fix
the
NLD δ. Then as n grows,
e
∗
1
1
UUB
Pe
(n, δ) = √ e−n[δ −δ+ 2 log 4 ] 1 + O
nπ

1
n

.

¯
¯
EL [f (Λ)] = E[f (Λ)|A] Pr(A) + E[f (Λ)|A] Pr(A).

(19)

Since f (·) is nonnegative we have
E[f (Λ)] ≥ E[f (Λ)|A] Pr(A),

(16)

(20)

which leads to (18).
We now arrive at our main result:
Theorem 3: There exists a lattice Λ whose error probability
is upper bounded by

Proof: Immediate by the Stirling approx. for Γ[z].
Notes:
1) This bound is different from the ML bound in [7] (an
explicit ﬁnite-dimensional version of the random coding bound
[7]). In fact, the UUB can be viewed as the ML bound with
r = ∞.
2) Numerically, The UUB is only slightly weaker than the ML
bound δ < δcr . As expected, for δ > δcr the ML bound is
much better since they have different exponents.
3) The resulting exponent is of a straight line, as expected
(and as seen in the DMC case [5]). The exponent keeps its
straight-line form for any δ (since (16) holds for any δ).

XB
Pe (Λ) ≤ Pe (n, δ, α) + ξ,

(21)

for any dimension n, any parameter 0 ≤ α < 1, and ξ > 0
XB
arbitrarily small. Pe (n, δ, α) is given by
1
γnVn
1 − αn

∞
αreff

r
Q( 2σ )rn−1 dr.

(22)

Clearly, α can be optimized, and hence we deﬁne
XB
Pe (n, δ)

3

XB
inf Pe (n, δ, α).

0≤α<1

(23)

Proof: Let Λ be a given lattice. We start with the union
bound as in Theorem 1:
Pe (Λ) ≤

˜
Q
λ∈Λ\{0}

λ
2σ

+ Pr{ z > r0 },

Proof: The integral in (21) can be bounded by:
∞

(24)

(a)

≤

˜ λ
where r0 can be arbitrarily large. Deﬁne f (λ) to be Q 2σ
for λ ≥ αreﬀ and zero elsewhere. Therefore for all the
lattices in Lx we have

λ∈Λ\{0}

= f (Λ).

1
EL [f (Λ)]
Pr{Lx }
1
≤
EL [f (Λ)]
1 − αn
γ
≤
f (λ)dλ.
1 − αn Rn

f (Λ) ≤

(26)
(27)

(29)

r
nVn rn−1 dr
2σ

(30)

αreff ≤ λ ≤2r0
2r0

=
≤

Q
r=αreff
∞

Q

αreff

λ
2σ

r
nVn rn−1 dr,
2σ

where

β

E XPURGATION B OUND

2 ∗

n−1
2

− log

(33)

1+O

log2 n
n

(35)
(36)

(1 − 2Ex (δ))2
.
2
4Ex (δ)

(37)

2

αn
e−α nEx (δ)
K 1+O
n
1 − α (nπ) α82 e2(δ∗ −δ) + 1
2

r2

8e−nα ρ /8 (α2 ρ∗ )
α2 ρ∗ − 4 + 12
n

.

¯ XB
Proof: the upper bound Pe (n, δ, α) is asymptotically
given by

eff
Theorem 4: Let ρ∗
nσ2 . Then for any dimension n > 3,
α ∈ (0, 1) s.t. α2 ρ∗ − 4 + 12 > 0, the expurgation bound
n
XB
Pe (n, δ, α) is upper bounded by

n−1
1
2
2π n

n−1
2

8
1
√ δ∗ −δ 2(δ∗ −δ)
,
(e
− 4)
2e

K′

A. An Analytical Bound

γVn σ n
1 − αn

8e−nα ρ /8 (α2 ρ∗ )
α2 ρ∗ − 4 + 12
n

e−β/2 eβEx (δ) K ′ e−nEx (δ)
˜ XB
Pe (n, δ) =
∗
1 − e−β/2 (nπ) 1 e2(δ −δ) + 1
8
2

We now wish to analyze the ﬁnite-dimensional expurgation
bound further in order to get an analytical bound and a precise
asymptotic form.

¯ XB
Pe (n, δ, α)

dρ

α2 ρ∗

Theorem 5: For ﬁxed NLD δ, the following error probability is asymptotically achievable:

Notes: 1) For α arbitrarily close to 1 (from below), for large
1
enough n the term 1−αn goes to 1 and the behavior of the
term is governed by the integral. 2) For α = 0 the bound
reduces to Theorem 1. 3) For ﬁxed n, α can be optimized in
order to give the best bound.
OF THE

n−3
1
2
2π n

nρ
8

B. Asymptotic form
(31)

and the proof is concluded since r0 can be arbitrarily large.

IV. A NALYSIS

ρ(n−3)/2 e−

The detailed proof of the lemma is omitted. The proof follows
from the fact that the logarithm of the integrand of the LHS
of (34) is concave, and therefore can be upper bounded by
its ﬁrst-order taylor series. The modiﬁed integral converges
for x > 4 − 12 and therefore (34) follows. The technique is
n
similar [7, Lemma 2].
The above derivation is useful since it gives a bound that
does not require numeric calculation of unsolvable integrals.
In addition, it can lead to more precise asymptotic analysis.

(28)

dλ

Q

∞

(a) follows from the well known bound on the Q function:
2
1
Q(x) ≤ √2πx e−x /2 for all x > 0. (b) follows from the
following technical lemma:
Lemma 3: Let n ∈ N and x ∈ R s.t. n > 3 and x > 4− 12 .
n
Then
n−1
∞
n−3
8e−nx/8 x 2
.
(34)
ρ 2 e−nρ/8 dρ ≤
n x − 4 + 12
x
n

We continue with
f (λ)dλ =

r 2
1
√ r e−( 2σ ) /2 rn−1 dr
2π 2σ

2 ∗

(b)

(25)

r
Q( 2σ )rn−1 dr

n−1
1
2
2π n

=σ n

We use Lemma 2, Lemma 1 and the MHS theorem, and
conclude that there exists a lattice Λ with

Rn

αreff

≤ σn

λ
2σ

˜
Q

αreff
∞

where
K

log2 n
n

1
8
√
.
δ ∗ −δ (α2 e2(δ ∗ −δ) − 4)
2 αe

,

(38)

(39)

The proof follows from (33), and the approximations of Vn
and ρ∗ (see [7, Eqs. (64)-(68)]).
β
We now select α =
1 − n since any other selection
would weaken the bound by a non-constant factor. Since

,

(32)
2
reff
where ρ∗
.
nσ2
Note that as n grows, the condition α2 ρ∗ −4+ 12 > 0 translates
n
to δ < δex + log α.

n/2

β
1− n
= e−β/2 + O(log(n)/n), we arrive at (35) with
′
K given in (36). Further optimizing w.r.t. β gives (37).

4

,

1

2.8

2.6

2.4

∆ex

2

∆cr

2.8

1.6

10

10

6

10

10

10

8

10

2.6

2.4

∆ex

2

∆cr

2.8

2.6

∆ex

2.4

1.6

2

∆cr

1.6

66

83

10
2.8

∆cr

49

10

4

2

32

10

Error probability

Error probability

10

∆ex

2.4

15

10

0.01

2.6

1.6

100

NLD ∆

NLD ∆

Fig. 2. ML bound (dashed) vs the optimized expurgation bound (solid) for
dimension n = 100 and σ2 = 1. Here the expurgation bound improves
essentially only for δ < δex .

Fig. 1. ML bound (dashed) vs the optimized expurgation bound (solid) for
∼
dimension n = 10 and σ2 = 1. The expurgation bound is better at δ < δcr .

10

Error Probability

5

10

Notes: 1) The precise asymptotic form in Theorem 5 reveals
the sub-exponential term in the expurgation ‘exponent’. It is
revealed that beyond the exponential form e−nEx (δ) , there is
also a polynomial factor that renders the exponential term
alone inexact. 2) Further analysis shows that the (38) is in fact
a precise asymptotic form of the expurgation bound (here we
only presented the upper bound since this contributes directly
to the achievability bound). The proof for this fact follows
the steps of the proof of [7, Lemma 5]. This fact shows that
the analytical bound and its approximations are tight. 3) We
XB
˜ XB
do not claim that Pe (n, δ) approximates Pe (n, δ), since
¯ XB
the optimization of α is done on the bound Pe (n, δ, α).
However, it approximates it very well, we show next.

8

10

11

10

14

10

17

10

20

20

30

40

50

60

70

Dimension n

XB
Fig. 3. The ﬁnite dimensional expurgation bound Pe (n, δ) (solid) vs.
the expurgation exponent e−nE(δ) (dashed) vs the precise asymptotic form
˜ XB
˜ XB
Pe (n, δ) (dot-dashed). Clearly Pe (n, δ) better approximates the true
bound. (here δ = −2.2nat and σ2 = 1).

V. N UMERICAL E XAMPLES AND C ONCLUSIONS
XB
Here we present the expurgation bound Pe , with α values
optimized numerically, vs. the ML bound from [7]. The ML
bound is the ﬁnite-dimensional version of the random coding
bound. When error exponents are considered, the expurgation
technique improves upon random coding only for δ < δex
[4]. However, as we demonstrate in Fig. 1, for short lengths
(e.g. n = 10) the bound improves even for higher values of
δ, sometimes even as high as around δcr . For larger n, e.g.
n = 100 as shown in Fig. 2, the advantage of the expurgation
vanishes above δex .
In Fig. 3 we demonstrate the inaccuracy of the expurgation
exponent form, and show the accuracy of the precise asymp˜ XB
totic form Pe (n, δ). As shown in the ﬁgure, the exponential
form alone is far off by orders of magnitude from the true
˜ XB
bound, where Pe (n, δ) is much more precise.

R EFERENCES
[1] G. D. Forney Jr. and G. Ungerboeck, “Modulation and coding for linear
Gaussian channels,” IEEE Trans. on Information Theory, vol. 44, no. 6,
pp. 2384–2415, 1998.
[2] J. H. Conway and N. J. A. Sloane, Sphere packings, lattices and groups,
ser. Grundlehren der math. Wissenschaften. Springer, 1993, vol. 290.
[3] U. Erez and R. Zamir, “Achieving 1/2 log(1+SNR) over the additive
white Gaussian noise channel with lattice encoding and decoding,” IEEE
Trans. on Information Theory, vol. 50, pp. 2293–2314, Oct. 2004.
[4] G. Poltyrev, “On coding without restrictions for the AWGN channel,”
IEEE Trans. on Information Theory, vol. 40, no. 2, pp. 409–417, 1994.
[5] R. G. Gallager, Information Theory and Reliable Communication. New
York, NY, USA: John Wiley & Sons, Inc., 1968.
[6] C. E. Shannon, “Probability of error for optimal codes in a gaussian
channel,” The Bell System technical journal, vol. 38, pp. 611–656, 1959.
[7] A. Ingber, R. Zamir, and M. Feder, “Finite dimensional inﬁnite constellations,” Submitted to IEEE Trans. on Information Theory. See arxiv.org.
[8] ——, “The dispersion of inﬁnite constellations,” in Proc. IEEE International Symposium on Information Theory, Aug. 2011, pp. 1407 –1411.
[9] P. M. Gruber and C. G. Lekkerkerker, Geometry of Numbers. Amsterdam: North-Holland, 1987.
[10] H. A. Loeliger, “Averaging bounds for lattices and linear codes,” IEEE
Trans. on Information Theory, vol. 43, pp. 1767–1773, Nov. 1997.

The above example demonstrate the usefulness of our
reﬁned bound. We expect the same technique to be able to
improve existing ﬁnite blocklength bounds in many additional
channels, such as the binary symmetric channel, moduloadditive channels and more, and, with some modiﬁcations, for
the power-constrained Gaussian channel.

5

