Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Fri May 18 14:37:49 2012
ModDate:        Tue Jun 19 12:55:25 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      494309 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569564281

Non-Random Coding Error Exponent for Lattices
Yuval Domb

Meir Feder

School of Electrical Engineering,
Tel-Aviv University, Tel-Aviv 69978, Israel
Email: yuvald@eng.tau.ac.il

School of Electrical Engineering,
Tel-Aviv University, Tel-Aviv 69978, Israel
Email: meir@eng.tau.ac.il

One simple and practical bounding technique for the discrete case was derived in [6]. The bound and its various
extensions provide error bounds for speciﬁc codes or code
families, as a function of their distance spectrum. Despite its
simple derivation and form, it has led to signiﬁcant results
in coding theory. Amongst those is the error analysis for
Maximum Likelihood (ML) decoding of LDPC codes [7].
One result of this paper is a simple upper bound on the
error probability of speciﬁc lattice codes or code families
over continuous channels, as a function of their distance
spectrum. The bound is constructed by replacing the wellknown Minkowski-Hlawka theorem [8] with a non-random
alternative. Although tighter distance spectrum based bounds
for special ﬁnite dimension lattices exist, an interesting and
unique outcome of this bound is an error exponent for speciﬁc
lattice sequences. As a corollary to that exponent, knowledge
of a sequence’s distance spectrum directly reveals its gap
to capacity. Although the focus of this paper is circularlysymmetric continuous noise channels, the results are easily
extendable to general non-symmetric channels.
The paper is organized as follows: Section II provides
preliminary background, section III presents the derivation
of the Minkowski-Hlawka non-random alternative, section IV
outlines a well-known general ML decoding upper bound,
section V applies our new techniques to the general bound
of section IV, section VI presents a new error exponent for
speciﬁc lattice sequences over AWGN channels, and the ﬁnal
section concludes this work with two simple examples.

Abstract—An upper bound on the error probability of speciﬁc
lattices, based on their distance spectrum, is constructed. The
derivation is accomplished using a simple alternative to the
Minkowski-Hlawka mean-value theorem of the geometry of
numbers. In many ways, the new bound greatly resembles
the Shulman-Feder bound for linear codes. Based on the new
bound, an error exponent is derived for speciﬁc lattice sequences
(of increasing dimension) over the AWGN channel. Measuring
the sequence’s gap to capacity, using the new exponent, is
demonstrated.

I. I NTRODUCTION
For continuous channels, Inﬁnite Constellation (IC) codes
are the natural coded-modulation scheme. The encoding operation is a simple one-to-one mapping from the information
messages to the IC codewords. The decoding operation is
equivalent to ﬁnding the “closest”1 IC codeword to the corresponding channel output. Lattices are the subset of linear
ICs. As such they are usually more convenient for encoding
and decoding. The notion of a lattice code as a form of
coded-modulation is not new. It dates back to a 1975 paper
by de-Buda [1]. As is the case with all codes, the most
important baseline feature for analysis of a lattice is its error
performance. A widely accepted framework for lattice codes’
error analysis is commonly referred to as Poltyrev’s setting
[2]. In Poltyrev’s setting the code’s shaping region, deﬁned
as the ﬁnite subset of the otherwise inﬁnite set of lattice
points, is ignored, and the lattice structure is analyzed for its
packing properties only. Consequently, the usual rate variable
R is inﬁnite and replaced by the Normalized Log Density
(NLD) δ. The lattice analogous to Gallager’s random-coding
error exponent [3], over a random linear codes ensemble, is
Poltyrev’s error exponent over a set of lattices of constant
density.
Both Gallager and Poltyrev’s error exponents are asymptotic
measures of the exponential behavior of the average error
probability over an ensemble. Consequently, the error exponent is often a crude upper bound for the error probability
in ﬁnite dimension n. Moreover, it is an average property
of the ensemble and does not imply much about a speciﬁc
code. Various upper error bounding techniques and bounds
for speciﬁc codes and code families have been constructed for
linear codes over discrete channels [4]. On the other hand, only
a few bounds have been devised for lattices over particular
continuous channels [5].
1 Closest

II. P RELIMINARIES
A lattice Λ is a discrete n-dimensional subgroup of the
Euclidean space Rn that is an Abelian group under addition.
A generating matrix G of Λ is an n×n matrix with real valued
coefﬁcients constructed by concatenation of a properly chosen
set of n linearly independent vectors of Λ. The generating
matrix G deﬁnes the lattice Λ by Λ = {λ : λ = Gu, u ∈ Zn }.
A fundamental parallelepiped of Λ, associated with G is the set
n
of all points p = i=1 ui gi where 0 ≤ ui < 1 and {gi }n
i=1
are the basis vectors of G. The lattice determinant, deﬁned
as det Λ ≡ |deg G|, is also the volume of the fundamental
parallelepiped. Denote by β and δ the density and NLD of Λ
respectively; thus β = enδ = (det Λ)−1 .

in the sense of the appropriate distance measure for that channel.

1

III. N ON -R ANDOM M INKOWSKI -H LAWKA

with

The lattice-dual of the random linear codes ensemble, in
ﬁnite-alphabet codes, is a set of lattices originally deﬁned
by Siegel [9], [10], for use in proving what he called the
mean-value theorem. This theorem, often referred to as the
Minkowski-Hlawka-Siegel (MHS) theorem, is a central constituent in upper error bounds on lattices. The theorem states
that for any dimension n ≥ 2, and any bounded Riemannintegrable function g(λ) there exists a lattice Λ of density β
for which
x
g(λ) ≤
(1)
g δ dx = β
g(x)dx.
e
Rn
Rn

λ∈γΛ0 \{0}

x
dx
eδ

(3)

g(λ)dµ(γ)
Γ λ∈γΛ \{0}
0

=

g(γλ)dµ(γ)
λ∈Λ0 \{0}

=

Γ

γλ
eδ
Γ

λ
g δ
e
Θ
g

λ∈Λ0 \{0}

=
λ∈Λ0 \{0}
∞

=

N (R)
0+

g
Θ

dµ(γ)
θ


 dµ(θ)

Rθ
eδ

dµ(θ)dR

∞

N (R)
Rθ
·g
dµ(θ)dVn Rn
n−1
eδ
0+
Θ nVn R
x
N( x )
=
n−1 · g eδ dx
Rn \{0} nVn x
x
=
N( x )g δ dx.
(4)
e
n
R
=

where the third equality follows from the deﬁnition of Γ and
Θ and the measures µ(γ) and µ(θ), the fourth equality is due
to the circular symmetry of the integral term, and the sixth
equality is a transformation from generalized spherical polar
coordinates to the cartesian system (see Lemma 2 of [10]).
Finally there exists at least one rotation γ ∈ Γ for which
the sum over γΛ0 is upper bounded by the average.
The corollary presented below is a restricted version of
lemma 1 constrained to the case when the function g(λ) is
circularly-symmetric, (i.e. g(λ) = g( λ )). To simplify the
presentation, it is implicitly assumed that g(λ) is circularlysymmetric for the remainder of this paper. It should be
noted that all results presented hereafter apply also to a nonsymmetric g(λ) with an appropriately selected rotation γ of
Λ0 .

Lemma 1 (“Non-Random Mean-Value Theorem”). Let Λ0 be
a speciﬁc n-dimensional lattice with NLD δ, and g(λ) be a
Riemann-integrable function, then there exists an orthogonal
rotation γ such that
N( x )g

:x>0
:x≤0

Proof: Let Θ denote the space of all points θ in the ndimensional space with θ = 1, so that Θ is the surface of the
unit sphere. Let µ(θ) denote the ordinary solid-angle measure
on this surface, normalized so that Θ dµ(θ) = 1. We continue
with the following set of equalities

Siegel proved the theorem by averaging over a fundamental
set2 of all n-dimensional lattices of unit density. The drawback
of this theorem is similar to the random-coding theorem. The
theorem proves existence of good lattices but does not show
how to ﬁnd them. Moreover it does not provide tools for
analysis of speciﬁc lattices. An alternative to (1), constructed
for speciﬁc lattices, based on their distance spectrum, is
introduced later in this section.
We begin with a few deﬁnitions, before stating our central
lemma. The lattice Λ0 always refers to a speciﬁc known ndimensional lattice of density β, rather than Λ which refers to
some unknown, yet existing n-dimensional lattice. The lattice
Λ0 is the normalized version of Λ0 (i.e. det(Λ0 ) = 1). Deﬁne
the distance series of Λ0 as the ordered series of its unique
norms {λj }∞ such that λ1 is its minimal norm. {λj }∞
j=1
j=1
is deﬁned for Λ0 respectively. The normalized continuous dis∞
tance spectrum of Λ0 is deﬁned as N (x) = j=1 Nj δ(x−λj ),
∞
where {Nj }j=1 is the ordinary distance spectrum of Λ0 , and
δ(·) is the dirac delta function. Let Γ denote the group3 of
all orthogonal n × n matrices with determinant +1 and let
µ(γ) denote the normalized measure so that Γ dµ(γ) = 1.
The notation γΛ0 is used to describe the lattice generated by
γG, where G is a generating matrix of the lattice Λ0 .
Our central lemma essentially expresses Siegel’s meanvalue theorem for a degenerate ensemble consisting of a
speciﬁc known lattice Λ0 and all its possible rotations around
the origin.

Rn

0

where Vn is the volume of an n-dimensional unit sphere, and
· denotes the Euclidean norm.

λ∈Λ\{0}

g(λ) ≤

N (x)
nVn xn−1

N(x)

(2)

Corollary 1. Let Λ0 be a speciﬁc n-dimensional lattice
with NLD δ, and g(λ) be a circularly-symmetric Riemannintegrable function, then

2 Let Υ denote the multiplicative group of all non-singular n × n matrices
with determinant 1 and let Φ denote the subgroup of integral matrices in
Υ. Siegel’s fundamental set is deﬁned as the set of lattices whose generating
matrices form a fundamental domain of Υ with regards to right multiplication
by Φ (see section 19.3 of [8]).
3 This group, consisting only of rotation matrices, is usually called the
special orthogonal group.

g(λ) =
λ∈Λ0 \{0}

N( x )g
Rn

with N(x) as deﬁned in lemma 1.

2

x
dx
eδ

(5)

Proof: When g(λ) is circularly-symmetric,
g(λ)dµ(γ) =
Γ λ∈γΛ \{0}
0

with

g(γλ)dµ(γ)
g(λ)
g(λ)

(6)

λ∈Λ0 \{0}

The right-hand side of (5), (or (2)), can be trivially upper
bounded by replacing N(x) with a suitably chosen function
α(x), so that
x
N( x )g δ dx ≤
e
n
R

x
α( x )g δ dx.
e
n
R

j = arg min
i∈I

(7)

max

e−δ x≤λmax

α(x)

g(x)dx

(8)

Rn

Proof: Substitute a speciﬁc α(x) for N(x) in (5), and
upper bound by taking the maximum value of α(x) over the
integrated region, outside the integral.

r

Pe (Λ) ≤ min 
r

λ∈Λ\{0}

We now proceed to deﬁne an α(x) that is suitable for
purposes of this paper and is optimal in some sense. For that,
g(λ) is further constrained to be a monotonic, non-increasing
function of λ . Let N (x) be a smoothed version of the
normalized continuous distance spectrum, selected such that
it satisﬁes
N (R)dR

∀r ∈ (0, eδ λmax ].

Rn

eδ λmax

=

R
eδ

Rn

x
dx
eδ

z

Proof: See [11].
We call the ﬁrst term of (13) the Union Bound Term (UBT)
and the second term the Sphere Bound Term (SBT) for obvious
reasons.

dR

α( x )g

(ρ)dρ

where Ball(z, z ) is an n-dimensional ball of radius
centered around z.

dR

0+

z

V. A PPLICATIONS OF THE G ENERAL ML B OUND

R
eδ

N (R)g

≤

f

(13)

(9)

N (R)g
0+
eδ λmax

(ρ) ×

r

Given the above, α(x) can be deﬁned by expanding (7) as
follows:
x
dx =
eδ

z

∞

0+

N( x )g

f
0

Pr(λ ∈ Ball(z, z )| z = ρ)dρ +

r

0+

(12)

Theorem 2 (General ML Upper Bound). Let Λ be an ndimensional lattice, and f z (ρ) the pdf of an ACSN channel’s
noise vector’s norm, then the error probability of an ML
decoder is upper bounded by


One should note that (8) could be met at equality with
appropriate choice of α(x), though ﬁnding such α(x) may
require a tedious numerical exploration. The added value in
(8) stems from its simplicity, given any choice of α(x).

N (R)dR ≤

αi (x).

Many tight ML upper bounds originate from a general
bounding technique, developed by Gallager [12]. Gallager’s
technique has been utilized extensively in literature [4], [13],
[14]. Similar forms of the general bound, displayed hereafter,
have been previously presented in literature [5], [15]. Playing
a central role in our analysis, we present it as a theorem.
Before proceeding with the theorem, let us deﬁne an
Additive Circularly-Symmetric Noise (ACSN) channel as an
additive continuous noise channel, whose noise is circularlysymmetric and a non-increasing function of its norm.

where λmax is the maximal x for which g(x) = 0.

r

max

e−δ x≤λmax

IV. A G ENERAL ML D ECODING U PPER B OUND

Theorem 1 (“Non-Random Minkowski-Hlawka” - NRMH).
Let Λ0 be a speciﬁc n-dimensional lattice of density β, g(λ) be
a bounded Riemann-integrable circularly-symmetric function,
and α(x) be deﬁned such that (7) is satisﬁed, then
g(λ) ≤ β

(11)

As it turns out αopt (x) is a piecewise constant function. It
is constant over shells deﬁned by consecutive radii from the
normalized distance series {λj }∞ , (i.e. a shell is deﬁned by
j=1
{x : λj < x ≤ λj+1 }). The function αopt (x) can be obtained
as the solution to a linear program presented in [11].

Provided the substitution, it is possible to deﬁne the following
simple upper bound. The bound is general up to choice of
α(x), and clariﬁes the motivation for the substitution.

λ∈Λ0 \{0}

:x>0
:x≤0

where the equalities follow methods used in (4) together
with g(λ)’s circular-symmetry, and the inequality follows from
g(λ) being monotonically non-increasing together with N (x)
obeying (9).
We deﬁne {αi (x)}i∈I , the set of all functions α(x) such
that (9) is satisﬁed and select αopt (x) = αj (x) such that the
bound in (8) is tightest; thus by deﬁnition

dµ(γ)
Γ

λ∈Λ0 \{0}

=

0

Γ

λ∈Λ0 \{0}

=

N (x)
nVn xn−1

α(x)

The ML decoding upper bound (13) is further bounded
in three different methods, by exchanging the lattice sum
λ∈Λ\{0} g(λ) with various terms that bound it from above.
The resulting applications vary in purpose, simplicity, and
exhibit different performance. We present the applications and
discuss their differences.

(10)

3

resulting bound is similar to the Spherical Upper Bound of [5],
hence the name. The bounding technique for the probability
term, presented in the following lemma, is based on [16].

A. Minkowski-Hlawka-Siegel (MHS)
Application of the MHS theorem from (1), leads to the
random-coding error bound on lattices. We quote the theorem.

Lemma 2 (Appendix D of [16]). Let x be a vector point in
n-space, z an isotropically distributed n-dimensional random
vector, and ρ a real number then

Theorem 3 (MHS Bound, Theorem 5 of [15]). Let f z (ρ)
be the pdf of an ACSN channel’s noise vector’s norm, then
there exists an n-dimensional lattice Λ of density β for which
the error probability of an ML decoder is upper bounded by
r∗

Pe (Λ) ≤ βVn

Pr(x ∈ Ball(z, z )| z = ρ) ≤

∞

f

z

(ρ)ρn dρ +

f

z

(ρ)dρ

r∗ = (βVn )−1/n .
r
z

n−1
2

(19)

Theorem 5 (SUB). Let a speciﬁc n-dimensional lattice Λ0 of
density β be transmitted over an ACSN channel with f z (ρ)
the pdf of its noise vector’s norm, then the error probability
of an ML decoder is upper bounded by


(15)

Proof: Set g(λ) as
f

2

Proof: See [11].

with

g(λ) =

1−

(14)

r∗

0

x
2ρ

(ρ) Pr(λ ∈ Ball(z, z )| z = ρ)dρ, (16)

0

M

r

Nj

Pe (Λ0 ) ≤ min 

noting that it is a bounded function of λ and continue to bound
the UBT from (13) using (1). The remainder of the proof is
presented in [11].
Since this bound is based on the MHS ensemble average, it
shows existence of a lattice Λ which is upper bounded by it.
It does not however aid in ﬁnding such lattice; neither does it
provide tools for examining speciﬁc lattices.

r

λj
2ρ

1−

f

z

(ρ) ×

λj /2

j=1
2

n−1
2



∞

dρ +

f

z

(ρ)dρ

(20)

r

where {λj }∞ and {Nj }∞ are the previously deﬁned disj=1
j=1
tance series and spectrum of Λ0 respectively, and M is the
largest index such that λj ≤ 2r.

B. Non-Random Minkowski-Hlawka (NRMH)
Unlike the previous, application of the NRMH theorem
provides a tool for examining speciﬁc lattices. Its appealing
advantage is that it is essentially the MHS application multiplied by a constant.

[11].

Theorem 4 (NRMH Bound). Let a speciﬁc n-dimensional
lattice Λ0 of density β be transmitted over an ACSN channel
with f z (ρ) the pdf of its noise vector’s norm, then the error
probability of an ML decoder is upper bounded by

When the channel is AWGN with noise variance σ 2 , the
upper error bound on the ML decoding of a “good”4 lattice
from the MHS ensemble (14) can be expressed in the following
exponential form [2], [15]

r

VI. E RROR E XPONENTS FOR THE AWGN C HANNEL

Pe (Λ) ≤ e−n(Er (δ)+o(1))

∞

r

Pe (Λ0 ) ≤ min βαVn

Proof: Bound the UBT of (13) directly, using (19). See

f

z

(ρ)ρn dρ +

0

f
r

z

(ρ)dρ
with

(17)

with
α = max α

opt

e−δ x≤2r

(x)

(21)

(18)

Er (δ) =

 ∗
e
−
 (δ ∗ δ) + log 4 ,
e2(δ



where αopt (x) is as deﬁned by (12).

−δ)

−2(δ ∗ −δ)−1
,
2

0,

δ ≤ δcr
δcr ≤ δ < δ ∗
δ ≥ δ∗

(22)

Proof: Set g(λ) as in (16), noting that it is bounded by
λmax = 2r. The remainder is identical to the proof of theorem
3 replacing β with βα.
Since αopt (x) is a monotonically non-increasing function
of x, optimization of r is usually possible using an iterative
numerical algorithm. In the ﬁrst iteration, set r = (βVn )−1/n
and calculate α according to (18). In each additional iteration,
set r = (βαVn )−1/n and recalculate α. The algorithm is
terminated on the ﬁrst iteration when α is unchanged.

1
1
log
(23)
2
2πeσ 2
1
1
δcr = log
(24)
2
4πeσ 2
where o(1) goes to zero asymptotically with n.
Applying the method above to the upper error bound on a
speciﬁc lattice from (17), it is possible to construct an error
exponent for a speciﬁc lattice sequence based on its distance
spectrum.

C. Sphere Upper Bound (SUB)

Theorem 6 (Non-Random Coding Error Exponent). Let Λ0 [n]
be a lattice sequence transmitted over an AWGN channel with

δ∗ =

This subsection is added for completeness. Here the UBT of
(13) is upper bounded by bounding the probability term inside
the integral. When the channel is restricted to AWGN, the

4 Deﬁne a “good” lattice, from an ensemble, as one that is upper bounded
by the ensemble’s average.

4

noise variance σ 2 , then the error probability of an ML decoder
is upper bounded by
Pe (Λ0 [n]) ≤ e−n(Er (δ+ν[n])+o(1))

(25)

with

1
log α[n].
(26)
n
Proof: It follows from the proof of theorem 4, that
replacing β with βα[n] there, is equivalent to replacing δ with
δ + ν[n] here.
Clearly (25) can be used to determine the exponential decay
of the error probability of a speciﬁc lattice sequence. This
leads us to the following corollary.
ν[n]

Corollary 2. A lattice sequence for which ν[n] = o(1)
achieves the unrestricted AWGN channel capacity δ ∗ .
Fig. 2. The exponential decay series ν[n] for the lattice sequence BWn ,
calculated for dimensions 4, 8, and 16 and interpolated in-between.

VII. E XAMPLES
Two examples are presented that display the simplicity and
effectiveness of our new bound. The spectral data for the
examples is taken from [17]. Both examples are calculated
for an AWGN channel with noise variance σ 2 .
In the ﬁrst example presented in ﬁgure 1, the error probability of the Leech lattice Λ24 is upper bounded by NRMH (17)
and SUB (20). The ordinary Union Bound (UB), the MHS
bound for dimension 24 (14), and the Sphere Lower Bound
(SLB) of [18] are added for reference.

R EFERENCES
[1] R. de Buda, “The upper error bound of a new near-optimal code,” IEEE
Trans. Inf. Theory, vol. 21, no. 4, pp. 441–445, July 1975.
[2] G. Poltyrev, “On coding without restrictions for the awgn channel,” IEEE
Trans. Inf. Theory, vol. 40, no. 2, pp. 409–417, 1994.
[3] R. G. Gallager, Information Theory and Reliable Communication. John
Wiley and Sons, 1968.
[4] S. Shamai and I. Sason, “Variations on the gallager bounds, connections,
and applications,” IEEE Trans. Inf. Theory, vol. 48, no. 12, pp. 3029–
3051, December 2002.
[5] H. Herzberg and G. Poltyrev, “Techniques of bounding the probability
of decoding error for block coded modulation structures,” IEEE Trans.
Inf. Theory, vol. 40, no. 3, pp. 903–911, May 1994.
[6] N. Shulman and M. Feder, “Random coding techniques for nonrandom
codes,” IEEE Trans. Inf. Theory, vol. 45, no. 6, pp. 2101–2104, September 1999.
[7] G. Miller and D. Burshtein, “Bounds on the maximum-likelihood
decoding error probability of low-density parity-check codes,” IEEE
Trans. Inf. Theory, vol. 47, no. 7, pp. 2696–2710, November 2001.
[8] C. G. Lekkerkerker, Geometry of Numbers. John Wiley and Sons, 1969.
[9] C. L. Siegel, “A mean value theorem in geometry of numbers,” The
Annals of Mathematics, vol. 46, no. 2, pp. 340–347, April 1944.
[10] A. M. Macbeath and C. A. Rogers, “A modiﬁed form of siegel’s
mean-value theorem,” Mathematical Proceedings of the Cambridge
Philosophical Society, vol. 51, no. 4, pp. 565–576, 1955.
[11] Y. Domb and M. Feder, “A distance spectrum based upper error bound
for lattices.” [Online]. Available: http://arxiv.org/abs/1201.6022
[12] R. G. Gallager, Low Density Parity Check Codes. MIT Press, 1963.
[13] S. Youseﬁ and A. Khandani, “A new upper bound on the ml decoding
error probability of linear binary block codes in awgn interference,”
IEEE Trans. Inf. Theory, vol. 50, no. 12, pp. 3026–3036, December
2004.
[14] M. Twitto, I. Sason, and S. Shamai, “Tightened upper bounds on the ml
decoding error probability of binary linear block codes,” IEEE Trans.
Inf. Theory, vol. 53, no. 4, pp. 1495–1510, April 2007.
[15] A. Ingber, R. Zamir, and M. Feder, “Finite dimensional inﬁnite constellations,” submitted to IEEE Trans. Inf. Theory.
[16] Y. Lomnitz and M. Feder, “Communication over individual channels,”
IEEE Trans. Inf. Theory, vol. 57, no. 11, pp. 7333–7358, November
2011.
[17] J. H. Conway and N. J. A. Sloane, Sphere Packings, Lattices and Groups,
2nd ed. Springer-Verlag, 1993.
[18] V. Tarokh, A. Vardy, and K. Zeger, “Universal bound on the performance
of lattice codes,” IEEE Trans. Inf. Theory, vol. 45, no. 2, pp. 670–681,
March 1999.

Fig. 1. A comparison of NRMH and SUB for the Leech lattice. The UB,
MHS and SLB are added for reference. The graph shows the error probability
as a function of the Volume-to-Noise Ratio (VNR) for rates δ ∗ < δ < δcr .

In the second example, the exponential decay series ν[n]
is calculated for the ﬁrst three lattices of the Barnes-Wall
lattice sequence BW4 = D4 , BW8 = E8 , and BW16 = Λ16 .
Unfortunately the distance spectrum for BWn is generally
unknown, preventing asymptotical analysis. Nonetheless an
interpolation for dimension 4 to 16 is presented in ﬁgure 2.

5

