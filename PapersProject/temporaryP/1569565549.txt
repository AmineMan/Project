Creator:         TeX output 2012.05.15:1238
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Tue May 15 12:38:48 2012
ModDate:        Tue Jun 19 12:55:48 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      281051 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569565549

Controlled Sensing for Sequential Multihypothesis
Testing
George K. Atia and Venugopal V. Veeravalli
Department of Electrical and Computer Engineering
Coordinated Science Laboratory
University of Illinois at Urbana-Champaign
Urbana, IL 61801–2307
Emails: {atia1,vvv}@illinois.edu
all tests with the same power the SPRT requires on average the
smallest number of observations. This result was extended in
[3] to the case of multiple hypothesis testing and a sequential
test was proposed. This test was later shown to satisfy certain
asymptotic optimality conditions [4].
The problem of sequential binary hypothesis testing with
observation control was considered in [5] and an asymptotically optimal sequential test was presented. However, the
result in [5] was restricted to binary hypothesis testing.
More importantly, other than satisfying asymptotic optimality
subject to vanishing error probabilities, no strict guarantees
on the actual performance were provided. Hence, it remains
unclear how would one design a test to meet speciﬁc error
probability requirements even for the binary case. A Bayesian
version of the sequential problem (with observation control)
was considered in [6] in the non-asymptotic regime. Since
the optimal policy is generally hard to characterize, certain
conditions under which the optimal control is shown to be
an open-loop control, i.e., one which does not depend on
measurements, were identiﬁed. In this paper, we generalize the
result in [5] to the case of multihypothesis testing, subject to
hard constraints on the risks associated with wrong decisions
about every hypothesis in the asymptotic setting where the
risks are sufﬁciently small. For zero-one loss functions, the
risk corresponds to the frequentist error probability, which
represents the probability of accepting a given hypothesis
incorrectly. Designing a test that satisﬁes strict constraints
provides a recipe for efﬁcient test design. We also show that
the classic result of Burnaˇev [7] on the expected coding length
s
for variable length coding can be recovered from the result in
this paper by regarding the coding problem as a special case of
controlled multihypothesis testing. It is worth mentioning that
variable-length coding was considered from a control theoretic
perspective in [8] and a parallel connection to active sensing
was established in a dynamic programming framework.
The rest of the paper is organized as follows. In Section
II, the problem setup is described. A lower bound on the
optimal expected stopping time is presented in Section III.
In Section IV, we present a sequential test, which is shown
to be asymptotically optimal. A connection to variable-length
channel coding is explored in Section V. Finally, conclusions
are given in Section VI.

Abstract—The problem of controlled sensing for multihypothesis testing is considered. Prior to decision making, a controller
sequentially chooses among a set of control actions to shape the
quality of the observations. The goal is to design an efﬁcient control policy, a stopping rule and a ﬁnal decision rule, to minimize
the expected stopping time subject to hard constraints on the
risks associated with wrong decisions about each hypothesis. We
propose a sequential test, which is shown to be asymptotically
optimal when the risks are sufﬁciently small. Optimality is based
on a derived lower bound on the minimum expected stopping
time of tests in the class of tests satisfying the predeﬁned risk
constraints. Furthermore, by viewing the variable-length coding
problem as a special case of sequential multihypothesis testing
with observation control, we recover the classic result of Burnaˇev
s
on the expected coding length for variable-length coding over
Discrete Memoryless Channels (DMCs) at zero rate.

I. I NTRODUCTION
Controlled sensing refers to adaptively managing and controlling multiple degrees of freedom in an informationgathering system to fulﬁll the goal of a given inference task. It
has immediate implications in various applications, including
infrastructure monitoring systems, surveillance systems and
sensor networks.
In this paper, we consider the problem of multihypothesis
testing with observation control. In contrast to [1], where the
main focus was on hypothesis testing with a ﬁxed sample
size, here we focus on the sequential setup. The goal is to
optimize the tradeoff between reliability and detection delay.
At each time instant, prior to making a decision about the
hypothesis, the decision-maker sequentially chooses among a
set of available controls to shape the quality of the observations. The controller can adaptively choose when to stop
taking measurements. Hence, an admissible sequential test is
fully described through a causal control policy, a stopping rule
and a ﬁnal decision rule. In contrast to the ﬁxed sample size
scenario considered in [1], the error exponent is not a good
metric for the optimality of a sequential test, since the expected
stopping time depends on the underlying hypothesis.
In [2], the problem of binary sequential hypothesis testing
without control was considered. Therein, the optimal expected
stopping time is characterized subject to constraints on the
probability of error under each hypothesis. It was shown that
the Sequential Probability Ratio Test (SPRT) is optimal, i.e., of

1

¯
¯
numbers. Deﬁne the largest threshold as Rmax = maxi∈M Ri .
The goal is to ﬁnd a test that minimizes the expected stopping
¯
time among the class Γ(R) in an asymptotic setting, i.e., when
the risks are sufﬁciently small.
Before we state our results we ﬁrst introduce some more notation. The quantity du is the Kullback-Leibler (KL) distance
ij
between the two densities pu and pu [9], i.e., du
D(pu ||pu ).
i
j
ij
i
j
∗
Also deﬁne di as
∑
d∗ max min
q(u)du
(4)
i
ij

II. P ROBLEM S ETUP
Consider a sequential hypothesis testing problem of M
simple hypotheses: Hi , i ∈ M {0, . . . , M − 1}, where at
each time the measurement takes values in X and the control
takes values in U. The control set U is assumed to be ﬁnite.
Under each hypothesis Hi , i = 0, . . . , M − 1, and at each time
k, conditioning on the current control uk = u, the current
observation Xk is assumed to be conditionally independent of
(
)
past measurements and past controls xk−1 , uk−1 , where
( k−1 k−1 )
x
,u
((x1 , . . . , xk−1 ) , (u1 , . . . , uk−1 )) ,

q(u)

∗
and denote by qi the corresponding maximizing distribution.
n
If Pi is the restriction of measure Pi to the σ-algebra Fn ,
then the Log-Likelihood Ratio (LLR) of i w.r.t. a dominating
measure Qn is deﬁned as

and to be conditionally distributed with density pu (x). We
i
consider causal control, where at each time k, the control Uk
can be any (possibly randomized) function of past measurements and past controls, i.e., Uk , k = 2, 3, . ( . , n, is described
.
)
by an arbitrary conditional pmf q (k) = qk uk |xk−1 , uk−1 ,
and U1 is distributed according to a pmf q1 (u1 ). Under the
aforementioned memoryless assumption, the joint distribution
of (X n , U n ) under each hypothesis Hi , pi (xn , un ) , i =
0, . . . , M − 1, can be written as
n

n

pi (x , u )

q1 (u1 )

n
∏

puk (xk )
i

k=1

n
∏

qk (uk |x

k−1

,u

k−1

Zi (n) = log

Zij (n) =

). (1)

πj αji (γ)

(5)

log

pUk (Xk )
i
.
pUk (Xk )
j

(6)

III. L OWER B OUND
The following theorem establishes a lower bound on the
¯
expected stopping time of any test in the class Γ(R) as the
risks go to zero.
¯
Theorem 1: (Lower bound) Let Γ(R) denote the class of
¯ max → 0. Then, ∀i ∈ M, the
tests deﬁned in (3) and R
expected stopping time satisﬁes
¯
| log Ri |
¯
(1 + o(1)) as Rmax → 0 (7)
inf Ei [N ] ≥
∗
¯
di
γ∈Γ(R)
¯
where d∗ is deﬁned in (4) and o(1) → 0 as Rmax → 0. Ei [.]
i
denotes the expectation w.r.t. measure Pi .
To prove this result, we ﬁrst prove the following lemma.
¯
Lemma 1: For the class of tests Γ(R) in (3)
{
¯
ρ| log Ri | }
lim
inf Pi N >
= 1, for every 0 < ρ < 1.
∗
¯
¯
di
Rmax →0 γ∈Γ(R)
It is not hard to see that Theorem 1 follows immediately from
Lemma 1 and Markov inequality.
To prove Lemma 1, we also need the following lemma.
¯
Lemma 2: If N is the stopping time of a test γ ∈ Γ(R),
then
{
}
¯
lim
inf Pi Zij (N ) ≥ ρ| log Ri | = 1,

(2)

j=0
j̸=i

¯
¯
Rmax →0 γ∈Γ(R)

We now introduce a class of tests for which the risks do not
¯
exceed predeﬁned numbers Ri , i = 0, 1, . . . , M − 1, i.e.,
¯
¯
Γ(R) = {γ : Ri (γ) ≤ Ri , i ∈ M}

n
∑
k=1

k=2

M −1
∑

dPn
i
(X n , U n ).
dQn

Also, let Zij denote the LLR between hypotheses Hi and Hj ,
which is the LLR when Q = Pj , i.e.,

At each time instant the controller has to decide whether to
take more observations or to stop and make a decision about
the unknown hypothesis. If the controller decides to take an
observation, the controller selects one of the possible actions
in U and a positive cost is incurred. If the controller decides
to stop at time N = n, a decision is made according to the
decision rule δ : X n × U n → M.
Let Fk be the σ-ﬁeld generated by (X k , U k ). An admissible
sequential test γ = (ϕ, N, δ) consists of a causal observation
control policy ϕ, deﬁned through (conditional) distributions
as before, an Fk -stopping time N and a ﬁnal decision rule
δ. Clearly, there is a tradeoff between the performance of the
test and the expected time to reach the ﬁnal decision. Our goal
is to design an efﬁcient test to optimize this tradeoff. More
speciﬁcally, we would like to design a test with minimum
expected delay subject to constraints on the error probabilities.
Let (π0 , . . . , πM −1 ) be the prior distribution of the hypotheses. For i ̸= j, αji = Pj (δ = i) is the probability of accepting
Hi when Hj is true, where Pj is a probability measure under
hypothesis j. Then, the risk for test γ associated with making a
decision δ = i, which is the probability of incorrectly deciding
i, is given by
Ri (γ) =

j∈M
j̸=i u∈U

∀j ∈ M, for every 0 < ρ < 1.

(3)

Proof: Deﬁne the subset Qn of the sample space as

¯
¯ ¯
¯
where R = (R0 , R1 , . . . , RM −1 ) is a vector of positive ﬁnite

¯
Qn = {(xn , un ) : Zij (n) < ρ| log Ri |, δ = i, N = n}

2

(8)

¯

Noting that αji ≤ Rji from the deﬁnition of Ri in (2) and the
π
¯
fact that γ ∈ Γ(R), we have the following set of inequalities
∞
∑∫
¯
Ri
pj (xn , un )dµ
≥ αji ≥
πj
Qn
n=1
∞
∞
∑∫
∑
(a)
¯ρ
¯ρ
≥ Ri
pi (xn , un )dµ = Ri
Pi {Qn }
(9)
Qn

n=1

Stopping rule: The stopping time Na for test γa is
Na = min inf{n : Li (n) ≥ exp(bi )}
i∈M

where bi , i = 0, 1, . . . M − 1, are design thresholds (to be
speciﬁed).
Decision rule: Finally, the decision rule is
δa = i, if Li (Na ) = max Lj (Na ).

n=1

j∈M

where µ is a properly deﬁned measure. (a) follows from the
¯
fact that Zij (n) < ρ| log Ri | on Qn . Hence,
∞
∑

¯ 1−ρ
Ri
πj

Pi {Qn } ≤

n=1

(10)

∞
∑

Pi {Qn } + Pi {δ
n=1
M −1 ¯
∑ Rj
¯i
(b) R 1−ρ
≤

πj

+

j=0
j̸=i

̸= i}

An,j = {(xn , un ) : NA = n, δ = j}
(11)

πi

(a)
(b) π (M − 1)
πj
j
exp(Zji (n)) ≥ Lj (n) ≥
.
¯
πi
Rj

The
(b) follows from (10) and from the fact that αij ≤
¯
R.H.S. of (11) goes to 0 as Rmax → 0. The result in Lemma
2 follows.
The following result follows from a standard martingale
convergence argument as in Lemma 5 in [5] and is omitted
due to space constraints.
Pi { max min

1≤m≤n j∈M

pi (xn , un ) ≤

as n → ∞ (12)

It follows that
∞
∑
αij =
Pi {An,j } ≤
n=1

A. Test speciﬁcations
To specify the test γa we need to deﬁne the control policy,
the stopping and the decision rules.
Control policy: If at time k we decide to continue taking
observations, then we select a control uk+1 ∈ U by sampling
from the distribution

where ˆk = arg maxi∈M Li (k) and
i
distribution as deﬁned in (4).

∗
qˆ
ik

∞
∑
¯
¯
Rj
Rj
Pj {An,j } ≤
(M − 1)πi n=1
(M − 1)πi

In this section, we show that the expected stopping time of
test γa matches the lower bound in Theorem 1 asymptotically.
For notation, f ∼ g means that f is asymptotically equal to
g, i.e., f /g → 1. We prove the following theorem.
Theorem 2: The expected stopping time Ei [Na ], i =
0, 1, . . . M − 1, of sequential test γa deﬁned through control
policy (15), stopping rule (16) and decision rule (17), and risk
¯
constraints Ri , i = 0, 1, . . . M − 1, satisﬁes
¯
| log Ri |
.
(22)
Ei [Na ] ∼
∗
di

k̸=i

k

(21)

B. Asymptotic Optimality of the Sequential Test

(14)

∗
ˆ
P{Uk+1 = u|Ik = ˆk } = qˆ
i
i

(20)

∑
¯
But since Rj = i̸=j πi αij , it follows that Rj ≤ Rj . Since
¯
the result holds for all j, test γa ∈ Γ(R).

In this section, we propose a sequential test γa by modifying
a test proposed in [4] to account for observation control.
Let Li (n) denote the Generalized Likelihood Ratio (GLR)
between hypothesis Hi and the remaining hypotheses, i.e.,

q (k+1) (u)

¯
Rj
pj (xn , un )
(M − 1)πi

∫
¯
Rj
Pi {An,j } ≤
pj (xn , un )dµ
(M − 1)πi An,j

IV. S EQUENTIAL T EST

πi exp(Zi (n))
.
maxk∈M πk exp(Zk (n))

(19)

Step (a) is true since the denominator in (14) is maximized
over the set M\{j} and i is one index in that set. Step (b)
follows since the test ends at n and the stopping criteria must
be met for the choice of bj in the statement of Lemma 3. Thus,

Combining the result in Lemma 2 and (12) Lemma 1 follows.
Speciﬁcally,
{
¯
ρ| log Ri | }
Pi N ≤ ∗
→ 0.
(13)
di + 1 − ρ

Li (n) =

(18)

On the set An,j we have the following set of inequalities,

¯
Rj
πi .

Zij (m) ≥ n(d∗ +1−ρ)} → 0
i

(17)

In other words, we stop as soon as the GLR exceeds a
predeﬁned threshold for some i and decide that this i is the
true hypothesis.
Lemma 3: Choose bi = log (M −1)πi , i = 0, 1, . . . , M .
¯
Ri
Then, test γa with control policy (15), stopping rule (16) and
¯
decision rule (17), belongs to the class Γ(R) deﬁned in (3).
Proof: Suppose i is the true hypothesis. For any j ∈
M, j ̸= i, deﬁne the set An,j in the sample space as

¯
which goes to 0 as Rmax → 0, for every 0 < ρ < 1. Thus,
¯
Pi {Zij (n) < ρ| log Ri |} ≤

(16)

(15)

¯
when Rmax → 0 and where d∗ is deﬁned in (4).
i
The main difﬁculty arises from the fact that unlike the traditional sequential hypothesis testing problem where the LLRs

is the maximizing

3

are i.i.d. [3] [10], the LLRs are no longer i.i.d. with observation control. Theorem 4.2 in [4] establishes the asymptotic
optimality for general statistical models, i.e., without the i.i.d.
assumption when the r-quick convergence condition holds.
The main idea we need from that theorem is that if the LLRs
1
n Zij (n) converge under the i-th measure r-quickly to positive
constants ℓij , i ̸= j, then the r-th moment of the sample
size required for the LLRs to cross predeﬁned thresholds is
governed by the minimum constant minj ℓij . Note that for
the purpose of this paper we are only interested in optimality
relative to the expected stopping time and not relative to
higher moments of the stopping time distribution. Hence, to
establish (22) it sufﬁces to prove the 1-quick convergence1 of
1
the random variable n Zij (n). Speciﬁcally, since d∗ can be
i
written as
∑
∗
d∗ = min
qi (u)du
i
ij
j̸=i

V. C ONNECTION TO VARIABLE L ENGTH C HANNEL
C ODING
In this section, we show that the variable-length channel
coding problem can be viewed as a special case of sequential
hypothesis testing with observation control. Then, we show
that the classic result of Burnaˇev [7] on the optimal code
s
length for variable-length coding over DMCs can be recovered
from the result derived in this paper on the optimal stopping
time for M -ary controlled sequential hypothesis testing. First,
we show how the problem of variable-length coding can be
mapped to a sequential hypothesis testing problem.
Consider a DMC, with a ﬁnite input alphabet Z, a ﬁnite
channel output alphabet X , and a channel deﬁned through
transition probabilities W (x|z). If we assume perfect causal
feedback, the variable length block code is deﬁned by an
encoder and a decoder. The encoder function zk (., .) : M ×
X k−1 → Z at time k determines the channel input zk (i, xk−1 )
based on the message i ∈ M = {0, 1, . . . , M − 1}, and
past channel outputs xk−1 . At the decoding time N , which
is a stopping time w.r.t. the receiver observation, the decoder
computes ˆ = δ(xN ) ∈ M. In [7] Burnaˇev determined the
i
s
reliability function of variable length-coding over DMCs with
feedback. He showed that
(
)
log M
log Pe
E(N ) =
−
(1 + o(1))
(29)
C
C1

u∈U

we would like to show that
∑
1
Pi −1−quickly
∗
Zij (n) − − − − −
− − − −→
qi (u)du , i ̸= j, ∀j ∈ M (23)
ij
n
u∈U

∗
where qi is the maximizing distribution in (4). To show 1quick convergence, we need to show that ∀ϵ > 0, Ei [T (ϵ)] is
bounded, where
∑
∗
T (ϵ) = sup{n : Zij (n) − n
qi (u)du ≥ nϵ}.
(24)
ij

where C1 = maxz,z′ D(W (.|z)||W (.|z ′ )), Pe denotes the
error probability, and C denotes the channel capacity.
For communication at zero rate, i.e., when log M → 0 (for
E[N ]
example when M is ﬁxed), the ﬁrst term on the R.H.S. in (29)
is dominated by the second and,

u∈U

To argue this, we also deﬁne T1 (ϵ1 ) and T2 (ϵ2 ) as follows
T1 (ϵ1 ) = sup{n : Zij (n) −

n
∑∑

q (k) (u)du ≥ nϵ1 } (25)
ij

k=1 u∈U

T2 (ϵ2 ) = sup{n :

n
∑∑

∗
(q (k) (u) − qi (u))du ≥ nϵ2 }. (26)
ij

E(N ) ∼

k=1 u∈U

T (ϵ) ≤ max{T1 (ϵ/2), T2 (ϵ/2)}.
Hence, given the deﬁnitions of T1 in (25) and T2 in (26), to
show that Ei [T ] < ∞ it sufﬁces to show that there are numbers
γ1 , γ2 < 1 such that, for any ϵ1 , ϵ2 > 0, the following two
inequalities hold
{
}
n
∑∑
(k)
u
n
q (u)dij ≥ nϵ1 ≤ O(γ1 ) (27)
Pi Zij (n) −
k=1 u∈U

Pi

n
∑∑

}
(q

(k)

(u) −

∗
qi (u))du
ij

≥ nϵ2

(30)

Now we view the variable-length coding problem as a controlled sequential sensing problem, namely, the message set
M corresponds to the set of hypotheses, the channel output
corresponds to the observations. Deciding on a decoding time
corresponds to the stopping rule and decoding plays the role
of the decision rule. While the encoding strategy for choosing
the channel input Zk at every time instant can also be viewed
as analogous to the control policy for choosing the control Uk ,
there are still major differences in the informational structures.
Speciﬁcally, the channel input Zk at time k depends on the
message, when the control Uk at time k cannot depend on
the unknown hypothesis. Furthermore, the transition probability W (xk |zk ) is independent of the message, unlike the
observation model pu (xk ) which depends on the underlying
i
hypothesis.
Despite the aforementioned differences in their information
structures, it is not hard to see that the channel coding
problem can be treated as a special case of the sequential
hypothesis testing with control if at each time k we consider the M ×1 vector (zk (0, xk−1 ), zk (1, xk−1 ), . . . , zk (M −
1, xk−1 )) ∈ Z M to correspond to the control uk ∈ U.
Particularly, for the equivalent sequential hypothesis testing

By the triangular inequality, it is not hard to see that

{

− log Pe
.
C1

n
≤ O(γ2 ) (28)

k=1 u∈U

since the expectation will then be bounded by sums of
decreasing geometric series. The conditions in (27) and (28)
are veriﬁed and the proof is deferred to the appendix. This
establishes the asymptotic optimality of test γa and proves
Theorem 2.
1 1-quick convergence is equivalent to the notion of complete convergence,
which was ﬁrst introduced in [11].

4

pu (X )

problem, we take the control set U = Z M . For a control
u = (z(0), z(1), . . . , z(M − 1)) the observation model is
simply pu (x) ≡ W (x|z(i)). Now consider equiprobable
i
messages, i.e., πi = 1/M for all messages. Given that we
have posed the channel coding problem as a hypothesis testing
problem, we can simply invoke Theorem 1 to compute a bound
on the expected coding length, subject to a constraint on the
error probability Pe ≤ ϵ, ϵ → 0. We just need to compute
d∗ in (4) for the equivalent hypothesis testing problem. Based
i
on the previous analogy, and recalling that u is on the form
u = (z(0), z(1), . . . , z(M − 1)),
∑
d∗ = max min
q(u)D(W (.|z(i))||W (.|z(j))). (31)
i
q(u),u∈Z M j∈M

k
Thus, if ϵ1 > 0, then the random variable Wk = log pi (Xk ) −
u
j
u
dij + ϵ1 has a positive mean, and its moment generating
function, ϕ(s) = E[esW ], is ﬁnite for −1 ≤ s ≤ 0 for all
u ∈ U and j ∈ M. Hence, there exists some s∗ (ϵ1 ) < 0 and
η(ϵ1 ) > 0 such that
[
]
( (
))
pu (Xk )
i
u
∗
Ei exp s log u
− dij + ϵ1
≤ e−η .
pj (Xk )

Since this holds for every control u, and since
Zij (n) =

log

k=1

u

pUk (Xk )
i
pUk (Xk )
j

then

{
}
n
[
]
∑∑
Pi Zij (n) −
q (k) (u)du ≤ −nϵ1
ij

Because of the symmetry of the transition probability for
all channel inputs, the inner minimization over j in (31) is
superﬂuous. Consequently, the outer maximization over q(u)
is achievable by a point mass distribution at the two most
distinguishable channel input symbols, i.e. d∗ = C1 , ∀i, where
i
C1 is deﬁned after (29). Note that for the symmetric setup
¯
where Ri = ϵ/M , it follows that E[N ] ∼ log(1/ϵ) , which is
C1
Burnaˇev’s bound at zero rate in (30).
s

[
≤ Ei

k=1 u∈U

(33)

The other side of the inequality can also be proven following
the same argument. Condition (27) follows.
ACKNOWLEDGMENT
This work was supported by the Air Force Ofﬁce of
Scientiﬁc Research (AFOSR) under the Grant FA9550-10-10458 through the University of Illinois at Urbana-Champaign,
by the U.S. Defense Threat Reduction Agency through subcontract 147755 at the University of Illinois from prime award
HDTRA1-10-1-0086, and by the National Science Foundation
under Grant NSF CCF 11-11342.

We considered the problem of controlled sensing for sequential multihypothesis testing. We derived a lower bound
on the expected stopping time subject to hard constraints on
the risks associated with wrong decisions. We also proposed
a test which was shown to be asymptotically optimal. Our
result generalizes the classic result of Chernoff to tests that are
designed to meet speciﬁc performance requirements. Furthermore, we showed that the problem of variable length-coding
can be regarded as a special case of controlled multihypothesis
testing and hence recovered Burnaˇev’s bound on the expected
s
code length for variable-length coding over DMCs at zero rate.

R EFERENCES
[1] S. Nitinawarat, G. K. Atia, and V. V. Veeravalli, “Controlled sensing for
hypothesis testing,” in Proc. of the 37-th Int. conf. on Acoustics, Speech
and Sig. Proc. (ICASSP), Kyoto, Japan, Mar. 2012.
[2] A. Wald, Sequential Analysis. NY: John Wiley and Sons, Inc., 1947.
[3] C. Baum and V. V. Veeravalli, “A sequential procedure for multiple
hypothesis testing,” IEEE Trans. Inf. Theory, vol. 40, pp. 1994–2007,
1994.
[4] V. P. Dragalin, A. G. Tartakovsky, and V. V. Veeravalli, “Multihypothesis
sequential probability ratio tests–part I: Asymptotic optimality,” IEEE
Trans. Inf. Theory, vol. 45, no. 7, pp. 2448 –2461, Nov. 1999.
[5] H. Chernoff, “Sequential design of experiments,” Ann. Math. Statist.,
vol. 30, pp. 755–770, 1959.
[6] M. Naghshvar and T. Javidi, “Active M-ary sequential hypothesis
testing,” in Proc. of the IEEE Int. Symp. on Inf. Theory (ISIT), Jun.
2010, pp. 1623 –1627.
[7] M. V. Burnaˇev, “Data transmission over a discrete channel with
s
feedback. random transmission time,” Probl. Pered. Inf., vol. 12, no. 4,
pp. 10 –30, 1976.
[8] M. Naghshvar and T. Javidi, “Variable-length coding with noiseless
feedback and ﬁnite messages,” in Proc. of the 44-th Asilomar Conf.
on Signals, Syst. and Comput., Monterey, California, USA, Nov 7-10,
2010, pp. 317–321.
[9] T. M. Cover and J. A. Thomas, Elements of Information Theory. NY:
John Wiley and Sons, Inc., 2006.
[10] V. Veeravalli and C. Baum, “Asymptotic efﬁciency of a sequential
multihypothesis test,” IEEE Trans. Inf. Theory, vol. 41, no. 6, pp. 1994
–1997, Nov. 1995.
[11] P. L. Hsu and H. Robbins, “Complete convergence and the law of large
numbers,” Proc. Nat. Acad. Sci., vol. 33, no. 2, pp. 25–31, Feb. 1947.

A PPENDIX
Proof of (27) and (28):
The condition in (28) follows directly from the consistency of
the GLR estimator, i.e., ˆk → i w.p. 1 (with probability 1),
i
∗
where i is the true hypothesis. Consequently q (k) → qi w.p.
1. Deﬁne T3 as the ﬁrst time such that ˆk = i, ∀n ≥ T3 . Then,
i
∗
(q (k) (u) − qi (u))du ≤ KT3
ij

k=1 u∈U
]
n
( (
∑∑
))
∗
(k)
u
exp s Zij (n) −
q (u)dij + nϵ1

n
≤ O(γ1 ) for some γ1 < 1.

VI. C ONCLUSION

n
∑∑

n
∑

(32)

k=1 u∈U

for some constant K > 0. Hence, by the consistency of the
GLR estimator and the ﬁniteness of the set M
n
Pi {T3 > n} ≤ O(γ3 )

where γ3 < 1. Hence, (28) follows.
To argue the condition in (27) note that
[
pUk (Xk ) ] ∑ (k)
=
q (u)du .
Ei log i k
ij
pU (Xk )
j
u∈U

5

