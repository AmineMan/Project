[[[ ID ]]]
1569565389
[[[ INDEX ]]]
253
[[[ TITLE ]]]
Shannon Entropy Convergence Results in the Countable Infinite Case
[[[ AUTHORS ]]]
J. Silva
P. Parada
[[[ ABSTR ]]]
Not saved
[[[ BODY ]]]
Not saved
[[[ REFS ]]]
T. M. Cover
--
Elements of Information Theory
----
Siu-Wai Ho
--
Shannon information measures
----
Siu-Wai Ho
--
and variational distance
----
I. Csisz´ r
--
tutorial
----
L. Devroye
--
Combinatorial Methods in Density Estimation
----
Francisco Piera
--
Shannon entropy
----
S. Kullback
--
“On information and sufﬁciency
----
Given that µ ∈ H(X)
˜2
--
convergence theorem [12
----
Remark 3: It is important to mention that from i)
which concludes the proof from iii).
--
have that µ ∈ H(X|µn ) ∀n
[[[ META ]]]
xmlpapertitle -> Shannon Entropy Convergence Results in the Countable Infinite Case
parsed -> yes
xmlabstract -> The convergence of the Shannon entropy in the countable infinity case is revisited and extended in this work. New results are presented that provide necessary and sufficient conditions for the convergence of the entropy in different settings, including scenarios with both finitely and infinitely supported measures. These results show some connections between the Shannon entropy convergence and the convergence in information divergence.
xmlsessionid -> S1.T8.2
xmlendtime -> 11:10
xmlpaperid -> 1569565389
xmlsession -> S1.T8: Information Theoretic Tools and Properties
xmldate -> 1341219000000
file -> PapersDataset\1569565389.txt
xmlstarttime -> 10:50
xmlauthors -> Jorge Silva, Patricio Parada
xmlroom -> Stratton (491)
[[[ LINKS ]]]

