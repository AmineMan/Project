[[[ ID ]]]
1569564291
[[[ INDEX ]]]
139
[[[ TITLE ]]]
Biff (Bloom Filter) Codes: Fast Error Correction for Large Data Sets
[[[ AUTHORS ]]]
M. Mitzenmacher
G. Varghese
[[[ ABSTR ]]]
Not saved
[[[ BODY ]]]
Not saved
[[[ REFS ]]]
Trans. on Knowledge
invertible Bloom ﬁlters. IEEE
data streams via Newton’s identities
M. T. Goodrich. Straggler identiﬁcation in round-trip
D. Eppstein
--
23(2):297-306
----
M. Goodrich
--
pp
----
M. Luby
--
51(1):120–127
----
M. Mitzenmacher
--
pp
----
M. Molloy. The pure literal rule threshold
--
pp
----
M. Patrascu
--
pp
----
E. Porat
--
pp
[[[ META ]]]
xmlpapertitle -> Biff (Bloom Filter) Codes: Fast Error Correction for Large Data Sets
parsed -> yes
xmlabstract -> Large data sets are increasingly common in cloud and virtualized environments. For example, transfers of multiple gigabytes are commonplace, as are replicated blocks of such sizes. There is a need for fast error-correction or data reconciliation in such settings even when the expected number of errors is small.

Motivated by such cloud reconciliation problems, we consider error-correction schemes designed for large data, after explaining why previous approaches appear unsuitable. We introduce Biff codes, which are based on Bloom filters and are designed for large data. For Biff codes with a message of length $L$ and $E$ errors, the encoding time is $O(L)$, decoding time is $O(L + E)$ and the space overhead is $O(E)$. Biff codes are low-density parity-check codes; they are similar to Tornado codes, but are designed for errors instead of erasures. Further, Biff codes are designed to be very simple, removing any explicit graph structures and based entirely on hash tables. We derive Biff codes by a simple reduction from a set reconciliation algorithm for a recently developed data structure, invertible Bloom lookup tables. While the underlying theory is extremely simple, what makes this code especially attractive is the ease with which it can be implemented and the speed of decoding, which we demonstrate with a prototype implementation.
xmlsessionid -> S3.T6.2
xmlendtime -> 15:20
xmlpaperid -> 1569564291
linked -> yes
xmlsession -> S3.T6: Codes and Their Applications
xmldate -> 1341234000000
file -> PapersDataset\1569564291.txt
xmlstarttime -> 15:00
xmlauthors -> Michael Mitzenmacher, George Varghese
xmlroom -> Kresge Rehearsal A (033)
[[[ LINKS ]]]
148 8
----
150 8
----
397 8
----
411 8
----
569 8
