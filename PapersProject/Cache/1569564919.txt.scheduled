[[[ ID ]]]
1569564919
[[[ INDEX ]]]
183
[[[ TITLE ]]]
On the Uncertainty of Information Retrieval in Associative Memories
[[[ AUTHORS ]]]
E. Yaakobi
J. Bruck
[[[ ABSTR ]]]
Not saved
[[[ BODY ]]]
Not saved
[[[ REFS ]]]
Y. Cassuto
--
“Codes for symbol-pair read channels
----
S. Kannan
--
“More on reconstructing strings from random traces: insertions and deletions
----
V.I. Levenshtein
--
“Error graphs and the reconstruction
of elements in groups
----
K. Viswanathan
--
“Improved string reconstruction
over insertion-deletion channels
[[[ META ]]]
xmlpapertitle -> On the Uncertainty of Information Retrieval in Associative Memories
parsed -> yes
xmlabstract -> We (people) are memory machines. Our decision processes, emotions and interactions with the world around us are based on and driven by associations to our memories. This natural association paradigm will become critical in future memory systems, namely, the key question will not be ``How do I store more information?'' but rather, ``Do I have the relevant information? How do I retrieve it?''

The focus of this paper is to make a first step in this direction. We define and solve a very basic problem in associative retrieval. Given a word W, the words in the memory that are t-associated with W are the words in the ball of radius t around W. In general, given a set of words, say W, X and Y, the words that are t-associated with {W,X,Y} are those in the memory that are within distance t from all the three words. Our main goal is to study the maximum size of the t-associated set as a function of the number of input words and the minimum distance of the words in memory - we call this value the uncertainty of an associative memory. We derive the uncertainty of the associative memory that consists of all the binary vectors with an arbitrary number of input words. In addition, we study the retrieval problem, namely, how do we get the t-associated set given the inputs? We note that this paradigm is a generalization of the sequences reconstruction problem that was proposed by Levenshtein (2001). In this model a word is transmitted over multiple channels. A decoder receives all the channel outputs and decodes the transmitted word. Levenshtein computed the minimum number of channels that guarantee a successful decoder - this value happens to be the uncertainty of an associative memory with two input words.
xmlsessionid -> S1.T6.2
xmlendtime -> 10:30
xmlpaperid -> 1569564919
xmlsession -> S1.T6: Combinatorial Problems in Coding
xmldate -> 1341216600000
file -> C:\Users\Amine\git\Project\PapersProject\PapersDataset\1569564919.txt
xmlstarttime -> 10:10
xmlauthors -> Eitan Yaakobi, Jehoshua Bruck
xmlroom -> Kresge Rehearsal A (033)
[[[ LINKS ]]]

