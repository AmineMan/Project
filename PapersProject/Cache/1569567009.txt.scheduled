[[[ ID ]]]
1569567009
[[[ INDEX ]]]
605
[[[ TITLE ]]]
Multi-Level Error-Resilient Neural Networks
[[[ AUTHORS ]]]
A. Karbasi
A. H. Salavati
[[[ ABSTR ]]]
Not saved
[[[ BODY ]]]
Not saved
[[[ REFS ]]]

[[[ META ]]]
xmlpapertitle -> Multi-Level Error-Resilient Neural Networks
parsed -> yes
xmlabstract -> The problem of neural network association is to retrieve a previously memorized pattern from its noisy version using a network of neurons. An ideal neural network should include three components simultaneously: a learning algorithm, a large pattern retrieval capacity and resilience against noise. Prior works in this area usually improve one or two aspects at the cost of the third. 

Our work takes a step forward in closing this gap. More specifically, we show that by forcing natural constraints on the set of learning patterns, we can drastically improve the retrieval capacity of our neural network. Moreover, we devise a learning algorithm whose role is to learn those patterns satisfying the above mentioned constraints. Finally we show that our neural network can cope with a fair amount of noise.
xmlsessionid -> S6.T8.4
xmlendtime -> 12:50
xmlpaperid -> 1569567009
xmlsession -> S6.T8: Probability and Estimation
xmldate -> 1341311400000
file -> PapersDataset\1569567009.txt
xmlstarttime -> 12:30
xmlauthors -> Amin Karbasi, Amir Hesam Salavati
xmlroom -> Stratton (491)
[[[ LINKS ]]]

