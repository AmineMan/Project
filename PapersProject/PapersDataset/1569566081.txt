Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Thu May 17 05:35:14 2012
ModDate:        Tue Jun 19 12:54:39 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      456259 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569566081

Reliable versus Unreliable Transmission for Energy
Efﬁcient Transmission in Relay Networks
Anders Høst-Madsen

Nan Jiang, Yang Yang, and Zixiang Xiong

Dept of Electrical Engineering
University of Hawaii, Honolulu, HI 96822
Email: ahm@hawaii.edu

Dept of ECE
Texas A&M University, College Station, TX 77843
Email: {nanjiang,yangyang}@tamu.edu, zx@ece.tamu.edu

on the contents of the packages. With reliable transmission,
the functions operate on both contents of packets and channel
coding parts. In all cases, a big advantage is that the layering
of the network according to the OSI 7-layer model is maintained, even if some crosslayer interfacing is needed. On the
other hand, general network information theory methods may
require completely scrapping the separation between the lower
3-4 layers. It might be worth having that disruption; but to
argue that we should be able to quantify the gain achieved by
non-reliable transmission. Thus, we need to be able to bound
the rate achievable by reliable transmission, even if we want
to consider non-reliable transmission.
The aim of this paper is to quantify the gain achievable
by non-reliable transmission in a few cases. Deterministic
capacity was introduced in [3] as the supremum of all rates
achievable by reliable transmission. The gain G (energy savings) for non-reliable transmission therefore satisﬁes

Abstract—A network code is said to be reliable when all transmissions in the network are (deterministic) functions of the source
messages; well-known examples include decode-forward for relay
networks. It is said to be unreliable when transmissions depend
on the noise realization at nodes; examples include compressforward and amplify-forward. The deterministic capacity of a
network is deﬁned as the supremum of the rates achievable by
reliable codes. In this paper we derive the deterministic capacity
of some relay networks in the low power regime. The resulting
energy per bit is then compared with the one achievable by
arbitrary transmission.

I. I NTRODUCTION
Coding methods for wireless networks can generally be divided into two classes: those where relays process the received
signal and forwards it, and those where the relays decode (a
function of) the original message, and encodes this into a
new signal. In the ﬁrst class (some times denoted estimateforward) are methods such as amplify-forward and compressforward [1, Theorem 6] that have wide set of generalizations.
The second class (sometime denoted regenerative coding) has
as its source the original decode-forward strategy of [1].
What characterizes these methods, as opposed to the ﬁrst
class, is that relays decode the original message, or more
generally, a function of the original message, reliably, and
transmits a message which is a possibly different function
of the decoded message (e.g., in [2] the parity information).
One way to characterize this class is that the transmission
is reliable. Relays decode their messages with a vanishing
error probability, and base their transmission on deterministic
functions of the messages. We will therefore denote this type
of coding as reliable coding. In contrast, amplify-forward type
methods introduce further randomness through the noise at the
relays. Informally one could say that amplify-forward type
methods introduce errors in their transmission streams, while
reliable transmission eliminates errors.
Why reliable transmission? One way to think of reliable
transmission is as follows: nodes decode transmitted packages, with few errors. They then compute functions of these
packages, and transmit these new computed packages. In a
traditional multi-hop network, the functions are the identity
functions. With network coding, the functions operate only

G ≥

Eb (lower bound for deterministic capacity)
(1)
Eb (achievable by arbitrary transmission)

G ≤

Eb (achievable by deterministic codes)
(2)
Eb (lower bound for arbitrary transmission)

and

Clearly, for (1) we need a bound on reliable codes, which is
exactly provided by deterministic capacity.
II. D EFINITIONS AND I NITIAL R EMARKS
We consider a network with N nodes as in [4, Sec.
15.10]. We denote the transmitted symbol (which might be
a vector) at time m at node i by Xi [m] and the string
of transmitted symbols in the interval 1 . . . k by X i [k] =
[Xi [1], Xi [2], . . . , Xi [k]]. Similarly for the received signals
Yi [n] and Y i [n] at node i. The output alphabet at node i
is Xi , the input alphabet Yi , and the nodes are connected
through memoryless channels. A (length n) code for the
network is deﬁned as in [4, Sec. 15.10]: Node 1, the source
has a message W intended for node N that it transmits at
rate R; we consider the message a uniform random variable
over 1, 2, . . . , 2nR . The encoder at node 1 is a function
n
X 1 [n] : 1, 2, . . . , 2nR → X1 and the transmission at node
1 is X 1 [n](W ). At node i > 1 the encoder is a function
m−1
Xi [m] : Yi
→ Xi that depends only on past received

Work supported in part by NSF grants 1017823 & 1017829 and by the
Qatar National Research Fund.

1

symbols, that is the transmission is Xi [m](Yi [1] . . . Yi [m−1]),
m ∈ {1, . . . , n} . The decoder at node N is a function
n
ˆ
W : Yi → 1, 2, . . . , 2nR , and the performance is measured
by the average error probability
ˆ
= P (W = W ).

Pe

In general, we will denote rates in the low power regime
by sans serif.
We need the following generalizations of results in [5].
Lemma 2. Suppose that for each value of B a random (N vector) variable X(B) that satisﬁes var[X(B)] ≤ P is given.
Let Y = cH X(B) + Z, where Z ∼ N (0, N0 B). Then

(3)

Thus far the setup is exactly like in [4, Sec. 15.10]. We now
deviate by introducing a corresponding deterministic code:
ˆ
X i [n]

:

1, 2, . . . , 2nR → Xin

lim BI(X(B); Y )

B→∞

(4)

ˆ
lim P {W (Y N [n]) = W } = 0.

Y1

(6)

The deﬁnition of deterministic capacity is abstract and very
general. The essence is that it allows arbitrary computations
on the data; general capacity allows arbitrary computations
on the signals.
We will here restrict attention to Gaussian channels as
they are representative of wireless networks. The received
signal is subject to additive complex Gaussian noise of
power BN0 , where N0 is the noise power spectral density,
and B is the bandwidth. The complex channel gain from
node i to node j is cji . Each node is subject to a power
n
1
constraint n k=1 |Xi [k]|2 ≤ Pi . In many cases we will
N
consider a total power constraint i=1 Pi ≤ P .

=
min

P
C log e

+ Z2

(11)

var[cH X(B)]
1
B→∞
N0 ln 2
var[cH X(B)|U (B)]
1
− lim
B→∞
N0 ln 2
lim BI(X(B); Y2 |U (B))
=

lim

(12)

B→∞

var[cH X(B)|U (B)]
2
B→∞
N0 ln 2
lim BI(U (B); Y1 |V (B))
=

lim

(13)

B→∞

=

var[cH X(B)|V (B)]
1
B→∞
N0 ln 2
var[cH X(B)|U (B), V (B)]
1
− lim
B→∞
N0 ln 2
lim

(14)

Assuming all limits are deﬁned.
Claim 1 of Lemma 3 can be used to argue that the (lower
bound on) minimum energy per bit is achieved for B → ∞.
Then claim 2 can be used to actually compute the limits.
IV. D ETERMINISTIC C APACITY OF R ELAY N ETWORKS IN
THE L OW P OWER R EGIME
Consider a network that uses the sequence of reliable
codes X i [n], that is, there exists a corresponding sequence
ˆ
of deterministic codes X i [n] satisfying (5). Deﬁne

(7)

we have multiplied with N0 / log e to simplify formulas in the
following. From this quantity energy per bit can be found by
Eb
N0

=

lim BI(U (B); Y1 )

In the rest of the paper we will concentrate solely on energy
per bit, rather than general capacity. The reason is that for
deterministic capacity, see Lemmas 2-3, it is possible in many
cases to obtain the limit of capacity for SNR → 0, even if
deterministic capacity is not known for general SNR > 0; at
the same time, for deterministic capacity, the minimum energy
per bit is achieved for SNR → 0 (this may not be true for
general capacity). It is therefore possible to evaluate (1) even
when general deterministic capacity is unknown.
If we denote by C(B) the capacity in bits/s/Hz for a given
bandwidth, we can deﬁne the following limit (if it exists)
N0
lim BC(B),
log e B→∞

(10)

cH X(B)
2

B→∞

III. T HE L OW P OWER R EGIME

=

cH X(B) + Z1
1

where Z1 and Z2 are independent, Z1 , Z2 ∼ N (0, N0 B).
Suppose that (U (B), V (B)) → X(B) → Y1 and
(U (B), V (B)) → X(B) → Y2 form Markov chains. Then
1) For
ﬁxed
U, V, X,
BI(X; Y1 ),
BI(U ; Y1 ),
BI(X; Y2 |U ), and BI(U ; Y1 |V ) are increasing
functions of B.
2) We have the following limits.

The deterministic capacity is the supremum of all rates R that
are achievable by deterministic codes. We say that a sequence
of codes X i [n] is reliable if there exist a corresponding
ˆ
sequence of deterministic codes X i [n] so that (5) is satisﬁed.

C

=

Y2

(5)

n→∞

(9)

Lemma 3. Suppose that for each value of B we are given
random variables U (B), V (B),and a vector random variable
X(B) that satisfy var[X(B)] ≤ P . Deﬁne

Deﬁnition 1. A rate R is said to be achievable by deterministic codes if there exists a sequence of (2nR , n) codes
{X i [n], i = 1 . . . N } and a sequence of corresponding deterˆ
ministic codes{X i [n], i = 1 . . . N }, so that
n→∞

var[cH X(B)]
B→∞
N0 ln 2
lim

Furthermore, BI(X(B); Y ) is an increasing function of B.

and making the following deﬁnition

ˆ
∀i : lim P {X i [n](W ) = X i [n](Y i [n])} = 0

=

Wi

ˆ
= X i [n]

(15)

and notice that for deterministic capacity, node i must be
able to decode at least Wi with asymptotically zero error

(8)

2

probability. In the following deﬁne
H(W )
R = lim
n→∞
n
H (Wi∈A |Wj∈B )
RA|B = lim
n→∞
n
A. The Diamond Relay Channel without Direct Link

3

(16)
2

(17)
1

Assume that the relays are ordered so that |ci1 | ≥ |cj1 |
for i ≤ j. For deterministic capacity, each relay must be
able to decode a message Wi = fi (W ). The channel from
the source to the relays forms a degraded broadcast channel
with correlated messages. It is clear that if i ≤ j, node i
can also decode message Wj . We can therefore assume that
the message set is also degraded in the sense that there exist
functions gi so that Wi = gi−1 (Wi−1 ). The capacity of the
channel from the source to the relays is therefore given by
the usual capacity expression for the degraded Gaussian relay
channel [6], with Ri replaced by Ri|i+1,i+2,...N −1 ,
Ri|i+1,i+2,...N −1 ≤ log 1 +

Diamond Relay Channel with direct link.

We consider the following coding scheme, which we will call
successive cooperation. We divide the transmission time into
three intervals. In the ﬁrst time interval node 1 transmits X 1
1
so that node 2 can decode the message W . In the second time
interval node 2 transmits X 2 and node 1 transmits X 2 = k1 X 2
2
1
2
(where k1 is a complex constant), so that the signals from
nodes 1 and 2 add up coherently at the destination, node 4.
Node 3 decodes the message W from Y 1 and Y 2 , the signals
1
1
received during the ﬁrst and second time interval.In the third
time interval node 3 transmits X 3 and nodes 1 and 2 transmit
X 3 = k2 X 3 and X 3 = k3 X 3 , so that all the signals add up
1
2
coherently at the destination.

αi P
N0 B + j<i αj P

Theorem 4. Consider the diamond relay channel with a total
power constraint and assume that |c21 | ≥ |c31 | ≥ |c41 | . Fix
the rate R. The total power required to achieve this rate with
deterministic codes is then bounded by P ≥ l3 2 + l2 2 +
|l11 |2 , where the right hand side is given by the minimum of
the two following solutions

The channel from the relays to the destination is a MAC
channel with correlated messages. The capacity is not known
in general, but in this special case it’s easy to see that we have
the outer bound
R2,...i|i+1,...,N −1

4

Figure 1.

≤ I(X2 , . . . Xi ; YN |Xi+1 , . . . , XN −1 )

|l11 |2

The proof closely follows the usual MAC proof in [4].
The above outer bound is achievable as follows. Deﬁne
˜
˜
independent messages W2 , . . . , WN −1 . The source transmits
˜ 2 , . . . , WN −1 . Relay i (and therefore
˜
a superposition of W
˜
also relays 2, . . . , i − 1) decodes message Wi . Relays 2, . . . , i
˜ i to the destination. It is imjointly beamform message W
mediate that this achieves the above outer bound region
asymptotically.

|l12 |2
|l22 |2
l3

2

B. The Diamond Relay Channel with Direct Link
What made the problem easy for the diamond relay channel
without a direct link is that the source-relay and relaydestination channel are separate. When we add a direct link
from the source to the destination, this is no longer true. The
channel out of the source is still a type of broadcast channel,
but it is no longer degraded. The capacity therefore is not
known. The best outer bounds therefore are those of Marton
and Körner [7] and Nair and El Gamal [8], which we will
modify and apply here. The Marton-Körner type bounds do not
have any known general extensions to more than two sources,
so we will have to limit results to at most two relays, see Fig.
1. Furthermore, the distributions of auxiliary random variables
are in general essentially impossible to ﬁnd. This is where the
low power theory, Section III gets into the picture. This allows
us to directly ﬁnd bounds on energy, without ﬁnding bounds
on capacity.
Without loss of generality we can assume that |c21 | ≥ |c31 |.
First, let us outline an achievable deterministic coding scheme.

|l11 |2

=

l2

2

=

l3

2

=

R
|c21 |2
1
1
=
−
R,
2
|c31 |
|c21 |2
|c41 |2 |c42 |2 |l12 |2
=
(|c41 |2 + |c43 |2 )2
R − |c41 |2 |l12 |2 − |c42 |2 |l22 |2
=
|c41 |2 + |c42 |2 + |c43 |2
2|c41 ||l12 ||c42 ||l22 | + |c41 |2 |l11 |2
−
.
|c41 |2 + |c42 |2 + |c43 |2
=

(18)

R
|c21 |2
R − |c31 |2 |l11 |2
|c41 |2 + |c42 |2
R − (|c41 |2 + |c42 |2 ) l2 2 − |c41 |2 |l11 |2
.(19)
|c41 |2 + |c42 |2 + |c43 |2

If
|c42 |2 |c43 |2 (|c42 |2 + |c43 |2 )
|c43 |2 (|c41 |2 + |c43 |2 )
|c41 |4 (4|c42 |2 + |c43 |2 )
+
|c43 |2 (|c41 |2 + |c43 |2 )
|c41 |2 4|c42 |4 + 2|c42 |2 |c43 |2 + |c43 |4
+
(20)
|c43 |2 (|c41 |2 + |c43 |2 )
successive cooperation achieves the deterministic capacity in
the low power regime.
|c31 |2

3

≥

(where limn→∞ n = 0 [4]). Denote P0 = P (E = 0) and
P1 = P (E = 1). With this we get

Proof: We will provide the principles of the proof. The
full details can be found in [9]. We will prove the bounds
(compare [8])
R

nR

≤ I(U ; Y4 )

(21)

≤

≤ I(U3 ; Y3 |X3 )

(22)

(a)

R

≤ I(U ; Y4 |U3 , X3 ) + I(U3 ; Y3 |X3 )

(23)

R

≤ I(X1 ; Y2 |X2 , X3 )

(24)

R3

≤
≤

≤
=

=

n

n

+ I(W ; Y 2 [n]|E = 0)P0

n

n

+ I(W ; Y 2 [n]|E = 0)P0

n

n

H(Y2 [m]|Y 2 [m − 1], E = 0)

+ P0

n

n
n

H(Y2 [m]|Y 2 [m − 1], X2 [m], X3 [m], E = 0)

+P0
m=1

−H(Y2 [m]|Y 2 [m − 1], W, X2 [m], X3 [m], E = 0)
n

≤

n

n + P0

H(Y2 [m]|X2 [m], X3 [m], E = 0)
m=1

−H(Y2 [m]|X1 [m], X2 [m], X3 [m], E = 0)
n

≤

n

n

+ P0

I(X1 [m]; Y2 [m]|X2 [m], X3 [m], E = 0)
m=1

n

+P1

I(X1 [m]; Y2 [m]|X2 [m], X3 [m], E = 0)
m=1
n

=

n

n

+

I(X1 [m]; Y2 [m]|X2 [m], X3 [m], E)
m=1
n

≤

n

n

I(X1 [m]; Y2 [m]|X2 [m], X3 [m]) + nH( n )

+
m=1
n

=

n

n

+

I(X1 [m]; Y2 [m]|X2 [m], X3 [m]).

(30)

m=1

In step (a) we have used (29), in (b) n n has absorbed
H(W )P (E = 1) ≤ nR n and H( n ). Step (c) follows from
the fact that X2 [m] is a function of Y 2 [m−1], and, conditioned
on E = 0, so is X3 [m].
Applying Lemmas 2-3 to equations (21-24) we then obtain
R

ˆ
ˆ
X 3 [n] = X 3 [n](Y 3 [n]) or X 3 [n] = X 3 [n](Y 3 [n])
,
ˆ [n] = X [n](Y [n]) = X [n](Y [n])
X3
3
3
3
3

Notice that by the deﬁnition of deterministic capacity, Deﬁnition 1, P (E = 1) = n . Furthermore, for any random variables
A and B
n

+ I(W ; Y 2 [n]|E = 0)P0

−H(Y2 [m]|Y 2 [m − 1], W, E = 0)
(c)

ˆ
ˆ
c41 X 1 [n] + c42 X 2 [n] + c43 X 3 [n] + Z 4 [n]27)
(
ˆ
ˆ
= c41 X 1 [n] + c42 X 2 [n] + c43 X 3 [n]
4
c41
(28)
+
Z [n] + Z 4 [n].
c21 2
ˆ
A genie provided with Y 4 [n] can decode W , as with high
ˆ [n] = Y [n]. Since Y [n] and Y [n] have
ˆ
ˆ
probability Y 4
4
4
4
1
ˆ
the same distribution , a genie provided Y 4 [n] can also
decode W with high probability. Finally, with high probability
ˆ
Y 4 [n] = Y 4 [n], and node 2 can therefore decode W with high
probability.
We will now use this fact to prove (24). For this we need
a more careful accounting of errors and we therefore deﬁne

≤ H( n ) =

n

m=1

=

|I(A; B) − I(A; B|E)|

n

n

where Z4 [n] is iid Gaussian noise with power
2
ˆ
1 − |c41 |2 N0 B and X 3 [n] is the deterministic code
|c21 |
corresponding to X 3 [n]. Consider the companion signals

1
0

+ I(W ; Y 2 [n])

+H(W )P (E = 1) + H( n )
(b)

where Z3 [n] is iid Gaussian noise with power
2
1 − |c31 |2 N0 B. Since Y 3 [n] has the same distribution as
|c21 |
Y 3 [n], node 2 can decode W3 with high probability for large
n. It then forms
c41
ˆ
Y 4 [n] =
Y [n] + c42 X 2 [n] + c43 X 3 [n] + Z 4 [n]
c21 2
ˆ
= c41 X 1 [n] + c42 X 2 [n] + c43 X 3 [n]
c41
(26)
+
Z [n] + Z 4 [n],
c21 2

E=

n

+I(W ; Y 2 [n]|E = 1)P1 + H( n )

for some joint distribution p(u3 )p(u|u3 )p(x3 |u3 )p(x1 , x2 |u).
As an example of the methodology of deterministic capacity
we will prove (24); the other bounds follow similar principles.
The ﬁrst step is to argue that node 2 can decode the full
message W as |c21 | ≥ |c31 | ≥ |c41 |. Node 2 can form
c31
Y [n] + Z 3 [n]
Y 3 [n] =
c21 2
c31
(25)
= c31 X 1 [n] +
Z [n] + Z 3 [n],
c21 2

ˆ
Y 4 [n]
ˆ
Y [n]

n

≤

R3

≤

lim var[c42 X2 (B) + c43 X3 (B) + c41 X1 (B)]

B→∞
|c31 |2

lim var[X1 (B)|X3 (B)]

B→∞
2

−|c31 |
R

≤

lim var[X1 (B)|X3 (B), U3 (B)]

B→∞

lim var[c42 X2 (B) + c43 X3 (B)

B→∞

+c41 X1 (B)|U3 (B), X3 (B)]
+|c31 |2 lim var[X1 (B)|X3 (B)]

(29)

B→∞

−|c31 |2 lim var[X1 (B)|X3 (B), U3 (B)]

ˆ
subtlety here is that X 2 [n] and Z 2 [n] are independent due to the
deterministic assumption, whereas X 2 [n] and Z 2 [n] are not independent;
that is the reason we need three different companion signals.
1 The

B→∞

R

4

≤

2

|c21 |

lim var[X1 (B)|X2 (B), X3 (B)].

B→∞

(31)

Upper bound
Lower bound

18
16

0.25

14
0.2
Lower bound on G (dB)

Energy saving (G) by non−reliable transmission (dB)

20

12
10
8

0.15

Node 2
0.1

6

0.05

4

Node 1

0
0

2
1
2

2

0

4
6

−1 Node 4
8

0
0
10

10
1

2

10

3

10

10

N

Figure 2. Energy saving for symmetric N -relay diamond relay channel
without direct link.

lim cov[X(B)]

B→∞

= LL ; S = L

−1

X.

as with amplify-forward [10]. We plot the the performance for
the symmetric channel. The result is in Fig. 2.
For the 2-relay diamond relay channel with a direct link,
we compare the energy corresponding to the outer bound on
deterministic capacity given by Theorem 4 with that achievable
by amplify-forward for various relay positions, see Fig. 3.

(32)

Here L = {lij } is a triangular matrix found through Cholesky
factorization. The random variables S are asumptotically uncorrelated (but not necessarily independent). We now use
that var[S1 |S3 ] ≤ var[S1 ] and similar and var[S1 |S3 , U3 ] =
var[S1 |U3 ] and similar, as S3 is a function of U3 . Since |c31 | ≥
|c41 | the bounds are maximized if we set var[S1 |U3 ] = 0.
Furthermore limB→∞ var[Si ] = 1, and we put
α

=

lim var[S2 ] − lim var[S2 |U3 ],

B→∞

VI. C ONCLUSION
We have seen that it is possible to calculate bounds on the
energy gain achieved by non-reliable transmission for some
examples. This is only possible because we have an abstract
deﬁnition of deterministic capacity through Deﬁnition 1; otherwise, it would just be a comparison of arbitrary achievable
rates. What the results prove is that unreliable transmission is
more energy efﬁcient, although perhaps the number of relays
have to be large for the gain to be (guaranteed) signiﬁcant.

(33)

B→∞

where 0 ≤ α ≤ 1. We can then write (31) as
R

≤

y position of node 3 (m)

Figure 3. Lower bound on energy savings for 2-relay diamond relay channel
with direct link.

Let
H

−2

x position of node 3 (m)

|c42 l23 + c43 l33 + c41 l13 |2
+|c42 l22 + c41 l12 |2 + |c41 l11 |2

≤

|c31 |2 |l11 |2 + |c31 |2 |l12 |2 α

R

≤

R

≤

|c42 l22 + c41 l12 | (1 − α) + |c31 | |l11 | + |c31 | |l12 | α [1] T. Cover and A. E. Gamal, “Capacity theorems for the relay channel,”
IEEE Transactions on Information Theory, vol. 25, no. 5, pp. 572–584,
|c21 |2 |l11 |2 .
(34)
September 1979.

R3

2

R EFERENCES
2

2

2

2

[2] P. Razaghi and W. Yu, “Parity forwarding for multiple-relay networks,”
IEEE Transactions on Information Theory, vol. 55, no. 1, pp. 158–173,
Jan. 2009.
[3] A. Høst-Madsen, “Deterministic capacity of networks,” in IEEE Information Theory Workshop (ITW’07), Lake Tahoe, CA, 2007.
[4] T. Cover and J. Thomas, Information Theory, 2nd Edition. John Wiley,
2006.
[5] D. Guo, S. Shamai, and S. Verdu, “Mutual information and minimum
mean-square error in Gaussian channels,” IEEE Transactions on Information Theory, vol. 51, no. 4, pp. 1261–1282, Apr. 2005.
[6] P. Bergmans, “A simple converse for broadcast channels with additive
white Gaussian noise,” IEEE Transactions on Information Theory, vol.
IT-20, no. 2, pp. 279–280, March 1974.
[7] K. Marton, “A coding theorem for the discrete memoryless broadcast
channel,” IEEE Transactions on Information Theory, vol. 25, no. 3, pp.
306–311, May 1979.
[8] C. Nair and A. E. Gamal, “An outer bound to the capacity region of the
broadcast channel,” IEEE Transactions on Information Theory, vol. 53,
no. 1, pp. 350–355, Jan. 2007.
[9] A. Høst-Madsen, “Deterministic capacity of networks in the low power
regime,” IEEE Trans. Inform. Theory, submitted.
[10] U. Niesen and S. Diggavi, “The approximate capacity of the gaussian
n-relay diamond network,” in Information Theory Proceedings (ISIT),
2011 IEEE International Symposium on, 31 2011-aug. 5 2011, pp. 259
–263.

To get an actual outer bound, these bounds must be maximized over the parameters lij and α and R3 . We ﬁx R and
minimize P . The key observation is that it turns out that
for any values of the other parameters the sign of ∂P is
∂α
independent of α. Any solution must therefore be on the
boundaries, that is for α = 0 or α = 1. The solution for
α = 0 can be shown to be (19) and for α = 1 to be (18). To
prove the ﬁnal claim of the proof the ﬁrst step is to realize
that any solution with α = 1 can be achieved with successive
cooperation (whereas this is not possible for α = 0). And if
the condition (20) is satisﬁed, the power consumption with
α = 1 is smaller than the power consumption with α = 0.
V. C OMPARISON OF R ELIABLE AND N ON -R ELIABLE
TRANSMISSION

The approximate capacity of the diamond relay channel
without direct link was found in [10]. We compare the energy
per bit achieved by deterministic capacity as outlined in Section IV-B with the outer bound on capacity from [10] as well

5

