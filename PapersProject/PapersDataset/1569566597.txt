Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Fri May 18 22:39:25 2012
ModDate:        Tue Jun 19 12:54:56 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      444986 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569566597

On Secure Communication with Constrained
Randomization
Matthieu R. Bloch

J¨ rg Kliewer
o

School of Electrical and Computer Engineering
Georgia Institute of Technology
Atlanta, Georgia 30332–0250
Email: matthieu.bloch@ece.gatech.edu

School of Electrical and Computer Engineering
New Mexico State University
Las Cruces, New Mexico 88003-8001
Email: jkliewer@nmsu.edu

of universal codes is even established without any assumption
regarding the eavesdropper’s channel statistics [7], [8].
In contrast to the problem of channel knowledge, little
attention has been devoted to the problem of imperfect local
sources of randomness. In particular, the questions of how
much randomness is required to guarantee secrecy and how
sensitive are secure communication codes to imperfections in
randomness are still largely open.
In this paper, we provide partial answers to these questions.
Our main contributions are 1) the characterization of secrecy
capacity with a rate-limited source of randomness and a less
capable eavesdropper’s channel, and 2) the derivation of a
sufﬁcient condition for secure communication with a nonuniform randomization.
The remainder of the paper is organized as follows. Section II introduces the wiretap channel model used to analyze
the effect of constrained randomization and presents our results
on the secrecy-capacity of wiretap channels with a ratelimited local source of randomness. Section III discusses the
possibility of secure communication with a non-uniform local
source of randomness that cannot be processed. All proofs are
relegated to appendices to streamline the presentation; due to
space limitations, some proof details are also omitted.

Abstract—In this paper, we investigate how constraints on the
randomization in the encoding process affect the secrecy rates
achievable over wiretap channels. In particular, we characterize
the secrecy capacity with a rate-limited local source of randomness and a less capable eavesdropper’s channel, which shows that
limited rate incurs a secrecy rate penalty but does not preclude
secrecy. We also show that secure communication is possible when
randomizing with a non-uniform source of randomness, which
suggests the possibility of designing robust coding schemes.

I. I NTRODUCTION
The wiretap channel model [1], [2] has attracted much
attention in recent years because of its potential to strengthen
the security of communication systems [3], [4]. Although this
model provides a convenient abstraction to design codes for
secure communication, it relies on two implicit simplifying
assumptions. First, the model assumes that the transmitter
knows the statistics of the channel. Second, the model assumes
that the transmitter has access to an arbitrary local source
of randomness, whose statistics can be optimized as part of
the code design. In practice, however, these assumptions are
unlikely to be perfectly guaranteed. For instance, an eavesdropper has little incentive to help characterize the channel
statistics and, realistically, the legitimate parties may only have
approximate knowledge of the true statistics. Similarly, the
statistics of the local source of randomness may be imperfectly
known, or the source may only provide a limited rate of
randomness.
Secure communications with imperfect channel knowledge
have already been the subject of previous investigations. For
instance, several works have studied compound wiretap channels (see [5] and references therein), in which the transmitter
only knows that its channel belongs to a set of possible
channels. Other works have investigated the secrecy capacity
of state-dependent channels under different assumptions regarding state information (see [3], [4] and references therein).
Finally, some recent works have shown the existence of
universal wiretap codes that guarantee secrecy as soon as the
channel capacity of the eavesdropper’s channel is known to be
low enough [6]; for multiple-antenna systems, the existence

We
consider
a
discrete
wiretap
channel
X , WYZ|X , Y × Z , characterized by a ﬁnite input alphabet
X , two ﬁnite output alphabets Y and Z, and transition
probabilities pYZ|X . As illustrated in Figure 1, we assume
that the transmitter (Alice) wishes to transmit a secret
message to the receiver observing Y n (Bob), in the presence
of an eavesdropper observing Zn (Eve). The channel
X , WY|X , Y is called the main channel while the channel
X , WZ|X , Z is called the eavesdropper’s channel. We
assume the eavesdropper’s channel is less capable, that is for
any input X we have I(X; Z) I(X; Y). The encoding process
may be stochastic, but the only source of randomness is a
discrete memoryless1 source (R, pR ) with known alphabet R
and known statistics pR . This model captures a situation in

This work was supported in part by the U.S. National Science Foundation
under grants CCF-0830666 and CCF-1017632.

1 The assumption of a memoryless source is a matter of convenience, and
the proofs in the appendices generalize to arbitrary sources.

II. R ATE -L IMITED R ANDOMNESS

1

A LICE

B OB

pR

M

Yn

ENCODER

Xn

DECODER

WYZ|X

Remark 3: Using standard techniques, one can show that
the cardinality of U is bounded by |U| 2.
The expression in Proposition 1 is similar to that obtained
in [2, Corollary 2]. The effect of the local source of randomness explicitly appears in the expression through the
auxiliary time-sharing random variable U and the constraint
I(X; Z|U) H(R). Proposition 1 conﬁrms the optimal structure of the encoder, which performs two distinct operations:

ˆ
M

E VE
Zn

Fig. 1.

Communication over a randomness-limited wiretap channel.

1) Uniformization: the encoder generates nearly-uniform
random numbers K at rate H(R) from the local source
of randomness;
2) Randomization: the encoder uses a fraction I(X; Z|U)
of the randomness rate to randomize the choice of a
codeword;

which the transmitter does not have access to a inﬁnite pool
of random numbers, and those must be generated on-the-ﬂy
during encoding from a source of randomness (thermal noise,
photon counting). In addition, it forces us to explicitly specify
how to use the randomness in the encoding process.
Deﬁnition 1: A (2nR , n) wiretap code Cn for the discrete
wiretap channel X , pYZ|X , Y × Z with local source of randomness (R, pR ) consists of the following.
nR
• a message alphabet M = 1, 2
;
n
n
• an encoding function e : M × R → X ;
n
• a decoding function f : Y → M ∪ {?}.
The performance of Cn is measured in terms of the average
ˆ
probability of error Pe (Cn )
P M = M|Cn and of the
secrecy leakage L(Cn )

The identiﬁcation of the optimal encoder structure suggests
that non-uniform randomization may affect the performance
of a code, which we discuss in Section III. Proposition 1 also
highlights that the common folklore in information-theoretic
security, according to which secrecy is achievable provided the
randomization can exhaust the capacity of the Eve’s channel,
is somewhat misleading. If the source provides a non-zero rate
of randomness (H(R) > 0), then the secrecy capacity with a
rate-limited source of randomness is positive if and only if
the secrecy capacity with unlimited randomness is positive.
Intuitively, this happens because the channel seen by Eve is
an “effective channel”, which is partly controlled by Alice
through time-sharing and the choice of the codebook.
Also note that if the rate of randomness vanishes, then
no secure communication is possible. This conﬁrms that,
except for pathological channels (for instance, one for which
I(X; Z) = 0 for any X), one cannot replace the local source
of randomness by a pseudo-random number generator without
losing the information-theoretic secrecy guarantees.

I(M; Zn |Cn )

Deﬁnition 2: A rate R is achievable if there exists a sequence of (2nR , n) wiretap codes {Cn }n 1 such that
lim Pe (Cn ) = 0 and

n→∞

lim L(Cn ) = 0.

n→∞

The (strong) secrecy capacity with rate-limited randomness Cs
is deﬁned as the supremum of all achievable rates.
Remark 1: The deﬁnition of a wiretap code above implicitly allows the encoder to process the observations obtained
from the local source of randomness. In particular, the encoder
can remove a possible bias in the randomness. What happens
when the encoder does not perfectly process the local source
is discussed in Section III.
Remark 2: The model can be viewed as a special case of
wiretap channel with channel state known non-causally at
the transmitter [9], in which the state is independent of the
channel; however, our result does not follow from [9] because
we consider a strong secrecy metric.
Proposition 1: The secrecy capacity of a wiretap channel
(X , WYZ|X , Y × Z) with a rate-limited source of local randomness (R, pR ) and a less capable eavesdropper’s channel2
is
Cs =

max

pUVXYZ ∈P

III. N ON -U NIFORM R ATE -L IMITED R ANDOMNESS
The result of Proposition 1 suggests that one should always
“uniformize” the local source of randomness to create uniformly distributed random numbers. This operation, however,
may be imperfect and one may wonder whether achieving
secrecy is then still possible. A situation where the random
numbers may not be perfectly uniform is if the local source
of randomness is another message source; understanding this
setting is crucial to assess whether secrecy constraints incur
an overall rate loss or not [4].
For simplicity, we assume that the output of uniformization
is a random variable K ∈ 1, 2nRr with perhaps non-uniform
distribution pK . In this case, we show that secrecy is still
achievable, but at a lower rate limited by the R´ nyi entropy
e
1
rate of order two n R2 (K) where



(I(X; Y|U) − I(X; Z|U))

where the set P is the set of distributions pUXYZ that factorize
as pUXYZ = pU pX|U WYZ|X and with I(X; Z|U) H(R).
Proof: See Appendix A and Appendix B.
2 We used the less capable assumption to avoid dealing with the problem of
channel preﬁxing. Days before submitting the current paper, [10] was posted
on ArXiv and independently solved the general case. Proposition 1 appears
as [10, Corollary 12].

R2 (K)

u∈

2

pK (u)2  .

− log 
1,2nRr

˜
˜
where Y i−1
{Yj }i−1 , Zi+1
{Zj }n
j=i+1 and δ( ) is a
j=1
function of that goes to zero with . Next, by deﬁnition of
the encoder e and by independence of Rn and M,

Proposition 2: A secrecy rate R is achievable when randomization is performed with randomness K if it satisﬁes
R<

max

pUXYZ ∈P

(I(X; Y|U) − I(X; Z|U)) ,

1
1
H(Xn |M) = H(e(M, Rn )|M)
n
n

where P is the set of distributions I(X; Y|U) that factorize as
1
pU pX|U WYZ|X and such that I(X; Z|U) < n R2 (K).
Proof: See Appendix C.
It is not straightforward to establish a converse for Proposition 2 because typical converse arguments make no assumption
regarding the internal structure of the encoder. In particular, it
seems difﬁcult to include a constraint that would prevent any
processing of K.
1
1
In general, n R2 (K)
n H(K), and the constraint in
Proposition 2 is therefore more stringent than in Proposition 1.
The effect can be quite dramatic, and the following example
shows that the gap between the rates in Proposition 1 and
Proposition 2 can be large.
Example 1: Assume the encoder performs randomization
with a biased local source of randomness, which produces
random numbers K ∈ 1, 2nRr such that
P(K = 1) = 2−nαRr and P(K = i) =

Now, we also have
1
H(Xn |M)
n
1
= H(Xn ) −
n
1
H(Xn ) −
n
1
= H(Xn ) −
n
1
= H(Xn ) −
n

1
1
H(M) + H(M|Xn )
n
n
1
1
1
H(M) + H(M|Xn ) + I(M; Zn ) − δ( )
n
n
n
1
1
n
n
H(M|Z ) + H(M|X ) − δ( )
n
n
1
1
n n
H(MX |Z ) + H(Xn |MZn )
n
n
1
+ H(M|Xn ) − δ( )
n
1
1
= I(Xn ; Zn ) + H(Xn |MZn ) − δ( )
n
n
1
n
n
I(X ; Z ) − δ( ),
(2)
n

1 − 2−nαRr
if i = 1,
2nRr − 1

where the last inequality follows because M → Xn → Zn
forms a Markov chain and H(M|Xn Zn ) = H(M|Xn ). Then,

1
where α ∈]0; 2 [ is a parameter that controls the uniformity of
the distribution. Note that
1
R2 (K)
n→∞ n

lim

= αRr

whereas

1
H(K)
n→∞ n

lim

1
I(Xn ; Zn )
n
n
1
˜
˜
H Zi |Y i−1 Zi+1 − H Zi |Y i−1 Zi+1 Xi
n i=1

= Rr .

Consequently, without proper uniformization, the achievable
rates predicted in Proposition 2 could be arbitrarily small.

1
=
n

IV. C ONCLUSION
We have shown for the classical wiretap channel that strong
secrecy can be guaranteed even in the presence of nonuniform or rate-limited randomness, albeit at the expense of
a lower secrecy capacity. The result of this work enables
several interesting applications. For example, if the public
message in the wiretap channel model is identiﬁed as the
output of a source encoder, which is in general not uniformly
distributed, extra information can be conveyed publicly while
still providing secure communication. Another application is
secure transmission in a network, in which multiple links
are wiretapped by the same eavesdropper via channels with
different capacities and in which only a given amount of
randomness exists.

R
H(R)

R

I M; Yi |Y
i=1

i−1 ˜ i+1

Z

−I M; Zi |Y

i−1 ˜ i+1

Z

˜
I Xi ; Zi |Y i−1 Zi+1 ,

(3)

i=1

I(VQ ; YQ |QUQ ) − I(VQ ; ZQ |QUQ ) + δ( )

(4)

I(XQ ; ZQ |QUQ ) − δ( ).

(5)

Finally, deﬁne U UQ Q, V VQ Q, X XQ , Y YQ and
Z ZQ . Note that U → V → X → YZ forms a Markov chain
and that the statistics pYZ|X are those of the original channel
WYZ|X . Substituting these deﬁnitions in (4) and (5), we obtain
R

Let > 0 and let R be an achievable rate. Then, there exists
a (2nR , n) code Cn such that Pe (Cn )
and L(Cn )
.
Following the converse technique in [2], we obtain
n

n

where the inequality follows because conditioning does not
˜
increase entropy and Zi+1 Y i−1 → Xi → Zi forms a Markov
chain. Let us now deﬁne a random variable Q independent of
all others and uniformly distributed on 1, n . For i ∈ 1, n ,
˜
we also deﬁne Ui
Y i−1 Zi+1 and Vi
Ui M. Combining
inequalities (1), (2), and (3), and substituting the deﬁnition of
Q, Ui , Vi above, we obtain

A PPENDIX A
C ONVERSE P ROOF FOR P ROPOSITION 1

1
n

1
H(Rn ) = H(R) . (1)
n

H(R)

I(V; Y|U) − I(V; Z|U) + δ( )
I(X; Z|U) − δ( ).

Because the eavesdropper’s channel is less capable, then
+δ( ), I(V; Y|U) − I(V; Z|U) I(X; Y|U) − I(X; Z|U). Since can
be chosen arbitrarily small, we obtained the desired converse.

3

for some κ > 0. The fact that L(Cn ) 2−κ n for some κ > 0
follows from [12, Lemma 1]. Combining all rate constraints
in the previous lemmas, and since can be chosen arbitrarily
small, we see that any rate R < I(X; Y|U) − I(X; Z|U) such
that I(X; Z|U) H(R) is achievable. Note that the constraint
on R0 plays no role since it represents a negligible rate of time
sharing information to synchronize transmitter and receiver.

A PPENDIX B
ACHIEVABILITY P ROOF FOR P ROPOSITION 1
The proof relies on binning, superposition coding, and
stochastic encoding as in [2, Lemma 2]; however, since the
local source of randomness is explicit and since we impose
a strong secrecy criterion, some details must be laid out
carefully. We denote the set of -strongly typical sequences
with respect to pX by T n(X) and the set of conditional strongly typical sequence with respect to pYX and xn ∈ T n(X)
by T n(Y|xn ).
We ﬁrst show the existence of a code Cn assuming an
unlimited amount of uniform randomness is available. We ﬁx a
joint distribution pUX on U × X such that3 I(X; Z|U) H(R)
and I(X; Y|U) − I(X; Z|U) > 0, and we construct a code
Cn for the broadcast channel with conﬁdential messages
(X , pYZ|X , Y × Z). Let > 0, R > 0, Rr > 0, R0 > 0 and
n ∈ N. We randomly construct a code as follows. We generate
2nR0 sequences independently at random according to pU ,
which we label un (i) for i ∈ 1, 2nR0 . For each sequence
un (i), we generate 2n(R+Rr ) sequences independently at
random according to pX|U , which we label xn (i, j, k) with
j ∈ 1, 2nR and k ∈ 1, 2nRr . To transmit a message
i ∈ 1, 2nR0 and j ∈ 1, 2nR , the transmitter obtains a
realization k of a uniform random number K ∈ 1, 2nRr ,
and transmits xn (i, j, k) over the channel. Upon receiving y n ,
Bob decodes i as the received index if it is the unique one
such that (un (i), y n ) ∈ T n(U Y ); otherwise, he declares an
error. Bob then decodes (j, k) as the other pair of indices if
it is the unique one such that (xn (i, j, k), y n ) ∈ T n(U XY ).
Similarly, upon receiving z n , Eve decodes i as the received
index if it is the unique one such that (un (i), z n ) ∈ T n(U Z);
otherwise, she declares an error.
Lemma 1: If R0 < min(I(U; Y), I(U; Z)) and R + Rr <
I(X; Y|U), then E(Pe (Cn )) 2−αn for some α > 0.
Proof: The proof follows from a standard random coding
argument and is omitted.
Lemma 2: If Rr
>
I(X; Z|U), then we have
ECn (V(pMZn , pM pZn ))
2−βn for some β > 0, where V
denotes the variational distance.
Proof: See Appendix C.
Using Markov’s inequality, we conclude that there exists
at least one code Cn satisfying the rate inequalities in
Lemma 1 and Lemma 2, such that Pe (Cn )
3 · 2−αn and
−βn
V(pMM0 Zn , pM pM0 Zn )
3·2
. Finally, the uniform
numbers K can be approximately obtained from (R, pR ) with
an appropriate function φ.
Lemma 3 (adapted from [11]): If Rr < H(R), then there
exists φ such that V pφ(Rn ) , pK
2−nη for some η > 0.
Consequently, one can show that, even if the code Cn is used
with φ(Rn ) in place of K, then
Pe (Cn )

2−κn

and

V(pMM0 Zn , pM pM0 Zn )

A PPENDIX C
P ROOF OF P ROPOSITION 2
The proof is similar to that Appendix B, with Lemma 4 in
place of Lemma 2. Lemma 2 is obtained in the special case
of K uniform.
1
Lemma 4: If n R2 (K) > I(X; Z|U), then we have
ECn (V(pMZn , pM pZn )) 2−βn for some β > 0.
The proof relies on a careful analysis and a slight generalization of the “cloud-mixing” lemma [13]; the notation is
that of Appendix B. We deﬁne the distribution qUn Xn Zn on
U n × X n × Z n as
qUn Xn Zn (un , xn , z n ) = WZn |Xn (z n |xn )pXn Un (xn , un ).
First note that the variational distance V(pMZn , pM pZn ) can
be bounded as follows.
V(pMZn , pM pZn )
V(pMUn Zn , pM pUn Zn )
= EUn M V pZn |MUn , pZn |Un
EUn M V pZn |MUn , qZn |Un + V qZn |Un , pZn |Un
2EUn M V pZn |MUn , qZn |Un
Then, let Un be the sequence in U n corresponding to M0 = 1.
1
By symmetry of the random code construction, the average
of the variational distance V(pMZn , pM pZn ) over randomly
generated codes Cn satisﬁes
ECn (V(pMZn , pM pZn ))
2ECn V pZn |Un =Un M=1 , qZn |Un =Un
1
1

,

where
2nRr
n

WZn |Xn (z n |xn (1, 1, k))pK (k).

pZn |Un =Un M=1 (z ) =
1
k=1

The average over the random codes can be further bounded by
splitting the average between Un and the random code Cn (un )
1
1
for a ﬁxed value of un .
1
ECn V pZn |Un =Un M=1 , qZn |Un =Un
1
1
=

pUn (un )ECn (un ) V pZn |Un =un M=1 , qZn |Un =un
1
1
1
1
un ∈U n
1
n

2P(U ∈ T n(U))
/
+

pUn (un )ECn (un ) V pZn |Un =un M=1 , qZn |Un =un
1
1
1
1

un ∈T n(U)
1

2−κn .

where the last inequality follows from the fact that the variational distance is always less than 2. By construction, the ﬁrst
term on the right-hand side vanishes as n gets large; we now

3 If

such a probability distribution does not exist, then the result of
Proposition 1 is trivial and there is nothing to prove.

4

.

(a)

proceed to bound the expectation in the second term. First note
that, for any z n ∈ Z n ,

2−n(H(Z|X)−δ(

pXn |Un =un (xn )WZn |Xn (z n |xn )
1

n

ECn (un ) pZn |Un =un M=1 (z )
1
 nR 1

xn :(xn ,z n )∈T n(XZ|un )
1

2

n

−n(H(Z|X)−δ( ))



r

2

n

WZn |Xn (z |x (1, 1, k))pK (k)

= ECn (un ) 
1

(b)

k=1
2nRr

2−n(H(Z|X)+H(Z|U)−δ(

(1)

1{(xn (1, 1, k), z n ) ∈ T n(XZ|un )}
1

n

2nH(Z|U) 2− 2 (H(Z|X)+H(Z|U)−δ(

n

WZn |Xn (z |x (1, 1, k))pK (k)

n

= 2− 2 (

k=1
n

n

1{(x (1, 1, k), z ) ∈ T
/

(XZ|un )}
1

z n ∈T n(Z|un )
/
1

p(1) (z n ) − E p(1) (z n )
z n ∈T n(Z|un )
1

p(2) (z n ) − E p(2) (z n )

.

z n ∈T n(Z|un )
1

One can show that the average of the ﬁrst sum and of the last
sum vanish as n goes to inﬁnity. We now focus on the average
of the second sum. For z n ∈ T n(Z|un ), Jensen’s inequality
1
√
and the concavity of x → x guarantee that
Var p(1) (z n ) .

In addition,
2nRr

Var p

n

pK (k)2 Var WZn |Xn (z n |Xn (1, 1, k))

(z ) =
k=1

1{(Xn (1, 1, k), z n ) ∈ T n(XZ|un )})
1
Note that
Var WZn |Xn (z n |Xn (1, 1, k))1{(Xn (1, 1, k), z n ) ∈ T n(XZ|un )}
1
pXn |Un =un (xn )
1

=
xn ∈X n

WZn |Xn (z n |xn )1{(xn , z n ) ∈ T n(XZ|un )}
1

2

pXn |Un =un (xn )WZn |Xn (z n |xn )2
1

=

))

R EFERENCES

pZn |Un =un M=1 (z n ) − qZn |Un =un (z n )
1
1

E p(1) (z n ) − E p(1) (z n )

R2 (K)
)
n

(K)
Hence, if R2n > I(X; Z|U) + δ( ), the sum vanishes as n
goes to inﬁnity, which concludes the proof. Note that if K is
uniform, then R2 (K) = nRr , and we obtain Lemma 2.

V pZn |Un =un M=1 , qZn |Un =un
1
1

+

R2 (K)
−I(X;Z|U)−δ(
n

)+

n

so that we can upper bound V pZn |Un =un M=1 , qZn |Un =un
1
1
as

+

.

z n ∈T n(Z|un )
1

2nRr
n

R2 (K)
n

E p(1) (z n ) − E p(1) (z n )

k=1

(1)

−n(H(Z|X)+H(Z|U)−δ( ))+

pK (k)2

and

WZn |Xn (z n |xn (1, 1, k))pK (k)

(z )

2

−n(H(Z|X)+H(Z|U)−δ( ))
k=1

2nRr

p

n

(z )

We now let 1 denote the indicator function and we deﬁne

n

,

2

Var p

= qZn |Un =un (z n ).
1

(2)

))

2nRr

k=1

p(1) (z n )

qZn |Un =un (z n )
1

where (a) and (b) follow from the AEP; therefore,

ECn (un ) WZn |Xn (z n |xn (1, 1, k)) pK (k)
1

=

))

xn :(xn ,z n )∈T n(XZ|un )
1

5

[1] A. D. Wyner, “The Wire-Tap Channel,” Bell System Technical Journal,
vol. 54, no. 8, pp. 1355–1367, October 1975.
[2] I. Csisz´ r and J. K¨ rner, “Broadcast Channels with Conﬁdential Mesa
o
sages,” IEEE. Trans. Inf. Theory, vol. 24, no. 3, pp. 339–348, May 1978.
[3] Y. Liang, H. V. Poor, and S. S. (Shitz), Information-Theoretic Security, ser. Foundations and Trends in Communications and Information
Theory. Delft, Netherlands: Now Publishers, 2009, vol. 5, no. 1–5.
[4] M. Bloch and J. Barros, Physical-Layer Security: From Information
Theory to Security Engineering. Cambridge University Press, October
2011.
[5] Y. Liang, G. Kramer, H. V. Poor, and S. S. (Shitz), “Compound Wiretap
Channels,” EURASIP Journal on Wireless Comm. and Networking, vol.
142374, pp. 1–12, 2009.
[6] J. Muramatsu and S. Miyake, “Construction of Wiretap Channel Codes
by Using Sparse Matrices,” in Proc. IEEE Information Theory Workshop,
Taormina, Sicily, October 2009, pp. 105–109.
[7] X. He and A. Yener, “Providing secrecy when the eavesdropper channel
is arbitrarily varying: A case for multiple antennas,” in Proc. 48th
Annual Allerton Conf. Communication, Control, and Computing, 2010,
pp. 1228–1235.
[8] X. He, A. Khisti, and A. Yener, “MIMO Broadcast Channel with Arbitrarily Varying Eavesdropper Channel: Secrecy Degrees of Freedom,”
in Proc. IEEE Global Telecommunications Conf., 2011, pp. 1–5.
[9] Y. Chen and A. J. Han Vinck, “Wiretap Channel With Side Information,”
IEEE Transactions on Information Theory, vol. 54, no. 1, pp. 395–402,
2008.
[10] S. Watanabe and Y. Oohama, “Broadcast Channels with Conﬁdential
Messages by Randomness Constrained Stochastic Encoder,” preprint,
January 2012. [Online]. Available: arXiV:1201.6468
[11] R. Ahlswede and I. Csisz´ r, “Common Randomness in Information
a
Theory and Cryptography. II. CR Capacity,” IEEE Trans. Inf. Theory,
vol. 44, no. 1, pp. 225–240, January 1998.
[12] I. Csisz´ r, “Almost Independence and Secrecy Capacity,” Problems of
a
Info. Transmission, vol. 32, no. 1, pp. 40–47, January-March 1996.
[13] P. W. Cuff, “Communication in Networks for Coordinating Behavior,”
Ph.D. dissertation, Princeton University, July 2009.

