Creator:         TeX output 2012.05.18:1027
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Fri May 18 10:27:59 2012
ModDate:        Tue Jun 19 12:54:07 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      595.28 x 841.89 pts (A4)
File size:      413763 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569565661

Graph-based Code Design for Quadratic-Gaussian
Wyner-Ziv Problem with Arbitrary Side Information
Yi-Peng Wei*, Shih-Chun Lin†, Yu-Hsiu Lin* and Hsuan-Jung Su*
*Graduate Institute of Communication Engineering, National Taiwan University, Taipei, Taiwan
†Graduate Institute of Computer and Communication Engineering, National Taipei University of Technology, Taipei, Taiwan
r98943073@ntu.edu.tw, sclin@ntut.edu.tw, r97942045@ntu.edu.tw, hjsu@cc.ee.ntu.edu.tw
Abstract— Wyner-Ziv coding (WZC) is a compression technique using decoder side information, which is unknown at the
encoder, to help the reconstruction. In this paper, we propose and
implement a new WZC structure, called residual WZC, for the
quadratic-Gaussian Wyner-Ziv problem where side information
can be arbitrarily distributed. In our two-stage residual WZC, the
source is quantized twice and the input of the second stage is the
quantization error (residue) of the ﬁrst stage. The codebook of the
ﬁrst stage quantizer must be simultaneously good for source and
channel coding, since it also acts as a channel code at the decoder.
Stemming from the non-ideal quantization at the encoder, a problem of channel decoding beyond capacity is identiﬁed and solved
when we design the practical decoder. Moreover, by using the
modiﬁed reinforced belief-propagation quantization algorithm,
the low-density parity check code (LDPC), whose edge degree is
optimized for channel coding, also performs well as a source code.
We then implement the residual WZC by an LDPC and a lowdensity generator matrix code (LDGM). The simulation results
show that our practical construction approaches the WynerZiv bound. Compared with previous works, our construction
can offer more design ﬂexibility in terms of distribution of side
information and practical code rate selection.

theoretical results in [6] [7] can be applied to such cases
is unknown. Moreover, the results in [4] [6] [7] require two
nested codebooks good for the source and/or channel coding.
Practically constructing such good codebooks with nested
structure in [4] [6] [7] is still a challenging task.
Instead of building WZC from nested codebooks as in [4]
[6] [7], we proposed a new coding structure in our previous
work [8], where two codebooks without nested structure were
used in a two-stage serial quantization process. The encoder
ﬁrst quantizes the source once, and then uses another codebook
to quantize the quantization error of the ﬁrst stage. The
quantization index of the second stage is then sent to the
decoder. We name the coding in [8] residual WZC, which
reﬂects some resemblances of our coding structure to the
residual vector quantizer [9, Sec 12.11] for source coding
without side information. In a theoretical random coding
setting, the residual WZC was proved to be Wyner-Ziv-bound
achieving.

I. I NTRODUCTION

In this paper, we show that using graph-based codes,
the theoretically-optimal residual WZC in [8] can be practically implemented. Different from the celebrated quadraticGaussian WZC in [10] [11], our scheme can approach the
Wyner-Ziv bound for all rate regimes when the side information is arbitrarily distributed. By using the loss to the
Wyner-Ziv bound as the performance metric, simulation shows
that the performance of our code is comparable to that in
[10]. However, in contrast to [10], our simulation result is
independent of the distribution of the side information, as long
as the variance of the side information is the same. Besides,
our WZC has a complexity similar to that of [10] and linear in
the codeword length, and much lower than that of the lattice
decoder (NP problem) in [4].

Wyner-Ziv coding (WZC) [1], which is a generalization
of the lossless Slepian-Wolf coding (SWC) [2], refers to a
lossy source coding with side information at the decoder only.
Among the applications of WZC [3], one important scenario is
the quadratic-Gaussian problem, where the difference between
the source and the side information is Gaussian and meansquare error (MSE) is adopted as the distortion measure.
For this case, WZC does not incur rate loss when compared
with source coding with side information available at both
the encoder and the decoder. This zero-rate-loss result was
originally proved for the case where the side information
is Gaussian [1], but recently generalized to the case where
the side information can be arbitrarily distributed [4]. There
are many applications of quadratic-Gaussian WZC, such as
distributed source coding in the sensor networks [3] and the
protocols in the relay networks [5].
The theoretical analysis of Wyner and Ziv [1] was based
on the non-structured codebook which is hard to implement
in practice. Later on, some theoretical works based on structured codebooks were proposed [4] [6] [7]. However, only
[4] focused on the quadratic-Gaussian cases. Whether the
This work was supported by National Science Council, National Taiwan
University and Intel Corporation under Grants NSC 100-2911-I-002-001, NSC
100-2218-E-027-008 and 10R70501.

1

Practically implementing the residual WZC is not trivial.
Firstly, the codebook of the ﬁrst stage quantizer acts as a
channel code in our decoder, and must be simultaneously
good for source and channel coding (SSC). Moreover, the
non-ideal practical quantizers at the encoder make the channel
decoder operate in a rate regime above capacity. We propose a
method which can increase the equivalent signal-to-noise ratio
(SNR) at the channel decoder to solve this problem. Secondly,
although the low-density parity check code (LDPC) has been
proved to be SSC theoretically [12], the edge degree design
and practical quantization algorithm for SSC LDPC are still

where QA (xi ) is the nearest multiple of A to xi , ∀i.
Deﬁnition 2 (mod-A distance): The mod-A distance between two vectors a = (a1 , . . . , an )T and b = (b1 , . . . , bn )T is
n

||b − a||2 ≡ ∑ [(bi − ai ) mod A]2 .
A
i=1

The residual WZC is described in detail as follows:
Encoder part: The input of the ﬁrst-stage quantizer C1 in
Fig. 1 is
(αx + d) mod A,

unknown. We modify the recently proposed reinforced belief
propagation (RBP) algorithm [13] so that the LDPC, whose
edge degree is originally optimized for channel coding, is
good for source coding. The codebook of the second stage
of our residual WZC is chosen as a low-density generator
matrix code (LDGM). We also apply the RBP algorithm to
LDGM, which is much simpler than the well-known harddecimation-based algorithm [14] for LDGM, and reduces the
overall WZC complexity a lot. More detailed comparisons
between our practical construction and previous works can
be found in Section IV-B.

where α is a scaling factor which will be determined later, d is
a randomly generated dither signal known both at the encoder
and the decoder, and A is called as the modulo size. The
entries of the dither are uniformly distributed in the interval
[− A , A ]. According to Crypto Lemma in [8] [4], we know
2 2
that (αx + d) mod A is uniform in the region [− A , A ]n and
2 2
independent of x. Then the distribution of x, determined by
the distribution of side information ya from (1), will not affect
the quantization result of our residual WZC encoder. The
ﬁrst-stage quantizer C1 searches a codeword −c1 in C1 such
that the mod-A distance (in Deﬁntion 2) between αx + d and
−c1 is minimized, under the distortion constraint 1 E[e1 T e1 ] ≤
n
αD + α2 PV . The quantization error after the ﬁrst stage is

II. S YSTEM MODEL AND RESIDUAL W YNER -Z IV CODING

e1 = (αx + d + c1 ) mod A.

Fig. 1.

Coding structure of the proposed residual Wyner-Ziv coding

In the considered quadratic-Gaussian Wyner-Ziv problem,
the relationship between the length-n source vector x and the
arbitrary side information ya is ∗
x = ya + v,

(1)

where v is an independent and identically distributed (i.i.d.)
Gaussian vector with each element distributed as N(0, PV ),
and v is independent of ya . Moreover, ya can be arbitrarily
ˆ
distributed. Denoting the reconstruction as x, the “quadratic”
MSE distortion measure is adopted with maximum distortion
D
1
ˆ
E[(x − x)2 ] ≤ D.
(2)
n
The Wyner-Ziv bound is then [4]
( )
1
PV
RW Z (D) = log
,
(3)
2
D
when PV > D. When PV ≤ D, RW Z (D) = 0 and we will neglect
this trivial case in the following.
A. Structure of the proposed residual Wyner-Ziv coding
We brieﬂy review the residual WZC in [8], and the coding
structure is depicted in Fig. 1. First, we introduce some
deﬁnitions as follows
Deﬁnition 1: Given a vector x = (x1 , . . . , xn )T and a predetermined value A, the modulo A operation is deﬁned as
x mod A = (x1 − QA (x1 ), . . . , xn − QA (xn ))T ,
∗ In this paper, a vector is denoted in bold lower-case, while the superscript
T denotes the transpose of a vector. A zero-mean Gaussian random variable
with variance σ2 is denoted by N(0, σ2 ). A random variable X for Shannon’s
random coding setting is denoted in capital italic. The entropy is denoted as
h(·). All logarithms are of base 2.

2

(4)

The input of the second-stage quantizer C2 in Fig. 1 is the
quantization error e1 of the ﬁrst stage in (4). The distortion
constraint for the second stage is 1 E[e2 T e2 ] ≤ αD, and the
n
quantization output and the quantization error of the second
stage are c2 and
e2 = (e1 − c2 ) mod A,
(5)
respectively. Finally, the encoder sends the index representing
c2 to the decoder.
Decoder part: The decoder receives the index representing
c2 and the side information ya . As in Fig. 1, the decoder ﬁrst
computes w = (c2 − αya − d) mod A. From [8], equivalently
we have
w = (c1 + αv − e2 ) mod A.
(6)
Then we can channel decode c1 from w, by treating
αv − e2

(7)

as the equivalent channel noise, where e2 is given in (5). By
ˆ
denoting the channel decoder output as c1 , we can compute
ˆ
ˆ
ˆ
v, the reconstruction of v, as v = (w − c1 ) mod A. Finally, the
ˆ
reconstruction x is
ˆ
ˆ
x = ya + v.
Let the code rates of C1 and C2 be R1 and R2 , respectively.
According to [8], by letting α be
α = 1 − D/PV ,

(8)

there exists codebooks C1 and C2 such that the MSE distortion
constraint (2) is met if
1
PV
1
R1 ≥ log A − log(2πe(αPV )) + ε1 , R2 ≥ log( ) + ε2 (9)
2
2
D
1
R1 ≤ log A − log(2πe(αPV )) + ε1 ,
(10)
2

Fig. 2.

Graph-based code implementation of residual Wyner-Ziv coding

where ε1 , ε2 → 0 as A → ∞ and the code length n → ∞. Indeed
(9) ensures the success of the two quantization processes in the
encoder, while (10) ensures the success of channel decoding
in the decoder [8]. Then from (9)(10), we know that one can
achieve the Wyner-Ziv bound in (3) as
1
PV
R2 = log( ).
2
D

(11)

III. D ESIGN FLOW FOR GRAPH - BASED CODE

quantizers C1 and C2 can exactly achieve the rate-distortion
bound, we will get the practical quantization error variance
D2,ε of e2 in (5) larger than the theoretical one predicted in
[8]. From (6), the variance of the equivalent noise (7) will also
be larger than the theoretical value in [8], which makes the
selected R1 operating in the regime above the channel capacity
in (10) with A = Aε .
To solve the channel decoding beyond capacity problem
described above, we propose a method which increases Aε
to A p while R1 is ﬁxed as that in Step 2 of Table I. The
key idea is that the equivalent SNR at the channel decoder in
Fig. 2 will also increase. To be more speciﬁc, from the random
codebook construction in [8], we know that the optimal
constellation of C1 is uniformly distributed in [− Aε , Aε ]. Thus
2 2
we use the uniform pulse amplitude modulation (PAM) as the
constellation of C1 , and the equivalent SNR of the channel (6)
with A = Aε is
A2 /k
ε
SNRε =
,
(13)
D2,ε + α2 PV
where k is a constant related to the order of the PAM
constellation. If we increase the modulo size from Aε to
A p with rates R1 and R2 unchanged, the quantization error
variance of e2 in (5) will become

IMPLEMENTATION

Theoretically, from [8], the C1 must be a SSC code while C2
must be a good source code. We implement C1 and C2 in Fig. 1
by an LDPC and an LDGM, respectively. The detailed block
diagram of our practical implementation is shown in Fig. 2.
Before introducing our ﬂow to select the code parameters and
the detailed encoding/decoding algorithms in Section III-B,
in Section III-A, we ﬁrst discuss some problems encountered
when building our ﬂow for the practical implementation.
A. Issues for practical implementation
Finite modulo size : In [8], the Wyner-Ziv bound is achieved
while the modulo size A approaches inﬁnity. However, inﬁnite
modulo size A is impractical since the rate R1 in (9) will
become inﬁnite, too. Thus we propose the following method
to estimate how large A should be in practice. From [8], the
ε1 and ε2 in (9) satisfy
ε2 < ε1 = h(αV − E2 ) − h((αV − E2 ) mod A),

(12)

where V ∼ N(0, PV ), and E2 is a random variable corresponding to e2 in (5) in the Shannon-random coding setting. The
distribution of E2 is detailed in [8]. By numerically calculating
the right-hand-side (RHS) of the equality in (12), we can
choose A to make ε1 and ε2 smaller than a threshold ε.
In the following, we use the modulo size Aε to represent
the sufﬁciently large modulo size such that we can essentially
neglect ε1 and ε2 in (9).
Channel decoding beyond capacity : With Aε obtained
previously, we can select R1 from (9) by replacing A with Aε
and neglect ε1 . However, if we directly implement the channel
decoder in Fig. 2 with selected R1 and Aε , the channel decoder
will always fail. The reason is as follows. Since no practical

3

D2,p = (A p /Aε )2 D2,ε ,

(14)

because the variance of C1 ’s input, which is uniformlydistributed, will increase from A2 /12 to A2 /12. Then the
ε
p
equivalent SNR becomes
SNR p =

A2 /k
A2 /k
p
ε
=
,
A
D2,p + α2 PV
D2,ε + ( A ε )2 α2 PV
p

which is larger than SNRε in (13) since A p > Aε .
Now we consider the loss of the practical channel decoder
with practical C1 in Fig. 2 compared to the optimal channel
coding in [8]. For the practical channel coding, let σ2 be
n,ε
the variance of the maximum tolerable equivalent noise for
the successful decoding, where the PAM constellation of C1
is chosen according to Aε . Then under the non-ideal channel
decoding, we have
σ2 < D2,ε + α2 PV ,
n,ε

(15)

where the RHS is the variance of the equivalent noise (7).
When the PAM constellation of C1 is chosen according to
A p instead of Aε , the signal power of codeword c1 is scaled
by (A p /Aε )2 . Then the maximum tolerable equivalent noise
variance σ2 for the practical channel coding can be estimated
n,p
by
σ2 = (A p /Aε )2 σ2 .
(16)
n,p
n,ε
Now we wish σ2 ≥ D2,p + α2 PV to ensure the practical
n,p
channel decoding in (6) being successful. Using this criterion
with (14) and (16), the practical modulo size A p in Fig. 2 must
meet,
A2 α2 PV 1
)2 .
(17)
Ap ≥ ( 2 ε
σn,ε − D2,ε

σ2 and D2,ε can be obtained via numerical simulations. From
n,ε
(15), we know that A p selected according to (17) is lager than
Aε . Although increasing the modulo size can solve the channel
decoding beyond capacity problem, there will be a loss in the
ﬁnal distortion compared with the theoretically predicted D
using R2 in (11) owing to the increment of the quantization
error variance of e2 in (5) from (14).
Edge degree for SSC LDPC : One of the critical parts
of our residual WZC is the requirement of a practical SSC
code C1 . The best known SSC so far is the trellis coded
quantation (TCQ)/modulation. However, according to the simulation results in [15], using TCQ as our C1 will result in
signiﬁcant performance loss compared with the Wyner-Ziv
bound. Alternatively, in [12], LDPC was proved to be an
SSC code for the binary source/channel under the optimal encoder/decoder. However, the theoretical proof in [12] gives no
hints for the edge degree design and the practical quantization
algorithms for SSC LDPC. Recently, the RBP algorithm was
proposed in [13] for the quantization of the binary source with
LDPC. However, the LDPC in [13] is not SSC, since its edge
degree exhibits the ultra-sparse structure which makes LDPC
poor for the channel coding when the belief-propagation (BP)
algorithm [16] is used.
To solve the practical design problem for SSC LDPC, we
propose using LDPC with the edge degree optimized for the
channel coding, and modifying the binary RBP in [13] for
our continuous LDPC quantization with mod-A operation.
Although our edge degree for the ﬁrst-stage quantizer C1 in
Fig. 2 is sub-optimal for the source coding, our simulation
results show that it sufﬁces to make the overall residual WZC
approach the Wyner-Ziv bound. Indeed, our simulation results
in Section IV-A show that our LDPC has a shaping loss [9]
about only 0.5 dB away from the rate-distortion bound when
the quantizer input is uniformly-distributed. Our modiﬁed RBP
algorithm is given in Sec. III-B.
B. Design ﬂow and encoding/decoding algorithms
Our overall design ﬂow is summarized in Table I and is
explained in detail as follows. The Step 1 and 2 in Table I are
described previously in Sec. III-A. To design the edge degree
of the SSC LDPC in Step 3, as discussed in Sec. III-A, we
adopt the EXIT chart ﬁtting approach in [17] to obtain an
LDPC good for the channel coding. By running the BP channel
decoding algorithm, we can calculate the σ2 described before
n,ε
(15) for our LDPC with the PAM constellation points. For Step
4, the rate of the LDGM is given in (11), and the quantization
alphabet is uniformly spaced with energy α2 PV suggested in
[8]. The edge degree of LDGM is obtained similarly as in
[18].
To calculate D2,ε in Step 4 of Table I, we modify the RBP in
[13] as the quantization algorithm for both LDPC and LDGM
at the WZC encoder in Fig. 2. The RBP is a generalization
of BP by adding an reinforcement term controlled by the
constants γ0 , γ1 ∈ [0, 1] to the marginal L-value calculated from
the variable nodes (VND) of the graph-based code. The main
modiﬁcation of our RBP algorithm is the a priori information

4

TABLE I
D ESIGN F LOW OF R ESIDUAL WZC
1:
2:

3:

4:

5:

Determine the target (ideal) MSE distortion D:
Given PV and WZC rate R2 , determine D from (11)
Determine code rate R1 of the 1st-stage quantizer:
Given ε, ﬁnd A = Aε such that ε1 < ε from (12).
Compute R1 from (9) with A = Aε .
Find the maximum tolerable noise variance σ2 of the channel
n,ε
decoder with A = Aε :
Design SSC LDPC with rate R1 . Calculate σ2 with BP.
n,ε
Find the distortion D2,ε of the 2nd-stage C2 with A = Aε
Design LDGM with rate R2 .
Calculate D2,ε with modiﬁed RBP applied to LDPC and LDGM.
Determine the practical modulo size A p :
Calculate A p using the RHS of (17). If the LDPC decoder fails,
increase A p until it succeeds. Test the ﬁnal MSE with the ﬁnal A p .

from the source. Taking quantizer C1 as an example. We let
ui be the ith element of C1 ’s input (uniform), and c1,i be the
ith coded symbol of codeword c1 . To reﬂect the modulo Aε
operation before C1 in Fig. 1, we use the following conditional
probability density function (PDF) to calculate the a priori
information
fui |c1, i =

∑ fG,σ2 (ui − c1,i + Aε b),
n,ε

(18)

b∈Z

where fG,σ2 (g) is the PDF of N(0, σ2 ), and Z is the integer
n,ε
n,ε
set. The rest of the algorithm is the same as that in [13] and
is omitted here. After obtaining D2,ε in Step 4, we can follow
Step 5, which is described in Sec. III-A, to get the practical
modulo size A p in Fig. 2 and complete our design.
Finally, note that the complexity of the BP channel decoding
algorithm for our WZC decoder is linear [16] in codelength
(i.e. O(n)), also is the RBP algorithm used in our WZC
encoder. Adopting the RBP algorithm instead of the O(n2 )
hard-decimation-based one in [14] [18] signiﬁcantly reduces
our computation complexity.
IV. D ESIGN EXAMPLE AND D ISCUSSIONS
In our design example, different from the Gaussian side
information in [10] [19], we let each element of the side
information y in (1) be uniformly distributed in [−A/2, A/2].
Due to the dither, the distribution of y will not affect our
performance. The details of our design example is given in
Sec. IV-A, with the distortion performance given in the end of
this subsection. Finally, Sec. IV-B provides more discussions
on our work.
A. Design example with detailed code parameters selection
Following our design ﬂow in Table I, we ﬁrst set PV in
(3) as 0.28 and the WZC rate R2 = 0.953, and then the ideal
distortion D is 0.0747. For Step 2, given ε=0.005, we ﬁnd
that choosing Aε as 3 is sufﬁcient. R1 is 0.68 bpcu. For Step
3, we use 2-PAM LDPC to implement C1 with constellation
points ± Aε . To achieve the WZC bound, we choose codeword
4
length n = 105 symbols per source block. The degree proﬁle
is : check nodes (CND): 100% of degree 12; VND: 35.36%
of degree 2, 44.74% of degree 3, and 19.89% of degree 9. By
applying the BP channel decoding algorithm, we obtain σ2
n,ε
as 0.185.

For Step 4, we adopt 4-ary LDGM where every two bits
of the LDGM CND are Gray-mapped to a 4-ary symbol.
The degree proﬁle can be found in [18]. By running the
RBP quantization algorithm with γ0 = 1, γ1 = 0.99980 at the
LDPC and LDGM, we obtain D2,ε as 0.0577. The Monte
Carlo simulation tests 2000 blocks of uniformly-distributed
source samples and 3000 iterations are run for each source
block. The summation over integer set Z in (18) is obtained
by limiting |b| ≤ 3, b ∈ Z. As in [13], in some few cases the
RBP algorithm diverges, i.e. not all the constraints of CND
are satisﬁed. For these few cases, as in [13], restarting the
RBP by adding 0.00001 to γ1 will solve the problem. Finally,
from Step 5, we calculate the lower-bound of A p in (17) as
3.261. The bit error rate of LDPC is smaller than 10−4 when
the modulo size A p is 3.29.
Finally, we run the Monte Carlo simulation to test 2000
source blocks. The distortion loss compared with the ideal D
is 0.995 dB at the WZC rate 0.9531 b/s. The best simulation
result known with PV = 0.28 [10], which is only for the
Gaussian side information, has 1.07 dB loss at the rate 1.07
b/s and block length n = 105 . The results in [10] are obtained
using 8192-state trellis coded quantization (TCQ) and 3-stage
SWC (three LDPCs in the SWC encoder). Our work is as
competitive as [10]. Besides, our SSC LDPC has only 0.48 dB
SNR loss compared to the capacity and 0.43 dB shaping loss
compared to the rate-distortion bound. More design examples
can be found in [20].
B. Detailed comparison
Although the well-known practical WZC design [10] also
performs a two-stage quantization/cpmpression process, the
second stage quantizer/compressor in [10] is lossless with
input being the quantization output of the ﬁrst stage. In our
residual WZC, the second stage quantizer is lossy with input
being the quantization error of the ﬁrst stage, and thus the
decoder structure is also different from that in [10]. Compared
with the WZC in [10], the main advantage of our coding
scheme is the ﬂexibility. Firstly, as shown in [8], our residual
WZC can approach the Wyner-Ziv bound with arbitrary side
information in all rate regimes, while the WZC in [10] [11]
can only guarantee the optimality in high rate regimes. In
[10], the lower the WZC rate the more severe the rate loss
is. Secondly, our construction offers more ﬂexibility in the
practical code rate selection. In [10], the WZC is implemented
by a rate RN TCQ and a multilevel SWC (formed by RN
LDPCs). The rate of TCQ RN is limited to be an integer,
and for each RN = 1, 2, . . ., only one possible WZC rate can
be implemented. However, almost all the rational WZC rates
can be implemented by our construction.
Our construction is also different from and more ﬂexible
than the graph-based construction in [6] for which the encoder
codebook is nested. Moreover, the WZC in [6] has only been
proven to be optimal for the binary symmetric source with
Hamming distortion measure. Whether it can be extended
to the quadratic-Gaussian case as considered in this paper
or not is still unknown. Finally, our simulation results show

5

that LDPC itself sufﬁces to be a good SSC code, thus the
compound LDGM/LDPC construction proposed in [6] may
not be necessary for our ﬁrst-stage quantizer C1 .
V. C ONCLUSION
In this paper, we considered the quadratic-Gaussian WynerZiv problem where side information can be arbitrarily distributed. We implemented the theoretically-claimed residual
WZC by LDPC and LDGM. We identiﬁed and solved a
problem called the channel decoding beyond capacity problem
when designing our practical decoder. Moreover, we modiﬁed
the RBP algorithm to make the LDPC with the edge degree
optimized for the channel coding perform well as a source
code. The simulation results showed that our practical construction approaches the Wyner-Ziv bound, and has a similar
performance compared with previous works. Moreover, our
construction can offer more design ﬂexibility in terms of the
distribution of the side information and the practical code rate
selection.
R EFERENCES
[1] A. D. Wyner, “The rate-distortion function for source coding with side
information at the decoder-II: General sources,” Inf. Contr., vol. 38, pp.
60–80, Jan. 1978.
[2] D. Slepian and J. K. Wolf, “Noiseless coding of correlated information
sources,” IEEE Trans. Inform. Theory, vol. 19, no. 4, pp. 471–480, July
1973.
[3] Z. Xiong, A. D. Liveris, and S. Cheng, “Distributed source coding for
sensor networks,” IEEE Signal Processing Mag., vol. 21, no. 5, pp. 80–
94, Sep. 2004.
[4] R. Zamir, S. Shamai(Shitz), and U. Erez, “Nested linear/lattice codes for
structured multiterminal binning,” IEEE Trans. Inform. Theory, vol. 48,
no. 6, pp. 1250–1276, Jun. 2002.
[5] G. Kramer, M. Gastpar, and P. Gupta, “Cooperative strategies and
capacity theorems for relay networks,” IEEE Trans. Inform. Theory,
vol. 51, no. 9, pp. 3037–3063, Sep. 2005.
[6] M. J. Wainwright and E. Martinian, “Low-density graph codes that are
optimal for binning and coding with side information,” IEEE Trans.
Inform. Theory, vol. 55, no. 3, pp. 1061–1079, Mar. 2009.
[7] S. B. Korada and R. L. Urbanke, “Polar codes are optimal for lossy
source coding,” IEEE Trans. Inform. Theory, vol. 56, no. 4, pp. 1751–
1768, Apr. 2010.
[8] S.-J. Lin, S.-C. Lin, K.-S. Chen, and H.-J. Su, “Coding for noisy
quadratic-Gaussian Wyner-Ziv problem: A successive quantization approach,” in IEEE Information Theory Workshop, 2009.
[9] A. Gersho and R. M. Gray, Vector quantization and signal compression.
Kluwer Academic Fublishers, 1992.
[10] Y. Yang, S. Cheng, Z. Xiong, and W. Zhao, “Wyner-Ziv coding based
on TCQ and LDPC codes,” IEEE Trans. Commun., vol. 57, no. 2, pp.
376–387, Feb. 2009.
[11] Z. Liu, S. Cheng, A. D. Liveris, and Z. Xiong, “Slepian-Wolf coded
nested lattice quantization for Wyner-Ziv coding: High-rate performance
analysis and code design,” IEEE Trans. Inform. Theory, vol. 52, no. 10,
pp. 4358–4379, Oct. 2006.
[12] V. Chandar, “Sparse graph codes for compression, sensing, and secrecy,”
Ph.D. dissertation, Massachusetts Institute of Technology, June 2010.
[13] A. Braunstein, F. Kayhan, and R. Zecchina, “Efﬁcient LDPC codes
over GF(q) for lossy data compression,” ver.2, Oct. 2011. [Online].
Available: http://arxiv.org/abs/0901.4467v2
[14] T. Filler and J. Fridrich, “Binary quantization using belief propagation
with decimation over factor graphs of LDGM codes,” in 45th Annual
Allerton Conf. on Comm. Control, and Comput., Monticello, IL, USA,
2007.
[15] K.-S. Chen, “Low density constructions for simultaneously good for
channel and source coding problem with applications,” Master’s thesis,
National Taiwan university, 2009.
[16] D. J. C. MacKay, “Good error-correcting codes based on very sparse
matrices,” IEEE Trans. Inform. Theory, vol. 45, no. 2, pp. 399–431,
March 1999.
[17] S. ten Brink, G. Kramer, and A. Ashikhmin, “Design of low-density
parity-check codes for modulation and detection,” IEEE Trans. Commun., vol. 52, no. 4, pp. 670–678, Apr. 2004.
[18] Q. Wang and C. He, “Approaching 1.53-dB shaping gain with LDGM
quantization codes,” in IEEE Global Telecommunications Conference,
2007, pp. 1571–1576.
[19] S. S. Pradhan and K. Ramchandran, “Distributed source coding using
syndromes (DISCUS): Design and construction,” IEEE Trans. Inform.
Theory, vol. 49, no. 3, pp. 626–643, Mar. 2003.
[20] Y.-P. Wei, S.-C. Lin, S.-J. Lin, and H.-J. Su, “Residual-quantization
based code design for source coding with arbitrary decoder side information,” to be submitted to IEEE Trans. Inform. Theory.

