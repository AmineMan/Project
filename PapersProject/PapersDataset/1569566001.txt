Title:          paper_final.dvi
Creator:        pdvips(k) p1.7b Copyright 2008 ASCII MEDIA WORKS. (ptex-staff@ml.asciimw.jp)  based on dvips(k) 5.97 Copyright 2008 Radical Eye Software (www.radicaleye.com)
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Sun May 13 14:57:58 2012
ModDate:        Tue Jun 19 12:55:49 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      595 x 842 pts (A4)
File size:      580829 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569566001

p -Constrained

†

Least Squares (0 < p < 1) and
Its Critical Path

Masahiro Yukawa†,∗ and Shun-ichi Amari†
Mathematical Neuroscience Laboratory, Brain Science Institute, RIKEN, 351-0198 Saitama, Japan
Department of Electrical and Electronic Engineering, Niigata University, 950-2181 Niigata, Japan

∗

Abstract—The p -constrained least squares, which is denoted
by (Pc ), for 0 < p < 1 is addressed. A maximal continuous
curve of its critical solutions β(c) for different bounds c forms
a critical path which can be constructed with the variational
method. The path is a piecewise smooth single-valued function
of c, containing non-optimal points such as saddle points and
local maxima in general as well as global minima. The path of
global minima may coincide with a critical path but may jump
from a critical path to another one. The breakpoints of the greedy
path (a critical path constructed with a certain greedy selection
criterion) coincide with the step-by-step solutions generated by
the orthogonal matching pursuit (OMP). A critical point of
(Pc ) is also a critical point of the p -penalized least squares
(Qλ ) which reformulates (Pc ) with the Lagrangian multiplier.
The greedy path is a multi-valued function of λ and is formed
by a collection of multiple critical paths of (Qλ ).

the links established in this work are more direct. The results
are demonstrated by an illustrative example.
L EAST S QUARES P ROBLEM AND
C RITICAL PATH
In this section, the p -constrained least squares problem is
ﬁrst formulated. A critical point is then deﬁned and its local
optimality is touched on with its geometric property. A critical
path is ﬁnally deﬁned and its variation is discussed.
II.

A.

p -C ONSTRAINED

p -constrained least squares problem
We consider the following linear model:

y := [y1 , y2 , · · · , yd ]T = X T βo + v ∈ Rd ,
T

I. I NTRODUCTION
Regularization with the p quasi-norm for 0 < p < 1 is an
attractive approach for sparse optimization such as compressed
sensing [1–3]. It has been shown experimentally that the use
of the p norm yields a sparser solution and lower prediction
error for model selection compared to the 1 norm [4]. It
has also been proved that fewer measurements as well as
weaker conditions are enough for sparse signal recovery [4–
6]. Unlike the 1 -norm case, the two problems — the p constrained least squares (Pc ) and the p -penalized least
squares (Qλ ) — need to be distinguished from each other
[7]. In the previous works including [4–6], those problems
are not explicitly distinguished and the p -constrained least
squares (Pc ) has not been considered. Several approximate
solvers for (Qλ ) with a given λ have been developed based
on thresholding, iteratively reweighted least squares, etc.
In this paper, we address the p -constrained least squares
(Pc ) in depth. We call a point satisfying a certain ﬁrst order
condition a critical point. A critical path is deﬁned as a
maximal continuous curve of critical points β(c) for different
bounds c, and is a piecewise smooth single-valued function of
c. The path contains non-optimal points such as saddle points
and local maxima in general as well as global minima. It
turns out that the breakpoints of the greedy path (a critical
path constructed with a certain greedy selection criterion)
coincide with the step-by-step solutions generated by the
orthogonal matching pursuit (OMP) [8]. The greedy path starts
at the origin and continues to an ordinary least square (OLS)
solution, unless ending on the way. A critical point of (Pc ) is
also a critical point of (Qλ ). While the correspondence of
a critical point with c is one to one on the greedy path, its
correspondence with the regularization parameter λ is not one
to one, and a collection of multiple critical paths of (Qλ ) forms
a critical path of (Pc ). It also turns out that each step-bystep solution of OMP is the limit of a sequence of critical
points of (Qλ ) as λ diminishes. Although a link between
OMP and the 1 minimization has been established in [9],

1

(1)

where X := [x1 x2 · · · xn ] ∈ R
is a known matrix with
its columns being the design variables, β o ∈ Rn consists of
the explanatory parameters which are unknown, and v ∈ Rd is
the noise vector. Under this simple model, the p -constrained
least squares problem is formulated as follows:
(Pc )

minimizeβ∈Rn
subject to

ϕ(β) :=

n×d

1
X Tβ − y
2

1
β
Fp (β) :=
p

n
p
p

=

2
2

ψp (βi ) ≤ c, (2)
i=1

where p > 0, · p denotes the p (quasi-)norm, ψp (β) :=
p
1
p |β| , β ∈ R, and c ≥ 0 is a nonnegative constant. When
p ≤ 1, it is known that the function Fp (β) has a sparsity
seeking property [3]; i.e., a solution of the p -constrained least
squares problem (Pc ) tends to be sparse.
In the speciﬁc case that p = 1, the p -constrained least
squares is called Lasso [10]. In this case, it has been shown
that the solution path of (Pc ) with the constant c shifting
from zero to inﬁnity is piecewise linear and that the path can
be constructed by the homotopy algorithm, or equivalently by
the least angle regression (LARS) algorithm with a simple
modiﬁcation [11].
We address the case that p < 1 in this work. In this
case, the function Fp is nonconvex and this makes signiﬁcant
differences from the case that p = 1. We present some
remarkable differences below as will become clearer in the
following section.
(a) (Pc ) has multiple local minima in general for some
choices of the c value.
(b) A path of local/global minima of (Pc ) with the constant
c shifting from zero to inﬁnity is not piecewise linear
and is not ensured to be continuous.
(c) (Pc ) is essentially different from the p -penalized least
squares problem:
(Qλ ) minimizeβ∈Rn ϕ(β) + λFp (β),

λ ≥ 0. (3)

B. Critical point
T

Given any vector β := [β1 , β2 , · · · , βn ] ∈ R , deﬁne
its support (i.e., the set of active indices) as supp(β) :=
{i ∈ {1, 2, · · · , n} : βi = 0}. Let I := {i1 , i2 , · · · , is } :=
supp(β), where s := |supp(β)| denotes the cardinality
of supp(β). Then, we denote by β(I) the sub-vector of
β consisting of its nonzero components; i.e., β(I) :=
[βi1 , βi2 , · · · , βis ]T ∈ Rs . Also we denote by ∇I the gradient
in terms of the nonzero components; e.g.,
∇I ϕ(β) :=

n

∂
∂
∂
ϕ(β),
ϕ(β), · · · ,
ϕ(β)
∂βi1
∂βi2
∂βis

The ﬁrst and second derivatives of ψp (β)(:=
β = 0 are respectively given by
ψp (β) = sgn(β) |β|−(1−p) ,
−(2−p)

ψp (β) = − (1 − p) |β|

1
p

T

.

p

|β| ) at a point
(4)

.

(5)

The critical point is deﬁned as follows.
ˆ
Deﬁnition 1 (Critical point). Let β ∈ Rn satisfy the ﬁrst order
condition
ˆ
ˆ
ˆ
∇I ϕ(β) = −λ∇I Fp (β)

(6)

ˆ
ˆ
ˆ
for some λ ≥ 0, where I := supp(β). Then β is said to be
ˆ or a critical point of
a critical point of (Pc ) for c := Fp (β),
ˆ
(Qλ ) for λ := λ.
We emphasize that the local minimality of a critical point
(which determines the stability at the point) is essentially
different in (Pc ) and (Qλ ). In (Pc ), a critical point is a local
optimum when the function ϕ is minimal locally over the
(nonconvex) constraint set Bc := {β ∈ Rn : Fp (β) ≤ c}.1
In (Qλ ), on the other hand, a critical point is a local optimum
when the function ϕ + λFp is minimal locally over the
whole Euclidean space Rn . In short, the local minimality in
(Pc ) is deﬁned with the convex function under the nonconvex
constraint, whereas that in (Qλ ) is deﬁned with the nonconvex
function without any constraint. This makes an essential
difference in the local optimality in the two different problems,
as seen in Section III.
A geometric property of the local optimality of a critical
ˆ
point β in (Pc ) is given as follows. Let R denote the contour
ˆ
of the function ϕ passing the point β. Also let ∂Bc denote the
ˆ
boundary of Bc for c := Fp (β). Suppose for simplicity that
there exists the unique OLS solution β ∗ ∈ argminβ∈Rn ϕ(β)
(i.e., ϕ is strictly convex or the problem is overdetermined). To
exclude trivial cases, assume that β∗ (which is the center of
ˆ
R) locates outside the constraint set Bc . Suppose that β has no
ˆ = n. Then, (i) β is a critical
ˆ
zero components, i.e., supp(β)
point if the two surfaces R and ∂Bc touch with each other
ˆ
(i.e., share the same tangent plane) at β, and (ii) it is a local
minimum if ∂Bc is closer to the tangent plane than R. In the
ˆ
case that β has some zero components, the above geometric
property applies in the subspace MI := {β : supp(β) = I =
ˆ
supp(β)}.
1 At a critical point β, the function ϕ takes a critical value over B for
ˆ
c
ˆ
ˆ
c := Fp (β), and the function ϕ + λFp takes a critical value over Rn .

2

C. Critical path
We deﬁne the set of critical points for (Pc ) and (Qλ ) as
C := {The set of all critical points of (Pc ) for some c ≥ 0}
= {The set of all critical points of (Qλ ) for some λ ≥ 0} .
The equality above is clear from the deﬁnition of a critical
point. Some important facts are listed below.
1) A local minimum of (Qλ ) is a local minimum of (Pc ),
but the converse is not always true. (This will be seen
in Section III-A.)
2) The correspondence between c and λc has multiplicity.
(This will be seen in Section III-C.)
3) The paths of global minima of (Pc ) and (Qλ ) are both
subsets of C.
4) The path of global minima of (Qλ ) is always discontinuous [7].
5) The path of global minima of (Pc ) is possibly discontinuous [7].
Each critical point is associated with a certain value of c, and
in general there exist multiple critical points that are associated
with a single value of c. It is clear by deﬁnition that the origin
is the unique critical point that is associated with c = 0.2
When the c value increases from zero, the paths of the multiple
critical points associated with each value of c form multiple
curves in Rn . We call each of such curves a critical path of
(Pc ). The formal deﬁnition of critical path is given below.
Deﬁnition 2 (Critical path). A critical path of (Pc ) (or (Qλ ))
is a subset of C and is a maximal continuous curve that is a
single-valued function of c (or λ).
We now regard each point on a critical path as a function
of c, and denote it by β(c). How does β(c) behave for a
d
˙
slight variation of c? It is described by β(c) := dc β(c). Let
ˆ
ˆ
β := β(c) and λ := λc in (6) and differentiate its both sides
with respect to c. Then, with simple manipulations, we obtain
the equation of critical path:
˙
˙
β(c) = −λc Gc,I (β(c))−1 ∇I Fp (β(c)),
˙
where λc :=

d
dc λc ,

(7)

provided that the matrix

Gc,I (β(c)) := ∇I ∇I (ϕ + λc Fp )(β(c))
is nonsingular. A critical path is a piecewise smooth curve
governed by (7). The path always starts from the origin
(i.e., β(0) = 0) and may end at an OLS solution β∗ ∈
ˆ
argminβ∈Rn ϕ(β) at which (6) holds for λ = 0. As it is
deﬁned as a maximal continuous curve, a critical path is more
likely to continue from β(0) to β∗ than the path of global
minima of (Pc ). In the following section, we deﬁne the greedy
path which is one of the possible critical paths starting at the
origin and which coincides with the path of global minima of
(Pc ) if the global-minima path is continuous. (We do not give
any precise proof for this.)
III. C RITICAL PATH AND I TS L INK TO OMP
This section studies the greedy path and clariﬁes its link
to OMP. Following the condition for local optimality, how to
construct the greedy path is presented. The correspondence
between (Pc ) and (Qλ ) is ﬁnally discussed.
2 In this case, the set of active indices I is an empty set, and hence the
condition is automatically satisﬁed.

A. Condition for local optimality
The lemma below and its following remark clarify the
difference between (Pc ) and (Qλ ) mentioned in Section II-B.
Lemma 1 (Conditions for local optimality in (Pc ) and (Qλ )).
1) Necessary and sufﬁcient condition for (Qλ ) : A vector
ˆ
β is a local minimum of (Qλ ) if and only if it is a
ˆ
critical point and the Hessian matrix Gc,I (β) is positive
semideﬁnite.
ˆ
2) A sufﬁcient condition for (Pc ) : A vector β is a local
ˆ
minimum of (Pc ) if it is a critical point and Gc,I (β) is
positive semideﬁnite. (Note that this is not a necessary
condition.)
3) Necessary and sufﬁcient condition for (Pc ) : A vector
ˆ
β is a local minimum of (Pc ) if and only if it is a
critical point and there exists a δ > 0 such that
1
ˆ
ˆ
(I)T ∇I ∇I ϕ(β) (I) + ∇I ϕ(β)T (I) ≥ 0 (8)
2
for any ∈ Rn satisfying
ˆ
ˆ
Fp (β + ) ≤ Fp (β),
2 ≤ δ.

(9)
(10)

ˆ
Note here that β + is a vector which is in the δ-vicinity
ˆ
of β and at the same time in the origin-centered p ball
ˆ
whose boundary the vector β lies on.
Proof: Lemma 1.1 is clear. We prove Lemma 1.2 and Lemma
1.3 below. Although the statement is true for an arbitrary I,
we only provide a proof for the case that I = {1, 2, · · · , n}.
ˆ
We drop the index I for simplicity. By deﬁnition, β is a local
minimum if and only if there exists a δ > 0 such that
ˆ
ˆ
ϕ(β + ) ≥ ϕ(β)

(11)

for any ∈ Rn satisfying (9) and (10). Now, for a sufﬁciently
small δ > 0, the Taylor expansions of ϕ and Fp are respectively given by
1
ˆ
ˆ
ˆ
ˆ
ϕ(β + ) − ϕ(β) = ∇ϕ(β)T + T ∇∇ϕ(β) ,
(12)
2
1
ˆ
ˆ
ˆ
ˆ
Fp (β + ) − Fp (β) = ∇Fp (β)T + T ∇∇Fp (β) , (13)
2
where the higher order terms in the expansions of Fp are
neglected. Lemma 1.3 is veriﬁed by (11) and (12). It also
holds that
1
ˆ
ˆ
ˆ
∇ϕ(β)T = −λc ∇Fp (β)T ≥ λc T ∇∇Fp (β) (14)
2
where the equality follows from (6) and the inequality follows
from (9) and (13). By (12) and (14), it is seen that (11) holds
if
T

ˆ
∇∇ (ϕ + λc Fp ) (β) ≥ 0.

(15)

ˆ
The inequality (15) holds if the matrix Gc (β) is positive
semideﬁnite. This veriﬁes Lemma 1.2. A proof for an arbitrary
I can be obtained by noting that, due to (9), the norm of
(Ic ), where Ic := {1, 2, · · · , n} \ I, diminishes quickly as δ
approaches zero.
2

3

Remark 1 (On Lemma 1: Difference between (Pc ) and
(Qλ ) in local optimality). We stress that the positive semidefiniteness condition is necessary for (Qλ ) but not for (Pc ).
This is because, regarding the inequality in (14), the equality
holds only when the equality holds in (9), which is the case
ˆ
that β + lies on the surface ∂Bc (the boundary of the
constraint set). The surface ∂Bc is nearly the tangent plane
ˆ
ˆ
at β for a sufﬁciently small δ and, if β + lies on the
ˆ T (I) = 0, implying that
tangent plane, we have ∇I ϕ(β)
the inequality (8) holds automatically due to the positive
ˆ
semideﬁniteness of ∇I ∇I ϕ(β). The bound is loose when
the vector is orthogonal to the tangent plane. Therefore,
the condition (8) may holds even if the Hessian matrix is not
ˆ
positive semideﬁnite. Indeed, there is a case that a vector β is
a local minimum of (Pc ) but is a saddle of (Qλ ) (see Section
IV); this is the case that (8) holds but the Hessian matrix is
not positive semideﬁnite.
B. Construction of the greedy path and its link to OMP
We present how to construct the greedy path β(c) and shows
its link to OMP. It is basically an extension of the LARS
algorithm from p = 1 to p < 1. We mention that a critical
path can never intersect with itself since a local minimum of
(Pc ) lies on the boundary of the constraint set Bc unless it is
a global minimum of ϕ. As stated in Section II, the path is a
piecewise smooth curve. We consider the breakpoint condition.
For a ﬁxed I, the path is smooth as its variation is governed by
(7). At a breakpoint, therefore, the active index set I should
change.
Now the question is under what condition such an activeindex-set change can happen. For simplicity, consider the
case that I := supp(β(c)) changes from I = {i∗ } to
Iinc = {i∗ , j ∗ }.3 At a breakpoint β(c1 ), the path leaves
the βi∗ coordinate and goes on along the βi∗ - βj ∗ plane.
On this plane, (6) should still hold for the incremented
active index set Iinc . We now track the path in a reverse
way toward the breakpoint β(c1 ) on the βi∗ - βj ∗ plane.
Referring to (4), it is seen that limβj∗ →0 |ψ (βj ∗ )| = ∞.
Since |ψ (βi∗ )| < ∞ at the breakpoint β(c1 ), (6) suggests
∂
that ∇I ϕ(β(c1 )) = ∂i∗ ϕ(β(c1 )) = 0 with λc = 0. In an
analogous way, we can verify in general that the breakpoint
condition is given by
∇I ϕ(β(c)) = 0,

(16)

where I := supp(β(c)). The condition (16) implies that a
breakpoint β(c) is a minimizer of the function ϕ over the
subspace MI = {β : supp(β) = I = supp(β(c))}.
At each breakpoint including the starting point, we need
to select one of the inactive indices. Our strategy is greedy;
i.e., an index is selected in such a way that the value of ϕ
is locally minimized in the vicinity of each breakpoint. How
can we ﬁnd the greedy path? Let us discuss which index to
select at the starting point β(0) := 0. Indeed, the selection can
be done in the same way as the LARS algorithm. Namely,
∂
ϕ(0) is selected. The reason is
i∗ ∈ argmaxi=1,2,··· ,n
∂βi
given as follows. Consider two closed balls: an 1 ball with
a small radius ρ > 0 and an p ball with a radius ρp . (The
two balls touch each other at the vertices of the balls.) The
LARS path goes along the βi∗ coordinate, meaning that one
of the vertices of the 1 ball on the coordinate minimizes ϕ
3 By the continuity of critical path, it is clear that I ⊂ I
inc , although the
continuity at breakpoints needs to be veriﬁed.

over the 1 ball. The vertex also minimizes ϕ over the p ball
since it is a subset of the 1 ball. Analogously, we can verify
that, at each breakpoint β(c), the greedy selection is given as
follows:4

Proposition 1 (Link between OMP and (Pc )). Suppose that
the greedy path continues to an OLS solution. Then, the
breakpoints of the greedy path coincide with the step-by-step
solutions generated by OMP.
Proposition 1 indicates a more direct link between OMP
and the p -constrained least squares than between OMP and
the 1 minimization. Another remarkable link between OMP
and the p -penalized least squares (Qλ ) will be presented in
the following subsection.

local minima

β2

0.6
0.4
saddle points
0.2
saddle points
0
0

local minima

0.5

1

1.5

β1

2

(a) The greedy path with its correspondence to (Qλ )

1
0.8

λc

where the equality follows because of the condition (16).
∂
We note that
ϕ(β(c)) = xT (X T β(c) − y) represents
i
∂βi
the magnitude of the correlation between the vector xi and
the residual error vector X T β(c) − y. The greedy path is
constructed as follows.
1) At the starting point β(0) = 0, select an index i∗ by
(17) and let I := {i∗ }.
2) Go along the βi∗ coordinate in the direction of −a,
where a := [a1 , a2 , · · · , an ]T ∈ Rn is the Minkowskian
∂
ϕ(0) if i = i∗
gradient of ϕ given by ai := ∂βi
0
if i = i∗ .
n
3) If the path reaches a point β(c1 ) ∈ R satisfying the
breakpoint condition (16), select the next coordinate βj ∗
based on (17) and increment the active index set as I :=
{i∗ , j ∗ }.
4) From the breakpoint β(c1 ), the path goes on the βi∗ βj ∗ plane with keeping the condition (6) satisﬁed. The
path is characterized by (7).
5) The path is deﬁned analogously until reaching an OLS
solution β∗ , unless ending on the way.
The following proposition immediately follows from the
breakpoint condition (16) and the greedy selection criterion
(17).

0.8

0.6
0.4
0.2
0
0

1

2

3

c

4

5

(b) c - λc correspondence
An example of the greedy path and c - λc correspondence.

Fig. 1.
1

λ = 0.5

0.9

fλ (β)

∂
∂
i ∈ argmax
ϕ(β(c)) = argmax
ϕ(β(c)) , (17)
∂βi
i=1,2,··· ,n ∂βi
i∈Ic
∗

1

0.8

λ = 0.385

0.7

λ = 0.3

0.6
0.5

Fig. 2.

0

0.5

1

β

Graphs of fλ (β) :=

1
(β
2

1.5

− 1)2 + 2λ|β|1/2 .

C. Correspondence between (Pc ) and (Qλ )
Recall that a critical point of (Pc ) for c is also a critical point
of (Qλ ) for λ := λc . Each point on the greedy path is thus
a critical point of (Qλ ) for each corresponding λ. We now
discuss the correspondence between c and λc . Referring to
Remark 1, a local minimum of (Qλ ) is also a local minimum
of (Pc ), but the converse is not always true. This asymmetry
indicates that the correspondence would not be simple. Indeed,
the following lemma implies that λc is not monotone in c.

a multi-valued function, i.e., multiple points β(λ) correspond
to a single λ-value. The greedy path is indeed formed by
a collection of some critical paths of (Qλ ), each of which
is a single-valued function of λ by deﬁnition. The following
proposition offers an interesting link between OMP and (Qλ ).

Lemma 2 (The λc values at breakpoints). At each breakpoint
of the greedy path, it holds that λc = 0.

Proof: The claim is readily veriﬁed by Proposition 1 and
Lemma 2.
2
The results presented in this section can be better understood
through an illustrative example in the following section.

Proof: Since every component of ∇I Fp (β(c)) is nonzero
for I := supp(β(c)), the claim is readily veriﬁed by (6) and
(16).
2
In fact, multiple c values correspond to a single value of λ.
If we regard the greedy path as a function of λ, say β(λ), it is
4 One can focus on the coordinates associated with inactive indices and
consider an p -ball centered at the breakpoint with a small radius.

4

Proposition 2 (Link between OMP and (Qλ )). Suppose that
the greedy path continues to an OLS solution. Each step-bystep solution generated by OMP is the limit of a sequence of
critical points of (Qλ ) as λ → 0.

IV. I LLUSTRATIVE E XAMPLE
We consider the orthogonal case XX T = I. Let ϕ(β) :=
∗ 2
∗
1
T
2 β − β 2 and p = 0.5, where β = [2, 1] . In this case,
Fig. 1 clearly illustrates the correspondence between (Pc ) and
(Qλ ). Figure 1(a) draws the greedy path, and Fig. 1(b) depicts

the graph of λc as a function of c. The curves on the ﬁgures
are divided into four segments, and each pair of segments in
the same color (and the same line-type) are associated with
each other.
A. Correspondence between β(c) and c
The correspondence between β(c) on the greedy path and
the c value is one to one. When c increases from zero within
the range of the blue curve in Fig. 1(b), β(c) shifts from the
origin to the right along the blue line segment in Fig. 1(a).
When c increases further up to the end of the green curve
range, β(c) shifts to the right further up to the breakpoint
β(c1 ) := [2, 0]T . Then, when c increases again up to the end
of the yellow curve range, β(c) tracks the red and yellow
curves up to the OLS solution β ∗ (i.e., the global minimum
of ϕ). It can be seen in this case that the path continues to β∗ ,
and every point on the path is the global solution of (Pc ) for
each value of c ≥ 0.
B. Correspondence between β(c) and λc
The correspondence between β(c) and the λc value is not
one to one. Indeed, multiple values of λc correspond to a
single vector β(c), as can be seen through the c - β(c) correspondence and the the c - λc correspondence. Whereas every
point on the path is the global minima of (Pc ), each point can
be a local minimum or a saddle point of (Qλ ) (see Remark
1); this is indicated in Fig. 1(a). To see this, we focus on
the fact that the orthogonality allows us to separate (Qλ ) into
two minimization problems: (i) minβ1 1 (β1 − 2)2 + 2λ|β1 |1/2
2
and (ii) minβ2 1 (β2 − 1)2 + 2λ|β2 |1/2 . Graphs of the function
2
of the second problem for three values of λ are drawn in
Fig. 2. For λ = 0.3, the graph has a pair of local minimum
and maximum (excluding the origin). As λ grows, the distance
between the pair of local minimum and maximum shrinks and
they are merged into a single inﬂection point; this happens
for λ = 0.385. As λ grows further, the graph becomes
monotonically increasing in the positive region (i.e., β > 0);
this is the case of λ = 0.5.
The above observation brings information about what type
of critical point in (Qλ ) each point on the red and yellow
segments is. Draw a horizontal line in Fig. 1(b) slightly above
the zero level of λc . The line crosses the curve four times,
once on each curve segment. Let us focus on two of them
on the red and yellow segments. Those points corresponds in
Fig. 1(a) to some point on the red curve around β(c1 ) and
some point on the yellow curve around β ∗ , respectively. The
β2 values of the two points correspond to the local maximum
and minimum in Fig. 2, respectively. As λc increases up to
0.385, the distance between the two points shrinks and the
joint point of the red and yellow curves Fig. 1(a) corresponds
to the inﬂection point on the green graph in Fig. 2. It can be
veriﬁed that, in terms of β1 , the points on the red and yellow
curves are local minima. We can thus see that each point on
the red and yellow curves is respectively a saddle point and a
local/global minimum. In the same way, we can see that each
point on the blue and green curves is respectively a saddle
point and a local/global minimum. (Note that any point on
the blue and green curves is a local minimum in terms of β2 ,
corresponding to the origin in Fig. 2.)
C. Illustration of Propositions 1 and 2
It is easily veriﬁed that the step-by-step solutions of OMP
in this case is β OMP := [2, 0]T and β OMP := [2, 1]T . One can
1
2
see that the ﬁrst step-by-step solution β OMP is the breakpoint
1

5

β(c1 ) of the greedy path, and the second one β OMP is the
2
end point β(c2 ). This clearly demonstrates Proposition 1.
Now, consider the horizontal line again mentioned in Section IV-B. The four intersection points correspond in Fig. 1(a)
to (i) a point around the origin on the blue segment, (ii)
two points around β(c1 ) (one on the green segment and one
on the red segment), and (ii) a point around β(c2 ) on the
gold segment. Now we gradually shift the horizontal line in
Fig. 1(b) downward up to the level of λc = 0. Then, how
do the four points in Fig. 1(a) behave? Clearly, (i) the point
around the origin approaches the origin, (ii) the two points
around β(c1 ) approach β(c1 ), and (iii) the point around β(c2 )
approach β(c2 ). This demonstrates Proposition 2.
V. C ONCLUDING R EMARKS
This paper has investigated the p -constrained least squares
(Pc ) and its critical path. The greedy path has turned out to
contain the step-by-step solutions of OMP as its breakpoints.
The path has also turned out to be formed by a collection of
critical paths of the p -penalized least squares (Qλ ). This is
understood by the fact that λc takes the zero value at every
breakpoint, implied also by the remarkable difference between
(Pc ) and (Qλ ) in local optimality.
The links between OMP and the p least squares problems
are more direct than that between OMP and the 1 minimization. It should be remarked however that the links do not
directly imply any link between OMP and existing approximate solvers for the p -penalized least squares problem. In
fact, an approximate solution obtained by one of those solvers
corresponds not necessarily to the greedy path but possibly
to another critical path. Although we have focused on the
greedy path, most of the results presented in this paper can be
applied to the other paths. The outcomes of the study will thus
play a central role in polishing such an approximate solution
further based on possible additional requirements. This simple
consideration indicates that the new insight into critical paths
of the p -constrained least squares will be of great use in
devising an efﬁcient approach to sparse optimization.
Acknowledgment: This work was partially supported by JSPS
Grants-in-Aid (24760292).
R EFERENCES
[1] S. S. Chen, D. L. Donoho, and M. A. Saunders, “Atomic decomposition
by basis pursuit,” SIAM J. Sci. Comput., vol. 20, no. 1, pp. 33–61, 1998.
[2] E. J. Candes and M. B. Wakin, “An introduction to compressive
sampling,” IEEE Signal Processing Magazine, vol. 25, no. 2, pp. 21–30,
Mar. 2008.
[3] M. Elad, Sparse and Redundant Representations: From Theory to
Applications in Signal and Image Processing. New York: Springer,
2010.
[4] Z. Xu, H. Zhang, Y. Wang, and X. Chang, “L1/2 regularizer,” Science
in China Series F: Inform. Sci., vol. 52, no. 1, pp. 1–9, Jan. 2009.
[5] R. Chartrand and V. Staneva, “Restricted isometry properties and nonconvex compressive sensing,” Inverse Problem, vol. 24, pp. 1–14, 2008.
[6] M.-J. Lai and J. Wang, “An unconstrained q minimization with 0 <
q < 1 for sparse solution of under-determined linear systems,” SIAM
J. Optimization, vol. 21, no. 1, pp. 82–101, 2011.
[7] M. Yukawa and S. Amari, “On extensions of LARS by Information
Geometry : Convex objectives and p -norm,” in APSIPA Annual Summit
and Conference: Special Session on Recent Advances in Adaptive/Sparse
Signal Processing, Oct. 2011.
[8] J. Tropp and A. C. Gilbert, “Signal recovery from partial information
via orthogonal matching pursuit,” IEEE Trans. Inform. Theory, vol. 53,
no. 12, pp. 4655–4666, Dec. 2007.
[9] D. L. Donoho and Y. Tsaig, “Fast solution of 1 -norm minimization
problems when the solution may be sparse,” IEEE Trans. Inform. Theory,
vol. 54, no. 11, pp. 4789–4812, Nov. 2008.
[10] R. Tibshirani, “Regression shrinkage and selection via the lasso,”
J. Royal Statistical Society. Siries B, vol. 58, no. 1, pp. 267–288, 1996.
[11] B. Efron, T. Hastie, I. Johnstone, and R. Tibshirani, “Least angle
regression,” The Annals of Statistics, vol. 32, no. 2, pp. 407–499, 2004.

