Title:          ./isit2012translocation.dvi
Creator:        dvips(k) 5.991 Copyright 2011 Radical Eye Software
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Sat May 19 05:13:53 2012
ModDate:        Tue Jun 19 12:56:37 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      455914 bytes
Optimized:      no
PDF version:    1.7
ISIT'2012 1569566787

Rank Modulation for Translocation Error Correction
Farzad Farnoud (Hassanzadeh)

Vitaly Skachek

Olgica Milenkovic

Department of Electrical and
Computer Engineering
UIUC
Urbana, IL 61801
Contact: www.ifp.illinois.edu/~hassanz1

Department of Electrical and
Computer Engineering
McGill University
Montreal, QC H3A 2A7, Canada
Email: vitaly.skachek@gmail.com

Department of Electrical and
Computer Engineering
UIUC
Urbana, IL 61801
Email: milenkov@illinois.edu

have nearly-uniform leakage rates. Leakage rates depend not
only on the charge and position of the cells, but also on a
number of external factors, the inﬂuence of which may not
be adequately captured by adjacent transposition errors. For
example, if a cell for a variety of reasons has a higher leakage
rate than other cells, given sufﬁcient time, the charge of this
cell may drop below the charge of a number of other cells.
Using Kendall’s τ distance, this process may be modeled as a
sequence of adjacent transposition errors [3], [8]. However, as
this type of error is the result of a single error event, for the
purpose of error correction it should be modeled as one error
only. This is reminiscent of the scenario when one models a
sequence of individual symbol errors as a single burst error.
In what follows, we present a novel approach to rank
modulation coding which allows for correcting a more varied
class of errors when compared to classical schemes. The focal
point of the study that follows is the notion of a translocation
error, a concept that can be viewed as a generalization of the
notion of an adjacent transposition in a permutation. Roughly
speaking, a translocation moves the ranking of one particular
element in the permutation below the ranking of a certain
number of closest-ranked elements. As such, translocations are
suitable for modeling errors that arise in ﬂash memory systems
where high leakage levels for subsets of cells are expected or
possible. The study of translocations is also closely related
to a number of problems in combinatorial theory, such as the
longest common subsequence problem and permutation coding
in the Levenshtein and Hamming metric [9], [10].
The rank modulation problem is by now fairly well understood from the perspective of code construction. The asymptotic capacity of rank-modulated channel was derived in [8],
while some practical code constructions were proposed in [3],
[6] and [11]. Here, we complement the described work in
terms of deriving upper and lower bounds on the capacity
of translocation rank modulation codes, and in terms of
presenting constructive, asymptotically good coding schemes.
Our constructions are based on a novel idea of permutation
interleaving, and are of independent interest in combinatorics
and algebra.
The paper is organized as follows. In Section II we provide
the motivation for studying translocations as well as basic
deﬁnitions used in our analysis. The properties of permutations
under translocations and bounds on the size of translocation

Abstract—We consider rank modulation codes for ﬂash memories that allow for handling arbitrary charge drop errors. Unlike
classical rank modulation codes used for correcting errors that
manifest themselves as swaps of two adjacently ranked elements,
the proposed translocation codes account for more general forms
of errors that arise in storage systems. Translocations represent
a natural extension of the notion of adjacent transpositions and
as such may be analyzed using related concepts in combinatorics
and rank modulation coding. Our results include deriving the
asymptotic capacity of translocation rank codes, construction
techniques for asymptotically good codes and a simple decoding
algorithm.

I. I NTRODUCTION
Permutation codes and permutation arrays are collections
of suitably chosen codewords from the symmetric group,
used in applications as varied as single user communication
over Gaussian channels [1], reduction of impulsive noise over
power-lines [2] and coding for storage [3]. Many instances
of permutation-based codes were studied in the coding theory
literature, with special emphasis on permutation arrays under
the Hamming distance and rank modulation codes under the
Kendall τ distance [4], [5, Chapter 6B]. The distances used
for code construction in storage devices have mostly focused
around two families of combinatorial measures: adjacent transpositions and measures obtained via embeddings into the
Hamming space [2], [3]. This is due to the fact that such
distance measures capture the displacement of symbols in
retrieved messages that arise in modern storage systems.
One emerging application of permutation codes in storage is
rank modulation. Rank modulation is an encoding scheme that
may improve the lifespan, storage efﬁciency and reliability of
future generations of ﬂash memory storage devices [3], [6].
The idea behind the modulation scheme is that information
should be stored in the form of rankings of cells charges,
rather than in terms of the absolute values of the charges. This
simple conceptual coding framework may reduce the problem
of cell block erasures as well as potential cell over-injection
issues [6], [7]. In their original formulation, rank-modulation
codes represent a family of codes capable of handling errors of
the form of adjacent transpositions. Such transposition errors
represent the most likely errors in a system where the cells
This work was supported by the NSF STC-CSoI 2011 and NSF CCF
0809895 grants and a AFRLDL-EBS AFOSR Complex Networks grant.

1

6

3

6
8

1

5
2

4

5

9

Leakage

[638159247]

9

2
3

7

Our interest in translocations in permutations is motivated
by rank modulation coding. In classical multi-level ﬂash
memories, each cell used for storing information is subject to
leakage. As a result, classical error control schemes of nonzero rate can not be efﬁciently used in such systems. One
solution to the problem is to encode the information in terms of
rankings, rather than absolute values of the stored information
sequences [3]. Hence, data is represented by permutations
and errors manifest themselves via reordering of the ordered
elements. The simplest model assumes that only adjacent
ranks may be exchanged – or equivalently, that only adjacent
positions in the inverse permutation may be exchanged.
This model has the drawback that it does not account
for more general changes in ranks. With respect to this
observation, consider the charge-drop model in Figure 1. Here,
cell number 3, ranked second, experienced a leakage rate
sufﬁciently high to move the cell’s ranking to the seventh
position. If other cells had signiﬁcantly more moderate leakage
rates, the resulting ranking would be the result of a (right)
translocation error. It is easy to note that in this framework,
one translocation φ(i, j) of “length” i − j corresponds to
i − j adjacent transpositions. Nevertheless, a translocation
should be counted as one single error, and not a sequence of
adjacent transposition errors. Furthermore, translocation errors
of arbitrary length are suitable for modeling arbitrary charge
drops of a given cell independently of the charge drops of
other cells.
We formalize the notion of translocation distance below.

8

1
4

7

[681592437]

Figure 1. Rank modulation codes and translocation errors caused by “large”
drops of charge levels.

codes are studied in the same section. Code constructions
and decoding are addressed in Sections III. Throughout the
paper, we omit the proofs of the claimed results due to space
limitations – the proofs can be found in the Arxiv preprint of
this work [12].
II. BASIC D EFINITIONS
A permutation is a bijection σ
[n] → [n], that is, for
any i, j ∈ [n], i ≠ j, we have σ(i) ≠ σ(j). For any σ ∈ Sn ,
we write σ = (σ(1), σ(2), ⋯, σ(n)), where σ(i) is the image
of i ∈ [n] under the permutation σ. Alternatively, we may
write σ as [σ(1), σ(2), ⋯, σ(n)] or as [σ(1)σ(2)⋯σ(n)] if
doing so does not cause ambiguity. The identity permutation
(1, 2, ⋯, n) is denoted by e, while σ −1 stands for the inverse
of a permutation σ.
We let Sn denote the set of all permutations of the set
[n], i.e., the symmetric group of order n. Additionally, let
S (P ) , P ⊆ [n], be deﬁned as the set of all permutations of
elements of P .
A permutation code of length n and minimum distance d in
a metric d is subset C of Sn such that for all distinct π, σ ∈ C,
we have d(π, σ) ≥ d.

Deﬁnition 2. Let σ, π ∈ Sn . The translocation distance
between σ and π is a function
d○ (σ, π)

Sn × Sn → Z+ ,
0

deﬁned as the minimum number of translocations needed to
transform σ to π.
In other words, d○ (σ, π) equals the smallest m such that
there exist a sequence of translocations φ1 , φ2 , ..., φm for
which π = σφ1 φ2 ⋯φm .
Observe that the function d○ (⋅, ⋅) is nonnegative and symmetric. It also satisﬁes the triangle inequality, namely for any
σ1 , σ2 and σ3 in Sn , one has

Deﬁnition 1. We say that a permutation τ ∈ Sn is a
transposition if for i, j ∈ [n],
τ = (1, ⋯, i − 1, j, i + 1, ⋯, j − 1, i, j + 1, ⋯, n).

If j = i + 1, then τ is called an adjacent transposition.
Assume that 1 ≤ i, j ≤ n. A translocation φ(i, j) is a
permutation deﬁned as follows. If i ≤ j, we have

d○ (σ1 , σ3 ) ≤ d○ (σ1 , σ2 ) + d○ (σ2 , σ3 ) .

φ(i, j) = (1, ⋯, i − 1, i + 1, i + 2, ⋯, j, i, j + 1, ⋯, n)

Therefore, it is indeed a metric over the space Sn .
Note that a translocation may correspond to either a left or
a right translocation. As seen from the example in Figure 1,
right translocations correspond to general cell leakage models.
On the other hand, left translocations assume that the charge
of a cell is increased above the level of other cells, which
corresponds to a phenomena not frequently encountered in
ﬂash memories. The translocation distance is easier to analyze
than the right translocation distance, and represents a natural
lower bound for this distance.

and if i > j, we have
φ(i, j) = (1, ⋯, j − 1, i, j, j + 1, ⋯, i − 1, i + 1, ⋯, n) .
For i ≤ j, the permutation φ(i, j) is called a right translocation
and the permutation φ(j, i) is called a left translocation.
Simply put, the product of a permutation σ and a translocation φ(i, j) is the permutation obtained by moving σ(i) to the
jth position and shifting all the elements between the ith and
jth positions. Observe that the inverse of the a translocation
φ(i, j) is the right translocation φ(j, i), and vice versa.

Deﬁnition 3. A subsequence of length m of σ =
(σ(1), . . . , σ(n)) is a sequence of the form σ(i1 ), . . . , σ(im ),

2

dH (π, σ) ≤ n, it follows that dH (π, σ) ≤ nd○ (π, σ). Thus,

with i1 < i2 < . . . im . Let σ1 , σ2 ∈ Sn . A longest common
subsequence of σ1 and σ2 is a subsequence of both σ1 and
σ2 of longest length. We denote this sequence by L (σ1 , σ2 ),
and its length by l (σ1 , σ2 ).

1
dH (π, σ) ≤ d○ (π, σ) ≤ dH (π, σ) .
n
These inequalities are also tight.

Deﬁnition 4. Let σ ∈ Sn and let l (σ) = l (σ, e). The
function l (σ) is termed the length of the longest increasing
subsequence of σ.

(1)

A. The Capacity of Translocation Codes

Let A○ (n, d) be the maximum size of a code of length
n and minimum translocation distance d. Also, let C○ (n) =
ln A○ (n,d)
denote the rate of the code. The following results
ln n!
follow from a simple computation of the volume of spheres
involving permutations.

Deﬁnition 5. Let R+ denote the set of nonnegative real
0
numbers. A metric d Sn × Sn → R+ is right-invariant if, for
0
all π, σ, ω ∈ Sn , we have d(π, σ) = d(πω, σω). Similarly, d is
left-invariant if d(π, σ) = d(ωπ, ωπ).

Proposition 6. For all integers n and d with n ≥ d ≥ 1,

It can be easily veriﬁed that the translocation distance and
the length of the longest common subsequence are both leftinvariant. Furthermore, it can be easily shown [12] that, for
π, σ ∈ Sn , the distance d○ (π, σ) equals n − l (π, σ).
For π, σ ∈ Sn , n−l (π, σ) is also known as the Ulam distance
[5], frequently used in voting theory. The Ulam metric is
closely connected to the edit (Leveshtein) distance between
binary sequences, deﬁned as the number of deletions and
insertions needed to transform one sequence to another [10].
Over the space of permutations, it is easy to see that Ulam’s
distance is half of Levenshtein’s distance. Nevertheless, with
the exception of two results – one pertaining to single-error
correction codes [10], and another to a purely combinatorial
analysis of substrings [13] that corresponds to zero-rate coding, no results on multiple error-correcting codes in the Ulam
metric are known.
There also exists an interesting relationship between the
translocation distance and the Kendall’s τ distance used for
classical rank modulation coding. The Kendall’s τ distance
dτ (σ, π) between two permutations π and σ is deﬁned as
the minimum number of adjacent transpositions required to
change π into σ. Since a translocation requires at most n − 1
adjacent transpositions, and since an adjacent transposition is
a translocation, it is easy to see that

A○ (n, d) ≥

(n − d + 1)!
⋅
n
(d−1)

Proposition 7. For all n, d ∈ Z with n ≥ d ≥ 1,
A○ (n, d) ≤ (n − d + 1)! .
From the two previous propositions, we obtain
(n − d + 1)!
≤ A○ (n, d) ≤ (n − d + 1)!
n
(d−1)

(2)

In what follows, all limits are in n. The results below
are stated for code families with length n, A○ (n, d(n))
codewords, and minimum translocation distance d(n). The
ratio d(n)/n is denoted by δ(n). Furthermore, lim δ(n) and
lim C○ (n) are denoted by δ and C○ , respectively.
Theorem 8. If δ = lim δ(n) exists, then C○ = 1 − δ.
III. T RANSLOCATION E RROR -C ORRECTING C ODES
We describe next constructions for single and t-translocation
error-correcting codes. The ﬁrst construction is based on single
transposition detecting codes, while the second construction
involves codes in the Hamming metric and interleaving methods.
Deﬁnition 9. For vectors σi , i ∈ [k], of lengths mi with m ≤
mk ≤ ⋯ ≤ m1 ≤ m+1, the interleaved vector σ = σ1 ○σ2 ○⋯○σk
is deﬁned as

1
dτ (σ, π) ≤ d○ (σ, π) ≤ dτ (σ, π).
n−1

σ(j) = σi (⌈j/k⌉),

Both the upper and lower bound are tight. Observe that the
inequalities imply that the translocation distance is not within
a constant factor from the Kendall’s τ distance, so that code
constructions and bounds speciﬁcally designed for the latter
distance measure are not tight and sufﬁciently efﬁcient with
respect to the translocation distance.
A similar pair of bounds may be shown to hold for the
translocation distance and the Hamming distance between
two permutations. The Hamming distance dH (σ, π) between
two permutations σ and π is deﬁned as n − F (σ, π) , where
F (σ, π) denotes the set of ﬁxed points in σ under the ordering
of π (and vice versa). The subsequence of σ that consists
of elements of F (σ, π) is also a subsequence of π and
thus d○ (σ, π) = n − l(σ, π) ≤ n − F (σ, π) = dH (σ, π).
Furthermore, since for any two permutations π, σ ∈ Sn one has

k

1 ≤ j ≤ ∑ mi
i=1

where i ≡ j (mod k). For a class of k codes Ci , let

C1 ○ ⋯ ○ Ck = {σ1 ○ ⋯ ○ σk σi ∈ Ci , i ∈ [k]}.

A single-transposition error detecting code: For σ1 , σ2 ∈
Sn , let dT (σ1 , σ2 ) denote the transposition distance between
σ1 and σ2 , i.e., the number of transpositions needed to
transform σ1 to σ2 . The parity of a transposition σ is deﬁned
as the parity of dT (σ, e). It is well-known that applying
a transposition to a permutation changes the parity of the
permutation, and also that, for n ≥ 2, half of the permutations
in Sn are even and half are odd. Hence, the code containing
all even permutations of Sn is a single-transposition error
detecting code of length n and cardinality Sn /2.

3

The following construction leads to single-translocation
error correcting codes. Assume that n = 3k. We start by
partitioning [n] into three sets P1 , P2 , and P3 , each of size k.
We let Ci be the set of all even permutations of elements of
Pi , for i = 1, 2, 3.

good Hamming distance. Furthermore, this approach may be
implemented in a recursive manner.
We ﬁnd the following results useful for describing our
recursive construction method.
Lemma 12. Let σ, π ∈ Sn be two permutations, such that
d○ (σ, π) = 1. Then, there exist at most three locations i, i ∈
[n − 1], such that for some j = j(i) ∈ [n − 1]:
σ(i) = π(j),
σ(i + 1) ≠ π(j + 1).

Proposition 10. The code C = C1 ○ C2 ○ C3 corrects one
translocation error.
1
The cardinality of C equals ( 2 ( n )!) and its rate equals
3
3

3 ln (1/2) + 3 ln ( n )!
3
ln n!

∼

n ln n + O (n)
∼ 1.
n ln n + O (n)

Corollary 13. Let σ, π ∈ Sn be two permutations, and
assume that there exist a ≥ 0 different locations i, i ∈ [n − 1],
such that σ(i) = π(j), but σ(i + 1) ≠ π(j + 1) for some
j ∈ [n − 1]. Then, d○ (σ, π) ≥ ⌈a/3⌉.

The construction above can be easily extended to the case
where n = 3k ± 1.
In what follows, we construct a family of codes with
translocation distance 2t + 1, length n = s (2t + 1) for some
2t+1
integer s ≥ 4t + 1, and cardinality M = (AH (s, 4t + 1))
,
where AH (s, d) denotes the maximum size of a permutation
code with length s and minimum Hamming distance d. The
construction relies on the use of 2t+1 permutation codes, each
with minimum Hamming distance at least 4t + 1.
For a given n and t, where n ≡ 0 (mod 2t + 1), partition the
set [n] into 2t + 1 classes Pi , each of size s, with
Pi = {j ∈ [n] j ≡ i (mod 2t + 1)} ,

i ∈ [2t + 1].

For an integer p ≥ 1, let µ = [12⋯p + 1] and let σ1 , σ2 ∈
S({p + 2, ⋯, 2p + 1}). In this case, we have
µ ○ σ1 = (1, σ1 (1), 2, σ1 (2), ⋯, p, σ1 (p), p + 1),

µ ○ σ2 = (1, σ2 (1), 2, σ2 (2), ⋯, p, σ2 (p), p + 1).

(4)

Lemma 14. For µ, σ1 , and σ2 described above, if
dH (σ1 , σ2 ) ≥ d, then
d○ (µ ○ σ1 , µ ○ σ2 ) ≥ ⌈2d/3⌉ .

As a result, for odd n, the code {[12⋯p + 1] ○ σ σ ∈ C1 },
where n = 2p + 1 and C1 is permutation code with length
p and minimum Hamming distance ⌈3d/2⌉, is a translocation
code with length n, minimum distance at least d, and size
AH (p, ⌈3d/2⌉) . This can be easily generalized for all n to
obtain codes of size
3d
n
AH (⌈ ⌉ − 1, ⌈ ⌉) .
2
2
By assuming that the permutation code in the Hamming
metric is capacity achieving, the asymptotic rate of the constructed code becomes 1/2 − (3/2)δ. Therefore, this code
construction incurs a rate loss of 1/2(1 + δ) when compared
to the capacity bound.
More generally, we have the following lemma.

(3)

For i ∈ [2t + 1], let Ci be a permutation code over Pi with
minimum Hamming distance at least 4t + 1. The code C =
C1 ○ ⋯ ○ C2t+1 is referred to as an interleaved code with 2t + 1
classes. The following theorem provides a lower-bound for the
minimum translocation distance of C.
Theorem 11. Consider positive integers s, t, n = s(2t + 1),
and a partitioning of [n] of the form of (3). If, for i ∈ [2t + 1],
Ci is a permutation code over Pi with minimum Hamming
distance at least 4t+1, then C = C1 ○⋯○C2t+1 is a permutation
code over [n] with minimum translocation distance greater
than or equal to 2t + 1.
The rate of translocation correcting codes based on interleaving may be easily estimated as follows. The cardinality
of the interleaved code of length n and minimum distance
d
at least d is at least (AH (⌊ n ⌋ , 2d − 1)) , for odd d, and
d

Lemma 15. For sets P and Q of sizes p + 1 and p respec′
tively, let C1 ⊆ S(P ) be a code with minimum translocation
distance d and C1 ⊆ S(Q) a code with minimum Hamming
′
′
distance 3d/2. The code C1 ○C1 = {σ ○ π σ ∈ C1 , π ∈ C1 } has
minimum translocation distance d.

n
(AH (⌊ d+1 ⌋ , 2d + 1)) , for even d. Assuming that Hamming codes with minimum distance d ∼ nβ are used for
interleaving, it can be shown that the asymptotic rate of the
interleaved code equals 1 − β. In the next subsection we
describe a simple modiﬁcation of the interleaving procedure,
which, when applied recursively, improves upon the code rate
1 − β.
d+1

We now turn our attention to a recursive code construction
based on the ﬁndings outlined above.
Let α = 3/2. For a given n, set P = {1, ⋯, ⌈ n ⌉} and set Q =
2
′
{⌈ n ⌉ + 1, ⋯, 2 ⌈ n ⌉ − 1}. Suppose C1 ⊆ S(P ) is a code with
2
2
minimum translocation distance d and C1 ⊆ S(Q) a code with
minimum Hamming distance α d. Assuming that permutation
codes with this given minimum Hamming distance exist, we
′
only need to provide a construction for C1 . An obvious choice
′
for C1 is a code with only one codeword, which leads to the
case discussed above.
The gap to capacity may be signiﬁcantly reduced by ob′
serving that C1 may be constructed from shorter codes. To

A. Recursive Constructions
The interleaving approach described in the previous subsection may be modiﬁed as follows. Rather than interleaving
permutation codes with good Hamming distance, one may
construct a code in the translocation metric by interleaving
a code with good translocation distance and a code with

4

′
′
′
this end, let C1 = C2 ○ C2 where C2 is a code of length ⌈ n ⌉
4
with minimum translocation distance d, while C2 is a code of
length ⌈ n ⌉ − 1 and minimum Hamming distance αd.
4
By repeating the same procedure k times we obtain a code
of the form
′
(((Ck ○ Ck ) ○ Ck−1 ) ○ ⋯) ○ C1

Finally, we brieﬂy comment on the rate loss introduced into
the interleaved code construction in order to perform efﬁcient
decoding. To compute the rate of the code C, note that
ln C
ln C1
ln C1 ln p!
=
=
⋅
ln n!
ln n!
ln p! ln n!

(5)

Assume that the Hamming code C1 is capacity achieving, and
that therefore it holds that
t
ln C1
= 1 − 4 lim ⋅
lim
ln p!
n

where each Ci , i ≤ k, is a code with minimum Hamming
n
′
distance αd and length ⌈ 2i ⌉−1 and Ck is a code with minimum
n
translocation distance d and length ⌈ 2i ⌉. Since each Ci is
a permutation code in the Hamming metric with minimum
n
distance αd, we must have ⌈ 2i ⌉ − 1 ≥ αd. To ensure that this
condition is satisﬁed, in (5), we let k be the largest value of
n
n
i satisfying 2i − 1 ≥ αd. It is easy to see that k = ⌊log αd+1 ⌋.
′
Furthermore, we choose Ck to consist of a single codeword.
The asymptotic rate of the recursively constructed codes
1
1
equals 1 − 2−⌊log αδ ⌋ − αδ ⌊log αδ ⌋.

By observing that,
lim

(n/2) ln n + O (n) 1
ln p!
= lim
=
ln n!
n ln n + O (n)
2

one arrives at
ln C
1
t
= − 2 lim
ln n! 2
n
For the recursive construction described in (5), the asymptotic
rate of the efﬁciently decodable codes outlined above equals
1
1
1 − 2−⌊log αδ ⌋ − αδ ⌊log αδ ⌋, with α = 2.
lim

B. Decoding of Interleaved Codes
An efﬁcient decoder implementation for the general family
of interleaved codes is not currently known. For the case of
recursive codes, decoding may be accomplished with low complexity provided that the Hamming distance of the component
permutation codes is increased from 3d/2 to 2d.
For simplicity of exposition, we assume n to be odd, more
precisely, of the form n = 2p + 1. The case of even n may be
handled in the same manner, provided that one ﬁxes the last
symbol of all codewords.
Assume that C ⊆ Sn is an interleaved code of the form
′
′
C = C1 ○ C1 where C1 is a permutation code over the set
{1, ⋯, p + 1} with minimum translocation distance 2t + 1 and
C1 is a permutation code over the set Q = {p + 2, ⋯, 2p + 1}
with minimum Hamming distance 4t + 1. In what follows
we present a decoding method where there are at most t
′
translocation errors. We assume C1 = {[1, 2, ⋯, p + 1]}. The
general case follows by repeating the same argument for each
layer of the recursive code.
Let

R EFERENCES
[1] J. Karlof, “Permutation codes for the gaussian channel,” Information
Theory, IEEE Transactions on, vol. 35, pp. 726 –732, July 1989.
[2] I. F. Blake, G. Cohen, and M. Deza, “Coding with permutations,”
Information and Control, vol. 43, no. 1, pp. 1–19, 1979.
[3] A. Jiang, M. Schwartz, and J. Bruck, “Error-correcting codes for rank
modulation,” in Proc. IEEE Int. Symp. Information Theory, (Toronto,
Canada), pp. 1736 –1740, July 2008.
[4] H. Chadwick and L. Kurz, “Rank permutation group codes based on
kendall’s correlation statistic,” IEEE Trans. Information Theory, vol. 15,
pp. 306 – 315, Mar. 1969.
[5] P. Diaconis, “Group representations in probability and statistics,” Lecture
Notes-Monograph Series, vol. 11, 1988.
[6] A. Jiang, M. Schwartz, and J. Bruck, “Correcting charge-constrained
errors in the rank-modulation scheme,” Information Theory, IEEE Transactions on, vol. 56, pp. 2112 –2120, May 2010.
[7] Z. Wang and J. Bruck, “Partial rank modulation for ﬂash memories,” in
IEEE International Symposium on Information Theory, pp. 864 –868,
June 2010.
[8] A. Barg and A. Mazumdar, “Codes in permutations and error correction
for rank modulation,” IEEE Trans. Information Theory, vol. 56, pp. 3158
–3165, July 2010.
[9] J.-C. Chang, R.-J. Chen, T. Klove, and S.-C. Tsai, “On the maximum
number of permutations with given maximal or minimal distance,”
Information Theory, IEEE Transactions on, vol. 49(4), pp. 1054–1059,
2003.
[10] V. I. Levenshtein, “On perfect codes in deletion and insertion metric,”
Discrete Math. Appl., vol. 2, no. 3, pp. 241–258, 1992.
[11] A. Mazumdar, A. Barg, and G. Zemor, “Parameters of rank modulation
codes: Examples,” in 49th Annual Allerton Conference on Communication, Control, and Computing, pp. 13 –17, Sept. 2011.
[12] F. Farnoud, V. Skachek, and O. Milenkovic, “Rank modulation for
translocation error correction,” Arxiv preprint arXiv:1202.0932, 2012.
[13] P. Beame, E. Blais, and D. Huynh-Ngoc, “Longest common subsequences in sets of permutations,” Arxiv preprint arXiv:0904.1615, 2009.
[14] T. Swart and H. Ferreira, “Decoding distance-preserving permutation
codes for power-line communications,” in AFRICON, pp. 1 –7, Sept.
2007.
[15] T. Wadayama and M. Hagiwara, “Lp decodable permutation codes based
on linearly constrained permutation matrices,” in IEEE International
Symposium on Information Theory, pp. 139 –143, July/Aug. 2011.

σ = [1, σ (1) , 2, σ (2) , ⋯, σ (p) , p + 1] ∈ C
ˆ
ˆ
ˆ
be the stored codeword and let π ∈ Sn be the retrieved word.
For i ∈ [p], denote by sπ the substring of π that starts with
i
element i and ends with element i + 1. If i + 1 appears before
ˆ
i in π, then sπ is considered empty. For i ∈ [n], let π (i) = u
i
if sπ contains a unique element of Q equal to u. Otherwise,
i
let π (i) = . The following lemma holds.
ˆ
Lemma 16. The permutation π differs from σ in at most
ˆ
ˆ
2d○ (σ, π) positions.
The ﬁrst step of the decoding algorithm is to extract π from
ˆ
the permutation π. By Lemma 16, we have dH (ˆ , π ) ≤ 2t.
σ ˆ
Since C1 has minimum Hamming distance 4t + 1, σ can be
ˆ
uniquely recovered from π . Thus, decoding is accomplished
ˆ
through Hamming distance decoding of permutation codes,
for which a number of interesting algorithms are known in
the literature, e.g., [14], [15].

5

