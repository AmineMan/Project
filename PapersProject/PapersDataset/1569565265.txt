Title:          Paper Title (use style: paper title)
Subject:        
Keywords:       
Author:         IEEE
Creator:        Acrobat PDFMaker 10.1 for Word
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Fri May 18 20:27:13 2012
ModDate:        Tue Jun 19 12:54:23 2012
Tagged:         yes
Pages:          5
Encrypted:      no
Page size:      595.44 x 841.68 pts
File size:      461894 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569565265

Three-Receiver Broadcast Channels with Side
Information
Saeed Hajizadeh
(Undergraduate Student)
Department of Electrical Engineering
Ferdowsi University of Mashhad
Mashhad, Iran
Saeed.hajizadeh1367@gmail.com

Ghosheh Abed Hodtani
Department of Electrical Engineering
Ferdowsi University of Mashhad
Mashhad, Iran
ghodtani@gmail.com

In this paper, we find the achievable rate region of
Multilevel BC and 3-receiver less noisy BC both with SI noncausally available at the encoder. Our achievable rate regions
reduce to that of [3] and [4] when there is no side information.
We also find the capacity region of the latter when side
information is also available at the receivers. The rest of the
paper is organized as follows. In section II, basic definitions
and notations are presented. In sections III and IV, new
achievable rate regions are given for the Multilevel BC and 3receiver less noisy BC, respectively. In section V, conclusion
is given.

Abstract—Three-receiver broadcast channel (BC) is of
interest due to its information theoretical differences with two
receiver one. In this paper, we derive achievable rate regions for
two classes of 3-receiver BC with side information available at
the transmitter, Multilevel BC and 3-receiver less noisy BC, by
using superposition coding, Gel’fand-Pinsker binning scheme
and Nair-El Gamal indirect decoding. Our rate region for
multilevel BC subsumes the Steinberg rate region for 2-receiver
degraded BC with side information as its special case. We also
find the capacity region of 3-receiver less noisy BC when side
information is available both at the transmitter and at the
receivers.
Keywords: 3-receiver broadcast channel, less noisy, Multilevel
broadcast channel

II.

The k-receiver, 𝑘𝑘 ≥ 3, broadcast channel (BC) was first
studied by Borade et al. in [1] where they simply surmised
that straightforward extension of Körner-Marton’s capacity
region for two-receiver BCs with degraded message sets [2] to
k-receiver multilevel broadcast networks is optimal. Nair-El
Gamal [3] showed that the capacity region of a special class of
3-receiver BCs with two degraded message sets when one of
the receivers is a degraded version of the other, is a superset of
[1], thus proving that direct extension of [2] is not in general
optimal. Nair and Wang later in [4] established the capacity
region of the 3-receiver less noisy BC. Channels with Side
information (SI), were first studied by Shannon [5], where he
found the capacity region of the Single-Input-Single-Output
channel when SI is causally available at the encoder. Gelf’and
and Pinsker [6] found the capacity region of a single-user
channel when SI is non-causally available at the transmitter
while the receiver is kept ignorant of it. Cover and Chiang [7]
extended the results of [6] to the case where SI is available at
both the encoder and the decoder. Multiple user channels with
side information were studied in [8] where inner and outer
bounds for degraded BC with non-causal SI and capacity
region of degraded BC with causal SI were found. Moreover,
in [9] inner and outer bounds were given to general two-user
BCs with SI available at the transmitter and other special cases
both for BCs and MACs were also found.
I.

DEFINITIONS

Random variables and their realizations are denoted by
uppercase and lowercase letters, respectively, e.g. x is a
realization of X. Let 𝒳𝒳, 𝒴𝒴1 , 𝒴𝒴2 , 𝒴𝒴3 , 𝑎𝑎𝑎𝑎𝑎𝑎 𝒮𝒮 be finite sets
showing alphabets of random variables. The n-sequence of a
random variable is given by 𝑋𝑋 𝑛𝑛 where the superscript is
omitted when the choice of n is clear, thus we only use
boldface letters for the random variable itself, i.e. 𝒙𝒙 = 𝑥𝑥 𝑛𝑛 .
is
the
Throughout,
we
assume
that
𝑋𝑋𝑖𝑖𝑛𝑛
sequence (𝑋𝑋𝑖𝑖 , 𝑋𝑋𝑖𝑖+1 , … , 𝑋𝑋 𝑛𝑛 ).

INTRODUCTION

Definition 1: A channel 𝑋𝑋 → 𝑍𝑍 is said to be a degraded
version of the channel 𝑋𝑋 → 𝑌𝑌 with SI if 𝑋𝑋 → 𝑌𝑌 → 𝑍𝑍 be a
Markov chain conditioned on every 𝑠𝑠 ∈ 𝒮𝒮 for all 𝑝𝑝(𝑢𝑢, 𝑥𝑥|𝑠𝑠).
Multilevel BC with side information, denoted by
�𝒳𝒳, 𝒮𝒮, 𝒴𝒴1 , 𝒴𝒴2 , 𝒴𝒴3 , 𝑝𝑝(𝑦𝑦1 , 𝑦𝑦3 |𝑥𝑥, 𝑠𝑠), 𝑝𝑝(𝑦𝑦2 |𝑦𝑦1 )� , is a 3-receiver BC
with 2-degraded message sets with input alphabet 𝒳𝒳 and
output alphabets 𝒴𝒴1 , 𝒴𝒴2 , and 𝒴𝒴3 . The side information is the
random variable S distributed over the set 𝒮𝒮 according to 𝑝𝑝(𝑠𝑠).
The transition probability function 𝑝𝑝(𝑦𝑦1 , 𝑦𝑦3 |𝑥𝑥, 𝑠𝑠) describes the
relationship between channel input X, side information S, and
channel outputs 𝑌𝑌1 and 𝑌𝑌3 while the probability function
𝑝𝑝(𝑦𝑦2 |𝑦𝑦1 ) shows the virtual channel modeling the output 𝑌𝑌2 as
the degraded version of 𝑌𝑌1 . Independent message sets
𝑚𝑚0 ∈ ℳ0 and 𝑚𝑚1 ∈ ℳ1 are to be reliably sent, m0 being the
common message for all the receivers and m1 the private
message only for Y1 . Channel model is depicted in Fig. 1.

1

Figure 1. Multilevel broadcast channel with side information.

Definition 2: A (𝑛𝑛, 2 𝑛𝑛𝑅𝑅0 , 2 𝑛𝑛𝑅𝑅1 , 𝜖𝜖) two-degraded message set
code
for
the
Multilevel
BC
with
side
information �𝑝𝑝(𝑦𝑦1 , 𝑦𝑦3 |𝑥𝑥, 𝑠𝑠), 𝑝𝑝(𝑦𝑦2 |𝑦𝑦1 )� consists of an encoder
map

Figure.2. Three-receiver less noisy broadcast channel with side
information.

Achievable rate tuples and the achievable rate region and
the capacity region 𝒞𝒞 𝐿𝐿 are defined in just the same way as
Multilevel BC.

𝑓𝑓 ∶ {1,2, … , 𝑀𝑀0 } × {1,2, … , 𝑀𝑀1 } × 𝒮𝒮 𝑛𝑛 ⟶ 𝒳𝒳 𝑛𝑛
𝑔𝑔 𝑦𝑦1 ∶ 𝒴𝒴1𝑛𝑛 ⟶ {1,2, … , 𝑀𝑀0 } × {1,2, … , 𝑀𝑀1 }
𝑔𝑔 𝑦𝑦2 ∶ 𝒴𝒴2𝑛𝑛 ⟶ {1,2, … , 𝑀𝑀0 }
𝑔𝑔 𝑦𝑦3 ∶ 𝒴𝒴3𝑛𝑛 ⟶ {1,2, … , 𝑀𝑀0 }

and a tuple of decoding maps

Such that 𝑃𝑃𝑒𝑒

(𝑛𝑛)

III.

Define 𝒫𝒫 as the collection of all random variables
(𝑈𝑈, 𝑉𝑉, 𝑆𝑆, 𝑋𝑋, 𝑌𝑌1 , 𝑌𝑌2 , 𝑌𝑌3 ) with finite alphabets such that
INFORMATION

𝑝𝑝(𝑢𝑢, 𝑣𝑣, 𝑠𝑠, 𝑥𝑥, 𝑦𝑦1 , 𝑦𝑦2 , 𝑦𝑦3 ) =
𝑝𝑝(𝑠𝑠)𝑝𝑝(𝑢𝑢|𝑠𝑠)𝑝𝑝(𝑣𝑣|𝑢𝑢, 𝑠𝑠)𝑝𝑝(𝑥𝑥|𝑣𝑣, 𝑠𝑠)𝑝𝑝(𝑦𝑦1 , 𝑦𝑦3 |𝑥𝑥, 𝑠𝑠)𝑝𝑝(𝑦𝑦2 |𝑦𝑦1 )

≤ 𝜖𝜖, i.e.

1
� � � 𝑝𝑝(𝒔𝒔)𝑝𝑝{𝑔𝑔 𝑦𝑦1 (𝒚𝒚1 ) ≠ (𝑚𝑚0 , 𝑚𝑚1 ) 𝑜𝑜𝑜𝑜
𝑀𝑀0 𝑀𝑀1
𝑛𝑛
𝑛𝑛
𝑀𝑀0

𝑀𝑀1

(𝑈𝑈, 𝑉𝑉) → (𝑋𝑋, 𝑆𝑆) → (𝑌𝑌1 , 𝑌𝑌3 )
(𝑆𝑆, 𝑋𝑋, 𝑌𝑌3 ) → 𝑌𝑌1 → 𝑌𝑌2

𝑚𝑚 0=1 𝑚𝑚 1 =1 𝑠𝑠 ∈𝒮𝒮

𝑔𝑔 𝑦𝑦2 (𝒚𝒚2 ) ≠ 𝑚𝑚0 𝑜𝑜𝑜𝑜 𝑔𝑔 𝑦𝑦3 (𝒚𝒚3 ) ≠ 𝑚𝑚0 |𝒔𝒔, 𝒙𝒙(𝑚𝑚0 , 𝑚𝑚1 , 𝒔𝒔)} ≤ 𝝐𝝐

(1)

By (1), the following Markov chains hold:

(2)
(3)

Theorem 1: A pair of nonnegative numbers (𝑅𝑅0 , 𝑅𝑅1 ) is
achievable for Multilevel BC with side information noncausally available at the transmitter provided that

1
(𝑅𝑅0 , 𝑅𝑅1 ) = (log 𝑀𝑀0 , 𝑙𝑙 𝑙𝑙𝑙𝑙 𝑀𝑀1 )
𝑛𝑛

The rate pair of the code is defined as

A rate pair (𝑅𝑅0 , 𝑅𝑅1 ) is said to be 𝜖𝜖-achievable if for any
𝜂𝜂 > 0 there is an integer 𝑛𝑛0 such that for all 𝑛𝑛 ≥ 𝑛𝑛0 we have a
code
for
(𝑛𝑛, 2 𝑛𝑛(𝑅𝑅0 −𝜂𝜂 ) , 2 𝑛𝑛(𝑅𝑅1 −𝜂𝜂 ) , 𝜖𝜖)
�𝑝𝑝(𝑦𝑦1 , 𝑦𝑦3 |𝑥𝑥, 𝑠𝑠), 𝑝𝑝(𝑦𝑦2 |𝑦𝑦1 )�. The union of the closure of all 𝜖𝜖achievable rate pairs is called the capacity region 𝒞𝒞 𝑀𝑀𝑀𝑀𝑀𝑀 .

𝑅𝑅0 ≤ min{𝐼𝐼(𝑈𝑈; 𝑌𝑌2 ) − 𝐼𝐼(𝑈𝑈; 𝑆𝑆), 𝐼𝐼(𝑉𝑉; 𝑌𝑌3 ) − 𝐼𝐼(𝑈𝑈𝑈𝑈; 𝑆𝑆)}
𝑅𝑅1 ≤ 𝐼𝐼(𝑋𝑋; 𝑌𝑌1 |𝑈𝑈) − 𝐼𝐼(𝑉𝑉; 𝑆𝑆|𝑈𝑈) − 𝐼𝐼(𝑋𝑋; 𝑆𝑆|𝑉𝑉)
(4)
𝑅𝑅0 + 𝑅𝑅1 ≤ 𝐼𝐼(𝑉𝑉; 𝑌𝑌3 ) + 𝐼𝐼(𝑋𝑋; 𝑌𝑌1 |𝑉𝑉) − 𝐼𝐼(𝑋𝑋; 𝑆𝑆|𝑉𝑉) − 𝐼𝐼(𝑈𝑈𝑈𝑈; 𝑆𝑆)
for some (𝑈𝑈, 𝑉𝑉, 𝑆𝑆, 𝑋𝑋, 𝑌𝑌1 , 𝑌𝑌2 , 𝑌𝑌3 ) ∈ 𝒫𝒫.

Corollary 1.1: By setting 𝑆𝑆 ≡ ∅ in (4), our achievable rate
region in Theorem 1 is reduced to the capacity region of
Multilevel BC given in [3].

Definition 3: A channel 𝑋𝑋 → 𝑌𝑌 is said to be less noisy than
the channel 𝑋𝑋 → 𝑍𝑍 in the presence of side information if
𝐼𝐼(𝑈𝑈; 𝑌𝑌|𝑆𝑆 = 𝑠𝑠) ≥ 𝐼𝐼(𝑈𝑈; 𝑍𝑍|𝑆𝑆 = 𝑠𝑠)
∀𝑝𝑝(𝑢𝑢, 𝑥𝑥, 𝑦𝑦, 𝑧𝑧|𝑠𝑠) = 𝑝𝑝(𝑢𝑢|𝑠𝑠)𝑝𝑝(𝑥𝑥|𝑢𝑢, 𝑠𝑠)𝑝𝑝(𝑦𝑦, 𝑧𝑧|𝑥𝑥, 𝑠𝑠) 𝑎𝑎𝑎𝑎𝑎𝑎 ∀𝑠𝑠 ∈ 𝒮𝒮.

Corollary 1.2: By setting 𝑌𝑌3 = 𝑌𝑌1 and 𝑉𝑉 = 𝑈𝑈 in (4), our
achievable rate region reduces to that of [8] for the two-user
degraded BC with side information.

The 3-receiver less noisy BC with side information is
depicted in Fig. 2, where 𝑌𝑌1 is less noisy than 𝑌𝑌2 and 𝑌𝑌2 is less
noisy than 𝑌𝑌3 , i.e. according to [4], 𝑌𝑌1 ≽ 𝑌𝑌2 ≽ 𝑌𝑌3 .

Proof: Fix n and a joint distribution on 𝒫𝒫. Note that side
information is distributed i.i.d according to

The messages 𝑚𝑚1 ∈ ℳ1 , 𝑚𝑚2 ∈ ℳ2 , 𝑚𝑚3 ∈ ℳ3 are to be
reliably sent to receivers 𝑌𝑌1 , 𝑌𝑌2 , 𝑎𝑎𝑎𝑎𝑎𝑎 𝑌𝑌3 , respectively. The code
and rate tuple definitions are as follows

𝑛𝑛

𝑝𝑝(𝒔𝒔) = � 𝑝𝑝(𝑠𝑠𝑖𝑖 )
𝑖𝑖=1

Split the ℳ1 message into two independent submessage
sets ℳ11 , 𝑎𝑎𝑎𝑎𝑎𝑎 ℳ12 so that 𝑅𝑅1 = 𝑅𝑅11 + 𝑅𝑅12 .

(𝑛𝑛, 2 𝑛𝑛𝑅𝑅1 , 2 𝑛𝑛𝑅𝑅2 , 2 𝑛𝑛𝑅𝑅3 , 𝜖𝜖)

(𝑅𝑅1 , 𝑅𝑅2 , 𝑅𝑅3 ) =

MULTILEVEL BROADCAST CHANNEL WITH SIDE

1
(𝑙𝑙 𝑙𝑙𝑙𝑙 𝑀𝑀1 , 𝑙𝑙 𝑙𝑙𝑙𝑙 𝑀𝑀2 , 𝑙𝑙 𝑙𝑙𝑙𝑙 𝑀𝑀3 )
𝑛𝑛

Codebook Generation: First randomly and independently
′
′
′
′
generate 2 𝑛𝑛�𝑅𝑅0 +𝑅𝑅0 � sequences 𝒖𝒖(𝑚𝑚0 , 𝑚𝑚0 ), 𝑚𝑚0 ∈ �1,2, … , 2 𝑛𝑛𝑅𝑅0 �,

2

𝑛𝑛
𝑚𝑚0 ∈ {1,2, … , 2 𝑛𝑛𝑅𝑅0 }, each one i.i.d according to ∏ 𝑖𝑖=1 𝑝𝑝(𝑢𝑢 𝑖𝑖 )
𝑛𝑛𝑅𝑅0
bins. It is clear that
and then randomly throw them into 2
′
𝑛𝑛𝑅𝑅0
sequences in each bin.
we have 2
′
Now for each 𝒖𝒖(𝑚𝑚0 , 𝑚𝑚0 ), randomly and independently
′ +𝑅𝑅 )
′
′
′
generate 2 𝑛𝑛(𝑅𝑅11 11 sequences 𝒗𝒗(𝑚𝑚0 , 𝑚𝑚0 , 𝑚𝑚11 , 𝑚𝑚11 ), 𝑚𝑚11 ∈
′
𝑛𝑛𝑅𝑅11
𝑛𝑛𝑅𝑅11 }
each one i.i.d according to
�, 𝑚𝑚11 ∈ {1, … , 2
�1, … , 2
𝑛𝑛
′
∏ 𝑖𝑖=1 𝑝𝑝 𝑉𝑉|𝑈𝑈 �𝑣𝑣 𝑖𝑖 �𝑢𝑢 𝑖𝑖 (𝑚𝑚0 , 𝑚𝑚0 )�, and randomly throw them into
2 𝑛𝑛𝑅𝑅11 bins.
′
′
Now for each sequence 𝒗𝒗(𝑚𝑚0 , 𝑚𝑚0 , 𝑚𝑚11 , 𝑚𝑚11 ), randomly and
′
independently
generate
2 𝑛𝑛(𝑅𝑅12 +𝑅𝑅12 )
′
′
′
sequences 𝒙𝒙(𝑚𝑚0 , 𝑚𝑚0 , 𝑚𝑚11 , 𝑚𝑚11 , 𝑚𝑚12 , 𝑚𝑚12 ) each one i.i.d
𝑛𝑛
𝑛𝑛
according to ∏ 𝑖𝑖=1 𝑝𝑝 𝑋𝑋|𝑈𝑈,𝑉𝑉 (𝑥𝑥 𝑖𝑖 |𝑣𝑣 𝑖𝑖 , 𝑢𝑢 𝑖𝑖 ) = ∏ 𝑖𝑖=1 𝑝𝑝 𝑋𝑋|𝑉𝑉 (𝑥𝑥 𝑖𝑖 |𝑣𝑣 𝑖𝑖 ). Then
𝑛𝑛𝑅𝑅12
randomly throw them into 2
bins. Then provide the
transmitter and all the receivers with bins and their codewords.
Encoding: We are given the side information 𝒔𝒔 and the
message pair (𝑚𝑚0 , 𝑚𝑚1 ). Indeed, our messages are bin indices.
We find 𝑚𝑚11 , 𝑎𝑎𝑎𝑎𝑎𝑎 𝑚𝑚12 . Now in the bin 𝑚𝑚0 of 𝒖𝒖 sequences
(𝒏𝒏)
′
′
look for a 𝑚𝑚0 such that (𝒖𝒖(𝑚𝑚0 , 𝑚𝑚0 ), 𝒔𝒔) ∈ 𝐴𝐴 𝝐𝝐 , i.e. the
sequence 𝒖𝒖 that is jointly typical with the 𝒔𝒔 given where
definitions of typical sequences are given in [12]. Then in the
′
bin 𝑚𝑚11 of 𝒗𝒗 sequences look for some 𝑚𝑚11 such that

We see that ∀𝜖𝜖 > 0, 𝑝𝑝(𝐸𝐸22 ) ≤ 𝜖𝜖 as 𝑛𝑛 → ∞ provided that

′
′
′
(𝒖𝒖(𝑚𝑚0 , 𝑚𝑚0 ), 𝒗𝒗(𝑚𝑚0 , 𝑚𝑚0 , 𝑚𝑚11 , 𝑚𝑚11 ),
(𝒏𝒏)
′
′
′
𝒙𝒙(𝑚𝑚0 , 𝑚𝑚0 , 𝑚𝑚11 , 𝑚𝑚11 , 𝑚𝑚12 , 𝑚𝑚12 ), 𝒔𝒔) ∈ 𝑨𝑨 𝝐𝝐

The third receiver 𝑌𝑌3 receives 𝒚𝒚3 and needs to decode only
the common message indirectly by decoding the message
𝑚𝑚11 . The error events are

′
𝑅𝑅0 + 𝑅𝑅0 ≤ 𝐼𝐼(𝑈𝑈; 𝑌𝑌2 ) − 3𝜖𝜖

The first receiver 𝑌𝑌1 receives 𝒚𝒚1 and needs to decode both
𝑚𝑚0 and 𝑚𝑚1 . Therefore, the error events are
(5)

′
′
′
𝐸𝐸11 = {( 𝒖𝒖(𝑀𝑀0 , 1), 𝒗𝒗(𝑀𝑀0 , 1, 𝑀𝑀11 , 1),
(𝑛𝑛)
′
′
′
𝒙𝒙(𝑀𝑀0 , 1, 𝑀𝑀11 , 1, 𝑀𝑀12 , 1), 𝒚𝒚1 ) ∉ 𝐴𝐴∈ }
′
′
′
𝐸𝐸12 = {( 𝒖𝒖(𝑀𝑀0 , 1), 𝒗𝒗(𝑀𝑀0 , 1, 𝑀𝑀11 , 1),
(𝑛𝑛)
′
′
′
𝒙𝒙(𝑀𝑀0 , 1, 𝑀𝑀11 , 1, 𝑚𝑚12 , 𝑚𝑚12 ), 𝒚𝒚1 ) ∈ 𝐴𝐴∈
′
′
𝑓𝑓𝑓𝑓𝑓𝑓 𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠 𝑚𝑚12 ≠ 1 𝑎𝑎𝑎𝑎𝑎𝑎 𝑚𝑚12 ≠ 𝑀𝑀12 }
′
′
′
𝐸𝐸13 = {( 𝒖𝒖(𝑀𝑀0 , 1), 𝒗𝒗(𝑀𝑀0 , 1, 𝑚𝑚11 , 𝑚𝑚11 ),
(𝑛𝑛)
′
′
′
𝒙𝒙(𝑀𝑀0 , 1, 𝑚𝑚11 , 𝑚𝑚11 , 𝑚𝑚12 , 𝑚𝑚12 ), 𝒚𝒚1 ) ∈ 𝐴𝐴∈
′
′
𝑓𝑓𝑓𝑓𝑓𝑓 𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠 𝑚𝑚1𝑖𝑖 ≠ 1 𝑎𝑎𝑎𝑎𝑎𝑎 𝑚𝑚1𝑖𝑖 ≠ 𝑀𝑀1𝑖𝑖 , 𝑖𝑖 = 1,2}
′
′
′
𝐸𝐸14 = {( 𝒖𝒖(𝑚𝑚0 , 𝑚𝑚0 ), 𝒗𝒗(𝑚𝑚0 , 𝑚𝑚0 , 𝑚𝑚11 , 𝑚𝑚11 ),
(𝑛𝑛)
′
′
′
𝒙𝒙(𝑚𝑚0 , 𝑚𝑚0 , 𝑚𝑚11 , 𝑚𝑚11 , 𝑚𝑚12 , 𝑚𝑚12 ), 𝒚𝒚1 ) ∈ 𝐴𝐴∈
′
′
𝑓𝑓𝑓𝑓𝑓𝑓 𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠 𝑚𝑚0 ≠ 1 𝑎𝑎𝑎𝑎𝑎𝑎 𝑚𝑚0 ≠ 𝑀𝑀0 𝑎𝑎𝑎𝑎𝑎𝑎 𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠
′
′
𝑚𝑚1𝑖𝑖 ≠ 1 𝑎𝑎𝑎𝑎𝑎𝑎 𝑚𝑚1𝑖𝑖 ≠ 𝑀𝑀1𝑖𝑖 , 𝑖𝑖 = 1,2}

The first receiver’s probability of error can be arbitrarily
made small provided that
′
𝑅𝑅12 + 𝑅𝑅12 ≤ 𝐼𝐼(𝑋𝑋; 𝑌𝑌1 |𝑉𝑉) − 6𝜖𝜖
′
′
𝑅𝑅11 + 𝑅𝑅11 + 𝑅𝑅12 + 𝑅𝑅12 ≤ 𝐼𝐼(𝑋𝑋; 𝑌𝑌1 |𝑈𝑈) − 6𝜖𝜖
′
′
′
𝑅𝑅0 + 𝑅𝑅0 + 𝑅𝑅11 + 𝑅𝑅11 + 𝑅𝑅12 + 𝑅𝑅12 ≤ 𝐼𝐼(𝑋𝑋; 𝑌𝑌1 ) − 5𝜖𝜖

′
′
′
(𝒖𝒖(𝑚𝑚0 , 𝑚𝑚0 ), 𝒗𝒗(𝑚𝑚0 , 𝑚𝑚0 , 𝑚𝑚11 , 𝑚𝑚11 ), 𝒔𝒔) ∈ 𝑨𝑨(𝒏𝒏)
𝝐𝝐

′
Now in the bin 𝑚𝑚12 of 𝒙𝒙 sequences look for some 𝑚𝑚12 such
that

We send the found 𝒙𝒙 sequence. Before bumping into
decoding, assume that the correct indices are found through
′
′
′
′
the encoding procedure, i.e. 𝑚𝑚0 = 𝑀𝑀0 , 𝑚𝑚11 = 𝑀𝑀11
′
′
and 𝑚𝑚12 = 𝑀𝑀12 .

(6)
(7)
(8)

′
′
′
𝐸𝐸31 = {( 𝒖𝒖(𝑀𝑀0 , 1), 𝒗𝒗(𝑀𝑀0 , 1, 𝑀𝑀11 , 1), 𝒚𝒚3 ) ∉ 𝐴𝐴∈ }
(𝑛𝑛)
′
′
′
𝐸𝐸32 = {( 𝒖𝒖(𝑀𝑀0 , 1), 𝒗𝒗(𝑀𝑀0 , 1, 𝑚𝑚11 , 𝑚𝑚11 ), 𝒚𝒚3 ) ∈ 𝐴𝐴∈ 𝑓𝑓𝑓𝑓𝑓𝑓
′
′
′
𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠 𝑚𝑚11 ≠ 1 𝑎𝑎𝑎𝑎𝑎𝑎 𝑚𝑚11 ≠ 𝑀𝑀11 }
(𝑛𝑛)
′
′
′
𝐸𝐸33 = {( 𝒖𝒖(𝑚𝑚0 , 𝑚𝑚0 ), 𝒗𝒗(𝑚𝑚0 , 𝑚𝑚0 , 𝑚𝑚11 , 𝑚𝑚11 ), 𝒚𝒚3 ) ∈ 𝐴𝐴∈ 𝑓𝑓𝑓𝑓𝑓𝑓
′
′
′
′
𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠 𝑚𝑚0 ≠ 1, 𝑚𝑚11 ≠ 1, 𝑚𝑚0 ≠ 𝑀𝑀0 , 𝑎𝑎𝑎𝑎𝑎𝑎 𝑚𝑚11 ≠ 𝑀𝑀11 }
(𝑛𝑛)

Decoding: Since the messages are uniformly distributed
over their respective ranges, we can assume, without loss of
generality, that the tuple (𝑚𝑚0 , 𝑚𝑚11 , 𝑚𝑚12 ) = (1,1,1) is sent.
The second receiver 𝑌𝑌2 receives 𝒚𝒚2 thus having the
following error events
′
𝐸𝐸21 = {(𝒖𝒖(𝑀𝑀0 , 1), 𝒚𝒚2 ) ∉ 𝐴𝐴 𝜖𝜖 }
(𝑛𝑛)
′
𝐸𝐸22 = {(𝒖𝒖(𝑚𝑚0 , 𝑚𝑚0 ), 𝒚𝒚2 ) ∈ 𝐴𝐴 𝜖𝜖 𝑓𝑓𝑓𝑓𝑓𝑓 𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠 𝑚𝑚0 ≠ 1
′
′
𝑎𝑎𝑎𝑎𝑎𝑎 𝑚𝑚0 ≠ 𝑀𝑀0 }

Again by using WLLN and AEP, we see that the third
receiver’s error probabilities can be arbitrarily made small
as 𝑛𝑛 → ∞ provided that

leads us to a redundant inequality.

′
𝑅𝑅0 ≥ 𝐼𝐼(𝑈𝑈; 𝑆𝑆) + 2𝜖𝜖
′
𝑅𝑅11 ≥ 𝐼𝐼(𝑉𝑉; 𝑆𝑆|𝑈𝑈) + 2𝜖𝜖
′
𝑅𝑅12 ≥ 𝐼𝐼(𝑋𝑋; 𝑆𝑆|𝑉𝑉) + 2𝜖𝜖

(𝑛𝑛)

′
𝐸𝐸23 = {(𝒖𝒖(𝑀𝑀0 , 𝑚𝑚0 ), 𝒚𝒚1 ) ∈

(𝑛𝑛)
𝐴𝐴 𝜖𝜖

′
′
𝑅𝑅0 + 𝑅𝑅0 + 𝑅𝑅11 + 𝑅𝑅11 ≤ 𝐼𝐼(𝑉𝑉; 𝑌𝑌3 ) − 3𝜖𝜖

Using Gel’fand-Pinsker coding we see that the encoders can
′
′
′
choose the proper 𝑚𝑚0 , 𝑚𝑚11 , 𝑎𝑎𝑎𝑎𝑎𝑎 𝑚𝑚12 indices with vanishing
probability of error provided that for every 𝜖𝜖 > 0 and
sufficiently large n

𝑓𝑓𝑓𝑓𝑓𝑓 𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠 𝑚𝑚0 ≠ 1}

Remark 1: The following error event

Now by the weak law of large numbers (WLLN)
[14], 𝑝𝑝(𝐸𝐸21 ) ≤ 𝜖𝜖, ∀𝜖𝜖 > 0 as 𝑛𝑛 → ∞. For the second error
event we have
𝑝𝑝(𝐸𝐸22 ) = � � 𝑝𝑝(𝒖𝒖)𝑝𝑝(𝒚𝒚2 ) ≤ 2 𝑛𝑛�𝑅𝑅0 +𝑅𝑅0 � 2 𝑛𝑛(𝐻𝐻(𝑈𝑈,𝑌𝑌2 )+𝜖𝜖)

2

′
𝑚𝑚 0 ,𝑚𝑚 0 𝐴𝐴(𝑛𝑛 )
𝜖𝜖
−𝑛𝑛(𝐻𝐻(𝑈𝑈)−𝜖𝜖) −𝑛𝑛(𝐻𝐻(𝑌𝑌2 )−𝜖𝜖)

2

=2

(9)

′

𝐼𝐼(𝑉𝑉; 𝑆𝑆|𝑈𝑈) + 𝐼𝐼(𝑈𝑈; 𝑆𝑆) = 𝐼𝐼(𝑉𝑉𝑉𝑉; 𝑆𝑆)

(10)
(11)
(12)

Now combining (5) - (9) and (10) - (12) and noting that

′
−𝑛𝑛�𝐼𝐼(𝑈𝑈;𝑌𝑌2 )−3𝜖𝜖−𝑅𝑅0 −𝑅𝑅0 �

3

(13)

′
𝑅𝑅3 + 𝑅𝑅3 ≤ 𝐼𝐼(𝑈𝑈; 𝑌𝑌3 )
′
𝑅𝑅2 + 𝑅𝑅2 ≤ 𝐼𝐼(𝑉𝑉; 𝑌𝑌2 |𝑈𝑈)
′
𝑅𝑅1 + 𝑅𝑅1 ≤ 𝐼𝐼(𝑋𝑋; 𝑌𝑌1 |𝑉𝑉)

and using Fourier-Motzkin procedure afterwards to eliminate
𝑅𝑅11 𝑎𝑎𝑎𝑎𝑎𝑎 𝑅𝑅12 , we obtain (4) as an achievable rate region for
Multilevel BC with side information.
∎
IV.

Now combining (16), (17) and (18) with (19), (20) and (21)
gives us (15).
∎

THREE-RECEIVER LESS NOISY BROADCAST
CHANNEL WITH SIDE INFORMATION

Define 𝒫𝒫 ∗ as the collection of all random variables
(𝑈𝑈, 𝑉𝑉, 𝑆𝑆, 𝑋𝑋, 𝑌𝑌1 , 𝑌𝑌2 , 𝑌𝑌3 ) with finite alphabets such that
𝑝𝑝(𝑢𝑢, 𝑣𝑣, 𝑠𝑠, 𝑥𝑥, 𝑦𝑦1 , 𝑦𝑦2 , 𝑦𝑦3 ) =
𝑝𝑝(𝑠𝑠)𝑝𝑝(𝑢𝑢|𝑠𝑠)𝑝𝑝(𝑣𝑣|𝑢𝑢, 𝑠𝑠)𝑝𝑝(𝑥𝑥|𝑣𝑣, 𝑠𝑠)𝑝𝑝(𝑦𝑦1 , 𝑦𝑦2 , 𝑦𝑦3 |𝑥𝑥, 𝑠𝑠)

Theorem 3: The capacity region of the 3-receiver less
noisy BC with side information, non-causally available at the
transmitter and the receivers is the set of all rate
triples(𝑅𝑅1 , 𝑅𝑅2 , 𝑅𝑅3 ) such that
𝑅𝑅1 ≤ 𝐼𝐼(𝑋𝑋; 𝑌𝑌1 |𝑉𝑉𝑉𝑉)
𝑅𝑅2 ≤ 𝐼𝐼(𝑉𝑉; 𝑌𝑌2 |𝑈𝑈𝑈𝑈)
𝑅𝑅3 ≤ 𝐼𝐼(𝑈𝑈; 𝑌𝑌3 |𝑆𝑆)

Theorem 2: A rate triple(𝑅𝑅1 , 𝑅𝑅2 , 𝑅𝑅3 ) is achievable for 3receiver less noisy BC with side information non-causally
available at the transmitter provided that
𝑅𝑅1 ≤ 𝐼𝐼(𝑋𝑋; 𝑌𝑌1 |𝑉𝑉) − 𝐼𝐼(𝑋𝑋; 𝑆𝑆|𝑉𝑉)
𝑅𝑅2 ≤ 𝐼𝐼(𝑉𝑉; 𝑌𝑌2 |𝑈𝑈) − 𝐼𝐼(𝑉𝑉; 𝑆𝑆|𝑈𝑈)
𝑅𝑅3 ≤ 𝐼𝐼(𝑈𝑈; 𝑌𝑌3 ) − 𝐼𝐼(𝑈𝑈; 𝑆𝑆)

for some joint distribution on 𝒫𝒫∗ .

(14)

(22)

Proof:

Achievability: The direct part of the proof is achieved if
�
you set 𝑌𝑌𝑘𝑘 = (𝑌𝑌𝑘𝑘 , 𝑆𝑆), 𝑘𝑘 = 1,2,3 in (15).

(15)

Converse: The converse part uses an extension of lemma 1
in [4].

Lemma 1: [4] Let the channel 𝑋𝑋 → 𝑌𝑌 be less noisy than the
channel 𝑋𝑋 → 𝑍𝑍. Consider (𝑀𝑀, 𝑆𝑆 𝑛𝑛 ) to be any random vector
such that

Corollary 2.1: By setting 𝑆𝑆 ≡ ∅ in the above rate region, it
reduces to the capacity region of 3-receiver less noisy BC
given in [4].

(𝑀𝑀, 𝑆𝑆 𝑛𝑛 ) → 𝑋𝑋 𝑛𝑛 → (𝑌𝑌 𝑛𝑛 , 𝑍𝑍 𝑛𝑛 )

Proof: The proof uses Cover’s superposition [15] and
Gel’fand-Pinsker random binning coding [6] procedures along
with Nair’s indirect decoding and is similar to the last proof
provided and thus only an outline is provided.

𝐼𝐼(𝑌𝑌 𝑖𝑖−1 ; 𝑍𝑍𝑖𝑖 �𝑀𝑀, 𝑆𝑆 𝑛𝑛 ) ≥ 𝐼𝐼(𝑍𝑍 𝑖𝑖−1 ; 𝑍𝑍𝑖𝑖 �𝑀𝑀, 𝑆𝑆 𝑛𝑛 )

forms a Markov chain. Then
1.

Fix n and a distribution on 𝒫𝒫 .
Again note that side information is distributed i.i.d
according to
∗

2.

𝐼𝐼(𝑌𝑌 𝑖𝑖−1 ; 𝑌𝑌𝑖𝑖 �𝑀𝑀, 𝑆𝑆 𝑛𝑛 ) ≥ 𝐼𝐼(𝑍𝑍 𝑖𝑖−1 ; 𝑌𝑌𝑖𝑖 �𝑀𝑀, 𝑆𝑆 𝑛𝑛 )

Proof: First of all note that since the channel is
memoryless we have

𝑛𝑛
(𝑀𝑀1 , 𝑀𝑀2 , 𝑀𝑀3 , 𝑌𝑌1𝑖𝑖−1 , 𝑌𝑌2𝑖𝑖−1 , 𝑌𝑌3𝑖𝑖−1 , 𝑆𝑆 𝑖𝑖−1 , 𝑆𝑆𝑖𝑖+1 ) → (𝑋𝑋𝑖𝑖 , 𝑆𝑆𝑖𝑖 ) → (𝑌𝑌1𝑖𝑖 , 𝑌𝑌2𝑖𝑖 , 𝑌𝑌3𝑖𝑖 )

𝑛𝑛

𝑝𝑝(𝒔𝒔) = � 𝑝𝑝(𝑠𝑠𝑖𝑖 )

Just like [4], for any 1 ≤ 𝑟𝑟 ≤ 𝑖𝑖 − 1

𝑖𝑖=1

𝐼𝐼(𝑍𝑍 𝑟𝑟−1 , 𝑌𝑌𝑟𝑟𝑖𝑖−1 ; 𝑌𝑌𝑖𝑖 �𝑀𝑀, 𝑆𝑆 𝑛𝑛 )
𝑖𝑖−1
= 𝐼𝐼�𝑍𝑍 𝑟𝑟 −1 , 𝑌𝑌𝑟𝑟+1 ; 𝑌𝑌𝑖𝑖 �𝑀𝑀, 𝑆𝑆 𝑛𝑛 �
𝑖𝑖−1
+𝐼𝐼�𝑌𝑌𝑟𝑟 ; 𝑌𝑌𝑖𝑖 �𝑀𝑀, 𝑆𝑆 𝑛𝑛 , 𝑍𝑍 𝑟𝑟 −1 , 𝑌𝑌𝑟𝑟+1 �
𝑖𝑖−1
𝑟𝑟 −1
𝑛𝑛
≥ 𝐼𝐼�𝑍𝑍 , 𝑌𝑌𝑟𝑟 +1 ; 𝑌𝑌𝑖𝑖 �𝑀𝑀, 𝑆𝑆 �
𝑖𝑖−1
+𝐼𝐼�𝑍𝑍 𝑟𝑟 ; 𝑌𝑌𝑖𝑖 �𝑀𝑀, 𝑆𝑆 𝑛𝑛 , 𝑍𝑍 𝑟𝑟−1 , 𝑌𝑌𝑟𝑟+1 �
𝑖𝑖−1
𝑟𝑟
𝑛𝑛
= 𝐼𝐼�𝑍𝑍 , 𝑌𝑌𝑟𝑟+1 ; 𝑌𝑌𝑖𝑖 �𝑀𝑀, 𝑆𝑆 �

Randomly
and
independently
generate
′
′
2 𝑛𝑛(𝑅𝑅3 +𝑅𝑅3 ) sequences 𝒖𝒖(𝑚𝑚3 , 𝑚𝑚3 ) , each distributed i.i.d
𝑛𝑛
according to ∏ 𝑖𝑖=1 𝑝𝑝(𝑢𝑢 𝑖𝑖 ) and randomly throw them into 2 𝑛𝑛𝑅𝑅3
bins.
′
For each 𝒖𝒖(𝑚𝑚3 , 𝑚𝑚3 ), randomly and independently generate
′ +𝑅𝑅 )
′
′
2 𝑛𝑛(𝑅𝑅2 2 sequences 𝒗𝒗(𝑚𝑚3 , 𝑚𝑚3 , 𝑚𝑚2 , 𝑚𝑚2 ) each distributed i.i.d
𝑛𝑛
according to ∏ 𝑖𝑖=1 𝑝𝑝 𝑉𝑉|𝑈𝑈 (𝑣𝑣 𝑖𝑖 |𝑢𝑢 𝑖𝑖 ) and randomly throw them into
2 𝑛𝑛𝑅𝑅2 bins.
′
′
Now for each generated 𝒗𝒗(𝑚𝑚3 , 𝑚𝑚3 , 𝑚𝑚2 , 𝑚𝑚2 ), randomly and
independently
generate
′
′
′
′
𝑛𝑛(𝑅𝑅1 +𝑅𝑅1 )
) , each one
sequences 𝒙𝒙(𝑚𝑚3 , 𝑚𝑚3 , 𝑚𝑚2 , 𝑚𝑚2 , 𝑚𝑚1 , 𝑚𝑚1
2
𝑛𝑛
distributed i.i.d according to ∏ 𝑖𝑖=1 𝑝𝑝 𝑋𝑋|𝑉𝑉 (𝑥𝑥 𝑖𝑖 |𝑣𝑣 𝑖𝑖 ) and randomly
𝑛𝑛𝑅𝑅1
throw them into 2
bins.
Encoding is succeeded with small probability of error
provided that
′
𝑅𝑅3 ≥ 𝐼𝐼(𝑈𝑈; 𝑆𝑆)
′
𝑅𝑅2 ≥ 𝐼𝐼(𝑉𝑉; 𝑆𝑆|𝑈𝑈)
′
𝑅𝑅1 ≥ 𝐼𝐼(𝑋𝑋; 𝑆𝑆|𝑉𝑉)

(19)
(20)
(21)

where the inequality follows from the memorylessness of the
channel and the fact that 𝑌𝑌 is less noisy than 𝑍𝑍, i.e.
𝑖𝑖−1
𝑖𝑖−1
𝐼𝐼�𝑌𝑌𝑟𝑟 ; 𝑌𝑌𝑖𝑖 �𝑀𝑀, 𝑆𝑆 𝑛𝑛 , 𝑍𝑍 𝑟𝑟−1 , 𝑌𝑌𝑟𝑟+1 � ≥ 𝐼𝐼�𝑍𝑍 𝑟𝑟 ; 𝑌𝑌𝑖𝑖 �𝑀𝑀, 𝑆𝑆 𝑛𝑛 , 𝑍𝑍 𝑟𝑟−1 , 𝑌𝑌𝑟𝑟+1 �.
Proof of the second part follows the same as the first part
∎
with negligible variations.
𝑛𝑛𝑅𝑅3 = 𝐻𝐻(𝑀𝑀3 ) = 𝐻𝐻(𝑀𝑀3 |𝑆𝑆 𝑛𝑛 ) = 𝐻𝐻(𝑀𝑀3 |𝑆𝑆 𝑛𝑛 , 𝑌𝑌3𝑛𝑛 )
Now we stick to the proof of the converse

+𝐼𝐼(𝑀𝑀3 ; 𝑌𝑌3𝑛𝑛 |𝑆𝑆 𝑛𝑛 ) ≤ 𝐻𝐻(𝑀𝑀3 |𝑌𝑌3𝑛𝑛 ) + 𝐼𝐼(𝑀𝑀3 ; 𝑌𝑌3𝑛𝑛 |𝑆𝑆 𝑛𝑛 )

(16)
(17)
(18)

𝑛𝑛

≤ 𝑛𝑛𝜖𝜖3𝑛𝑛 + � 𝐼𝐼(𝑀𝑀3 ; 𝑌𝑌3𝑖𝑖 |𝑆𝑆 𝑛𝑛 , 𝑌𝑌3𝑖𝑖−1 ) ≤ 𝑛𝑛𝜖𝜖3𝑛𝑛
𝑖𝑖=1

and decoding is succeeded if

4

𝑛𝑛

+ � 𝐼𝐼(𝑀𝑀3 ; 𝑌𝑌3𝑖𝑖 |𝑆𝑆
𝑖𝑖=1
𝑛𝑛

𝑖𝑖−1

,

𝑛𝑛
𝑆𝑆𝑖𝑖 , 𝑆𝑆𝑖𝑖+1 , 𝑌𝑌3𝑖𝑖−1 )

𝑛𝑛

+ � 𝐼𝐼(𝑋𝑋𝑖𝑖 ; 𝑌𝑌1𝑖𝑖 |𝑈𝑈𝑖𝑖 , 𝑆𝑆𝑖𝑖 ),

≤ 𝑛𝑛𝜖𝜖3𝑛𝑛

𝑖𝑖=1

𝑛𝑛
+ � 𝐼𝐼�𝑀𝑀3 , 𝑆𝑆 𝑖𝑖−1 , 𝑆𝑆𝑖𝑖+1 , 𝑌𝑌3𝑖𝑖−1 ; 𝑌𝑌3𝑖𝑖 �𝑆𝑆𝑖𝑖 � ≤ 𝑛𝑛𝜖𝜖3𝑛𝑛
𝑖𝑖=1
𝑛𝑛

where (a) follows from the memorylessness of the channel and
(b) follows from Lemma 1.

𝑛𝑛

𝑛𝑛
+ � 𝐼𝐼�𝑀𝑀3 , 𝑆𝑆 𝑖𝑖−1 , 𝑆𝑆𝑖𝑖+1 , 𝑌𝑌2𝑖𝑖−1 ; 𝑌𝑌3𝑖𝑖 �𝑆𝑆𝑖𝑖 � = 𝑛𝑛𝜖𝜖3𝑛𝑛 + � 𝐼𝐼(𝑈𝑈𝑖𝑖 ; 𝑌𝑌3𝑖𝑖 |𝑆𝑆𝑖𝑖 )
𝑖𝑖=1

𝑖𝑖=1

Now using the standard time sharing scheme, we can easily
conclude that any achievable rate triple for the three-receiver
less noisy broadcast channel with side information nancausally available at the transmitter and at the receivers, must
satisfy (22) and the proof is complete.
∎

𝑛𝑛
where 𝑈𝑈𝑖𝑖 ≜ �𝑀𝑀3 , 𝑆𝑆 𝑖𝑖−1 , 𝑆𝑆𝑖𝑖+1 , 𝑌𝑌2𝑖𝑖−1 � and the last inequality
follows from Lemma 1.

𝑛𝑛𝑅𝑅2 = 𝐻𝐻(𝑀𝑀2 ) = 𝐻𝐻(𝑀𝑀2 |𝑀𝑀3 , 𝑆𝑆

𝑛𝑛 )

= 𝐻𝐻(𝑀𝑀2 |𝑀𝑀3 , 𝑆𝑆 ,
𝑛𝑛

𝑌𝑌2𝑛𝑛 )

V.

+𝐼𝐼(𝑀𝑀2 ; 𝑌𝑌2𝑛𝑛 |𝑀𝑀3 , 𝑆𝑆 𝑛𝑛 ) ≤ 𝐻𝐻(𝑀𝑀2 |𝑌𝑌2𝑛𝑛 ) + 𝐼𝐼(𝑀𝑀2 ; 𝑌𝑌2𝑛𝑛 |𝑀𝑀3 , 𝑆𝑆 𝑛𝑛 )
𝑛𝑛

We established two achievable rate regions for two special
classes of 3-receiver BCs with side information. We also found
the capacity region of 3-receiver less noisy BC when side
information is available both at the transmitter and at the
receivers.

𝑛𝑛
≤ 𝑛𝑛𝜖𝜖2𝑛𝑛 + � 𝐼𝐼�𝑀𝑀2 ; 𝑌𝑌2𝑖𝑖 �𝑀𝑀3 , 𝑆𝑆 𝑖𝑖−1 , 𝑆𝑆𝑖𝑖 , 𝑆𝑆𝑖𝑖+1 , 𝑌𝑌2𝑖𝑖−1 � = 𝑛𝑛𝜖𝜖2𝑛𝑛
𝑛𝑛

𝑖𝑖=1

REFERENCES

𝑛𝑛
𝑛𝑛
+ � 𝐼𝐼�𝑀𝑀2 , 𝑀𝑀3 , 𝑆𝑆 𝑖𝑖−1 , 𝑆𝑆𝑖𝑖+1 , 𝑌𝑌2𝑖𝑖−1 ; 𝑌𝑌2𝑖𝑖 �𝑀𝑀3 , 𝑆𝑆 𝑖𝑖−1 , 𝑆𝑆𝑖𝑖+1 , 𝑌𝑌2𝑖𝑖−1 , 𝑆𝑆𝑖𝑖 �
𝑖𝑖=1

[1]

𝑛𝑛

[2]

= 𝑛𝑛𝜖𝜖2𝑛𝑛 + � 𝐼𝐼(𝑉𝑉𝑖𝑖 ; 𝑌𝑌2𝑖𝑖 |𝑈𝑈𝑖𝑖 , 𝑆𝑆𝑖𝑖 ),

[3]

𝑖𝑖=1

𝑛𝑛
where 𝑉𝑉𝑖𝑖 ≜ �𝑀𝑀2 , 𝑀𝑀3 , 𝑆𝑆 𝑖𝑖−1 , 𝑆𝑆𝑖𝑖+1 , 𝑌𝑌2𝑖𝑖−1 �. It is clear that for the
given choice of 𝑈𝑈𝑖𝑖 and 𝑉𝑉𝑖𝑖 , we have the Markov chain (2)
satisfied for the channel is assumed to be memoryless.

𝑛𝑛𝑅𝑅1 = 𝐻𝐻(𝑀𝑀1 |𝑆𝑆 𝑛𝑛 , 𝑀𝑀2 , 𝑀𝑀3 ) = 𝐻𝐻(𝑀𝑀1 |𝑀𝑀2 , 𝑀𝑀3 , 𝑆𝑆 𝑛𝑛 , 𝑌𝑌1𝑛𝑛 )

[4]
[5]

+𝐼𝐼(𝑀𝑀1 ; 𝑌𝑌1𝑛𝑛 |𝑀𝑀2 , 𝑀𝑀3 , 𝑆𝑆 𝑛𝑛 ) ≤ 𝐻𝐻(𝑀𝑀1 |𝑌𝑌1𝑛𝑛 ) + 𝐼𝐼(𝑀𝑀1 ; 𝑌𝑌1𝑛𝑛 |𝑀𝑀2 , 𝑀𝑀3 , 𝑆𝑆 𝑛𝑛 )
𝑛𝑛

𝑛𝑛
≤ 𝑛𝑛𝜖𝜖1𝑛𝑛 + � 𝐼𝐼�𝑀𝑀1 ; 𝑌𝑌1𝑖𝑖 �𝑀𝑀2 , 𝑀𝑀3 , 𝑆𝑆 𝑖𝑖−1 , 𝑆𝑆𝑖𝑖 , 𝑆𝑆𝑖𝑖+1 , 𝑌𝑌1𝑖𝑖−1 �
𝑛𝑛

𝑖𝑖=1

+ � 𝐼𝐼�𝑋𝑋𝑖𝑖 ; 𝑌𝑌1𝑖𝑖 �𝑀𝑀2 , 𝑀𝑀3 , 𝑆𝑆
𝑖𝑖=1
𝑛𝑛

𝑖𝑖−1

,

𝑛𝑛
𝑆𝑆𝑖𝑖 , 𝑆𝑆𝑖𝑖+1 , 𝑌𝑌1𝑖𝑖−1 �

𝑛𝑛
+ � 𝐼𝐼(𝑋𝑋𝑖𝑖 ; 𝑌𝑌1𝑖𝑖 �𝑀𝑀2 , 𝑀𝑀3 , 𝑆𝑆 𝑖𝑖−1 , 𝑆𝑆𝑖𝑖 , 𝑆𝑆𝑖𝑖+1 )
𝑖𝑖=1
𝑛𝑛

𝑛𝑛
− � 𝐼𝐼�𝑌𝑌1𝑖𝑖−1 ; 𝑌𝑌1𝑖𝑖 �𝑀𝑀2 , 𝑀𝑀3 , 𝑆𝑆 𝑖𝑖−1 , 𝑆𝑆𝑖𝑖 , 𝑆𝑆𝑖𝑖+1 �
𝑖𝑖=1
𝑛𝑛

𝑛𝑛
+ � 𝐼𝐼(𝑋𝑋𝑖𝑖 ; 𝑌𝑌1𝑖𝑖 �𝑀𝑀2 , 𝑀𝑀3 , 𝑆𝑆 𝑖𝑖−1 , 𝑆𝑆𝑖𝑖 , 𝑆𝑆𝑖𝑖+1 )
𝑖𝑖=1

CONCLUSION

[6]

(𝑎𝑎)
𝑛𝑛𝜖𝜖
≤ 1𝑛𝑛

[7]

= 𝑛𝑛𝜖𝜖1𝑛𝑛 +

[8]

[9]

(𝑏𝑏)
𝑛𝑛𝜖𝜖
≤ 1𝑛𝑛

[10]
[11]
[12]

𝑛𝑛

𝑛𝑛
− � 𝐼𝐼�𝑌𝑌2𝑖𝑖−1 ; 𝑌𝑌1𝑖𝑖 �𝑀𝑀2 , 𝑀𝑀3 , 𝑆𝑆 𝑖𝑖−1 , 𝑆𝑆𝑖𝑖 , 𝑆𝑆𝑖𝑖+1 � = 𝑛𝑛𝜖𝜖1𝑛𝑛

[13]
[14]

𝑖𝑖=1
𝑛𝑛

𝑛𝑛
+ � 𝐼𝐼�𝑋𝑋𝑖𝑖 ; 𝑌𝑌1𝑖𝑖 �𝑀𝑀2 , 𝑀𝑀3 , 𝑆𝑆 𝑖𝑖−1 , 𝑆𝑆𝑖𝑖+1 , 𝑌𝑌2𝑖𝑖−1 , 𝑆𝑆𝑖𝑖 � = 𝑛𝑛𝜖𝜖1𝑛𝑛

[15]

𝑖𝑖=1

[16]

5

S. Borade, L. Zheng, and M. Trott., “Multilevel Broadcast Networks,”
Int. Symp. on Inf. Theory, pp. 1151-1155, June 2007.
J. Körner and K. Marton, “General broadcast channels with degraded
message sets,” IEEE Trans. On Inf. Theory IT-23, Jan. 1977, pp. 60-64.
C. Nair and A. El Gamal, ”The capacity region of a class of 3-receiver
broadcast channels with degraded message sets,” IEEE Trans. On Inf.
Theory, vol. 55, no. 10, pp. 4479-4493, Oct. 2009.
C. Nair and Z. V. Wang, “The Capacity Region of the Three-receiver
Less Noisy Broadcast Channel,” IEEE Trans. On Inf. Theory, Vol. 57,
pp. 4058-4062, July 2011.
C. E. Shannon, “Channels with Side Information at the Transmitter,”
IBM Journal of Research and Development, Vol. 2, pp. 289-293, Oct.
1958.
S. I. Gel’fand and M. S. Pinsker, “Coding for Channel with random
parameters,” Probl. Contr. And Inform. Theory, Vol. 9, no. 1, pp. 19-31,
1980.
T. M. Cover; M. Chiang, “Duality Between Channel Capacity and Rate
Distortion with two-sided State Information,” IEEE Trans. On Inf.
Theory, Vol. 48, pp. 1629-1638, June 2002.
Y. Steinberg, “Coding for the Degraded Broadcast Channel with
Random Parameters, with Causal and Noncausal Side Information,”
IEEE Trans. On Inform. Theory, Vol. 51, no. 8, pp. 2867-2877, Aug.
2005.
Reza Khosravi-Farsani; Farokh Marvasti, “Capacity Bounds for
Multiuser Channels with Non-Causal Channel State Information at the
Transmitters,” Inf. Theory. Workshop (ITW), pp. 195-199, Oct. 2011.
J. Körner and K. Marton, “Comparison of two noisy Channels”, Topics
on Information Theory (ed. by I. Csiszar and P.Elias), Keszthely,
Hungry, August 1975, 411-423.
C. Nair, “Capacity Regions of two new classes of two-receiver broadcast
channels”, IEEE Trans. On Inf. Theory, Vol. 56, pp. 4207-4214, Sept.
2010.
T. M. Cover and J. A. Thomas, “Elements of Information Theory,” John
Wiley & Sons, 1991.
A. El Gamal and Y. H. Kim, “Network Information Theory,” Cambridge
University Press, 2011.
S. M. Ross, “A First Course in Probability Theory,” Prentice Hall,
printed in the United States of America, 5th edition, 1997.
T. M. Cover, “An Achievable Rate Region for the Broadcast Channel,”
IEEE Trans. On Inf. Theory, Vol. IT-21, pp. 399-404, July 1975.
Y. Stein berg and S. Shamai, “Achievable rates for the broadcast
channel with states known at the transmitter,” Int. Symp. on Inf. Theory,
2005, Adelaide, SA, pp. 2184-2188.

