Title:          isit_submit.dvi
Author:         Administrator
Creator:        dvips(k) 5.98 Copyright 2009 Radical Eye Software
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Thu May 17 23:54:25 2012
ModDate:        Tue Jun 19 12:56:38 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      317029 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569566711

On Modulo-Sum Computation over an
Erasure Multiple Access Channel
Ashish Khisti

Brett Hern and Krishna Narayanan

Electrical and Computer Engineering Dept.
University of Toronto, Canada
Email: akhisti@comm.utoronto.ca

Electrical and Computer Engineering Dept.
Texas A&M, College Station, TX, USA
Email: {krn@tamu.edu, hernbrem@neo.tamu.edu}

Abstract—We study computation of a modulo-sum of two
binary source sequences over a two-user erasure multiple access
channel. Each sender observes an independent and equiprobable
binary sequence and the receiver is interested in computing the
modulo-sum of these two sequences. The channel is modelled as
a binary-input, erasure multiple access channel, which can be in
one of three states — either the channel output is a modulo-sum
of the two input symbols, or the channel output equals the input
symbol on the ﬁrst link and an erasure on the second link, or it
equals the input symbol on the second link and an erasure on
the ﬁrst link. The associated state sequence is independent and
identically distributed. We establish upper and lower bounds
on the modulo-sum capacity. Our coding scheme uses either
the compute-and-forward or the decode-and-forward techniques.
The upper bound is obtained by a genie aided argument that
reduces the setup to a compound multiple-access channel. It is
in general is tighter than a simple upper bound obtained by
revealing one of the messages to the decoders. We also brieﬂy
consider the case when a strictly causal state feedback is available
to the encoders and establish that such feedback can increase the
modulo-sum capacity.

The authors observe that for a wide range of signal-to-noise
ratio (SNR), one can achieve higher rates using lattice codes
instead of an i.i.d. random code ensemble. The additive nature,
the Gaussian MAC channel is well suited for computing the
modulo sum of two messages using lattice codes. A simple
upper bound obtained by revealing one of the messages to the
destination, is sufﬁciently close to the known lower bounds
for a wide range of SNR. Several interesting extensions along
these lines are also discussed in [6], [11].
In the present paper we introduce a MAC channel model that
does not appear naturally matched for computing the modulosum function. Our model is an erasure multiple access channel
with binary inputs. With a certain probability, the destination
observes a modulo-sum of the two transmitted bits whereas
with a certain probability the destination observes only one of
the two bits and an erasure symbol associated with the other
transmitted bit. As our main result, we establish that the cutset upper bound is not tight and develop a new upper bound.
We also brieﬂy consider the case when there is strictly causal
feedback of the state sequence available from the destination
(using e.g., ARQ) and show that the capacity can be increased
compared to the case without such a feedback.

I. I NTRODUCTION
Many problems in network information theory require that
the intermediate relay nodes only compute a function of the
underlying source messages. One such example is the two-way
relay channel where two users need to communicate to each
other using a central relay node. It is natural that the relay node
only compute a modulo-sum of the messages of the two users.
In a classic paper, Korner and Marton [4] consider a multiterminal source coding problem where the destination terminal
is required to compute a modulo-sum of two binary sources.
Each source is revealed to one encoder. The authors establish
the optimality of a scheme using identical linear codebooks to
separately compress the two source sequences. There has been
a signiﬁcant interest in source and channel coding techniques
for function computation in recent times; see e.g. [1]–[3], [5]–
[13].
Recently Wilson et.al [11] and Nazer and Gastpar [6] study
achievable rates for computation of the modulo-sum of two
messages over a Gaussian multiple access channel (MAC).

II. P ROBLEM S TATEMENT AND M AIN R ESULTS
We study a multiple access channel with two transmitters
and one receiver. The channel input symbols are denoted by x
and y respectively and are binary valued. The channel output is
denoted by z and is also binary valued. The channel transition
probability is controlled by a state variable s ∈ {0, 1, 2}. In
particular we have:
⎧
⎪x ⊕ y , s = 0,
⎨
z = x,
(1)
s = 1,
⎪
⎩
y,
s = 2.
We assume that the receiver is revealed the pair (z, s). We
assume that Pr(s = 1) = Pr(s = 2) = ε and Pr(s = 0) = 1−
2ε where ε satisﬁes 0 ≤ ε ≤ 1/2. The channel is memoryless
n
i.e., Pr(s n = sn ) = i=1 Pr(si = si ) is satisﬁed.
A code of length n is deﬁned as follows. Sender i observes a
message wi uniformly and independently distributed over the
set [1, . . . , 2nR ]. For sake of convenience we will represent

Ashish Khisti’s work was supported by a Discovery Research Grant
from National Science Engineering Research Council (NSERC), Canada and
Helwett-Packard Innovation Research Proposal (HP-IRP) Award. Brett Hern
and Krishna Narayanan were supported by the National Science Foundation
under Grant CCF 0729210 and CCF 0830696.

1

message wi as a sequence bnR consisting of nR indepeni
dent and equiprobable bits. We deﬁne u = w1 ⊕ w2 as the
exclusive-or of bnR ⊕ bnR .
1
2
The messages are mapped into codewords x n = fn (w1 )
and y n = gn (w2 ) respectively and the decoder is required to
ˆ
ˆ
produce u = hn (z n , s n ). An error is declared if {u = u }.
A rate R is achievable if there is a sequence of encoders
and decoders such that the error probability goes to zero as n
approaches inﬁnity. The largest achievable rate is deﬁned as
the modulo-sum capacity.
Remark 1: In this paper we focus on the simpliﬁed model
in (1) where the channel can only take one of three states.
The results can be extended to the case when there are two
additional states — either the decoder observes both (x, y )
or it observes an erasure. Such extensions will be reported
elsewhere.
We summarize the main results in the remainder of this
section.

In our upper bound, we ﬁrst reveal the knowledge of B
to the two encoders non-causally. However the encoders are
n
n
not aware of the sets A and C. Note from (1) that zB = yB ,
n
n
n
n
n
zA = xA and zC = xC ⊕ yC .
2) Independence of Input Signals from w1 ⊕ w2 : Observe
n
that yB is sub-sequence transmitted by user 2 and hence
independent of u = w1 ⊕ w2 . Using this property we have:
nR = H(u)
=
=
≤

n n n
nR ≤ n(1 − ε) − H(xC , zA |yB , u) + n · on (1).

We propose the following lower bound on the modulo-sum
capacity.
Proposition 1: The modulo-sum capacity of the multipleaccess erasure channel (1) is lower bounded by the following
expression:
1
2

.

(4)
(5)
(6)
(7)

1
n
n n
where we use Fano’s inequality in n H(u|xA , yB , zC ) ≤ on (1)
and on (1) denotes a vanishing function in n.
3) Compound MAC Channel: Observe that the same coding
scheme must also work when the positions of sets A and C
are interchanged. This results in

A. Lower Bound

C ≥ R− = max 1 − 2ε,

n
H(u|yB )
n
n
n
n
n
n
H(u|yB , xA , zC ) + I(xA , zC ; u|yB , u)
n
n n
n(1 − ε) − H(xA , zC |yB , u) + n · on (1),

(8)

Combining (7) and (8) and ignoring the on (1) term, we
obtain the following:
n
n n
n n n
nR ≤ n(1 − ε) − max H(xA , zC |yB , u), H(xC , zA |yB , u)

(9)

(2)
≤ n(1 − ε) −

1
n
n n
n n n
H(xA , zC |yB , u)+H(xC , zA |yB , u)
2

≤ n(1 − ε) −

The lower bound of R = 1 − 2ε is attained using a computeand-forward technique [6]. The lower bound R = 1/2 is
attained using a standard multiple-access channel code to
transmit both w1 and w2 to the destination. This technique
is referred to as decode-and-forward in this paper. The coding
technique discussed in [3], which uses identical codebooks at
the two transmitters also sufﬁces to achieve this rate.

1
n
n
n n n
H(xA , zC , xC , zA |yB , u)
2
1
n
n
n
n n
H(xA , yC , xC , yA |yB , u)
2
1
n
n n
H(yA , yC |yB , u)
2
1
n
n n
H(yA , yC |yB )
2

(10)

= n(1 − ε) −
≤ n(1 − ε) −

B. Upper Bound

≤ n(1 − ε) −

We provide the following upper bound on the modulo-sum
capacity.
Theorem 1: The modulo-sum capacity of the multipleaccess erasure channel (1) is upper bounded by the following
expression:

(11)
(12)
(13)
(14)

where (14) from the fact that the transmit sequence by user 2,
y n is independent of w1 and hence w1 ⊕ w2 . Eq. (14) suggests
n
n
n
that for the rate to be high (yA , yC ) and yB must be strongly
correlated. However as we show below, such a constraint can
only reduce the upper bound obtained by revealing one of the
messages to the destination.
4) Penalty from Repetition Coding: Suppose that the sequence x n is completely revealed to the destination. The
receiver only needs to compute w2 and hence we have:

(1 − 3ε)+ + (2 − ε)
(3)
3
where (·)+ equals zero if the argument inside is negative.
The proposed upper bound is tighter than a genie-aided
bound where one of the messages, say w1 , is revealed to the
decoder. We provide some intuition behind the upper bound
below.
1) Revealing Side Information to the Transmitters: Our key
idea is to reveal part of the state sequence to the encoders. In
particular deﬁne the sets A = {i : si = 1}, B = {i : si = 2}
and C = {i : si = 0}. We illustrate the technique when |A| =
|B| = |C| = n , which roughly corresponds to the case when
3
n
ε = 1/3. We will use the notation zC to denote the projection
n
of z onto the indices i ∈ C etc.
C ≤ R+ =

n
n n
n
nR ≤ H(y n ) = H(yA , yC |yB ) + H(yB )

(15)

Eliminating the joint entropy term between (14) and (15) we
get
1
3
n
nR ≤ H(yB ) + n(1 − ε)
2
2

(16)

n
By using the simple upper bound H(yB ) ≤ |B| = nε we get
2−ε
R ≤ 3 which agrees with (3) for ε = 1/3.

2

C. Causal State Feedback

Our proposed decoder only uses the output of the channel
ˆ
when si = 0 and declares erasures if si = 0. Let G0 = G|si =0
be collection of column vectors in G when si = 0. We use
ˆ
the following lemma regarding G0 :
Lemma 1: For every δ > 0, there exists a function on,δ (1)
that goes to zero as n → ∞, such that following holds:

Consider the case when the encoders are revealed the state
sequences in a strictly manner. The encoding functions at time
i can depend on the state sequence up to time i − 1 i.e. xi =
i−1
i−1
fi (w1 , s1 ) and yi = gi (w2 , s1 ).
Proposition 2: The modulo-sum capacity the multiple access channel with strictly causal state feedback is lower and
−
+
upper bounded by RFB ≤ C ≤ RFB , where
1
.
1 + 2ε
=1−ε

−
RFB =

(17)

+
RFB

ˆ
Pr rank(G0 ) ≥ min(K, n(1 − 2ε − δ)) ≥ 1 − on,δ (1).
(25)

(18)

The proof of Lemma 1 is obtained by showing that, with
ˆ
high probability, each randomly selected column of G0 is in a
general position. We omit the proof. Clearly the receiver can
uniquely recover (bT ⊕ bT ) from
1
2

The lower bound is achieved by a two-phase protocol where
the users transmit uncoded bits in the ﬁrst phase and use a
multiple-access code in the second phase. The upper bound is
the genie-aided bound where one of the messages is revealed
to the destination. The problem reduces to communicating the
other message, say w2 to the destination. Feedback in such a
case is well known to not increase the point-to-point capacity.
III. L OWER B OUND : P ROOF

OF

ˆ
zT = (bT ⊕ bT ) · G0
0
1
2

ˆ
if G0 has full row-rank, which holds if R ≤ 1 − 2ε − δ. Since
δ > 0 is arbitrary this establishes our ﬁrst lower bound.
B. Achievability of R = 1/2: Decode and Forward Approach

P ROP. 1

The rate R = 1/2 is achieved by transmitting both w1
and w2 to the destination instead of taking advantage of the
fact that the destination only requires w1 ⊕ w2 . The multiple
access capacity region is given by the convex hull of rate pairs
(R1 , R2 ) that satisfy:

We separately establish the achievability of R = 1 − 2ε and
R = 1/2.
A. Compute and Forward Scheme
We use identical linear codebooks at the two transmitters
in the compute and forward scheme to achieve R = 1 − 2ε.
Recall that the messages w1 and w2 are assumed to be binary
valued sequences of length nR bits i.e., we take
bT
i

= [bi1 , . . . , biK ]

R1 ≤ I(x; z, s|y )
R2 ≤ I(y ; z, s|x)

(19)

(20)

where each gi ∈ {0, 1} is a length K binary valued
column vector. The transmitted sequence xT = [x1 , . . . , xK ]
at receiver 1 is expressed as:
= [bT g1 , . . . , bT gn ]
1
1

R ≤ I(x, y ; z, s|x ⊕ y ) = 2ε

(21)
(22)

must be satisﬁed when identical codebooks are used. Thus
the achievable rate now reduces to R = min(1/2, 2ε). Note
that with with identical codebooks, the rate R = 1/2 is
achievable for ε > 1/4, the region in which decode and
forward dominates compute and forward discussed before.
Achieving R = 1/2 with Compute and Forward: The rate
R = 1/2 can also be achieved using identical linear codes
if the receiver does not ignore the output when si = 0. Let
ˆ
ˆ
ˆ
Let G0 = G|si =0 , G1 = G|si =1 and G2 = G|si =2 be the
projections of G onto the indices where si = 0, si = 1 and
ˆ
si = 2 respectively. Following (24), we let zT = (bT +bT )G0 ,
1
2
C
ˆ
ˆ
zT = bT G1 and zT = bT G2 . Since the column vectors in
1
2
A
B
ˆ
ˆ
G1 and G2 are independently sampled it can be shown that

The transmitted sequence yT at user 2 is deﬁned in a similar
manner.
The receiver is interested in computing
uT = bT ⊕ bT = [b11 ⊕ b21 , . . . , b1K ⊕ b2K ] .
1
2

(29)

Taking x and y to be independent equiprobable binary symbols we get that MAC Capacity region contains R1 ≤ 1 − ε,
R2 ≤ 1 − ε and R1 + R2 ≤ 1. Since ε < 1/2 the rate pair
1
R1 = R2 = 2 is achievable. Thus each user can transmit wi
at a rate of R = 1/2 to the destination. The destination then
computes w1 ⊕ w2 .
Remark 2: The rate R = 1/2 can be achieved using a
decode and forward scheme even when the two transmitters
use identical codebooks. As established in [3], in addition
to (27)-(29), an additional constraint

K

xT = bT · G
1

(27)
(28)

R1 + R2 ≤ I(x, y ; z, s)

where K = nR denote the number of information bits in the
message. Let G be a matrix of dimensions K ×n, and let each
entry in G be sampled independently from an equiprobable
Bernoulli distribution. It is useful to express
G = [g1 , . . . , gn ]

(26)

(23)

Given our speciﬁc encoder, the received symbol can be expressed as:
⎧
⎪(bT ⊕ bT )gi , si = 0,
⎨ 1
2
(24)
zi = bT gi ,
si = 1,
1
⎪ T
⎩
si = 2.
b2 g i ,

3

sampled i.i.d. from a distribution with Pr(s = 0) = 1 − 2ε
and Pr(s = 1) = Pr(s = 2) = ε.
Substituting (41) into (38) we have:

for any δ > 0, with a probability that exceeds 1 − on,δ (1), we
have that
ˆ
ˆ
dim col-space(G1 ) ∩ col-space(G2 ) ≥ n · d12
Δ

+

= n (2ε − R)

n
n
n
nR ≤ n(1 − ε) + nδn − H(xA(s n ) , zC(s n ) |s n , yB(s n ) , u)
(42)

(30)

Thus one can ﬁnd a matrices Mi such that
ˆ
ˆ
G1 M1 = G2 M2 = A

In this paper we only provide the complete converse when
1
Pr(s = 0) = Pr(s = 1) = Pr(s = 2) = 3 . The proof for the
general case also uses (42) as a starting point and will appear
elsewhere.
For a sequence sn we ﬁrst consider a permutation function
π(sn ) such that A(sn ) = C(π(sn )), B(sn ) = B(π(sn )) and
C(sn ) = A(π(sn )). Note that Pr(s n = sn ) = Pr(s n =
π(sn )) = 31 . We establish the following lower bound:
n

(31)

where A is a full-matrix of dimension n × d12 . The receiver
ﬁrst computes
(zT ⊕ zT )M = (bT ⊕ bT ) · A
A
B
1
2

(32)

ˆ
and then needs to compute b1 ⊕ b2 from (b1 ⊕ b2 )T [G0 A].
ˆ 0 and A are independent the rank of
Since the entries in G
ˆ
[G0 A] is, with high probability at-least n(d12 + 1 − 2ε − δ).
From (30) we can show that R = max( 1 , 1−2ε) is achievable.
2
IV. U PPER B OUND : P ROOF

OF

n
n
n
H(xA(sn ) , zC(sn ) |yB(sn ) ,u, s n )+

n
n
n
H(xA(π(sn )) , zC(π(sn )) |yB(π(sn )) ,u, s n )

=

T HEOREM 1

We begin with some notation. For a given sequence sn
A(sn ) = {i : si = 1} and B(sn ) = {i : si = 2}. Let
n
C(sn ) = {i : si = 0}. We let xA(sn ) to be the projection of
n
the sequence x on the indices where si = 1 and use a similar
notation for other indices.
Since the receiver decodes u = w1 ⊕ w2 from its output,
from Fano’s inequality, we have that
1
H (u | s n , z n ) ≤ δn
n
for some sequence εn that goes to zero as n → ∞.
Now consider
nR = H(u)

=
≥
=

= H(u|s )
n
= H(u|s n , yB(s n ) )

n
n
n
= nδn + I(u; xA(s n ) , zC(s n ) |s n , yB(s n ) )
n
n
n
nδn + H(xA(s n ) , zC(s n ) |s n , yB(s n ) )
n
n
n
− H(xA(s n ) , zC(s n ) |s n , yB(s n ) , u)

(33)

(35)
(36)

n
n
n
H(xA(π(s n )) , zC(π(s n )) |s n , yB(π(s n )) , u).

n
n
n
+ H(xA(π(sn )) , zC(π(s n )) |yB(π(s n )) , u, s n )

1
n
n
n
≤ n(1 − ε) + nδn − H(yC(sn ) , yA(sn ) |yB(sn ) , s n )
2

(40)

(47)
(48)

(49)

(50)

(51)

To complete our analysis, we consider the upper bound by
revealing w1 to the decoder.

sn ∈S n

= n(1 − ε) + nδn

(46)

nR ≤ n(1 − ε) + nδn −
1
n
n
n
H(xA(s n ) , zC(s n ) |yB(s n ) , u, s n )
2

(39)

Pr(s n = sn ) (|A(sn )| + |C(sn )|)

(45)

Combining (42) and (49) we have:

(38)

where (35) follows from the fact that the message u is
independent of the sequence s n , equation (36) follows from
the fact that u = w1 ⊕ w2 is independent of w2 and hence
also independent of y n , and equation (37) follows from the
chain rule of mutual information and the application of Fano’s
inequality,
We upper bound the ﬁrst entropy term in (38) as follows.

≤

(44)

nR ≤ n(1 − ε) + nδn −

(37)

n
n
n
n
n
H(xA(s n ) , zC(s n ) |s n , yB(s n ) ) ≤ H(xA(s n ) , zC(s n ) |s n ),

(43)

where (44) follows from the construction of the permutation
function π(·), (45) follows from the fact that conditioning
reduces entropy and the chain rule, (46) follows from the
fact that z n = x n ⊕ y n and for any random variable A we
have that H(A) = H(f (A)) if the function f (·) is one-toone, while (48) follows from the fact that u = w1 ⊕ w2 is
independent of w2 and hence of y n .
Now applying (42) to the sequence π(s n ) we get

(34)
n

=

≥

n
n
n
H(xA(sn ) , zC(sn ) |yB(sn ) , u, s n )+
n
n
n
H(xC(sn ) , zA(sn ) |yB(sn ) , u, s n )
n
n
n
n
n
H(xA(sn ) , zC(sn ) , xC(sn ) , zA(sn ) |yB(sn ) , u, s n )
n
n
n
n
n
H(xA(sn ) , yC(sn ) , xC(sn ) , yA(sn ) |yB(sn ) , u, s n )
n
n
n
H(yC(sn ) , yA(sn ) |yB(sn ) , u, s n )
n
n
n
H(yC(sn ) , yA(sn ) |yB(sn ) , s n )

nR = H(w1 ⊕ w2 ) = H(w2 |w1 )

(41)

(52)

n

= H(w2 |w1 , s )

where (39) follows from the fact that conditioning reduces
entropy whereas (40) follows from the fact that both x n and
z n are binary sequences and (41) follows from the fact s n is

n

(53)
n

n

n

= H(w2 |w1 , s , y ) + I(y ; w2 |w1 , s )
≤ nδn + H(y n |s n )

4

(54)
(55)

curve is our new upper bound on the capacity without feedback
(c.f. Theorem 1). The fourth curve is the lower bound with
feedback in Prop. 2. Interestingly we see that it lies above
the upper bound for certain values of ε, thus establishing that
feedback helps in computation over the erasure multiple access
channel.

1
0.9

Modulo−Sum Rate

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

Upper Bound (Without Feedback)

VII. C ONCLUSION

Lower Bound (With Feedback)

We study computation of modulo-sum of two messages
over a multiple access channel with erasures. Unlike the
Gaussian model, our proposed this model does not have a
suitable structure to directly compute the modulo-sum. Our
main result is an upper bounding technique that reduces the
setup to a compound multiple access channel. Using this
bound we establish that a simple ARQ type feedback can
increase the modulo-sum capacity. In the full paper we will
report a complete derivation of the upper bound and other
extensions such as the case of lossy recovery.
While computation over Gaussian networks has received a
signiﬁcant interest in recent years, we understand little about
fundamental limits of computation over other channel models.
We expect the ideas involved in this paper to be also applicable
to other channel models.

Lower Bound (Without Feedback)
Upper Bound (With Feedback)

0.05

0.1

0.15

0.2

0.25

0.3

Erasure Probability: ε

0.35

0.4

0.45

0.5

Fig. 1. Comparison of upper and lower bounds for the Erasure-MAC channel
with and without feedback.
n
n
= nδn + H(yB(sn ) |s n ) + H(yA(sn ) , yC(sn ) |s n , yB(sn ) )
(56)

where (52) follows from the fact that w1 and w2 are mutually
independent, and (53) follows from the fact that s n is independent of (w1 , w2 ) and (55) follows since the message w1 ⊕ w2
can be recovered if the receiver is revealed (w1 , y n , s n ) and
hence Fano’s inequality implies, H(w2 |w1 , s n , y n ) ≤ nδn .
Combining (56) with (51) we get
1
3
n
R ≤ 1 − ε + 2δn +
H(yB(s n ) |s n )
2
2n
1
|B(s n )|
= 2δn + 1 − ε + Es n
2n
1
1
= 2δn + 1 − ε + ε = 1 − ε + 2δn
2
2
Since δn → 0 as n → ∞, this establishes that R ≤
required.
V. C ODING T ECHNIQUE

WITH

R EFERENCES
[1] S. Agrawal and S. Vishwanath, “On the secrecy rate of interference
networks using structured codes,” in Proc. Int. Symp. Inform. Theory,
Soul, Korea, 2009.
[2] X. He and A. Yener, “Providing secrecy with structured codes: Tools and
applications to two-user Gaussian channels,” Submitted to IEEE Trans.
Inform. Theory, 2009.
[3] B. Hern and K. Narayanan, “Multilevel coding schemes for computeand-forward,” in Proc. Int. Symp. Inform. Theory, St. Petersburg, Russia,
2011, pp. 1713–1717.
[4] J. Korner and K. Marton, “How to encode the modulo-two sum of binary
sources (corresp.),” IEEE Trans. Inform. Theory, vol. 25, pp. 219–221,
1979.
[5] D. Krithivasan and S. Pradhan, “Lattices for distributed source coding:
Jointly gaussian sources and reconstruction of a linear function,” IEEE
Trans. Inform. Theory, vol. 55, pp. 5628–5651, Dec. 2009.
[6] B. Nazer and M. Gastpar, “Computation over multiple-access channels,”
IEEE Trans. Inform. Theory, vol. 53, pp. 3498–3516, Oct. 2007.
[7] ——, “Compute-and-forward: Harnessing interference through structured codes,” IEEE Trans. Inform. Theory, vol. 57, pp. 6453–6486, Oct.
2011.
[8] T. Oechtering, E. Jorswieck, R. Wyrembelski, and H. Boche, “On the
optimal transmit strategy for the MIMO bidirectional broadcast channel,”
vol. 57, pp. 3817–3826, Dec. 2009.
[9] T. Philosof, R. Zamir, U. Erez, and A. Khisti, “Lattice strategies for the
dirty multiple-access channel,” IEEE Trans. Inform. Theory, vol. 57, pp.
5006–5035, Aug. 2011.
[10] A. Sahebi and S. Pradhan, “On the capacity of abelian group codes
over discrete memoryless channels,” in Proc. Int. Symp. Inform. Theory,
2011.
[11] M. P. Wilson, K. Narayanan, H. Pﬁster, and A. Sprintson, “Joint physical
layer coding and network coding for bi-directional relaying,” IEEE
Trans. Inform. Theory, vol. 56, pp. 5641–5654, Nov. 2010.
[12] R.
Zamir,
“Anti-structure
problems,”
submitted,
http://arxiv.org/abs/1109.0414, 2011.
[13] J. Zhang, U. Erez, M. Gastpar, and B. Nazer, “MIMO compute-andforward,” in Proc. Int. Symp. Inform. Theory, Soul, Korea, 2009.

(57)
(58)
(59)
2−ε
3 ,

as

F EEDBACK

We provide a sketch of the achievable rate with feedback
stated in Prop. 2. We use a two phase protocol. In the ﬁrst
phase encoders 1 and 2 transmit b1i and b2i respectively for
i = 1, 2 . . . , n. For those indices where si = 0 the receiver
obtains b1i ⊕ b2i . Among the remaining indices users 1 and
ˆ
2 construct w1 = {b1j }j:sj =2 and w2 = {b2j }j:sj =1 . In
ˆ
ˆ
the second phase, the messages w1j and w2j are transmitted
ˆ
to the destination using a multiple access channel code. By
computing the capacity region of the associated multiple
access channel (c.f. (27)-(29)), it can be veriﬁed that the
number of channel uses in this phase is ≈ 2nε. Thus the
n
1
total rate is ≈ n+2nε = 1+2ε as required.
VI. N UMERICAL R ESULTS
Fig. 1 provides a numerical computation of the upper and
lower bounds for the Erasure MAC channel both with and
without feedback. The upper-most dotted curve corresponds
+
to RFB = 1 − ε and is the upper bound on the capacity
with feedback. The lowermost curve, marked with backward
arrows, is the lower bound achieved by either the decode and
forward or the compute and forward schemes. The other solid

5

