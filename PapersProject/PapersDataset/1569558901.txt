Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Fri May 18 18:24:47 2012
ModDate:        Tue Jun 19 12:56:36 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      376321 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569558901

Snake-in-the-Box Codes for Rank Modulation
Yonatan Yehezkeally

Moshe Schwartz

Electrical and Computer Engineering
Ben-Gurion University of the Negev
Beer Sheva 84105, Israel
yonatany@post.bgu.ac.il

Electrical and Computer Engineering
Ben-Gurion University of the Negev
Beer Sheva 84105, Israel
schwartz@ee.bgu.ac.il

This scheme eliminates the need for discretization of chargelevels. In addition, rank modulation also improves the memory’s robustness against other noise types. Retention, the
process of slow charge leakage from cells, tends to affect all
cells with a similar trend [3]. Since rank modulation stores
information in the differences between charge-levels rather
than their absolute values, it offers more resilience against that
type of noise. It is also worth noting that the advantages of
rank modulation have been experimentally applied to phasechange memory with promising results (see [16]).
The Gray code [8] was ﬁrst introduced as a sequence of
distinct binary vectors of ﬁxed length, where every adjacent
pair differs in a single coordinate. It has since been generalized to sequences of states over other spaces, where each
state is derived from the former by a transformation from a
predetermined set of allowed transformations (see [17] for an
excellent survey). Among these, [11] studied Gray odes over
permutations, and presented such codes traversing the entire
group of permutations. In this fashion, it was suggested that
a set of n rank-modulation cells could implement a single
logical multilevel cell with n! levels, where increasing the
logical cell’s level by 1 corresponds to a single transition in the
code. This allows for a natural integration of rank modulation
with other multilevel approaches such as rewriting schemes
[4], [9], [10], [21]. This was done by restricting the allowed
transformations to “push-to-the-top” operations, namely only
programming a group of cells by increasing the charge-level
of a single cell above that of all other cells in the group. The
use of such Gray codes allows for faster cell programming
and eliminates overshoot problems (see [11]). In the context
of ﬂash memory, “push-to-the-top” operations have also been
used in [6], [7]. We also note that generating permutations
using “push-to-the-top” operations is of independent interest,
called “nested cycling” in [18] (see also references therein),
motivated by a fast “push-to-the-top” operation1 (cycling)
available on some computer architectures.
Other recent works have explored error-correcting codes for
rank modulation, where different types of errors are addressed
by a careful choice of metric. In [2], [12], [15], Kendall’s τmetric was considered, since a small charge-constrained error

Abstract—Motivated by the rank-modulation scheme with
applications to ﬂash memory, we consider Gray codes capable of
detecting a single error, also known as snake-in-the-box codes.
We study two error metrics: Kendall’s τ-metric, which applies to
charge-constrained errors, and the ∞ -metric, which is useful in
the case of limited-magnitude errors. In both cases we construct
snake-in-the-box codes with rate asymptotically tending to 1.
Index Terms—Snake-in-the-box codes, rank modulation, permutations, ﬂash memory

I. I NTRODUCTION
Flash memory is a non-volatile storage medium which is
electrically programmable and erasable. Its current wide use
is motivated by its high storage density and relative low cost.
Among the chief disadvantages of ﬂash memories is their
inherent asymmetry between cell programming (injecting cells
with charge) and cell erasure (removing charge from cells).
While single cells can be programmed with relative ease,
in the current architecture, the process of erasure can only
be performed by completely depleting large blocks of cells
of their charge. Moreover, the removal of charge from cells
physically damages them over time.
This issue is exacerbated as a result of the ever-present
demand for denser memory: smaller cells are more delicate,
and are damaged faster during erasure. They also contain less
charge and are therefore more prone to error. In addition, ﬂash
memories, at present, use multilevel cells, where charge-levels
are quantized to simulate a ﬁnite alphabet – the more levels,
the less safety margins are left, and data integrity is compromised. Thus, over-programming (increasing a cell’s chargelevel above the designated mark) is a real problem, requiring
a costly and damaging erasure cycle. Hence, in a programming
cycle, charge-levels are usually made to gradually approach the
desirable amount, making for lengthier programming cycles as
well (see [3]).
In an effort to counter these effects, a different modulation
scheme has recently been suggested for ﬂash memories – rank
modulation [11]. This scheme calls for the representation of
the data stored in a group of cells in the permutation suggested
by their relative charge-levels. That is, if c1 , c2 , . . . , cn ∈ R
represent the charge-levels of n ∈ N cells, then that group of
cells is said to encode that permutation σ ∈ Sn such that:

1 The operations described in [18] are actually mirror images of “pushto-the-top” . Furthermore, the permutation-generation scheme there is not a
Gray code since it repeats some of the previously generated permutations,
also making it inefﬁcient.

cσ(1) > cσ(2) > . . . > cσ(n) > 0.
This work was supported in part by ISF grant 134/10.

1

R(C ), is deﬁned as

translates into a small distance in the metric. In contrast, the
∞ -metric was used in [14], [19], as small distances in this
metric correspond to small limited-magnitude errors.
In this paper, we explore Gray codes for rank modulation
which detect a single error, under Kendall’s τ-metric (further
results in the ∞ -metric are mentioned in the conclusion to
this paper). Such codes are known as snake-in-the-box codes,
and have been studied extensively for binary vectors with
the Hamming metric and with single-bit ﬂips as allowable
transitions (see [1] and references therein).
The paper is organized as follows: In Section II we present
basic notation and deﬁnitions. In Section III we review properties of Kendall’s τ-metric, then present a recursive construction of snake-in-the-box codes over the alternating groups of
odd orders with rate asymptotically tending to 1. We conclude
in Section IV with a description of further results given without
proof, along with some ad-hoc results, and open questions.
Some proofs for stated results are omitted due to the limited
space; they can be found in the journal version of this work,
to appear in [22].

R(C ) =

log2 M
.
log2 |S|

In the context of rank modulation for ﬂash memories,
the set of transformations T comprises of “push-to-the-top”
operations, ﬁrst used in [11], and later also in [7], [20]. We
denote by ti : Sn → Sn the “push-to-the-top” operation on
index i, i.e.,
t i [ a 1 , a 2 , . . . , a i −1 , a i , a i +1 , . . . , a n ] =

= [ a i , a 1 , a 2 , . . . , a i −1 , a i +1 , . . . , a n ] ,
and throughout the paper we set T = {t2 , t3 , . . . , tn }. We also
note that, in cycle notation,
ti σ = σ (i, i − 1, . . . , 1) .

(1)

For ease of presentation only, we also denote by ti the
“push-to-the-bottom” operation on index n + 1 − i, i.e.,
t i [ a 1 , a 2 , . . . , a n − i , a n +1− i , a n +2− i , . . . , a n ] =

= [ a 1 , a 2 , . . . , a n − i , a n +2− i , . . . , a n , a n +1− i ] .

II. P RELIMINARIES

Let d : S × S → N ∪ {0} be a distance function inducing
a metric M over S. Given a transmitted codeword c ∈ C and
˜
its received version c ∈ S, we say a single error occurred
˜
if d(c, c) = 1. We are interested in Gray codes capable of
detecting single errors, which we now deﬁne.

We shall denote a permutation σ on n elements by σ =
[σ(1), σ(2), . . . , σ(n)]. This form is called the vector notation
for permutations. We let Sn be the group of all permutations
on [n]. For σ, τ ∈ Sn , their composition, denoted στ, is the
permutation for which στ (i ) = σ (τ (i )) for all i ∈ [n]. It is
well known that |Sn | = n!.
A cycle, denoted ( a1 , a2 , . . . , ak ), is a permutation mapping
ai → ai+1 for all i ∈ [k − 1], as well as ak → a1 . We
shall occasionally use cycle notation in which a permutation
is described as a composition of cycles. We also recall that
any permutation may be represented as a composition of
cycles of size 2 (known as transpositions), and that the parity
of the number of transpositions does not depend on the
decomposition. Thus we have even and odd permutations. We
let An be the subgroup of all even permutations on [n], called
the alternating group of order n. Again, it is well known that
1
| A n | = 2 | Sn |.

Deﬁnition 2. Let M be a metric over S induced by a distance
measure d. A snake-in-the-box code over M and S, using
transitions T, is a Gray code C over S and using T, in which
for every pair of distinct elements c, c ∈ C, c = c , one has
d (c, c ) 2.
Since throughout this paper our ambient space is Sn , and the
transformations we use are the “push-to-the-top” operations T,
we shall abbreviate our notation and call a snake-in-the-box
code of size M an (n, M, M)-snake, or an M-snake. We will
be considering two metrics in the next sections: Kendall’s τmetric, K, and the ∞ -metric, with their respective K-snakes
and ∞ -snakes.
III. K ENDALL’ S τ-M ETRIC AND K -S NAKES

Deﬁnition 1. Given a set S and a subset of transformations T ⊆
{ f | f : S → S}, a Gray code over S, using transitions T, of
size M, is a sequence C = (c0 , c1 , . . . , c M−1 ) of M distinct
elements of S, called codewords, such that for all j ∈ [ M − 1]
there exists t ∈ T such that c j = t(c j−1 ).

Kendall’s τ-metric [13], denoted K, is induced by the
bubble-sort distance which measures the minimal amount of
adjacent transpositions required to transform one permutation
into the other. For example, the distance between the permutations [2, 1, 4, 3] and [2, 4, 3, 1] is 2, as

Alternatively, when the original permutation c0 is known
(or irrelevant), we use a slight abuse of notation in referring
to the sequence of transformations (tk1 , . . . , tk M−1 ) generating
the code (i.e., c j = tk j (c j−1 )) as the code itself.
In the above deﬁnition, when M = |S| the Gray code is
called complete. If there exists t ∈ T such that t (c M−1 ) =
c0 the Gray code is cyclic, M is called its period, and we
shall, when listing the code by its sequence of transformations,
include tk M = t at the end of the list. The rate of C, denoted

[2, 1, 4, 3] → [2, 4, 1, 3] → [2, 4, 3, 1]
is a shortest sequence of adjacent transpositions between the
two. More formally, for α, β ∈ Sn , as noted in [12],
dK (α, β) = |{(i, j) | α(i ) < α( j) ∧ β(i ) > β( j)}| .
The metric K was ﬁrst introduced by Kendall [13] in the
study of ranking in statistics. It was observed in [12] that a
bounded distance in Kendall’s τ-metric models errors caused

2

by bounded changes in charge-levels of cells in the ﬂash
memory. Error-correcting codes for this metric were studied
in [2], [12], [15].
We let Kendall’s τ adjacency graph of order n ∈ N be
the graph Gn = (Vn , En ) whose vertices are permutations on
n elements (i.e., Vn = Sn ), and {α, β} ∈ En if and only
if dK (α, β) = 1. It is well known that Kendall’s τ-metric is
graphic [5], i.e., for every α, β ∈ Sn , dK (α, β) equals the
length of the shortest path between the two in Gn .

we order [5] \ {1, 3} in ascending order, i.e., ( a0 , a1 , a2 ) =
(2, 4, 5). We deﬁne the following permutations as starting
points for our construction

A. Construction
We begin the construction process by restricting ourselves
to Gray codes using only “push-to-the-top” operations on odd
indices. The following lemma provides the motivation for this
restriction.

σj(2n+1) = tk j σ( j−1)(2n+1) ,
i.e., we construct cycles corresponding to a mirror view of
(i )
C2n−1 on all but the two ﬁrst elements of σ0 (which, as we
recall, are (1, ai )).

Lemma 3. A Gray code over Sn using only “push-to-the-top”
operations on odd indices is a K-snake.

Example 5. In our running example, we deﬁne the following
permutations:

(0)

σ0

= [1, 2, 3, 4, 5]

(1)

σ0

(2)

= [1, 4, 3, 5, 2]

σ0

= [1, 5, 3, 2, 4]

2

and readily verify that they are all even.

We now deﬁne for all i ∈ [2n − 1] and j ∈ [ M2n−1 ] the
permutation
(i )

(i )

Lemma 3 saves us the need to check whether a Gray
code is in fact a K-snake, at the cost of restricting the set
of allowed transitions (and the size of the resulting code,
although Theorems 12,13, presented below, work to mitigate
this concern). In particular, if n is even, the last element cannot
be moved.
By starting with an even permutation, and using only “pushto-the-top” operations on odd indices, we get a sequence of
even permutations. Thus, throughout this part, the context of
the alternating group A2n+1 is assumed, where n ∈ N.
The construction we are about to present is recursive in nature. As a base for the recursion, we note that three consecutive
“push-to-the-top” operations on the 3rd index of permutations
in A3 constitute a complete cyclic (3, 3, K)-snake:

(0)

(0)

σ5 = t3 σ0 = [1, 2, 4, 5, 3]
(0)
(0)
σ10 = t3 σ5 = [1, 2, 5, 3, 4]
(0)
(0)
σ15 = t3 σ10 = [1, 2, 3, 4, 5]
(2)

(1)

(1)

σ5 = t3 σ0 = [1, 4, 5, 2, 3]
(1)
(1)
σ10 = t3 σ5 = [1, 4, 2, 3, 5]
(1)
(1)
σ15 = t3 σ10 = [1, 4, 3, 5, 2]

(2)

σ5 = t3 σ0 = [1, 5, 2, 4, 3]
(2)
(2)
σ10 = t3 σ5 = [1, 5, 4, 3, 2]
(2)
(2)
σ15 = t3 σ10 = [1, 5, 3, 2, 4]

2

and resume our construction.

We now note the following properties of our construction:
Lemma 6. Let i, k ∈ [2n − 1] and j, l ∈ [ M2n−1 ]. The
following are equivalent:
(i )

(k)

1) The permutations σj(2n+1) and σl (2n+1) are cyclic shifts
of each other.
(i )
(k)
2) σj(2n+1) = σl (2n+1) .
3) i = k and j = l.

C3 = ([1, 2, 3], [3, 1, 2], [2, 3, 1]) .
We shall extend C3 to the next order as a running example
alongside the general construction below.
Now, assume that there exists a cyclic (2n − 1, M2n−1 , K)be the sequence
snake, C2n−1 , and let tk1 , tk2 , . . . , tk M
2n−1
of transformations generating it, where k j is odd for all
j ∈ [ M2n−1 ]. We also assume that k1 = 2n − 1 (this
requirement, while perhaps appearing arbitrary, is actually
quite easily satisﬁed. Indeed, every sufﬁciently large cyclic
K-snake over S2n−1 must, w.l.o.g., satisfy it. We shall make
it a point to demonstrate that this holds for our construction).
We ﬁx arbitrary values for a0 , a1 , . . . , a2n−2 such that

{ a0 , a1 , . . . , a2n−2 } = [2n + 1] \ {1, 3} .

(3)

= σ0

(k)

(i )

Proof: First, if σj(2n+1) is a cyclic shift of σl (2n+1) , since
(k)

(i )

σj(2n+1) (1) = 1 = σl (2n+1) (1)
then necessarily
(i )

(k)

σj(2n+1) = σl (2n+1) .
It then follows that
(i )

(k)

ai = σj(2n+1) (2) = σl (2n+1) (2) = ak ,

(2)

hence i = k. Moreover, since the two permutations’ last n − 1
elements agree, and tk1 , tk2 , . . . , tk M
induce a Gray code,
2n−1
we necessarily have j = l.
Finally, that the last statement implies the ﬁrst is trivial.

For all i ∈ [2n − 1] we deﬁne
(i )

σ0 = [1, ai , 3, ai+1 , . . . , ai+2n−2 ],
where the indices are taken modulo 2n − 1, and such that we
(i )
(i )
indeed have σ0 ∈ A2n+1 , i.e., σ0 is an even permutation
(one simple way of achieving this is to choose them in
ascending order).

Lemma 7. For all i ∈ [2n − 1] it holds that
(i )

σM

2n−1 (2n +1)

(i )

= σ0 .

induce a
Proof: The transformations tk1 , tk2 , . . . , tk M
2n−1
cyclic code, and the claim follows directly.

Example 4. We recall that C3 is generated by the operations
(t3 , t3 , t3 ), which satisfy our requirement. As suggested above,

3

Therefore we have constructed 2n − 1 cycles comprised of
cyclically non-equivalent permutations (although, at this point
they are not generated by “push-to-the-top” operations).
It shall now be noted that

where, again, the indices are taken modulo 2n − 1. Thus for
all i ∈ [2n − 2] we have
(i )

(2n−1)

Hence, if we deﬁne for all i ∈ [2n − 1], 0
1 < m 2n, the permutations

(i )

and t3 σ1
= σ2 .
Let E denote the left-shift operator, and so

j < M2n−1 , and

(i )

(i )

(i )

E2 C2n+1 = σ2 , σ3 , . . . , σM

2n−1 (2n +1)−1

(i )

σj(2n+1)+1 = t2n+2−k j+1 σj(2n+1)

(i )

, σ0 , σ1

.

By the observations made above we conclude that
(0)

(i )

(i )

(1)

(i )

tk = t2n+1 t2n+2−k .
2n

(i )

( i +1)

t3 σ1 = [ ai , 3, 1, ai+1 , . . . , ai+2n−2 ] = σ2

m
σj(2n+1)+m = t2n−11 σj(2n+1)+1 ,
+

(2n−2)

(1)

C2n+1 = E2 C2n+1 , E2 C2n+1 , . . . , E2 C2n+1

is a cyclic (2n + 1, M2n+1 , K)-snake, consisting of

then it holds that
(i )

(i )

σ( j+1)(2n+1) = t2n+1 σj(2n+1)+2n .

M2n+1 = (2n − 1)(2n + 1) M2n−1

Our observation from one paragraph above means that at
this point we have 2n − 1 disjoint cycles, which we conveniently denote

permutations. A careful observation readily shows that C2n+1
has t2n+1 for its ﬁrst generating transformation.

(i )
C2n+1

=

(i )
(i ) (i )
σ0 , σ1 , . . . , σM
2n−1 (2n +1)−1

Example 10. Our running example ends with the full construction of a (5, 45, K)-snake, C5 , from Theorem 9. The down
arrows stand for an omitted sequence of t5 transformations. The
transition from column to column uses a single t3 transformation.

,
(0)

for all i ∈ [2n − 1] (for ease of notation, we let C2n+1 =
(2n−1)

C2n+1 ).
[5, 3, 1, 2, 4]
↓
[1, 2, 4, 5, 3]
[4, 1, 2, 5, 3]
↓
[1, 2, 5, 3, 4]
[5, 1, 2, 3, 4]
↓
[1, 2, 3, 4, 5]
[3, 1, 2, 4, 5]

Example 8. In our construction, the cycles we produced are:
(0)

σ0 = [1, 2, 3, 4, 5]
(0)
σ1 = [3, 1, 2, 4, 5]
(0)
σ2 = [5, 3, 1, 2, 4]
(0)
σ3 = [4, 5, 3, 1, 2]
(0)
σ4 = [2, 4, 5, 3, 1]
(0)
σ5 = [1, 2, 4, 5, 3]
(0)
σ6 = [4, 1, 2, 5, 3]
(0)
σ7 = [3, 4, 1, 2, 5]
(0)
σ8 = [5, 3, 4, 1, 2]
(0)
σ9 = [2, 5, 3, 4, 1]
(0)
σ10 = [1, 2, 5, 3, 4]
(0)
σ11 = [5, 1, 2, 3, 4]
(0)
σ12 = [4, 5, 1, 2, 3]
(0)
σ13 = [3, 4, 5, 1, 2]
(0)
σ14 = [2, 3, 4, 5, 1]

(1)

σ0
(1)
σ1
(1)
σ2
(1)
σ3
(1)
σ4
(1)
σ5
(1)
σ6
(1)
σ7
(1)
σ8
(1)
σ9
(1)
σ10
(1)
σ11
(1)
σ12
(1)
σ13
(1)
σ14

= [1, 4, 3, 5, 2]
= [3, 1, 4, 5, 2]
= [2, 3, 1, 4, 5]
= [5, 2, 3, 1, 4]
= [4, 5, 2, 3, 1]
= [1, 4, 5, 2, 3]
= [5, 1, 4, 2, 3]
= [3, 5, 1, 4, 2]
= [2, 3, 5, 1, 4]
= [4, 2, 3, 5, 1]
= [1, 4, 2, 3, 5]
= [2, 1, 4, 3, 5]
= [5, 2, 1, 4, 3]
= [3, 5, 2, 1, 4]
= [4, 3, 5, 2, 1]

(2)

σ0
(2)
σ1
(2)
σ2
(2)
σ3
(2)
σ4
(2)
σ5
(2)
σ6
(2)
σ7
(2)
σ8
(2)
σ9
(2)
σ10
(2)
σ11
(2)
σ12
(2)
σ13
(2)
σ14

= [1, 5, 3, 2, 5]
= [3, 1, 5, 2, 4]
= [4, 3, 1, 5, 2]
= [2, 4, 3, 1, 5]
= [5, 2, 4, 3, 1]
= [1, 5, 2, 4, 3]
= [2, 1, 5, 4, 3]
= [3, 2, 1, 5, 4]
= [4, 3, 2, 1, 5]
= [5, 4, 3, 2, 1]
= [1, 5, 4, 3, 2]
= [4, 1, 5, 3, 2]
= [2, 4, 1, 5, 3]
= [3, 2, 4, 1, 5]
= [5, 3, 2, 4, 1]

↓ t3
↓ t5
↓ t5
↓ t5
↓ t5
↓ t3
↓ t5
↓ t5
↓ t5
↓ t5
↓ t3
↓ t5
↓ t5
↓ t5
t5

[2, 3, 1, 4, 5]
↓
[1, 4, 5, 2, 3]
[5, 1, 4, 2, 3]
↓
[1, 4, 2, 3, 5]
[2, 1, 4, 3, 5]
↓
[1, 4, 3, 5, 2]
[3, 1, 4, 5, 2]

(1)

σ2
↓
(1)
σ5
(1)
σ6
↓
(1)
σ10
(1)
σ11
↓
(1)
σ0
(1)
σ1

[4, 3, 1, 5, 2]
↓
[1, 5, 2, 4, 3]
[2, 1, 5, 4, 3]
↓
[1, 5, 4, 3, 2]
[4, 1, 5, 3, 2]
↓
[1, 5, 3, 2, 4]
[3, 1, 5, 2, 4]

(2)

σ2
↓
(2)
σ5
(2)
σ6
↓
(2)
σ10
(2)
σ11
↓
(2)
σ0
(2)
σ1

2

We now turn to consider the size and rate of the constructed
codes, and show that their rate asymptotically tends to 1.
Theorem 11. The size of K-snakes constructed in Theorem 9
behaves asymptotically as

where the permutations in bold are those from Example 5. 2

|C2n+1 | = M2n+1 =

Each of the cycles of size (2n + 1) M2n−1 , is generated
by “push-to-the-top” operations, and contains all cyclic shifts
of elements present in our previous version of that cycle. We
merge these cycles into a single cycle in the following theorem.

(2n)!(2n + 1)!
1
∼ √
|S2n+1 | ,
n!2 · 22n
πn

which leads to an asymptotic rate of 1.
One observes that the codes Cn+1 utilize the transformation
t2n+1 overwhelmingly more than any other. This property
allows one to calculate the transformation required to advance
any given permutation in the code to its successor in O(1)
amortized run time. In addition, the recursive nature of Theorem 9 lends itself to the ranking and unranking of permutations
in the code (that is, the processes of attaching to a given
permutation its position in the code, and vice versa) in O(n2 )
run time. Methods of achieving these tasks are presented
and analyzed in [22]. Together, they facilitate the use of the
codes C2n+1 in the implementation of logic memory cells, by
allowing one to increase the cell’s ‘level’ as well as directly
write data to it (and naturally, to read written data as well).

Theorem 9. Given a cyclic (2n − 1, M2n−1 , K)-snake using
only “push-to-the-top” operations on odd indices such that its
ﬁrst transformation is t2n−1 , there exists a cyclic K-snake over
S2n+1 with the same properties, whose size is
M2n+1 = (2n − 1)(2n + 1) M2n−1 .
(i )
σ1

(0)

σ2
↓
(0)
σ5
(0)
σ6
↓
(0)
σ10
(0)
σ11
↓
(0)
σ0
(0)
σ1

Proof: Since k1 = 2n − 1, it holds for all i ∈ [2n − 1] that
(i )
(i )
(i )
= t3 σ0 , and we recall σ2 = t2n+1 σ1 . More explicitly,
(i )

σ1 = [3, 1, ai , ai+1 , . . . , ai+2n−2 ]
(i )

σ2 = [ ai+2n−2 , 3, 1, ai , ai+1 , . . . , ai+2n−3 ] ,

4

IV. C ONCLUSION

R EFERENCES

In this paper we explored rank-modulation snake-in-the-box
codes under Kendall’s τ-metric, and presented a construction
yielding codes with rates asymptotically tending to 1. Some
results w.r.t. bounds on the size of such codes were also
proven in [22], which can be summarized by the following
two theorems:

[1] H. L. Abbot and M. Katchalski, “On the construction of snake in the
box codes,” Utilitas Math., vol. 40, pp. 97–116, 1991.
[2] A. Barg and A. Mazumdar, “Codes in permutations and error correction
for rank modulation,” IEEE Trans. on Inform. Theory, vol. 56, no. 7,
pp. 3158–3165, Jul. 2010.
[3] J. Brewer and M. Gill, Nonvolatile Memory Technologies with Emphasis
on Flash. Wiley-IEEE Press, 2008.
[4] F. Chierichetti, H. Finucane, Z. Liu, and M. Mitzenmacher, “Designing
ﬂoating codes for expected performance,” IEEE Trans. on Inform. Theory, vol. 56, no. 3, pp. 968–978, Mar. 2010.
[5] M. Deza and H. Huang, “Metrics on permutations, a survey,”
J. Comb. Inf. Sys. Sci., vol. 23, pp. 173–185, 1998.
[6] E. En Gad, A. Jiang, and J. Bruck, “Compressed encoding for rank
modulation,” in Proceedings of the 2011 IEEE International Symposium
on Information Theory (ISIT2011), St. Petersburg, Russia, Aug. 2011,
pp. 884–888.
[7] E. En Gad, M. Langberg, M. Schwartz, and J. Bruck, “Constant-weight
Gray codes for local rank modulation,” IEEE Trans. on Inform. Theory,
vol. 57, no. 11, pp. 7431–7442, Nov. 2011.
[8] F. Gray, “Pulse code communication,” March 1953, U.S. Patent 2632058.
[9] A. Jiang, V. Bohossian, and J. Bruck, “Rewriting codes for joint
information storage in ﬂash memories,” IEEE Trans. on Inform. Theory,
vol. 56, no. 10, pp. 5300–5313, Oct. 2010.
[10] A. Jiang, M. Langberg, M. Schwartz, and J. Bruck, “Universal rewriting
in constrained memories,” in Proceedings of the 2009 IEEE International
Symposium on Information Theory (ISIT2009), Seoul, Korea, Jun. 2009,
pp. 1219–1223.
[11] A. Jiang, R. Mateescu, M. Schwartz, and J. Bruck, “Rank modulation
for ﬂash memories,” IEEE Trans. on Inform. Theory, vol. 55, no. 6, pp.
2659–2673, Jun. 2009.
[12] A. Jiang, M. Schwartz, and J. Bruck, “Correcting charge-constrained
errors in the rank-modulation scheme,” IEEE Trans. on Inform. Theory,
vol. 56, no. 5, pp. 2112–2120, May 2010.
[13] M. Kendall and J. D. Gibbons, Rank Correlation Methods. Oxford
University Press, NY, 1990.
[14] T. Kløve, T.-T. Lin, S.-C. Tsai, and W.-G. Tzeng, “Permutation arrays
under the Chebyshev distance,” IEEE Trans. on Inform. Theory, vol. 56,
no. 6, pp. 2611–2617, Jun. 2010.
[15] A. Mazumdar, A. Barg, and G. Z´ mor, “Constructions of rank modulae
tion codes,” in Proceedings of the 2011 IEEE International Symposium
on Information Theory (ISIT2011), St. Petersburg, Russia, Aug. 2011,
pp. 834–838.
[16] N. Papandreou, H. Pozidis, T. Mittelholzer, G. F. Close, M. Breitwisch,
C. Lam, and E. Eleftheriou, “Drift-tolerant multilevel phase-change
memory,” in Proceedings of the 3rd IEEE International Memory Workshop (IMW), Monterey, CA, U.S.A., May 2011, pp. 22–25.
[17] C. D. Savage, “A survey of combinatorial Gray codes,” SIAM Rev.,
vol. 39, no. 4, pp. 605–629, Dec. 1997.
[18] R. Sedgewick, “Permutation generation methods,” Computing Surveys,
vol. 9, no. 2, pp. 137–164, Jun. 1977.
[19] I. Tamo and M. Schwartz, “Correcting limited-magnitude errors in the
rank-modulation scheme,” IEEE Trans. on Inform. Theory, vol. 56, no. 6,
pp. 2551–2560, Jun. 2010.
[20] Z. Wang and J. Bruck, “Partial rank modulation for ﬂash memories,” in
Proceedings of the 2010 IEEE International Symposium on Information
Theory (ISIT2010), Austin, TX, U.S.A., Jun. 2010, pp. 864–868.
[21] E. Yaakobi, A. Vardy, P. H. Siegel, and J. K. Wolf, “Multidimensional
ﬂash codes,” in Proc. of the Annual Allerton Conference, 2008.
[22] Y. Yehezkeally and M. Schwartz, “Snake-in-the-box codes for rank
modulation,” IEEE Trans. on Inform. Theory, 2012.

Theorem 12. If C is an (n, M, K)-snake then
1
1) M
2 | Sn |.
2) M = 1 |Sn | if and only if for all {α, β} ∈ En it holds
2
that α ∈ C or β ∈ C.
Theorem 13. If an (n, M, K)-snake C contains a “push-to-thetop” operation on an even index then
M

1
n−3
1
.
| Sn | −
2
2
n−1

However, it is not presently known whether these bounds are
achievable, and therefore we are unable to determine how close
the codes generated by our construction come to being optimal
with respect to their sizes (rather than their asymptotic rates).
A computer search for cyclic codes, performed on S5 , yielded
(5, M, K)-snakes of maximal size M = 57 (for comparison,
the construction from Theorem 9 yields a (5, 45, K)-snake).
While an abundance of such codes were found (well over 500
nonequivalent codes), they all were in fact codes over A5 .
It shall be noted that a complete (but not cyclic) (5, 60, K)snake over A5 can also be constructed by amending the
code presented in Example 10. However, we do not currently
(2n+1)!
know whether (2n + 1, 2 , K)-snakes over A2n+1 exist
for every length.
These results, along with the bounds we showed in Theorems 12,13 give rise to the following conjecture: For all n ∈ N
a K-snake exists over An whose size is no less than that of
every K-snake over Sn .
In addition, [22] explores rank-modulation snake-in-the-box
codes using a different metric, the ∞ -metric, which is induced
by the embedding of Sn in Zn . More precisely, for α, β ∈ Sn
one deﬁnes
d∞ (α, β) = max |α(i ) − β(i )| .
i ∈[n]

We use the ∞ -metric to model a different kind of noisemechanism than that modeled by Kendall’s τ-metric, namely
spike noise. In this model, the rank of each memory cell is
assumed to have been changed by a bounded amount (see
[19]). Under this metric, the authors were able to present a
construction which gives rise to the following theorem:
Theorem 14. For all 4
snake of size
n
M=
!
2

n ∈ N there exists an (n, M,
n
+
2

∞ )-

n
−1 ! .
2

And it was again shown that these codes have rates asymptotically tending to 1.

5

