Creator:         TeX output 2012.05.16:2117
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Wed May 16 21:17:14 2012
ModDate:        Tue Jun 19 12:56:35 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      287636 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569565385

Systematic Error-Correcting Codes
for Rank Modulation
Hongchao Zhou

Anxiao (Andrew) Jiang

Jehoshua Bruck

Department of Electrical Engineering
California Institute of Technology
Pasadena, CA 91125
Email: hzhou@caltech.edu

Computer Science and Eng. Dept.
Texas A&M University
College Station, TX 77843
ajiang@cse.tamu.edu

Department of Electrical Engineering
California Institute of Technology
Pasadena, CA 91125
Email: bruck@caltech.edu

Error-correcting codes for rank modulation are very important for data reliability [3], [9]. Errors are caused by noise
in cell levels, and the smallest error that can happen is for
two adjacent cell levels to switch their order in the permutation, which is called an adjacent transposition [5]. An adjacent transposition changes a permutation [x1 , x2 , · · · , xn ] ∈
Sn to [x1 , · · · , xi−1 , xi+1 , xi , xi+2 , · · · , xn ] for some i ∈
{1, 2, · · · , n − 1}. In this paper, as in [1], [8], [9], we measure
the distance between two permutations x = [x1 , x2 , · · · , xn ] ∈
Sn and y = [y1 , y2 , · · · , yn ] ∈ Sn by the minimum number of
adjacent transpositions needed to change x into y (and vice
versa), and denote it by dτ (x, y). This distance metric is called
the Kendall’s τ -distance [5]. For example, if x = [2, 1, 3, 4]
and y = [3, 1, 4, 2], then dτ (x, y) = 4, because to change
the permutation from x to y (or vice versa), we need at
least 4 adjacent transpositions: [2, 1, 3, 4] → [1, 2, 3, 4] →
[1, 3, 2, 4] → [1, 3, 4, 2] → [3, 1, 4, 2]. Based on this distance
metric, an error-correcting code that can correct t errors is a
subset of Sn whose minimum distance is at least 2t + 1.
There have been some results on error-correcting codes
for rank modulation equipped with the Kendall’s τ -distance.
In [9], a one-error-correcting code is constructed based on
metric embedding, whose size is provably within half of the
optimal size. In [1], the capacity of rank modulation codes
is derived for the full range of minimum distance between
codewords, and the existence of codes whose sizes are within
a constant factor of the sphere-packing bound for any ﬁxed
number of errors is shown. Some explicit constructions of
error-correcting codes have been proposed and analyzed in
[11] and [12]. There has also been some work on errorcorrecting codes for rank modulation equipped with the L∞
distance [13], [14]. The distance metric is more appropriate for
cells where the noise in cell levels has limited magnitudes.
In this paper, we study systematic error-correcting codes
for rank modulation as a new approach for code design. Let
k and n be two integers such that 2 ≤ k < n. In an (n, k)
systematic code, we use the permutation induced by the levels
of n cells to store data. The ﬁrst k cells are called information
cells, whose induced permutation has a one-to-one mapping
to information bits. The last n − k cells are called redundant
cells, which are used to add redundancy to the codewords.
Compared to the existing constructions of error-correcting

Abstract—The rank modulation scheme has been proposed
recently for efﬁciently writing and storing data in nonvolatile
memories. Error-correcting codes are very important for rank
modulation, and they have attracted interest among researchers.
In this work, we explore a new approach, systematic errorcorrecting codes for rank modulation. In an (n, k) systematic
code, we use the permutation induced by the levels of n cells
to store data, and the permutation induced by the ﬁrst k cells
(k < n) has a one-to-one mapping to information bits. Systematic
codes have the beneﬁts of enabling efﬁcient information retrieval
and potentially supporting more efﬁcient encoding and decoding
procedures. We study systematic codes for rank modulation
equipped with the Kendall’s τ -distance. We present (k + 2, k)
systematic codes for correcting one error, which have optimal
sizes unless perfect codes exist. We also study the design of multierror-correcting codes, and prove that for any 2 ≤ k < n, there
always exists an (n, k) systematic code of minimum distance n−k.
Furthermore, we prove that for rank modulation, systematic
codes achieve the same capacity as general error-correcting codes.

I. I NTRODUCTION
The rank modulation scheme has been proposed recently for
efﬁciently and robustly writing and storing data in nonvolatile
memories (NVMs) [7], [8]. Its applications include ﬂash
memories [3], which are currently the most widely used family
of NVMs, and several emerging NVM technologies, such as
phase-change memories [2]. The rank modulation scheme uses
the relative order of cell levels to represent data, where a
cell level denotes a ﬂoating-gate cell’s threshold voltage for
ﬂash memories and denotes a cell’s electrical resistance for
resistive memories (such as phase-change memories). Consider
n memory cells, where for i = 1, 2, · · · , n, let ci ∈ R denote
the level of the ith cell. It is assumed that no two cells have
the same level, which is easy to realize in practice. Let Sn
denote the set of all n! permutations of {1, 2, · · · , n}. The
n cell levels induce a permutation [x1 , x2 , · · · , xn ] ∈ Sn ,
where cx1 > cx2 > · · · > cxn . The rank modulation scheme
uses such permutations to represent data. It enables memory
cells to be programmed efﬁciently and robustly from lower
levels to higher levels, without the risk of over-programming.
It also makes it easier to adjust cell levels when noise appears
without erasing/resetting cells, and makes the stored data be
more robust to asymmetric errors that change cell levels in the
same direction [7], [8].

1

codes for rank modulation, systematic codes have the beneﬁt
that they support efﬁcient data retrieval, because when there is
no error (or when error correction is not considered), data can
be retrieved by only reading the information cells. And since
every permutation induced by the information cells represents
a unique value of the data, the permutations can be mapped to
data (and vice versa) very efﬁciently via enumerative source
coding (e.g., by ordering permutations alphabetically and map
them to data) [4], [10]. In addition, the encoding algorithm
of the error-correcting code can potentially be made very
efﬁcient by deﬁning the positions of the redundant cells in
the permutation as a function of the corresponding positions
of the information cells.
We study the design of systematic codes, and analyze their
performance. We present a family of (k + 2, k) systematic
codes for correcting one error, where either k or k + 1
is a prime number. We show that they have optimal sizes
among systematic codes, unless perfect systematic one-errorcorrecting codes, which meet the sphere-packing bound, exist.
We also study the design of systematic codes that correct
multiple errors, and prove that for any 2 ≤ k < n, there exists
a systematic code of minimum distance n − k. Furthermore,
we prove that for rank modulation, systematic codes have the
same capacity as general error-correcting codes. This result
establishes that asymptotically, systematic codes are as strong
in their error correction capability as general codes.
The rest of the paper is organized as follows. In Section II,
we deﬁne some terms and show properties of systematic codes.
In Section III, we study systematic codes that correct one error.
In Section IV, we study codes that correct multiple errors. In
Section V, we present the capacity of systematic codes, which
matches the capacity of general codes. Due to space limitation,
we skip some details. Interested readers can refer to [15] for
the full paper.

into an initially- empty permutation. Hence, we deﬁne the
insertion vector of x as the positions of inserting 1, 2, · · · , n.
Speciﬁcally, for 1 ≤ i ≤ n, let gi (x) denote the position of the
insertion of the integer i. That is, if p ∈ {1, 2, · · · , n} denotes
the integer such that xp = i, then
gi (x) = |{j|1 ≤ j < p, xj < i}|.
Then we have the insertion vector
g(x) = [g1 (x), g2 (x), · · · , gn (x)] ∈ Z1 × Z2 × · · · × Zn ,
where Zi = {0, 1, 2, ..., i − 1}. Note that given g(x), we can
reconstruct x uniquely. It has been shown that for any x, y ∈
Sn [1],
n
∑
dτ (x, y) ≥
|gi (x) − gi (y)|.
i=1

For an (n, k) systematic code, it is required that for every
permutation a = [a1 , a2 , · · · , ak ] ∈ Sk , there is exactly one
codeword with a as its information sector, which we will
denote by xa . The code has k! codewords, and we deﬁne its
ln k!
rate as ln n! . Given an information sector a ∈ Sk , we can get
the insertion vector of its codeword xa , namely,
g(xa )

=

[g1 (xa ), g2 (xa ), ..., gn (xa )]

= [g1 (a), ..., gk (a), gk+1 (xa ), ...gn (xa )].
It means that xa can be constructed from a in the following way: First, we insert k + 1 (namely, the (k + 1)th
cell) into the permutation [a1 , a2 , · · · , ak ] at the position
gk+1 (xa ) ∈ Zk+1 ; next, we insert the integer k + 2 (namely,
the (k + 2)th cell) at the position gk+2 (xa ) ∈ Zk+2 ; and
so on. (The last integer to insert is n.) To design good
systematic codes, given the information permutation a, we
need to ﬁnd [gk+1 (xa ), gk+2 (xa ), ..., gn (xa )] appropriately to
maximize the code’s minimum distance.

II. T ERMS AND P ROPERTIES
In this section, we deﬁne some terms for systematic codes,
and show its basic properties. Let C ⊆ Sn denote a general
(n, k) systematic error-correcting code for rank modulation.
Given a codeword x = [x1 , x2 , · · · , xn ] ∈ C, we call the
permutation induced by the ﬁrst k cells (i.e., the information
cells) a = [a1 , a2 , · · · , ak ] ∈ Sk the information sector of
the codeword x. More speciﬁcally, if c1 , c2 , · · · , cn are the n
cells’ levels that induce the permutation [x1 , x2 , · · · , xn ] ∈
C, then we have ca1 > ca2 > · · · > cak . Clearly,
the information sector [a1 , a2 , · · · , ak ] is a subsequence of
its codeword [x1 , x2 , · · · , xn ]; namely, [a1 , a2 , · · · , ak ] =
[xi1 , xi2 , · · · , xik ] for some 1 ≤ i1 < i2 < · · · < ik ≤ n.

Example 2. Let k = 4 and n = 6. If a = [1, 3, 2, 4], g5 (xa ) =
3 and g6 (xa ) = 0, then xa = [6, 1, 3, 2, 5, 4].
2
The following theorem shows how the insertion of redundant cells into the information sector affects the Kendall’s τ distance between codewords.
Theorem 3. Given two permutations a, b ∈ Sk , the Kendall’s
τ -distance between xa and xb satisﬁes the inequality
dτ (xa , xb ) ≥ dτ (a, b) +

n
∑

|gi (xa ) − gi (xb )|.

i=k+1

III. O NE - ERROR - CORRECTING C ODES

Example 1. Let k = 4 and n = 6. Let c1 = 1.0, c2 = 2.1,
c3 = 0.8, c4 = 0.2, c5 = 1.5, c6 = 0.6. Then the permutation
induced by the n = 6 cells is [2, 5, 1, 3, 6, 4]. The permutation
induced by the k = 4 information cells is [2, 1, 3, 4]. We can
2
see that [2, 1, 3, 4] is a subsequence of [2, 5, 1, 3, 6, 4].

In this section, we analyze and design systematic codes for
correcting one error. Such codes have minimum distance 3. In
particular, we present a family of (k + 2, k) systematic codes,
where either k or k+1 is a prime number. It will be shown that
the codes have optimal sizes among systematic codes, unless
perfect systematic one-error-correcting codes, which meet the
sphere-packing bound, exist.

Given a permutation x = [x1 , x2 , · · · , xn ] ∈ Sn , we can
see it as constructed by sequentially inserting 1, 2, · · · , n

2

A. Properties of One-error-correcting Codes

The following theorem shows that the above code can
correct one error.

Given a permutation x ∈ Sn , the ball of radius r centered at x, denoted by Br (x), is the set of permutations in
Sn that are within distance r from x. Namely, Br (x) =
{y ∈ Sn |dτ (x, y) ≤ r}, for 0 ≤ r ≤ n(n−1) . (The
2
maximum Kendall’s τ -distance for any two permutations in
Sn is n(n−1) . [8]) A simple relabeling argument sufﬁces to
2
show that the size of a ball does not depend on the choice
of its center. So we use |Br (n)| to denote |Br (x)| for any
x ∈ Sn . It can be proved that [15] for any 0 ≤ r ≤ n(n−1) ,
2
(
)
n+r−1
|Br (n)| ≤
.
n−1

Theorem 7. The (k + 2, k) systematic code in Construction 6
has minimum distance at least 3. Hence it is a one-errorcorrecting code.
Proof: In the (k + 2, k) code of Construction 6, either k
or k + 1 is a prime number. Let us ﬁrst consider the case that
k is a prime number. Assume that a = [a1 , a2 , · · · , ak ] ∈ Sk
and b = [b1 , b2 , · · · , bk ] ∈ Sk are two distinct information
sectors, whose corresponding codewords are xa , xb ∈ Sn ,
respectively. Our goal is to prove that dτ (xa , xb ) ≥ 3. We
consider three cases:
1) Case 1: dτ (a, b) ≥ 3. In this case, we have
dτ (xa , xb ) ≥ dτ (a, b) ≥ 3.
2) Case 2: dτ (a, b) = 1. In this case, we can write b as
b = [b1 , b2 , · · · , bk ] = [a1 , a2 , · · · , ai+1 , ai , · · · , ak ] for
some i ∈ {1, 2, · · · , k − 1}. If we deﬁne ∆ = ai+1 − ai ,
then we get

An r-error-correcting code C ⊆ Sn for rank modulation
n!
needs to satisfy the sphere-packing bound: |C| ≤ |Br (n)| . If
the inequality in the above bound becomes equality, we call the
code perfect. For one-error-correcting codes, since |B1 (n)| =
n, the following result holds.
Theorem 4. A systematic (n, k) one-error-correcting code for
rank modulation is perfect if and only if n = k + 1. More
generally, a perfect one-error-correcting code, – systematic or
not, – of length n has (n − 1)! codewords.

gk+1 (xa ) − gk+1 (xb ) = 2∆

(mod k).

Since 1 ≤ |∆| ≤ k − 1 and k ≥ 3 is a prime number,
we know that 2∆ is not a multiple of k. As a result, we
get |gk+1 (xa ) − gk+1 (xa )| ≥ 1.
Similarly, we have

It is known that perfect codes are often rare. Well-known
examples include binary codes, where the only perfects codes
are Hamming codes and Golay codes, and Lee metric codes
in three-dimensional and higher-dimensional spaces [6]. For
rank modulation, there is a simple (3, 2) one-error-correcting
code that is perfect: {[1, 2, 3], [3, 2, 1]}. However, beside this
trivial code, no other perfect code has been found yet. If we
add the requirement that the code needs to be systematic, it
will be even harder for such codes to exist. For instance, it
can be proved that there does not exist any perfect systematic
one-error-correcting code when k = 3.

gk+2 (xa ) − gk+2 (xb ) = 8i∆

(mod k),

where 8i∆ is not a multiple of k, either, because 1 ≤
i, |∆| ≤ k−1 and k ≥ 3 is a prime number. This implies
that |gk+2 (xa ) − gk+2 (xb )| ≥ 1.
So by Theorem 3, we get dτ (xa , xb ) ≥ dτ (a, b) +
|gk+1 (xa ) − gk+1 (xb )|+|gk+2 (xa ) − gk+2 (xb )| ≥ 1+
1 + 1 = 3.
3) Case 3: dτ (a, b) = 2. In this case, it takes at least two
adjacent transpositions to change the permutation a into
b. These two transpositions can be either separated or
adjacent to each other. By considering the two cases separately (detailed proof omitted due to space limitation),
we can get that dτ (xa , xb ) ≥ 3.
Therefore, we can conclude that when k is a prime number,
for any two distinct codewords xa , xb , their distance is at
least 3. When k + 1 is a prime number, we can apply the
same procedure for the proof, – by only replacing “mod k”
with “mod k + 1”, – and get the result that dτ (xa , xb ) ≥ 3.
And that concludes the proof.
We now present the encoding and decoding algorithms of
the (k + 2, k) systematic code. Let L = {0, 1, · · · , k! − 1}
denote the set of information symbols to encode. (If the
input are information bits, they can be easily mapped to the
information symbols in L via enumerative source coding. L
can be rounded down to a power of 2.) For encoding, given
an information symbol ℓ ∈ L, it can be mapped to its corresponding permutation (i.e., information sector) a ∈ Sk in time
linear in k [10]. Based on Construction 6, the insertion vector
(gk+1 (xa ), gk+2 (xa )) can be directly computed, which gives

Theorem 5. There does not exist any (4, 3) systematic oneerror-correcting code for rank modulation.
For any given k ≥ 3, if the perfect (k + 1, k) code does not
exist, then the (k + 2, k) code becomes the optimal systematic
code.
B. Construction of (k + 2, k) One-error-correcting Codes
We now present the construction that builds a family of
(k + 2, k) systematic one-error-correcting codes.
Construction 6. Let k ≥ 3 be an integer such that either k or
k + 1 is a prime number. Given any information sector a =
[a1 , a2 , ..., ak ] ∈ Sk , let gk+1 (xa ) ∈ Zk+1 , gk+2 (xa ) ∈ Zk+2
be the positions of inserting k + 1 and k + 2. We set
∑k
gk+1 (xa ) = i=1 (2i − 1)ai mod m
∑k
(1)
gk+2 (xa ) = i=1 (2i − 1)2 ai mod m

where m = k if k is a prime number and m = k + 1 if k + 1 is
a prime number.
2

3

one permutation in {xs1 , xs2 , ..., xsi−1 }. Such vectors cannot
be chosen for the codeword xsi . Our proof is based on two
main observations: First, given si ∈ Sk , let Nl be the number
of permutations in Sk whose distance to si is l, then
(
)
j
∑
k+j−1
Nl ≤ |Bj (k)| ≤
(4)
1+
k−1

us the codeword xa . That completes the encoding algorithm.
The decoding algorithm of the construction is also efﬁcient:
Given the received codeword y, let b denote its information
sector. If there is an error in b, i.e., b ̸= a, then we can write
a = [b1 , ..., bi+1 , bi , ..., bk ] for some i with 1 ≤ i ≤ k − 1.
Based on the construction, this i can be determined by solving
a simple equation, hence, making the decoding process very
efﬁcient.

l=1

for 1 ≤ j ≤ d − 1.
Second, given sj with j < i, if dτ (si , sj ) = l, there are at
most
(
)
min (d−j−1,n−k) d − j − 1 + n − k
2
(5)
n−k

IV. M ULTI - ERROR - CORRECTING C ODES
In this section, we study the design of systematic codes
that correct multiple errors, and prove that for any 2 ≤ k < n,
there exists an (n, k) systematic code of minimum distance
n − k.
First, we present a generic scheme for constructing an (n, k)
systematic code of minimum distance d. The scheme is based
on greedy searching, hence, not explicit. But the analysis
of this scheme is very useful for proving the existence of
codes with certain parameters, and for deriving the capacity
of systematic codes.

assignments for [gk+1 (xsi ), gk+2 (xsi ), ..., gn (xsi )] such that
dτ (xsj , xsi ) ≤ d − 1.
From (4) and (5), we can get that the total number of unavailable assignments for [gk+1 (xsi ), gk+2 (xsi ), ..., gn (xsi )]
is at most
(
)
d−1
∑ (k + l − 2)
d−l−1+n−k
2min (d−l−1,n−k)
.
l
n−k
l=1

Construction 8. Let 2 ≤ k < n and d ≥ 1. In this scheme, we
construct an (n, k) systematic code of minimum distance d. It
uses a greedy approach for choosing codewords as follows. Let
s1 , s2 , · · · , sk! denote the k! permutations in Sk , respectively.
For i = 1, 2, · · · , k!, we choose the codeword xsi whose
information sector is si as follows: Among all the permutations
in Sn that contain si as their information sector, choose a
permutation xsi such that
∀j ∈ {1, 2, · · · , i − 1}, dτ (xsi , xsj ) ≥ d.

This completes the proof.
From this theorem, we can further get the following result.
Theorem 10. For any k ≥ 2 and d ≥ 1, there exists a (k + d, k)
systematic code of minimum distance d.
Now, we present an explicit construction of systematic
multi-error-correcting codes, by slightly modifying the multierror-correcting codes derived in [11]. The idea is that given
any two integers gi (xa ), gi (xb ) < 2m , there exists a function
ϕm : Z2m → {0, 1}m (called Gray map) such that

(2)

If all the k! codewords xs1 , xs2 , · · · , xsk! can be generated
successfully this way, we obtain an (n, k) systematic code of
2
minimum distance d.

|gi (xa ) − gi (xb )| ≥ dH (ϕm (gi (xa )), ϕm (gi (xb ))),
where dH indicates the Hamming distance between two binary
vectors. As a result, we can convert the problem of constructing rank modulation codes to the problem of constructing
binary error-correcting codes in Hamming space. To make the
code being systematic, we use ϕ⌈log2 i⌉ with 1 ≤ i ≤ k for the
mapping of information part, instead of using ϕ⌊log2 i⌋ in the
original construction.

Note that given any a ∈ Sk , there are (k+1)×(k+2)×· · ·×
n = n! permutations in Sn that have a as their information
k!
sector. For the above code construction to succeed, n−k needs
to be sufﬁciently large. In the following theorem, we derive a
bound for the parameters.

Construction 11. Let 2 ≤ k < n, we construct an (n, k)
systematic rank modulation code, denoted by Cτ ⊂ Sn . Given
any information sector a ∈ Sk , to construct its codeword
xa ∈ Cτ , we ﬁrst construct xa ’s image in a binary systematic
code CH , that is

Theorem 9. Construction 8 can successfully build an (n, k)
systematic code of minimum distance d if
(
)
d−1
∑ (k + l − 2)
d−l−1+n−k
n!
2min (d−l−1,n−k)
<
l
n−k
k!
l=1
(3)

f (xa ) =[ϕ⌈log2 1⌉ (g1 (a)), ..., ϕ⌈log2 k⌉ (gk (a)),

Proof: In Construction 8, for any information sector si ∈
Sk (where 1 ≤ i ≤ k!), there are n! possible choices for
k!
the vector [gk+1 (xsi ), gk+2 (xsi ), ..., gn (xsi )]. Our goal is to
make sure that at least one of them – which will become the
corresponding codeword xsi – can guarantee to satisfy the
requirement in (2).
Let us consider the maximum number of choices for the
vector [gk+1 (xsi ), gk+2 (xsi ), ..., gn (xsi )] whose corresponding permutations in Sn are at distance less than d from at least

ϕ⌊log2 (k+1)⌋ (gk+1 (xa )), ..., ϕ⌊log2 n⌋ (gn (xa ))].
∑
In f (xa ), the ﬁrst k ′ = k ⌈log2 i⌉ bits are the information
i=1
bits and they can be obtained from the information sector a
∑n
directly. The rest r′ = i=k+1 ⌊log2 i⌋ bits are the parity-check
bits based on the encoding of CH . Then we can get xa ∈ Sn
from f (xa ) uniquely. If CH is an (k ′ +r′ , k ′ ) binary systematic
code correcting t errors, then Cτ is an (n, k) systematic rank
modulation code correcting t errors.

4

V. C APACITY OF S YSTEMATIC C ODES

We consider two cases:
1) If d = O(n), we have d ≤ βn for some β > 0. By
Stirling’s approximation, the formula above yields

In this section, we prove that for rank modulation, systematic error-correcting codes achieve the same capacity as
general error-correcting codes. In [1], Barg and Mazumdar
have derived the capacity of general error-correcting codes
for rank modulation. Let A(n, d) denote the maximum size of
a code of length n and minimum distance d. (So the code is a
subset of Sn .) Deﬁne the capacity of error-correcting codes of
minimum distance d as C(d) = limn→∞ ln A(n,d) . It is shown
ln n!
in [1] that

if d = O(n)
 1,
1 − ϵ, if d = Θ(n1+ϵ ) with 0 < ϵ < 1
(6)
C(d) =

0,
if d = Θ(n2 ).

lim

n ln n − αn ln(αn)

n→∞

≥1

which shows that n ln n − αn ln(αn) = O(n). Hence α
approaches 1 as n → ∞.
2) If d = Θ(n1+ϵ ) for 0 < ϵ < 1, by applying Stirling’s
approximation to Equation (7), we get
n ln d − k ln k − (n − k) ln(n − k) + O(n)
= 1.
n→∞
n ln n − k ln k + O(n)
lim

Since k = αn and d = Θ(n1+ϵ ), we get

For systematic codes, let k(n, d) denote the maximum number of information cells that can exist in systematic codes of
length n and minimum distance d. (Such codes are (n, k(n, d))
systematic codes, and have k(n, d)! codewords.) The capacity
of systematic codes of minimum distance d is

lim

n→∞

(1 + ϵ)n ln n − αn ln n − (1 − α)n ln
= 1.
(1 − α)n ln n

That leads to α ≥ 1 − ϵ.
Based on the above analysis and the fact that Ssys (d) ≥ α,
we get the ﬁnal conclusion.

ln k(n, d)!
.
ln n!
The following theorem shows that systematic codes have the
same capacity as general codes.
Csys (d) = lim

ACKNOWLEDGMENT

n→∞

This work was supported in part by an NSF grant ECCS0801795 and by a BSF grant 2010075.
R EFERENCES

Theorem 12. The capacity of systematic codes of minimum
distance d is

if d = O(n)
 1,
1 − ϵ, if d = Θ(n1+ϵ ) with 0 < ϵ < 1
Csys (d) =

if d = Θ(n2 ).
0,

[1] A. Barg and A. Mazumdar, “Codes in permutations and error correction
for rank modulation,” in IEEE Transactions on Information Theory, vol.
56, no. 7, pp. 3158–3165, 2010.
[2] G. W. Burr et al., “Phase change memory technology,” in Journal of
Vacuum Science and Technology, vol. 28, no. 2, pp. 223-262, March
2010.
[3] P. Cappelletti, C. Golla, P. Olivo and E. Zanoni (Ed.), Flash memories,
Kluwer Academic Publishers, 1st Edition, 1999.
[4] T. M. Cover, “Enumerative source coding,” IEEE Transactions on Information Theory, vol. IT-19, no. 1, pp. 73–77, Jan. 1973.
[5] M. Deza and H. Huang, “Metrics on permutations, a survey,” J. Comb. Inf. Sys. Sci., vol. 23, pp. 173–185, 1998.
[6] S. W. Golomb and L. R. Welch, “Perfect codes in the Lee metric and
the packing of polyominoes,” SIAM J. Appl. Math., vol. 18, no. 2, pp.
302–317, 1970.
[7] A. Jiang, R. Mateescu, M. Schwartz and J. Bruck, “Rank modulation for
ﬂash memories,” in Proc. IEEE International Symposium on Information
Theory (ISIT), pp. 1731–1735, July 2008.
[8] A. Jiang, M. Schwartz and J. Bruck, “Error-correcting codes for rank
modulation,” in Proc. IEEE International Symposium on Information
Theory (ISIT), pp. 1736–1740, July 2008.
[9] A. Jiang, M. Schwartz and J. Bruck, “Correcting charge-constrained errors
in the rank-modulation scheme,” in IEEE Transactions on Information
Theory, vol. 56, no. 5, pp. 2112–2120, 2010.
[10] M. Mares and M. Straka, “Linear-time ranking of permutations,”
Algorithms-ESA, pp. 187–193, 2007.
e
[11] A. Mazumdar, A. Barg and G. Z´ mor, “Construction of rank modulation
codes,” IEEE Internatinal Sympos. Inform. Theory, pp. 834–838, 2011.
[12] A. Mazumdar, A. Barg and G. Z´ mor, “Parameters of rank modulation
e
codes: examples,” Annual conference on communication, control and
computing, pp. 13–17, 2011.
[13] M. Schwartz and I. Tamo, “Optimal permutation anticodes with the inﬁnity norm via permanents of (0, 1)-matrices,” in Journal of Combinatorial
Theory, Series A, vol. 118, pp. 1761–1774, 2011.
[14] I. Tamo and M. Schwartz, “Correcting limited-magnitude errors in the
rank-modulation scheme,” in IEEE Transactions on Information Theory,
vol. 56, no. 6, pp. 2551–2560, June 2010.
[15] H. Zhou, A. Jiang and J. Bruck, “Systematic Error-Correcting Codes for
Rank Modulation,” http://paradise.caltech.edu/etr.html, ETR112, California Institute of Technology, 2011.

Proof: Since systematic codes are a special case of
general error-correcting codes, by Equation (6), it is sufﬁcient
to prove

if d = O(n)
 1,
1 − ϵ, if d = Θ(n1+ϵ ) with 0 < ϵ < 1
Csys (d) ≥

0,
if d = Θ(n2 ).
According to Theorem 9, there exists an (n, k) systematic
code of minimum distance d if k is the maximum integer that
satisﬁes
(
) (
)
k+d n d+n−k
n!
2
< .
d
n−k
k!
For such k, we have k(n, d) ≥ k. For convenience, let α =
k
limn→∞ n be a constant. In this case, if α > 0,
ln k(n, d)!
ln k!
≥ lim
n→∞ ln n!
ln n!
αn log(αn)
= lim
= α.
n→∞
n log n

Csys (d) =

β+1−α
(α + β)n ln α+β + n ln 2 + (β + 1 − α)n ln (1−α)β
αβ

lim

n→∞

To prove the ﬁnal conclusion, we will show that if d =
O(n), then α = 1; if d = Θ(n1+ϵ ), then α ≥ 1 − ϵ. (If
d = Θ(n2 ), the result α ≥ 0 is trivial).
Based on the deﬁnition of k, we can get
( ) (
)
ln k+d 2n d+n−k
d
n−k
lim
=1
(7)
n→∞
ln n!
k!

5

