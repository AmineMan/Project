Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Thu May 17 16:16:05 2012
ModDate:        Tue Jun 19 12:54:43 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      444543 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569566527

Efﬁcient Tracking of Large Classes of Experts
Andr´ s Gy¨ rgy
a
o

Tam´ s Linder
a

G´ bor Lugosi
a

Department of Computing Science
University of Alberta, Canada
gya@szit.bme.hu

Department of Mathematics and Statistics
Queen’s University, Canada
linder@mast.queensu.ca

ICREA and Department of Economics
Pompeu Fabra University, Spain
gabor.lugosi@gmail.com

B. Tracking the best expert

Abstract—In the framework of prediction with expert advice
we consider prediction algorithms that compete against a class
of switching strategies that can segment a given sequence into
several blocks and follow the advice of a different “base” expert
in each block. The performance is measured by the regret deﬁned
as the excess loss relative to the best switching strategy selected
in hindsight. Our goal is to construct low-complexity prediction
algorithms for the case where the set of base experts is large.
In particular, starting with an arbitrary prediction algorithm A
designed for the base expert class, we derive a family of efﬁcient
tracking algorithms that can be implemented with time and space
complexity only O(nγ ln n) times larger than that of A, where n
is the time horizon and γ ≥ 0 is a parameter of the algorithm.
With A properly chosen, our algorithm achieves a regret bound
of optimal order for γ > 0, and only O(ln n) times larger than
the optimal order for γ = 0 for all typical regret bound types
we examined. For example, for predicting binary sequences with
switching parameters, our method achieves the optimal O(ln n)
regret rate with time complexity O(n1+γ ln n) for any γ ∈ (0, 1).

A more ambitious goal than performing nearly as well as the
best expert in a class E is to compete with the best sequence
of expert predictions that may switch its experts at a certain,
limited, number of times. Thus we compete with meta experts
described by sequences of base experts (i1 , . . . , in ) ∈ E n ,
such that at time instants t = 1, . . . , n a meta expert follows
the prediction of the “base” expert it ∈ E by predicting fit ,t .
The complexity of such a meta expert may be measured by
C = |{t ∈ {1, 2, . . . , n − 1} : it = it+1 }|, the number
of times it changes the base predictor (each such change
is called a switch). These C switches partition {1, . . . , n}
into C + 1 contiguous segments, on each of which the meta
expert follows the prediction of the same base expert. If a
maximum of m changes are allowed and the set of base experts
has N elements, then the class of meta experts is of size
m
n−1
N (N − 1)j . Clearly, a naive implementation of
j=0
j
popular algorithms such as the exponentially weighted average
forecaster [1] is not feasible in this case, but several more
efﬁcient algorithms have been proposed.
In one approach to the tracking problem a transition diagram
is used to deﬁne a Markovian model to specify a prior
distribution on the switches of the experts, and the starting
point of the current segment is estimated using this prior
[2], [3]. In its straightforward version, for each time instant
t, the performance of an expert algorithm is emulated for
all possible segment starting points 1, . . . , t, and a weighted
average of the resulting estimates is used to form the next
prediction. This method converts an efﬁcient algorithm to
compete with the best expert in a class E into one that
competes with the best sequence of experts with a limited
number of changes. However, the time complexity of the
resulting algorithm increases by a factor of n compared with
the original algorithm that competes with E, yielding a total
complexity that is quadratic in n.
Several methods have been introduced to reduce the above
complexity. A linear-complexity method was developed in [4],
which uses an easy-to-implement weighting of the paths in
the full transition diagram, but needs to know the number of
switches in advance. This assumption was eliminated by [5]
and [6], [7] at the price of somewhat increasing the regret;
the latter providing better bounds at the price of an increased
O(n3/2 ) complexity.
While these algorithms seem to solve the complexity problem arising in the transition diagram based approach, they
cannot be applied in this form to the case when the base

I. I NTRODUCTION
A. Prediction with expert advice
We consider on-line (sequential) prediction problems in
which an outcome space Y, a decision space D (a convex
subset of a vector space), and a set of reference experts E
are given. At each time instant t = 1, . . . , n, the environment
chooses an action yt ∈ Y and each expert i ∈ E forms its
prediction fi,t ∈ D. Then the forecaster chooses an action
pt ∈ D (without knowing yt ), suffers loss (pt , yt ), and the
losses (fi,t , yt ), i ∈ E are revealed to the forecaster. Here
: D×Y → R is a loss function that is convex in its ﬁrst argument. The goal of the forecaster is to minimize its cumulative
n
loss Ln = t=1 (pt , yt ). This is equivalent to minimizing
its excess loss Ln − mini∈E Li,n relative to choosing the best
n
expert in E in hindsight, where Li,n = t=1 (fi,t , yt ) for all
i ∈ E.
Several methods are known that can compete successfully with different expert classes E, under various assumptions on the loss function, in the sense that
the (worst-case) cumulative regret, deﬁned as Rn =
maxy1 ,...,yn ∈Y n Ln − mini∈E Li,n only grows sub-linearly,
that is, limn→∞ Rn /n = 0. We refer to [1] for a survey.
This research was supported in part by the National Development Agency of
Hungary from the Research and Technological Innovation Fund (KTIA-OTKA
CNK 77782), the Alberta Innovates Technology Futures, the Natural Sciences
and Engineering Research Council (NSERC) of Canada, the Spanish Ministry
of Science and Technology grant MTM2009-09063, and the PASCAL2
Network of Excellence under EC grant no. 216886.

1

expert class E is very large, since their complexity also scales
linearly with the number of base experts, and they do not seem
to allow to incorporate efﬁcient algorithms developed for E
(that scale much better in the size of E) without increasing
the complexity to at least O(n2 ) [8]. Such large base-expert
classes play important role in, e.g., lossless [9] and lossy data
compression [10]–[12]. To overcome quadratic complexity,
reduced transition diagrams have been used for the logarithmic
loss (i.e., data compression) by [13] and by [3] (the latter work
considers a probabilistic setup). Reduced transitions diagrams
for the tracking problem with (more) general loss functions
were considered in [14] and [15].
In this paper we tackle the complexity issue by presenting
a general method for designing reduced transition diagrams.
Our algorithm uniﬁes and generalizes the algorithms of [13]–
[15]. This algorithm has an explicit complexity-regret tradeoff, covering essentially all such results in the literature. In
addition to the (almost) linear complexity algorithms in the
aforementioned papers, the parameters of our algorithm can
be set to reproduce the methods based on the full transition
diagram [2], [3], [16], or the complexity-regret behavior of
[6], [7]. Also, our algorithm has regret of optimal order with
complexity O(n1+γ ln n) for any γ ∈ (0, 1), while setting γ = 0
results in complexity O(n ln n) and a regret that is only a
factor of ln n larger than the optimal rate (similarly to [13]–
[15]).
Due to space constraints the main results will only be
presented in their simplest form and for exp-concave loss
function only (i.e., for loss functions for which there exists
an η > 0 such that F (p) = e−η (p,y) is concave for ﬁxed
y ∈ Y); proofs and more general statements can be found
in [17].

path” T = (t1 , . . . , tC ; n) such that t0 := 1 < t1 < . . . <
tC < tC+1 := n + 1. For each c = 0, . . . , C, the meta expert
follows the advice of expert ic in the time interval [tc , tc+1 ).
Any meta expert that can be deﬁned using a given transition
path T is said to follow T .
The total loss of the meta expert indexed by (T, a), accumulated during n rounds, is
C

Ln (T, a) =

Let Tt denote the set of all transition paths up to time t
represented by vectors (t1 , . . . , tC ; t) with 1 < t1 < t2 <
. . . < tC ≤ t and 0 ≤ C ≤ t. For any T = (t1 , . . . , tC ) ∈
Tn and t ≤ n deﬁne the truncation of T at time t as
Tt = (t1 , . . . , tk ; t), where k is such that tk ≤ t < tk+1 .
Furthermore, let τt (T ) = τt (Tt ) = tk denote the last change
up to time t, and let Ct (T ) = C(Tt ) = k denote the number
of switches up to time t. A transition path T with C switches
splits the time interval [1, n] into C + 1 contiguous segments.
We apply algorithm A on T in such a way that at the beginning
of each segment (at time instants tc ) we restart A; this
algorithm will be denoted in the sequel by (A, T ). Denote the
output of the algorithm at time t by fA,t (Tt ) = fA,t (τt (T )).
This notation emphasizes the fact that, since A is restarted
at the beginning of each segment of T , its output at time t
depends only on τt (T ), the beginning of the segment which
includes t. The loss of algorithm (A, T ) up to time n is
C

Ln (A, T ) =

As most tracking algorithms, our algorithm will use weight
functions wt : Tt → [0, 1] satisfying Tt ∈Tt wt (Tt t) = 1
and wt (Tt ) =
Tt+1 :Tt =Tt wt+1 (Tt+1 ). To simplify the
notation, we formally deﬁne T0 as the “empty transition path”
T0 := {T0 }, L0 (A, T0 ) := 0, and w0 (T0 ) := 1.
Now we are ready to deﬁne our master algorithm, given in
Algorithm 1.

II. A REDUCED COMPLEXITY TRACKING ALGORITHM
Consider an on-line forecasting algorithm A, and suppose
that for all n and possible outcome sequences of length n, A
satisﬁes a regret bound
(1)

Algorithm 1 General tracking algorithm.
Input: prediction algorithm A, weight functions {wt ; t =
1, . . . , n}, learning parameters ηt > 0, t = 1, . . . , n.
For t = 1, . . . , n predict

with respect to the base expert class E, where ρE : [0, ∞) →
[0, ∞) is a nondecreasing and concave function with ρE (0) =
0. These assumptions on ρE are usually satisﬁed by the known
regret bounds for different algorithms [1]. Suppose 1 ≤ t1 <
t2 ≤ n and an instance of A is used for time instants t ∈
[t1 , t2 ) := {t1 , . . . , t2 − 1}, that is, algorithm A is run on data
obtained in the segment [t1 , t2 ). The accumulated loss of A
during this period will be denoted by LA (t1 , t2 ). Then (1)
implies

pt =

T ∈Tt

wt (T )e−ηt Lt−1 (A,Tt−1 ) fA,t (τt (T ))
.
−ηt Lt−1 (A,Tt−1 )
T ∈Tt wt (T )e

We note that the consistency of {wt } implies that Algorithm 1 is equivalent to the exponentially weighted average
forecaster with the set of experts {(A, T ) : T ∈ Tn , wn (Tn ) >
0} and initial weights wn (T ) for (A, T ).
The next lemma gives a general regret bound for Algorithm 1 in terms of the weight function wn and a transition path
T that approximates the true transition path in the following
sense: We say that T ∈ Tn covers T ∈ Tn if the change
points of T are also change points of T . Note that if T covers

LA (t1 , t2 ) − min Li (t1 , t2 ) ≤ ρE (t2 − t1 )
i∈E

t2 −1
where Li (t1 , t2 ) = t=t1
i in the interval [t1 , t2 ).

LA (tc , tc+1 ) .
c=0

A. A general tracking algorithm

Rn ≤ ρE (n)

Lic (tc , tc+1 ) .
c=0

(fi,t , yt ) denotes the loss of expert

Fix the time horizon n ≥ 1. A meta expert that changes
base experts at most C ≥ 0 times can be described by a
vector of experts a = (i0 , . . . , iC ) ∈ E C+1 and a “transition

2

T , then any meta expert that follows transition path T also
follows transition path T .
Lemma 1: Suppose the transition path Tn is covered by
ˆ
ˆ
Tn = (t1 , . . . , tC(Tn ) ; n) such that wn (Tn ) > 0, and A
satisﬁes the regret bound (1). Assume that is exp-concave
for the value of η and Algorithm 1 is used with ηt ≡ η. Then
C(Tn )

ˆ
ˆ
ρE (tc+1 − tc ) +

Ln − Ln (Tn , a) ≤
c=0

C. A low-complexity algorithm
Efﬁcient implementation of Algorithm 1 hinges on three
factors: (i) Algorithm A can be efﬁciently implemented; (ii)
the exponential weighting step can be efﬁciently implemented;
which is facilitated by (iii) the availability of the losses LA,t .
In what follows we assume that (i) and (iii) hold and develop
a method for (ii) via constructing a new weight function {wt }
ˆ
that signiﬁcantly reduces the complexity of implementing
Algorithm 1.
First, we observe that the predictor pt of Algorithm 1 can
ˆ
be rewritten as

1
1
ln
.1
η wn (Tn )

B. The weight function
One may interpret the weight function {wt } as the conditional probability that a new segment is started, given
the beginning of the current segment and the current time
instant. In this case one may deﬁne {wt } in terms of a timeinhomogeneous Markov chain {Ut ; t = 1, 2, . . .} whose state
space at time t is {1, . . . , t}. Starting from state U1 = 1, at any
time instant t, the Markov-chain either stays where it was at
time t − 1 or switches to state t. In particular, P(U1 = 1) = 1
and for 1 ≤ t < t,

pt =

(6)

(7)

T ∈Tt : τt (T )=t

If the ηt are constant during the time horizon, the above
means that Algorithm 1 can be implemented efﬁciently by
keeping a weight vt (t ) at each time instant t for every possible
starting point of a segment t = 1, . . . , t. Indeed, if ηt = η
for all t, then (7), (2), and (3) imply that each vt (t ) can
be computed recursively in O(t) time from the vt−1 (setting
v1 (1) = 1 at the beginning) using the switch probabilities
deﬁning wt . Using this recursion, the overall complexity of
computing the weights during n rounds is O(n2 ). Furthermore,
(6) means that one needs to start an instance of A for each
possible starting point of a segment. If the complexity of
running algorithm A for n time steps is O(n) (i.e., computing
A at each time instance has complexity O(1)), then the overall
complexity of our algorithm becomes O(n2 ).
Our goal is to reduce the linear growth of the per round
complexity. To this end, we modify the weight functions in
such a way that at any time instant t we allow at most O(g ln t)
actual segments with positive probability (i.e., segments containing t that belong to sample paths with positive weights),
where g > 0 is a parameter of the algorithm (note that g may
depend on, e.g., the time horizon n). By doing so, the time and
space complexity of the algorithm becomes O(g ln n) times
more than that of algorithm A (with space complexity bounded
away form zero), as we need to run O(g ln n) instances of A
in parallel and the number of non-zero terms in the recursion
for computing vt and in (6) is also O(g ln n). Thus, in case of
a linear-time-complexity algorithm A, the overall complexity
of Algorithm 1 becomes O(gn ln n).
In order to construct the new weight function, at each time
instant t we force some segments to end. Then any path that
contains such a segment will start a new segment at time t
(and hence the corresponding vector of transitions contains t).
Speciﬁcally, if a segment starts at time instant s, where s can
be written as o2u with o being an odd number and u an integer,
o, u ≥ 0 (that is, 2u is the largest power of 2 that divides t),
then a segment starting at s can “live” for at most g2u time
instances, where g > 0 is a parameter of the algorithm. Thus
at time s + g2u we force a switch in the path: given p(t|t )

where (u1 , . . . , ut ) is such that T = T (u1 , . . . , ut ). It is easy
to check that {wt } deﬁnes a sequence of compatible distributions as required. Clearly, the switch probabilities p(t|t )
uniquely determine {wt }.
Some examples that have been proposed for this construction (given in terms of the switch probabilities) include
• pHW (t|t ) = α for some 0 < α < 1 [4].
HS
• p
(t|t ) = 1/t [5], [7], [15].
KT
• The weight function w
is deﬁned by pKT (t|t ) =
1/2
t−t +1 [2], the Krichevsky-Troﬁmov estimate [1].
L
• w 1 used in [3] (similar weight functions were considered
in [18]), is deﬁned as follows: for a given > 0, let
∞
t
πj = 1/j 1+ , Zt = j=1 π(j) and Z∞ = j=1 π(j).
π(t−1)
Then wL1 is deﬁned by pL1 (t|t ) = (Z∞ −Zt−2 ) .
We will concentrate on the weights wL1 . It is shown in [3,
proof of Eq. (39)] that for any T ∈ Tn ,
(4)

rn (C) = (C + ) ln n + ln(1 + ) − C ln .

wt (T )e−ηt Lt−1 (A,Tt−1 ) .

vt (t ) =

(3)

L
ln(1/wn 1 (T )) ≤ rn (Cn (T ))

)

where the weights vt are given by

P(Ut = t|Ut−1 = t ) = 1 − P(Ut = t |Ut−1 = t ) = p(t|t )
(2)
where the so-called switch probabilities p(t|t ) need only
satisfy p(t|t ) ∈ [0, 1] for all 1 ≤ t < t. A realization
of this Markov chain uniquely determines a transition path:
Tt (u1 , . . . , ut ) = (t1 , . . . , tC ; t) ∈ Tt if and only if uk−1 = uk
for k ∈ {t1 , . . . , tC }, and uk−1 = uk for k ∈ {t1 , . . . , tC },
/
2 ≤ k ≤ t. Inverting this correspondence, any T ∈ Tt uniquely
determines a realization (u1 , . . . , ut ). Now the weight function
is given for all t ≥ 1 and T ∈ Tt by
wt (T ) = P(U1 = u1 , . . . , Ut = ut )

t
t =1 vt (t )fA,t (t
t
t =1 vt (t )

(5)

where

1 Throughout the paper ln and log denote the natural logarithm and the
base-2 logarithm, respectively.

3

for all t < t, we deﬁne a new switching probability
p(t|t ) = 1 − ht (t ) 1 − p(t|t )
ˆ

where
(8)

LC,n =





where ht (s) = I{s≤t<s+g2u } and IE denotes the indicator of
the event E. Thus ht (s) = 1 if and only if a segment started
at s is still alive at time t. In this way, given the switching
probabilities p(t|t ) and the associated weight function {wt },
we can deﬁne a new weight function {wt } via the new
ˆ
switching probabilities p(t|t ) and the procedure described in
ˆ
Section II-B. Note that the deﬁnition of {wt } implies that for
ˆ
a transition path T ∈ Tt either wt (T ) = 0 or wt (T ) ≥ wt (T ).
ˆ
ˆ
The above procedure is a common generalization of previous algorithms in the literature for pruning the transition
paths. Speciﬁcally, g = 1 yields the procedure of [13], g = 3
yields our previous procedure [14], g = 4 yields the method of
[15], while g = n yields the original weighting {wt } without
pruning. We will show that the time complexity of the method
with a constant g (i.e., when g is independent of the time
horizon n) is, in each time instant, at most O(ln n) times the
complexity of one step of A, while the time complexity of the
algorithm without pruning is O(n) times the complexity of A.
Complexities that interpolate between these two extremes can
be achieved by setting g = O(n) appropriately.
In what follows we assume that the original switching probabilities p(t|t ) associated with the wt satisfy p(t|t ) ∈ (0, 1)
for all 1 ≤ t < t. (Note that the weight function examples
introduced in Section II-B all satisfy this condition.) The
condition implies that wt (Tt ) > 0 for all Tt ∈ Tt . Furthermore,
if Tt = (t1 , . . . , tC ; t) ∈ Tt satisﬁes ti+1 − ti < g2uti ,
i = 1, . . . , C, where uti is the largest power of 2 divisor
of ti , then from (8) we get wt (T ) > 0. We say that a segment
ˆ
at time instant t is alive if it contains t and is valid if there is
a path Tt with wt (Tt ) > 0 that contains exactly that segment.
ˆ
Lemma 2: At any time instant t there are at most
g/2 ( log t + 1) segments that are valid and alive.
The lemma implies that Algorithm 1 can be implemented
efﬁciently with the proposed weight function {wt }.
ˆ
Theorem 1: Assume Algorithm 1 is run with weight function {wt } derived using any g > 0 from any weight function
ˆ
{wt } deﬁned as in Section II-B. If ηt = η for some η > 0
and all t = 1, . . . , n, then the time an space complexity of
Algorithm 1 is O(g ln n) times the time and space complexity
of A, respectively.

log n
log(g+1)
n
log C+1
log(g+1) +

+1

if C = 0,

2

if C ≥ 1.

(9)

We now apply the above construction and results to the
L
weight function {wt } = {wt 1 } to obtain our main theorem.
The proof is a combination of Lemmas 1 and 3, and (4).
Theorem 2: Assume Algorithm 1 is run with weight funcL
tion {wt 1 } (derived from {wt 1 }) with g > 0, based on a
ˆL
prediction algorithm that satisﬁes (1) for some ρE . Let SC,n
be deﬁned as in Lemma 3. If is exp-concave for some η > 0
and ηt = η for t = 1, . . . , n in Algorithm 1, then for any
T ∈ Tn the tracking regret satisﬁes
n
Ln − Ln (T, a) ≤ LC(T ),n (C(T )+1)ρE
LC(T ),n (C(T )+1)
+

rn LC(T ),n (C(T ) + 1) − 1
η

(10)

where rn is deﬁned in (5).
III. E XAMPLES
In this section we apply the results of the paper for a few
speciﬁc examples.
Example 1 (Exponential weighting): Here we apply our algorithm to the case where A is the exponentially weighted
average forecaster and the set of base experts is of size N ,
and discuss the obtained bounds (for simplicity we assume
C(T ) ≥ 1, but C(T ) = 0 would just slightly change the
presented bounds). If is exp-concave, then by [1] the regret
of A is bounded by ρE (n) = lnηN . Then, for g = O(1), the
bound (10) becomes
(C(T ) + 1)
Ln −Ln (T, a) ≤

n
log C(T )+1
log(g+1)

η

+2
ln(nN ) + O(1)

which is a factor of O(ln n) larger than the existing bounds
[2]–[5], valid for algorithms having complexity O(n2 ). For
g = 2nγ − 1, we obtain a bound of optimal (C(T ) + 1) ln n
order:
1
(C(T ) + 1) γ + 2
Ln − Ln (T, a) ≤
ln(nN ) + O(1).
η
The time complexity of our algorithm is only O(nγ ln n) times
larger than that of running A (which is typically linear in n).
Thus, in a sense the complexity of our algorithm can get very
close to linear while guaranteeing a regret of optimal order.
(Note however, that a factor 1/γ appears in the regret bounds
so setting γ very small comes at a price.)

D. Regret bounds
To bound the regret, the main problem is to relate an
arbitrary transition path T ∈ T and its “closest” approximation
T ∈ T that covers T and has positive weight. The next lemma
shows that any segment [t, t ) of T can be covered by at most
logarithmically many segments of T .
Lemma 3: For any T ∈ Tn , there exists T ∈ Tn such that
for any segment [t, t ) of T with 1 ≤ t < t ≤ n+1, wt (T ) >
ˆ
0, t and t are switching points of T (where t = n + 1 is
considered as a switching point), and T contains at most l =
log(t −t)
+ 1 segments in [t, t ). Furthermore,
log(g+1)

Example 2 (Krichevsky-Troﬁmov mixtures): Assume D =
E = (0, 1) and Y = {0, 1}, and consider the logarithmic
loss (p, y) = −Iy=1 ln p − Iy=0 ln(1 − p), which is expconcave with η ≤ 1, and hence we choose η = 1. This loss
plays a central role in data compression. In particular, if a
prediction method achieves, on a particular binary sequence
y n = (y1 , . . . , yn ), a loss Ln , then using arithmetic coding the
sequence can be described with at most Ln + 2 bits [2]. The
expert class E = (0, 1) corresponds to the situation where the

C(Tn ) ≤ C(Tn ) ≤ (C(Tn ) + 1)LC(Tn ),n − 1

4

sequence y n is encoded using an i.i.d. coding distribution or,
in a probabilistic interpretation, it is equivalent to minimizing
the worst case maximum coding redundancy relative to the
class of i.i.d. source distributions on {0, 1}n .
The Krichevsky-Troﬁmov forecaster [1] is an exponentially
weighted average forecaster over all base experts θ ∈ E using
initial weights 1/(π θ(1 − θ)), and can be computed efﬁciently as pKT (y t−1 ) = (n1 (t − 1) + 1/2)/t. The performance
t
1
of this forecaster can be bounded as Rn ≤ 2 ln n + ln 2.
In this framework, a meta expert is allowed to change θ ∈ E
a certain number of times. In the probabilistic interpretation,
this corresponds to the problem of coding a piecewise i.i.d.
source [2], [3], [6], [7], [13]. A slightly improved analysis
of Algorithm 1 with weight function wKT (compared to
ˆ
Theorem 2) shows that for any transition path T ∈ Tn and
meta expert (T, a) with C(T ) = C
Ln −Ln (T, a) ≤

The problem of competing with the best time-variant quantizer that can change the employed quantizer several times
(i.e., tracking the best quantizer), was analyzed in [8], based
on a combination of [12] and the tracking algorithm of [4].
There the best linear-complexity scheme achieves O((C +
1) ln n/n1/6 ) distortion redundancy when an upper bound C
on the number of switches in the reference class is known in
advance. On the other hand, applying a modiﬁed version of
our scheme for randomized prediction [17] with g = O(1)
in the method of [8], one can show that a linear-complexity
version of this algorithm can achieve distortion redundancy
O((C + 1)1/2 ln3/4 (n)/n1/4 ) + O((C + 1) ln(n)/n1/2 ) distortion redundancy for any (a priori unknown) C. When
g = 2nγ − 1, the distortion redundancy for linear complexity
1
becomes somewhat worse, proportional to n− 2(2+γ) up to
logarithmic factors.

2 n
(C + 1) ln 2 log C+1
+O((C +1) ln n).
2
log(g + 1)

R EFERENCES
[1] N. Cesa-Bianchi and G. Lugosi, Prediction, Learning, and Games.
Cambridge: Cambridge University Press, 2006.
[2] F. M. J. Willems, “Coding for a binary independent piecewiseidentically-distributed source,” IEEE Transactions on Information Theory, vol. IT-42, pp. 2210–2217, Nov. 1996.
[3] G. I. Shamir and N. Merhav, “Low-complexity sequential lossless coding
for piecewise-stationary memoryless sources,” IEEE Transactions on
Information Theory, vol. IT-45, pp. 1498–1519, July 1999.
[4] M. Herbster and M. K. Warmuth, “Tracking the best expert,” Machine
Learning, vol. 32, no. 2, pp. 151–178, 1998.
[5] W. Koolen and S. de Rooij, “Combining expert advice efﬁciently,” in
Proceedings of the 21st Annual Conference on Learning Theory, COLT
2008, Helsinki, Finland, July 2008, pp. 275–286.
[6] C. Monteleoni and T. S. Jaakkola, “Online learning of non-stationary
sequences,” in Advances in Neural Information Processing Systems 16,
S. Thrun, L. Saul, and B. Sch¨ lkopf, Eds. MIT Press, 2004.
o
[7] S. de Rooij and T. van Erven, “Learning the switching rate by discretising Bernoulli sources online,” in Proceedings of the Twelfth International
Conference on Artiﬁcial Intelligence and Statistics (AISTATS 2009), ser.
JMLR Workshop and Conference Proceedings, vol. 5, Clearwater Beach,
Florida USA, April 2009, pp. 432–439.
[8] A. Gy¨ rgy, T. Linder, and G. Lugosi, “Tracking the best quantizer,” IEEE
o
Transactions on Information Theory, vol. 54, pp. 1604–1625, Apr. 2008.
[9] F. M. J. Willems, Y. N. Shtarkov, and T. J. Tjalkens, “The context-tree
weighting method: Basic properties,” IEEE Transactions on Information
Theory, vol. IT-41, pp. 653–664, May 1995.
[10] T. Linder and G. Lugosi, “A zero-delay sequential scheme for lossy
coding of individual sequences,” IEEE Transactions on Information
Theory, vol. 47, pp. 2533–2538, Sep. 2001.
[11] T. Weissman and N. Merhav, “On limited-delay lossy coding and
ﬁltering of individual sequences,” IEEE Transactions on Information
Theory, vol. 48, pp. 721–733, Mar. 2002.
[12] A. Gy¨ rgy, T. Linder, and G. Lugosi, “Efﬁcient algorithms and minimax
o
bounds for zero-delay lossy source coding,” IEEE Transactions on
Signal Processing, vol. 52, pp. 2337–2347, Aug. 2004.
[13] F. Willems and M. Krom, “Live-and-die coding for binary piecewise
i.i.d. sources,” in Proceedings of the 1997 IEEE International Symposium on Information Theory (ISIT 1997), Ulm, Germany, June-July
1997, p. 68.
[14] A. Gy¨ rgy, T. Linder, and G. Lugosi, “Efﬁcient tracking of the best
o
of many experts,” in Information and Communication Conference,
Budapest, Aug. 25–28 2008, pp. 3–4.
[15] E. Hazan and C. Seshadhri, “Efﬁcient learning algorithms for changing
environments,” in Proceedings of the 26th Annual International Conference on Machine Learning. ACM, 2009, pp. 393–400.
[16] S. Kozat and A. Singer, “Universal switching linear least squares
prediction,” IEEE Transactions on Signal Processing, vol. 56, no. 1,
pp. 189–204, Jan. 2008.
[17] A. Gy¨ rgy, T. Linder, and G. Lugosi, “Efﬁcient tracking of large classes
o
of experts,” CoRR, vol. abs/1110.2755, 2011.
[18] V. Vovk, “Derandomizing stochastic prediction strategies,” Machine
Learning, vol. 35, no. 3, pp. 247–282, Jun. 1999.

For g = 1, this bound recovers that of [13] (at least in the
leading term), and improves the leading constant for g = 3
and g = 4 when compared to [14] and [15], respectively. On
the other hand, for g = 2nγ − 1, γ > 0, using with wL1 in
ˆ
Algorithm 1, a reﬁned version of Theorem 2 implies
Ln − Ln (T, a) ≤

3(C + 1)
2

1
+ 2 ln n + O(1).
γ

This bound achieves the optimal O(ln n) order for any γ > 0;
however, with an increased leading constant. On the negative
side, for speciﬁc choices of γ our algorithm does not recover
the best leading constants known in the literature (cf. [6], [7]
for γ = 1/2).
Example 3 (Tracking the best quantizers): The problem of
zero-delay adaptive universal lossy source coding of individual
sequences has recently been investigated in detail [8], [10]–
[12]. Here an inﬁnite sequence of [0, 1]-valued source symbols
x1 , x2 , . . . is transformed into a sequence of channel symbols
y1 , y2 , . . . which take values from the ﬁnite channel alphabet
{1, 2, . . . , M } and these channel symbols are then used to
produce the ([0, 1]-valued) reproduction sequence x1 , x2 , . . ..
ˆ ˆ
The scheme operates with zero delay, that is, yn depends
only on x1 , . . . , xn , and xn on y1 , . . . , yn , so that the encoder
ˆ
produces yn as soon as xn becomes available, and the decoder
can produce xn when yn is received. The quality of the reproˆ
n
ˆ
duction is measured by the average distortion t=1 d(xt , xt ),
where d is some nonnegative bounded distortion measure. The
squared error d(x, x ) = (x − x )2 is perhaps the most popular
example.
The natural reference class of codes (experts) in this case
is the set of M -level scalar quantizers
Q = {Q : [0, 1] → {c1 , . . . , cM }, {c1 , . . . , cM } ⊂ [0, 1]} .
The relative loss with respect to the reference class Q is known
in this context as the distortion redundancy. For the squared
error distortion, the best randomized coding methods [12],
with linear computational complexity with respect √ the set
to
Q, yield a distortion redundancy of order O(n−1/4 ln n).

5

