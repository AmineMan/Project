Title:          CandFtransformCR1.dvi
Creator:        dvips(k) 5.96 Copyright 2007 Radical Eye Software
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Thu May 17 20:33:43 2012
ModDate:        Tue Jun 19 12:56:38 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      595 x 842 pts (A4)
File size:      393062 bytes
Optimized:      no
PDF version:    1.7
ISIT'2012 1569566191

The Compute-and-Forward Transform
Or Ordentlich

Uri Erez

Bobak Nazer

Tel Aviv University
ordent@eng.tau.ac.il

Tel Aviv University
uri@eng.tau.ac.il

Boston University
bobak@bu.edu

Abstract—We derive an achievable rate region for the Gaussian
K-user multiple-access channel (MAC) where all users transmit
codewords from a chain of nested lattices. For any set of channel
coefﬁcients, this rate region contains points within a constant gap
from the sum capacity boundary of the MAC. The main tool
used is the recently proposed compute-and-forward framework.
A new transformation of a MAC to a modulo-lattice multipleinput multiple-output (MIMO) channel is introduced based on
this framework. Speciﬁcally, from one noisy linear combination of
the transmitted signals the receiver attempts to decode K linearly
independent equations with integer-valued coefﬁcients. While the
individual rates at which these equations can be decoded are
highly sensitive to the exact channel gains, their sum is always
within a constant gap from the sum capacity boundary of the
MAC. The transformation is then utilized for establishing the
desired rate region.

I. I NTRODUCTION
Nested lattice codes can be used to approach the capacity of
the Gaussian point-to-point channel [1] as well as any point on
the capacity region of the Gaussian broadcast channel [2]. It
seems natural to expect that they can be used to approach
the sum capacity of the Gaussian multiple-access channel
(MAC) as well. However, in many scenarios (e.g., interference
alignment on the signal scale [3]–[5]), we may require that the
users select their codewords from a chain of nested lattice
codebooks. In this case, the shared lattice structure of the
codebooks introduces a major difﬁculty: the lattice codewords
corresponding to several unique message tuples may sum up
to the same lattice codeword, making it impossible for the
receiver to distinguish these messages tuples from one another
by simply decoding their sum.
The usual approach, joint typicality decoding, has to date
eluded a full analysis, primarily due to the difﬁculty mentioned
above. Recent work has developed some bounds on joint
decoding for the two-user Gaussian MAC with symmetric
rates [6] but the general problem remains open. Of course,
one can operate near the sum capacity using either timesharing and rate-splitting [7]. However, in the context of
interference alignment, these techniques do not sufﬁce as the
demands of each receiver may require very different time or
power allocations, which cannot be met simultaneously at the
transmitters. In this paper, we develop a new lattice-based
multiple-access scheme, that we dub the compute-and-forward
This work was supported in part by the Binational Science Foundation
under Grant 2008455, a fellowship from The Yitzhak and Chaya Weinstein
Research Institute for Signal Processing at Tel Aviv University and the Feder
Family Award.

1

transform, due to its close connection to the original computeand-forward scheme for relay networks [8]. This technique can
either be viewed as a building block for interference alignment
for static channels or, more generally, as an approximately sum
rate optimal multiple-access scheme that requires only a single
layer of codewords.
In a relay network, the basic idea underlying compute-andforward is that each relay should decode an integer combination of the transmitted lattice points. The effective signal-tonoise ratio (SNR) is determined by how closely the integer
coefﬁcients match the channel coefﬁcients. For the multipleaccess setting with K users, the receiver should instead decode
K linearly independent equations of the transmitted lattice
points. Then, these equations can be solved for the lattice
points transmitted by each user. This approach is connected
to the integer-forcing receiver recently proposed for multipleantenna point-to-point channels [9]. A striking phenomenon
that, to the best of our knowledge, has gone unnoticed is that
while the computation rate for each of the K equations is
very sensitive to the exact channel gains, the sum of the rates
is equal to the sum-capacity of the MAC up to a constant gap,
independent of the channel gains and the SNR (see Figure 1).
To achieve this sum rate, our scheme associates each of the
computation rates to a speciﬁc transmitter and decodes the
equations using a form of successive interference cancellation
tailored to the modulo-lattice structure. Below, we develop
the compute-and-forward transform within the context of a
Gaussian MAC. Due to space limitations proofs are omitted
and the reader is referred to [10] for the full details.
II. P RELIMINARIES
In this section we give some basic deﬁnitions and results
that will be used in the sequel.
A. K-user Gaussian MAC
Consider the K-user Gaussian MAC
K

y=

hk xk + z,

(1)

k=1

where h = [h1 · · · hK ]T ∈ RK is the vector of channel gains,
xk ∈ Rn , k = 1, · · · , K are the channel inputs, z ∈ Rn is
additive white Gaussian noise (AWGN) with zero mean and
unit variance and y ∈ Rn is the channel’s output. Without
loss of generality we assume all K users are subject to the

Λ ⊆ ΛK ⊆ · · · ⊆ Λ1 . From these lattices, we construct K
codebooks, one for each user. Speciﬁcally, user k is allocated
the codebook Lk = Λθ(k) ∩ V, where V is the Voronoi region
of Λ and the function θ(k) : {1, . . . , K} → {1, . . . , K} maps
between users and lattices. The rate of each codebook Lk is
Rk = 1/n log |Λθ(k) ∩ V|.
User k encodes its message onto a lattice point from its
codebook, tk ∈ Lk . Each user also has a random2 dither vector
dk which is generated independently and uniformly over V.
These dithers are made available to the decoder. The signal
transmitted by user k is

Normalized Computation Rate

1.4
First Equation
Second Equation
Sum

1.2
1
0.8
0.6
0.4
0.2

xk = [tk − dk ] mod Λ.

0
0

0.2

0.4

0.6

0.8

C. Compute-and-Forward

1

h
Fig. 1. Highest, second highest, and sum of the two highest computation
rates vs. h for the channel y = x1 + hx2 + z at SNR = 40dB. All rates
are normalized by the multiple-access sum capacity 1/2 log(1 + h 2 SNR).

same power constraint1 xk 2 ≤ nSNR, k = 1, . . . , K. The
capacity region of the channel (1) is known (see e.g., [11]) to
be the set of all rate tuples (R1 , . . . , RK ) satisfying
Rk <
k∈S

1
log 1 + SNR
2

|hk |2

(2)

k∈S

K

s = βy +

for all subsets S ⊆ {1, . . . , K}. The achievability part
of the capacity theorem is established using i.i.d. Gaussian
codebooks for all users. Motivated by lattice interference
alignment, we are interested in establishing the achievability
of certain rate tuples under the constraint that the codebooks
used by the K users form a chain of nested lattice codes.
B. Nested Lattice Codes
We employ the nested lattice framework originally proposed
in [1]. A lattice Λ is a discrete subgroup of Rn which is closed
under reﬂection and real addition. Formally, for any t1 , t2 ∈ Λ,
we have that −t1 , −t2 ∈ Λ and t1 + t2 ∈ Λ. Note that by
deﬁnition the zero vector is always a member of the lattice.
Any lattice Λ in Rn is spanned by some n × n matrix G such
that Λ = {t = Gq : q ∈ Zn }. We say that a lattice is full-rank
if its spanning matrix G is full rank.
We denote the nearest neighbor quantizer associated with
the lattice Λ by QΛ (·) and the Voronoi region by V. The
modulo operation returns the quantization error w.r.t. the
lattice, [x] mod Λ = x − QΛ (x), and satisﬁes the distributive
law,
[a[x] mod Λ + b[y] mod Λ] mod Λ = [ax + by] mod Λ,
for all a, b ∈ Z.
A lattice Λ is said to be nested in Λ1 if Λ ⊆ Λ1 . Our
scheme utilizes a chain of K + 1 nested lattices satisfying
1 As

Our objective is to communicate over the MAC using
the compute-and-forward scheme from [8]. To this aim, the
receiver ﬁrst decodes a set of K lattice equations with linearly
independent coefﬁcient vectors. Afterwards, it solves this
set of equations for the transmitted lattice points. Assume
the receiver is interested in decoding the lattice equation
K
v =
k=1 ak tk mod Λ with coefﬁcient vector a =
[a1 · · · aK ]T ∈ ZK . Following the scheme of [8], the receiver
scales the observation y by a factor β, removes the dithers,
and reduces modulo Λ to get

otherwise the different powers can be absorbed into the channel gains.

2

ak dk mod Λ = [v + zeff (h, a, β)] mod Λ ,
k=1

where
K

zeff (h, a, β) =

(βhk − ak )xk + βz

(3)

k=1

is effective noise. From [8], we have that zeff (h, a, β) is
statistically independent of v and its effective variance3 is
2
σeff (h, a, β) = βh − a

2

· SNR + β 2 .

(4)

Let θ∗ = mink:ak =0 θ(k) be the index of the densest lattice
participating in the lattice equation v. The receiver produces
an estimate for v by applying to s the nearest neighbor lattice
quantizer w.r.t. Λθ∗ ,
ˆ
v = [QΛθ∗ (s)] mod Λ.

(5)

Let Vθ∗ be the Voronoi region of Λθ∗ , and deﬁne the error
probability
Pe = Pr (ˆ = v) ≤ Pr (zeff (h, a, β) ∈ Vθ∗ ) .
v
/

(6)

The next theorem summarizes and reformulates relevant results from Sections IV.C, IV.D, and V.A of [8].
Theorem 1: For any ǫ > 0 and n large enough there exists
a chain of nested lattices Λ ⊆ ΛK ⊆ · · · ⊆ Λ1 forming the
2 It can be shown that these random dithers can be replaced with deterministic ones, meaning that no common randomness is required.
3 Deﬁned as 1/nE z
2
eff .

set of codebooks L1 , . . . , LK having rates R1 , . . . , RK and
satisfying the power constraint such that:
(a) For all channel vectors h ∈ RK and coefﬁcient vectors
a ∈ ZK , the average error probability in decoding the
K
lattice equation v =
k=1 ak tk mod Λ of transmitted
lattice points tk ∈ Lk can be made smaller than ǫ so long
as the message rates do not exceed the computation rates,
Rk < Rcomp (h, a, β)

1
log
2

SNR
2
σeff (h, a, β)

,

(7)

for all k such that ak = 0 and some β ∈ R.
(b) The codebooks L1 , . . . , LK are isomorphic to some set
of linear codebooks C1 , . . . , CK over the ﬁnite ﬁeld Zp ,
where p is a large prime number.
(c) For the same p, the equation [p · t] mod Λ = 0 holds
∀t ∈ Λk , k = 1, . . . , K.
Corollary 1: Given K lattice equations V = [v1 · · · vK ]
with coefﬁcient vectors A = [a1 · · · aK ]T , the lattice points
t1 , . . . , tK can be recovered if [A] mod p is full rank over
Zp .
It follows from Theorem 1(a) that in order to maximize the
computation rate Rcomp (h, a, β) for a given coefﬁcient vector,
2
one has to minimize σeff (h, a, β) over β. This minimization
is performed in [8, Theorem 2] and yields (see [10])
2
σeff (h, a)

2
min σeff (h, a, β)
β∈R

=

SNR−1 IK×K + hhT

−1/2

2

a

,

(8)

Accordingly, we deﬁne
Rcomp (h, a)

max Rcomp (h, a, β) =
β∈R

1
log
2

SNR
2
σeff (h, a)

.

The following deﬁnition identiﬁes the K linearly independent
coefﬁcient vectors which yield the highest computation rates.
Deﬁnition 1: We say that an ordered set of linearly independent integer coefﬁcient vectors {a1 , . . . , aK } with corresponding computation rates Rcomp,k Rcomp (h, ak ) is optimal
if Rcomp,1 ≥ · · · ≥ Rcomp,K and for any k = 1, . . . , K and any
˜
set of integer coefﬁcient vectors {˜1 , . . . , ak } of rank k
a
˜
min Rcomp (h, aℓ ) ≤ Rcomp,k .

ℓ=1,...,k

(9)

III. M ULTIPLE -ACCESS VIA C OMPUTE - AND -F ORWARD
This section introduces a new coding technique for reliable
communication over the K-user Gaussian multiple-access
channel. This technique is based on the receiver decoding K
linearly independent equations of the transmitted codewords,
and then solving them for obtaining the messages transmitted
by each user. We begin this section with a high-level overview
of the scheme, which is illustrated in Figures 2 and 3.
Each user k maps its message wk to a lattice point tk
in its codebook Lk and transmits a dithered version of it.
The K lattice codebooks utilized by the different users form
a chain of nested lattices. Assume for now that the users

3

are ordered with descending rates R1 ≥ R2 ≥ · · · ≥ RK , i.e.,
θ(k) = k for k = 1, . . . , K. The receiver, which sees a noisy
real-valued linear combination of the transmitted codewords,
begins by decoding the integer-valued linear combination
v1 = [ a1m tm ] mod Λ which yields the highest computation rate Rcomp,1 . Using the compute-and-forward framework,
this is possible if R1 < Rcomp,1 . Then, it proceeds to decode
the equation v2 = [ a2m tm ] mod Λ which yields the second
highest computation rate Rcomp,2 . In general, t1 participates in
this equation and the condition for correct decoding of v2 is
therefore R1 < Rcomp,2 . Nevertheless, this condition can be
relaxed using the ﬁrst equation v1 that was already decoded.
Speciﬁcally, after appropriate scaling of the channel’s output
and dithers removal, the receiver has a noisy observation
s2 = [v2 + zeff (h, a2 )] mod Λ
of the desired equation v2 . If t1 participates in v1 , it
is possible to cancel out t1 from the second equation
by adding a scaled version of v1 to s2 . Namely, the receiver adds r21 v1 to s2 , where r21 is an integer chosen such that [(a11 + r21 a21 )] mod p = 0, which assures
[(a11 + r21 a21 )t1 ] mod Λ = 0 for any t1 ∈ L1 . After
reducing modΛ this yields
sSI = [v2 + r21 v1 + zeff (h, a2 )] mod Λ
2
= [˜2 + zeff (h, a2 )] mod Λ,
v
where t1 does not participate in v2 . Since the effective noise
˜
zeff (h, a2 ) is unchanged by this process, the receiver can
decode v2 as long as R2 < Rcomp,2 . Now, the receiver can get
˜
v2 by subtracting r21 v1 from v2 and reducing modΛ.4 The
˜
receiver decodes the remaining equations in a similar manner,
i.e., before decoding the kth equation vk with computation
rate Rcomp,k the receiver adds to
sk = [vk + zeff (h, ak )] mod Λ
k−1
an integer-valued linear combination
ℓ=1 rkℓ vℓ mod Λ of
the lattice equations that were already decoded. The coefﬁcients in the linear combination are chosen such that the effect
of t1 , . . . , tk−1 is canceled out from vk . Assuming that such
coefﬁcients {rk1 , . . . , rk,k−1 } exist the receiver can decode
k−1
vk = vk + ℓ=1 rkℓ vℓ mod Λ as long as Rk < Rcomp,k .
˜

In [10], we show that for any set of K linearly independent
coefﬁcient vectors {a1 , . . . , aK } there indeed always exist
integer-valued coefﬁcients {rij } such that in each kth decoding step the receiver can cancel out k−1 lattice points from the
desired equation vk , using the previously decoded equations
{v1 , . . . , vk−1 }. The procedure for ﬁnding these coefﬁcients
is reminiscent to the Gaussian elimination procedure of a
full rank matrix. One of the basic operations in Gaussian
4 The operation of extracting v from v is in fact not necessary as the
˜2
2
receiver is only interested in decoding any set of K linearly independent
equations. We describe this step only for facilitating the exposition of the
scheme.

−d1
w1

L1

t1

a1m dm
mod Λ

x1

−d2
w2

L2

t2

.
.
.
wK

LK

mod Λ

−dK
tK

y

h2

v1
ˆ

mod Λ

r21

β2

aKm dm

mod Λ

.
.
.
rKm vm −
ˆ

xK

mod Λ

−r21
QΛ2

βK

hK

.
.
.
mod Λ

Fig. 2.

a2m dm

z
x2

QΛ1

β1

h1

v2
ˆ
A

.
.
.
rKm vm
ˆ

QΛK

mod Λ

mod Λ

−1

ˆ1
t

ˆ2
t

.
.
.
vK
ˆ

mod Λ

L−1
1

w1
ˆ

L−1
2

w2
ˆ

.
.
.
ˆK
t

L−1
K

wK
ˆ

System diagram of the nested lattice encoding and decoding operations employed as part of the compute-and-forward transform.

zeff (h, a1 , β1 )
w1

L1

t1

mod Λ

v1

QΛ1
zeff (h, a2 , β2 )

w2

L2

t2
A

mod Λ

v2

.
.
.
wK

tK

Fig. 3.

mod Λ

r21
.
.
.
rKm vm −
ˆ

vK

v1
ˆ

mod Λ

−r21
QΛ2

zeff (h, aK , βK )

LK

mod Λ

QΛK

mod Λ

v2
ˆ
−1

A

.
.
.
rKm vm
ˆ
mod Λ

mod Λ

ˆ1
t

ˆ2
t

L−1
1

w1
ˆ

L−1
2

w2
ˆ

.
.
.
vK
ˆ

mod Λ

.
.
.
ˆK
t

L−1
K

wK
ˆ

Effective MIMO channel induced by the compute-and-forward transform of a Gaussian multiple-access channel.

elimination is row switching. In our considerations, this would
correspond to using an equation that was not decoded yet
for eliminating lattice points from another equation. Since our
successive cancelation procedure only uses decoded equations,
this is not possible. Therefore, a major difference between
our procedure for ﬁnding a good set of coefﬁcients {rij } and
Gaussian elimination is that row switching is not permitted in
our case. This incurs a constraint on the order at which we cancel out users from equations. Nevertheless, there always exists
at least one order of successive cancelation that is possible. In
other words, we can always cancel out the effect of k −1 users
from vk using the decoded equation {v1 , . . . , vk−1 }, but we
cannot always control which of the K users to cancel. As a
result, there always exists at least one permutation vector π
such that all K equations can be decoded as long as
Rπ(k) < Rcomp,k , k = 1, . . . , K.

(10)

It follows that a sum rate of K Rcomp,k is achievable over
k=1
the K-user MAC with our scheme where all users are using
nested lattice codebooks. As we shall see, this sum-rate is
within a constant gap, smaller than K/2 log(K) bits, from the
sum-capacity of the MAC, regardless of the channel gains and
the SNR.

4

A. The Compute-and-Forward Transform
The next deﬁnition introduces the compute-and-forward
transform of a multiple-access channel. This transform converts the output of a MAC into a set of K modulo Λ
channels with lattice equations corrupted by effective noises.
The coefﬁcient vectors of these equations are full rank.
Deﬁnition 2: Let {a1 , . . . , aK } be a set of optimal integer
coefﬁcient vectors (see Deﬁnition 1), β1 , . . . , βK the corresponding optimal scaling factors, and Rcomp,1 ≥ · · · ≥
Rcomp,K the corresponding optimal computation rates. We
deﬁne the compute-and-forward transform of the MAC with
nested lattice codes as




β1 y + K a1k dk mod Λ
s1
k=1


 .  

.
.
S= . =

.
.


sK
βK y + K aKk dk mod Λ
k=1
 


t1
  . 

= A  .  + Zeff  mod Λ,
(11)
.
tK

where we have written the channel output y, dithers dk , and
lattice codewords tk as length-n row vectors. We also have

T
T
that A = [a1 · · · aK ]T and Zeff = [zT
eff,1 · · · zeff,K ] . Note
that the transform is not unique.
The next theorem shows that the sum of the optimal
computation rates is equal to the sum-capacity of the original
MAC up to a constant gap.
Theorem 2: The sum of optimal computation rates is lower
bounded by
K

Rcomp,k ≥
k=1

1
K
log 1 + h 2 SNR −
log(K) .
2
2

(12)

Theorem 2 guarantees that the sum of the computation rates
is close to the sum capacity of the MAC. However, the theorem
does not tell us how the sum rate is divided between the K
rates. As the next theorem shows, in a degrees-of-freedom
(DoF) sense, the sum rate is split approximately equally
between all K rates for almost every channel realization.
Theorem 3: For almost every h ∈ RK the number of DoF
offered by any of the K optimal computation rates is
dcomp,k =

lim
SNR→∞ 1
2

Rcomp,k
1
=
.
K
log(1 + SNR)

(13)

B. Multiple-Access Sum Capacity to within a Constant Gap
In order to formally characterize the achievable rate region
of the compute-and-forward transform over a MAC, we will
need the following deﬁnition which identiﬁes the orders for
which successive cancelation can be performed.
Deﬁnition 3: For a full rank K × K matrix A with
integer-valued entries we deﬁne the pseudo-triangularization
process, which transforms the matrix A to a matrix
˜
A which is upper triangular up to column permutation
π = [π(1) π(2) · · · π(K)]. This is accomplished by leftmultiplying A by a lower triangular matrix L with unit
˜
diagonal, such that A = LA is upper triangular up to column
permutation π. Although the matrix A is integer valued, the
˜
matrices L and A need not necessarily be integer valued.
Note that the pseudo-triangularization process is reminiscent
of Gaussian elimination except that row switching and row
multiplication are prohibited.
Example 1: The 2 × 2 matrix
A=

2
3

1
1

can be pseudo-triangularized with two different permutation
vectors
˜
A=

1
3
−2

0
1

·A=

2 1
0 −1
2

, π = [1 2],

or
˜
A=

1 0
−1 1

·A =

2 1
1 0

, π = [2 1].

Any full rank matrix can be triangularized using the Gaussian
elimination process, and therefore any full rank matrix can be
pseudo-triangularized with at least one permutation vector π.

5

In particular, since for any MAC the integer-valued matrix A
from the compute-and-forward transform is full rank, it can
always be pseudo-triangularized with at least one permutation
vector π.
Theorem 4: Consider the MAC (1). For any ǫ > 0 and n
large enough there exists a chain of nested lattices Λ ⊆ ΛK ⊆
· · · ⊆ Λ1 forming the set of codebooks L1 , . . . , LK with rates
R1 , . . . , RK such that for all h ∈ RK , if:
1) each user k encodes its message using the codebook Lk ,
2) the integer-valued matrix from the compute-and-forward
transform of the MAC (1) can be pseudo-triangularized
with the permutation vector π, and the optimal computation rates are Rcomp,1 ≥ · · · ≥ Rcomp,K ,
3) all rates R1 , . . . , RK satisfy
Rk < Rcomp,π−1 (k) , for k = 1, . . . , K

(14)

−1

where π is the inverse permutation vector of π,
then all messages can be decoded with error probability
smaller than ǫ.
Combining Theorems 2, 3 and 4 gives the following theorems.
Theorem 5: The sum rate achieved by the compute-andforward transform has a gap of no more than K/2 log K bits
from the sum capacity of the MAC.
Theorem 6: The DoF attained by each user in the K-user
MAC under the compute-and-forward transform is 1/K for
almost every h ∈ RK .
R EFERENCES
[1] U. Erez and R. Zamir, “Achieving 1 log(1+ SNR) on the AWGN channel
2
with lattice encoding and decoding,” IEEE Trans. Information Theory,
vol. 50, no. 10, pp. 2293–2314, Oct. 2004.
[2] R. Zamir, S. Shamai (Shitz), and U. Erez, “Nested linear/lattice codes for
structured multiterminal binning,” IEEE Trans. on Information Theory,
vol. 48, no. 6, pp. 1250–1276, June 2002.
[3] G. Bresler, A. Parekh, and D. Tse, “The approximate capacity of the
many-to-one and one-to-many Gaussian interference channels,” IEEE
Trans. on Information Theory, vol. 56, no. 9, pp. 4566–4592, Sep. 2010.
[4] S. Sridharan, A. Jafarian, S. Vishwanath, and S. A. Jafar, “Capacity of
symmetric K-user Gaussian very strong interference channels,” in Proc.
of IEEE GLOBECOM, New Orleans, Louisiana, Dec. 2008, pp. 1–5.
[5] A. S. Motahari, S. O. Gharan, M. Maddah-Ali, and A. K. Khandani, “Real interference alignment: Exploiting the potential of single
antenna systems,” IEEE Trans. Information Theory, Submitted 2009,
http://arxiv.org/abs/0908.2282.
[6] O. Ordentlich and U. Erez, “Interference alignment at ﬁnite SNR for
time-invariant channels,” 2011, http://arxiv.org/abs/1104.5456.
[7] B. Rimoldi and R. Urbanke, “A rate-splitting approach to the Gaussian
multiple-access channel,” IEEE Trans. on Information Theory, vol. 42,
no. 2, pp. 364–375, Mar. 1996.
[8] B. Nazer and M. Gastpar, “Compute-and-forward: Harnessing interference through structured codes,” IEEE Trans. Information Theory,
vol. 57, no. 10, pp. 6463–6486, Oct. 2011.
[9] J. Zhan, B. Nazer, U. Erez, and M. Gastpar, “Integer-forcing linear
receivers,” IEEE Trans. Information Theory, Submitted Jan. 2012,
http://arxiv.org/abs/1003.5966/.
[10] O. Ordentlich, U. Erez, and B. Nazer, “The approximate sum capacity
of the symmetric Gaussian K-user interference channel,” IEEE Transactions on Information Theory, Submitted May 2012, available online.
[11] T. M. Cover and J. A. Thomas, Elements of Information Theory. Wiley,
1991.

