Title:          Microsoft Word - 2- Rev-Final-ISIT 2012
Author:         Pooya
Creator:        PrimoPDF http://www.primopdf.com/
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Sat May 19 07:13:04 2012
ModDate:        Sat May 19 07:13:04 2012
Tagged:         no
Pages:          3
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      281825 bytes
Optimized:      no
PDF version:    1.7
ISIT'2012 1569566433

Application of Information-Type Divergences to
Constructing Multiple-priors and Variational
Preferences
A. Ahmadi-Javid
Department of Industrial Engineering, Amirkabir University of Technology (Tehran Polytechnic), Tehran, Iran
ahmadi_javid@aut.ac.ir

respectively consider classes of variational and multiple-priors
preferences incorporating weighted Csiszar’s divergences.
Section 5 studies a wide class that includes all of the
preferences presented in the two preceding sections. Section 6
concludes the paper.

Abstract— This paper studies broad classes of variational and
multiple-priors preferences incorporating divergence measures
that are generalizations of the relative entropy. It is shown that
the proposed information-type preferences can be calculated
through convex optimization problems with a small number of
real variables.
Keywords- Information-type divergnecs, Generalized relative
entropy, Kullback-Leibler divergence, Variational preferences,
Multiple-priors preferences, Decision thoery under ambiguty

I.

II.

NOTATION AND MATHEMATICAL FORMULATION

Let (Ω, F, P ) be a probability space where Ω is a set of all
simple events, F is a σ -algebra of subsets of Ω , and P is a
reference probability measure on F. Suppose that ∆ is the set
of all finitely additive probability measures on (Ω,F ).
Moreover, suppose that L is the set of all Borel measurable
functions (random variables) X : Ω → ℜ , Χ ⊆ L is a
subspace including all real numbers, and L∞ is the set of all
bounded Borel measurable functions.
We define the utility function u : Χ → ℜ as a measurable
function, which is usually assumed to be non-decreasing and
concave. The expected utility preference, multiple-priors (or
maxmin expected utility), multiplier and variational
preferences are respectively defined as follows:
EUPu ( X ) = E P (u ( X ))
MAPu , ℑ ( X ) = inf {E Q (u ( X ))}

INTRODUCTION

The notion of ambiguity, which was first raised in the
decision-theory literature by Elsberg in 1961 [6], is the main
motivation for going beyond the traditional expected utility
preferences that were axiomatized by von Neumann and
Morgenstern [13]. Hence, in last two decades, various
preferences that try to model ambiguity have been introduced
and axiomatized. Gilboa and Schmeidler [7] proposed
multiple-priors (or maxmin expected utility) preferences.
Hansen and Sargent [8] studied multiplier preferences that
have been recently axiomatized by Strzalecki [15].
Maccheroni et al. [11] proposed and axiomatized a wider class
of preferences, called variational preferences, that includes as
special cases both multiplier and mean-variance preferences
introduced by Markowitz [12], on their domains of
monotonicity. Chateauneuf and Faro [5] introduced
homothetic preferences. Cerreia-Vioglio et al. [4] studied the
class of uncertainty-averse preferences that includes all the
above-listed preferences as special cases.
Ahmadi-Javid [1,2,3] shows how one can use informationtype divergences to construct a coherent risk measure, which
is an important notion in the mathematical-finance literature.
In this paper, we follow on this idea to establish informationtype preferences under ambiguity, which are highly important
in the economic literature. Here, we explore three broad
classes of multiple-priors and variational preferences that are
built by exploiting generalizations of the relative entropy. Our
analysis shows that all preferences in these three classes can
be computed by solving convex optimization problems with
only one or two real variables.
The paper is organized as follows. Notation and
mathematical formulation are in Section 2. Sections 3 and 4

Q∈ℑ

MPu , θ ( X ) = infP{E Q (u ( X )) + θ DKL (Q P ) }
Q <<
VPu ,c ( X ) = inf {E Q (u ( X )) + c(Q ) }
Q∈∆

where θ is a positive constant, ℑ is a convex subset of ∆ ,
c : ∆ → [0, ∞)
is
a
convex
function,
and

dQ  dQ 
 ln
 dP is the relative entropy of Q
dP  dP 
with respect to P , or the Kullback–Leibler divergence from
Q to P .
The generalized relative entropy of Q with respect to P ,
DKL (Q P ) := ∫

denoted by H g (P, Q ) , is an information-type divergence
measure, called (Csiszar’s) g-divergence, from Q to P :

1

which can be straightforwardly reformulated to a convex
optimization problem.
In the next corollary, we investigate the divergence
preference associated with the weighted relative entropy. For
this case, the above optimization problem can be solved
explicitly.

 dQ 
H g (P, Q ) := ∫ g 
 dP ,
 dP 
where g is a convex function with g (1) = 0 . This quantity is
an important non-symmetric (or directed) divergence measure
(see [10] for more details). Note that H g (P, Q ) ≥ 0 , and

H g (P, Q ) = 0 if Q = P . For g (x ) = x ln x, one obtains the
relative entropy of Q with respect to P .
Following [11], the weighted g-divergence H g ,w (P, Q ) ,

Corollary 2. Suppose that

 x ln x x > 0
g (x ) = 
 0 x = 0.

which is a generalization of the g-divergence H g (P, Q ) , may
be defined as follows:
 dQ 
H g ,w (P, Q ) := w g 
 dP
 dP 
where w is a density function over Ω with respect to the
reference probability measure P . See [11] for more comments
on this type of divergence.

Then, for X ∈L ∞ ,

(

DPu ,g ,w,θ ( X ) = −θ ln E P we −θ

−1

u( X )

).

∫

III.

IV.

CONSTRAINED DIVERGENCE PREFERENCES

{

}

Defining ℑ = Q << P : H g , w (P, Q ) ≤ β with β ≥ 0 , we can
introduce the following preference, called constrained
divergence preference:
{E Q (u ( X ))}.
CDPu ,g ,w,β ( X ) := MAPu ,ℑ ( X ) =
inf

DIVERGENCE PREFERENCES

Q<< P:H g , w ( P ,Q )≤ β

In this section, we study the class of the divergence
preferences
DPu ,g ,w,θ ( X ) := VPu ,c ( X ) = inf {E Q (u ( X )) + θ H g , w (P, Q ) }

We are again able to represent this class via an
optimization problem with a small number of real decision
variables.

Q<< P

where c(Q ) = θ H g , w (P, Q ) with θ ≥ 0 . This class is a subclass
of variational preferences that was recently considered in [11];
however, no result was given on how such preferences can be
computed practically. In the following, we provide a useful
representation for this class, which can be used to compute
such divergence preferences practically.

Theorem 3. Let g : ℜ → ]− ∞, ∞] be a closed convex function

with g (1) = 0 , u be a bounded measurable function, w be a
density function over Ω with respect to the reference
probability measure P , and let β ≥ 0 . Then, for X ∈L ∞ ,



 u( X )
  

DAPu ,g ,w,β ( X ) = sup t  µ − E P  w g *  −
− µ + β    .


t >0 , µ ∈ ℜ  
t

  



Proof. The proof follows from a strong Lagrangian-duality
theorem for the following optimization problem:
inf( ( )) { E P (Y u ( X )) }.
( )

Theorem 1. Let g : ℜ → ]− ∞, ∞] be a closed convex function

with g (1) = 0 , u be a bounded measurable function, w be a
density function over Ω with respect to the reference
probability measure P , and let θ > 0 . Then, for X ∈L ∞ ,

E Y =1,Y ≥0 ,E P w g Y ≤ β

DPu ,g ,w,θ ( X ) = sup{ µ − θ E P (w g * (− θ u( X ) − µ )) } ,

and the representation given in Theorem 1. See the proof of
Lemma 1.3 of [3] for a similar discussion.
□

−1

µ∈IR

where g * is the conjugate (the Legendre–Fenchel transform)
of g .
Proof. This result can be proven by implementing a strong
Lagrangian duality theorem for the following optimization
problem, implied by holding a generalized Slater’s constraint
qualification [9] (a similar discussion is presented in the proof
of Lemma 1.3 of [3]),
inf { E P (Y u ( X )) + θ E P (w g (Y )) }
( )

By Theorem 3, one can see that the constrained divergence
preference DAPu ,g ,w,β ( X ) is the optimal value of the following
convex optimization problem:



 u( X ) + η
 

sup η − tE P  w g *  −
+ β   .


t >0 , η ∈ ℜ 
t

 



The constrained divergence associated with the weighted
relative entropy can simplified to the formula in the following
corollary.

E Y =1,Y ≥0

and applying the result [15, Theorem 14.60] that allows to
interchange integration and minimization.
□

Corollary 4. Suppose that

Theorem 1 suggests that the divergence preference
DPu ,g ,w,θ ( X ) be computed by solving the following onedimensional optimization problem:
sup{µ − θ E P (w g * (− θ −1u ( X ) − µ ))},

 x ln x x > 0
g (x ) = 
 0 x = 0.
Then, for X ∈L ∞ ,

µ∈IR

2

{

(

MAPu ,g ,w,β ( X ) = sup tβ + t ln E P wet
t <0

V.

−1

u( X )

)}.

representations along the same lines of this paper may be a
very important direction for future research. Also, studying the
following class of homothetic preferences, called divergence
homothetic preferences:
DHPu ,g ,d ,w,β ( X ) = Q<<P:H ( P ,Q )≤β {d (Q )E Q (u ( X ))}
inf

MIXED DIVERGENCE PREFERENCES

In this section, we consider the following broad class of
preferences, called mixed divergence preferences:
MDPu ,g ,h ,w,θ ,β ( X ) := Q<<P:H ( P ,Q )≤β {E Q (u ( X )) + θ H g , w (P, Q ) }
inf

g ,w

where d : ∆ → [0, ∞ ) , is another avenue of future research.

h ,w

where θ ≥ 0 and β ≥ 0 . One can see that this class is a
subclass of variational preferences; indeed,
MDPu ,g ,h,w,θ ,β ( X ) = VPu ,c ( X )
with
θ H g , w (P, Q ) Q << P, H h , w (P, Q ) ≤ β
c(Q ) = 
+∞
otherwise.

Note that we also have
DPu ,g ,w,θ ( X ) = MDPu ,g ,h,w,θ ,∞ ( X ) ,

REFERENCES
[1]

[2]

[3]

CDPu ,h ,w,β ( X ) = MDPu ,g ,h ,w, 0,β ( X ) ,
which shows that the class of mixed divergence preferences
includes both of the classes studied in Sections 3 and 4.
Fortunately, a useful presentation for this class can again be
provided as follows. Using this theorem, we can compute a
mixed divergence preference by solving a convex optimization
problem with two real variables.

[4]

[5]
[6]
[7]
[8]

Theorem 5. Let g , h : ℜ → ]− ∞, ∞] be closed convex

functions with g (1) = h(1) = 0 , u be a bounded measurable
function, w be a density function over Ω with respect to the
reference probability measure P , and let θ ≥ 0 and β ≥ 0 .

[10]

Then, for X ∈L ∞ ,

[11]

[9]


 
u( X )
 
MDPu ,g ,w ,θ ,β ( X ) = sup tµ − E P  w k  − θ −1
− µ + β   ,


t > 0 , µ ∈ℜ
t
 
 


[12]

where k ( x ) = (t h + θ g )* ( x ) = sinf x{t h * (t s1 ) + θ g * (θ s 2 )} .
+s =
−1

1

−1

[13]

2

Proof. The proof is similar to the one of Theorem 3.

□
[14]

VI.

CONCLUDING REMARKS

Our results show how information-type divergences can be
used to construct a vast class of interesting preferences that are
efficiently computable. Incorporating other types of
divergences, e.g. Bregman divergences, and developing

[15]

3

Ahmadi-Javid, A. (2011) An information–theoretic approach to
constructing coherent risk measures. In: Proceedings of IEEE
International Symposium on Information Theory, August 2011, St.
Petersburg, Russia, pp. 2125–2127.
Ahmadi-Javid, A. (2012) Entropic value-at-risk: A new coherent risk
measure. Journal of Optimization Theory and Applications, In Press,
DOI 10.1007/s10957-011-9968-2.
Ahmadi-Javid, A. (2012) Addendum to: Entropic value-at-risk: A new
coherent risk measure. Journal of Optimization Theory and
Applications, In Press, DOI: 10.1007/s10957-012-0014-9.
Cerreia-Vioglio, S., F. Maccheroni, F., Marinacci, and L. Montrucchio
(2011) Uncertainty averse preferences, Journal of Economic Theory,
146, 1275–1330.
Chateauneuf, A., and J.H. Faro (2009) Ambiguity through confidence
functions, Journal of Mathematical Economics, 45, 535–558.
Ellsberg, D. (1961) Risk, Ambiguity, and the Savage Axioms, Quarterly
Journal of Economics, 75, 643–669.
Gilboa, I., and D . Schmeidler (1989) Maxmin Expected Utility with a
Non-Unique Prior, Journal of Mathematical Economics, 18, 141-153.
Hansen, L. P., and T. J. Sargent (2001) Robust Control and Model
Uncertainty, American Economic Review, 91, 60–66.
Jeyakumar, V., and H. Wolkowicz, (1992) Generalizations of Slater’s
constraint qualification for infinite convex programs, Mathematical
Programming, Series B 57, 85–101.
Liese, F., and I., Vajda, Convex Statistical Distances. Teubner,
Leipzig, (1987).
Maccheroni, F., M. Marinacci, and A. Rustichini (2006) Ambiguity
Aversion, Robustness, and the Variational Representation of
Preferences, Econometrica, 74, 1447–1498.
Markowitz, H. M. (1952) Portfolio Selection, Journal of Finance, 7, 7791.
Neumann, J. von, and O. Morgenstern, Theory of Games and Economic
Behavior, Princeton University Press, NJ, (2nd edition, 1947, 3rd
edition, 1953).
Rockafellar, R. T., and R. J. B. Wets, Variational analysis.
Fundamental Principles of Mathematical Sciences, 317, SpringerVerlag, Berlin: (1998).
Strzalecki, T. (2011) Axiomatic Foundations of Multiplier Preferences,
Econometrica, 79, 47–73.

