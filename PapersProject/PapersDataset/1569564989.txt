Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Mon May  7 16:05:48 2012
ModDate:        Tue Jun 19 12:56:12 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      345560 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569564989
1

Universal communication over unknown vector
channels
Yuval Lomnitz, Meir Feder
Tel Aviv University, Dept. of EE-Systems
Email: {yuvall,meir}@eng.tau.ac.il

that these models focus on capacity, i.e. before knowing the
channel, one is required to ﬁnd a rate of reliable transmission
which can be guaranteed a-priori. Clearly, if the channel is
completely general, the compound/AVC capacity is zero, as
it is possible, for example, that a channel with zero capacity
will be selected. In both models mentioned, constraints on
the family of channels, or on the possible state sequences
need to be deﬁned, and these constraints do not seem suitable
for natural channels. In addition to this fundamental gap,
the models considered under the AVC and compound-FSC
frameworks are quite limited, in a way that does not seem
to capture the possible complexity of an unknown natural
channel. For example, most papers on AVC consider only
memoryless channels, and the compound-FSC is stationary.
Using feedback, the communication rate can be adapted, so
that one does not have to commit to a communication rate
a-priori. Several works by us and other authors considered the
gains from such adaptation [2][3][7][5]. The ﬁrst question to
ask is, how the target communication rate should be deﬁned?
The sought rate R(PY|X ) can be a function of the channel, but
should be universally attainable without prior knowledge of
the channel, and should have an operational meaning.
In a previous paper [4], the problem of determining such
a communication rate was addressed. In general, the Shannon
capacity [8] of the channel, C(PY|X ) is not attainable universally with feedback, when the channel is unknown. The
problem of determining a universally-achievable rate is similar
to the source coding problem of setting a compression rate
for an individual sequence. Following the spirit of the “ﬁnite
state compressibility” of Lempel and Ziv [9], we proposed to
set as a target, the best rate that can be reliably attained by
a system employing ﬁnite block encoding (successively) over
the inﬁnite channel. The supremum of these rates is termed the
Iterative-Finite-Block (IFB) capacity and denoted CIFB (PY|X ).
When the channel is stationary and ergodic, then the IFB
capacity equals the Shannon capacity. As in the universal
source coding problem, due to the richness of the model
family, there is a large gap between the performance that
can be attained universally and the performance that can be
attained without constraints, when knowing the speciﬁc model
(the Shannon capacity) and this gap requires limiting the
abilities of the reference system. This motivates considering
the IFB capacity as a goal.
It is easy to see that the IFB capacity is not universally
achievable for completely general models. The counter example in [4] is of a family consisting of only two binary

Abstract—Consider communication over a channel whose
probabilistic model is completely unknown vector-wise and is not
assumed to be stationary. Communication over such channels is
challenging because knowing the past does not indicate anything
about the future. The existence of reliable feedback and common
randomness is assumed. In a previous paper it was shown that
the Shannon capacity cannot be attained, in general, if the
channel is not known. An alternative notion of “capacity” was
deﬁned, as the maximum rate of reliable communication by any
block-coding system used over consecutive blocks. This rate was
shown to be achievable for the modulo-additive channel with an
individual, unknown noise sequence, and not achievable for some
channels with memory. In this paper this “capacity” is shown
to be achievable for general channel models possibly including
memory, as long as this memory fades with time. In other words,
there exists a system with feedback and common randomness
that, without knowledge of the channel, asymptotically performs
as well as any block-coding system, which may be designed
knowing the channel. For non-fading memory channels a weaker
type of “capacity” is shown to be achievable.

I. I NTRODUCTION
Consider communication over a channel which has a general
probabilistic structure. In other words, the inﬁnite length out∞
put Y1 depends on the inﬁnite length input X∞ through an
1
n
arbitrary vector-wise probability function PY|X (Y1 |X∞ ), n =
1
1, 2, . . ., which is unknown to the transmitter and the receiver.
Particular cases of such a channel include any unknown
functional relation between the input and output sequences, as
well as arbitrarily varying channels, compound channels [1]
and channels with an individual state sequence [2][3][4][5].
In the current paper, an attempt is made to keep the model as
general as possible, i.e. minimize any assumptions on PY|X ,
except for causality. Without feedback, communication over
such a channel is limited, as the communication rate, and the
codebook would have to be selected in advance. Therefore,
the existence of a reliable feedback link is assumed.
Two traditional models, which relate to particular cases of
the current problem, are the arbitrarily varying channel (AVC)
model [1] and the compound ﬁnite state channel (compoundFSC) model [6]. In the AVC model, the channel is assumed
to be controlled by a sequence of states which is arbitrary
and unknown to the transmitter and the receiver. In the compound channel model, the channel is assumed to be arbitrarily
selected from a family of possible channels. In both models,
the capacity is the maximum rate of reliable communication
that can be guaranteed. Both models do not give a satisfying
answer to the current problem: the fundamental reason is

1

2

channels, termed “password” channels, where the ﬁrst input
bit X1 determines whether the channel becomes “good” or
“bad” for eternity, and where the values of X1 matching each
state are opposite in the two channels. There is no way for the
universal system to correctly guess X1 with high probability.
The conclusion is that the IFB capacity is not universally
attainable for some channels with inﬁnite memory. On the
other hand, the IFB capacity was shown to be asymptotically
attainable for the class of modulo-additive channels with an
individual, unknown noise sequence. In this case, it was
further shown, that the IFB capacity is related to the ﬁnite
state compressibility of the noise sequence, and the scheme
attaining it uses the Lempel-Ziv source encoder [9] to generate
decoding metrics. The result in [4] relies crucially on two
properties of the modulo additive channel:

will not only enable reliable transmission, but will also keep
the channel in a favorable state, whereas the universal system
does not know the long term effects of certain input symbols
or distributions. An alternative formulation is proposed, where
the reference system is crippled, so that it cannot enjoy the
ability to shape the past: the encoder and decoder operate over
ﬁnite blocks, however the error probability is required to be
small in the worst case channel state (history) prior to each
block, and average over blocks. This models a situation where
the reference encoder and decoder are “thrown” each time into
a different location in time, where the past state might have
been arbitrary. It is not required to have good performance
in each of these events, but only on average. This alternative
reference system is termed “arbitrary-ﬁnite-block” (AFB) and
the same universal system is shown to asymptotically approach
the respective AFB capacity, without requiring that the channel
memory is fading. This reference class is less natural than the
IFB, yet it enables releasing constraints on the channel.
Note that there are several alternative deﬁnitions of a limited
reference class for the universal communication problem [4].
Most notably, Misra and Weissman [11] generalized the main
results of [4] to ﬁnite-state communication systems with
feedback. For the sake of simplicity the current paper focuses
on the basic model of reference systems using block coding.
Although the current result is purely theoretical, it supplies
motivation for using competitive universality in communication.

1) The channel is memoryless with respect to the input xi
(i.e. current behavior is not affected by previous values
of the input).
2) The capacity achieving input distribution is ﬁxed (uniform i.i.d.) regardless of the noise sequence.
To avoid these assumptions it is required to address the
memory of the channel and the setting of the communication
prior. The second limitation, raises the question, how the
input distribution should be adapted, if the channel changes
arbitrarily over time? This question was the center of [5],
where universal prediction methods were used to set the communication prior. The focus of that paper is on channels which
are memoryless in the input, and therefore can be deﬁned by an
n
unknown sequence of memoryless channels PY|X (Y1 |Xn ) =
1
n
i=1 Wi (Yi |Xi ). It is shown there that the capacity of the
n
1
time-averaged channel W (y|x) = n i=1 Wi (y|x) can be
universally attained using feedback and common randomness
without knowing {Wi }, and that this value is the maximum
rate that can be achieved universally and does not depend
on the order of the channels in the sequence. The notion of
universality used in [5] is different and weaker than the IFB
universality, since the rate is only compared with other rates
that could have been universally attained.
In the current paper, ideas from [4] and [5] are combined
to generalize the previous results. It is shown that the IFB capacity is asymptotically universally attainable for any channel
with a fading memory, i.e. where the effect of the channel
history on the far future is vanishing. In this sense, the two
assumptions used in the previous paper [4] are avoided as
much as possible, and the assumptions made on the channel
are signiﬁcantly minimized. The fading memory condition
includes as particular cases memoryless arbitrarily varying
channels as well as compound indecomposable ﬁnite state
channels [10]. Here, an example is given of a class of ﬁnite
state channels where the state is a non-homogenous Markov
chain, which satisfy the fading memory condition.
Considering channels where memory of the past is not
necessarily fading, it may still be possible to communicate
universally over the channel, if it is not maliciously designed
like the password channel described above. The advantage of
the IFB reference class which enables it to win over any universal system is its ability to determine such a codebook that

II. P ROBLEM SETTING , DEFINITIONS AND MAIN RESULT
A. Notation
Vectors are denoted by boldface letters. Sub-vectors are deﬁned by superscripts and subscripts: xi
[xj , xj+1 , . . . , xi ].
j
xi equals the empty string if i < j. The subscript is sometimes
j
removed when it equals 1, i.e. xi
xi . For a vector x,
1
[k]
(i−1)k+k
xi
x(i−1)k+1 denotes the i-th block of length k in the
vector. For brevity, vectors with similar ranges are sometimes
joined together, for example, the notation (xy)k is used instead
1
k
of xk y1 . Exponents and logs are base 2. Random variables are
1
distinguished from their sample values by capital letters.
B. Channel model
Let x and y be inﬁnite sequences denoting the input and
the output respectively, where each letter is chosen from the
alphabets X , Y respectively, xi ∈ X , yi ∈ Y. Throughout the
current paper the input and output alphabets are assumed to
be ﬁnite. A channel PY|X is deﬁned through the probabilistic
relations PY|X (yn |x∞ ) = Pr(Yn = yn |X∞ = x∞ ) for n =
1, 2, ...∞. A ﬁnite length output sequence is considered in
order to make the probability well deﬁned.
∞
Deﬁnition 1. The channel deﬁned by Pr(Y1n |X1 ) is termed
causal if for all n:
n
n
Pr(Y1 |X∞ ) = Pr(Y1 |Xn ).
1
1

(1)

All the deﬁnitions below (including IFB/AFB capacity)
pertain to causal channels. This characterization of a causal

2

3

m
?1

m
?2

m
?3

m
?4

m
?5

Encoder

n-L

Encoder

Encoder

Encoder

Encoder

n

X

???? ???? ???? ???? ????
???
??? ???
??? ???
??? ???
??? ???
???
t=1

t = 50

Channel

???? ???? ???? ???? ????
???
??? ???
??? ???
??? ???
??? ???
???
Y

Decoder

Decoder

Decoder

Decoder

Decoder

ˆ
?1
m

ˆ
?2
m

ˆ
?3
m

ˆ
?4
m

ˆ
?5
m

- Part on which probability is evaluated in (2)

Fig. 2. An illustration of iterative mapping used for the comparison class,
with b = 5, k = 10

- Condition is allowed to affect probability
- Conditioning weakly affects probability

Fig. 1.

An illustration of the fading memory condition (Deﬁnition 2).

and decoder D to b blocks over the channel PY|X is deﬁned
b
as Pe = 1 i=1 Pe (i). Pe (i) is the worst case per-block error
b
probability, deﬁned as:

channel is similar to the deﬁnition used by Han and Verd´ [8]
u
(and references therein).

Pe (i) =

n−L−1
m
Pr(Yn |X∞ , Y1
)
1

m
− Pn (Yn |X∞ )
n−L

where the L1 norm is calculated over
g(Y|·) 1
y |g(y|·)|

m
Yn ,

1

≤ h,

max
(i−1)k

(XY)1

Deﬁnition 2. The channel is termed a fading memory channel
if for any h > 0 there exists L and a sequence of causal
conditional vector distribution functions {Pn (·|·)}, such that
for all n and m ≥ n:

Pr

[k]
D(Yi )

(3)
=m

[k]
Xi

=

(i−1)k
E(m), (XY)1

,

where m ∼ U {1, . . . , M }.

(2)

Deﬁnition 6 (IFB/AFB achievability). A rate R is iteratedﬁnite-block (IFB) / arbitrary-ﬁnite-block (AFB) achievable
over the channel PY|X , if for any > 0 there exist k, b∗ > 0
such that for any b > b∗ there exist an encoder E and a decoder
D with block length k and rate R for which the average error
probability in iterative / arbitrary mapping (resp.) of E, D to
b blocks is at most .

and deﬁned by

The difference between the terms on the LHS of (2) is that
Pn does not include (XY)n−L−1 (see Fig.1), and thus the
1
fading memory condition asserts that the dependence of the
conditional distribution of future outputs, on the channel state
at the far past, decays.
The fading memory condition does not imply stationarity or
ergodicity. The memoryless arbitrary varying channel model
considered in [5] is fading memory, and so are the FSC [10,
§4.6] or compound-FSC models [6], if the underlying FSC
is indecomposable. An example of a non-homogeneous ﬁnite
state channel with fading memory is presented in the full
paper.

Deﬁnition 7 (IFB/AFB capacity). The IFB/AFB capacity of
the channel PY|X is the supremum of the set of IFB/AFB
achievable rates, and is denoted CIFB /CAFB (resp.).
Notice that by deﬁnition, the AFB error probability is at
least as large as the IFB error probability, and as a result, the
AFB capacity is smaller than, or equal to the IFB capacity.
D. Competitive Universality
In the following, the properties of the adaptive system with
feedback, and IFB/AFB-universality are deﬁned. A randomized rate-adaptive transmitter and receiver for block length
n with feedback are deﬁned as follows: the transmitter is
presented with a message expressed by an inﬁnite bit sequence, and following the reception of n symbols, the decoder
announces the achieved rate R, and decodes the ﬁrst nR
bits. An error means any of these bits differs from the bits
of the original message sequence. Both encoder and decoder
have access to a random variable S (the common randomness)
distributed over a chosen alphabet, and a causal feedback
link allows the transmitted symbols to depend on previously
sent feedback from the receiver. See formal deﬁnitions in our
previous paper [7].
The following deﬁnition states formally the notion of
IFB/AFB-universality for rate adaptive systems:

C. IFB and AFB capacity
Deﬁnition 3 (Reference encoder and decoder). A ﬁnite length
encoder E with block length k and a rate R is a mapping E :
{1, . . . , M } → X k from a set of M ≥ exp(kR) messages to a
set of input sequences X k . A respective ﬁnite length decoder
D is a mapping D : Y k → {1, . . . , M } from the set of output
sequences to the set of messages.
Deﬁnition 4 (IFB error probability). The average error probability in iterative mapping of the k length encoder E and
decoder D to b blocks over the channel PY|X is deﬁned as
follows: b messages m1 , . . . , mb are chosen as i.i.d. uniformly distributed random variables mi ∼ U {1, . . . , M }, i =
[k]
1, . . . , b. The channel input is set to Xi = E(mi ), i =
[k]
ˆ
1, . . . , b, and the decoded message is mi = D(Yi ) where Y
is the channel output. The iterative mapping is illustrated in
b
ˆ
Fig.2. The average error probability is Pe = 1 i=1 Pr(mi =
b
mi ).

Deﬁnition 8 (IFB/AFB universality). With respect to a set of
(θ)
channels {PY|X }, θ ∈ Θ (not necessarily ﬁnite or countable), a
rate-adaptive communication system (possibly using feedback
and common randomness) is called IFB/AFB universal if for

Deﬁnition 5 (AFB error probability). The average error
probability in arbitrary mapping of the k length encoder E

3

4

every channel in the family and any , δ > 0 there is n large
enough such that when the system is operated over n channel
uses, then in probability 1− , the message is correctly decoded
and the rate is at least CIFB (PY|X )−δ or CAFB (PY|X )−δ (resp.).

N1

Epoch 1

Theorem 1. For any
> 0 there exists a sequence of
adaptive rate systems over a block of size N with feedback
and common randomness, for growing values of N , such that
with a probability of at least 1 − the message is received
correctly with a rate of:
(4)

III. C OMMUNICATION SCHEME AND PROOF OUTLINE
A. The communication scheme
In [5], a communication scheme for adapting the prior over
an arbitrarily varying channel which is memoryless in the input
was described. Combining Theorem 3 and Lemma 9 of [5]
yields:
˜
Lemma 1. [Lemma 9 of [5]] For every ˜, δ > 0 there exists
∗
n and a constant c∆ , such that for any n ≥ n∗ there is an
adaptive rate system with feedback and common randomness,
n
such that for any channel Pr(Y1n |X1 ):
1) The probability of error is at most ˜
˜
2) The rate satisﬁes R ≥ C(W SUBJ ) − ∆C with probability
˜
at least 1 − δ
where
n

Pr(Yi = y|Xi = x, Xi−1 , Yi−1 ),

Epoch 2

Epoch 3

Epoch 4

q = 2m−1 = 8

let m = 1 · 2−m . The length of the m-th epoch, Nm , is
2
chosen such that:
1) It is equal to or larger than the value of n∗ given by
˜
Lemma 1 for the parameters ˜ = δ = m .
˜
2) The value of ∆C given by Lemma 1 for n = Nm is not
larger than ∆C (the chosen value).
3) If the end of the next epoch Nm+1 would occur beyond
symbol N , then the current epoch Nm is extended to
reach symbol N .
The second requirement makes sure that there is no more than
a constant loss from capacity per epoch, while the dimension
of the super-symbol of each epoch is growing, and therefore
˜
the loss per symbol tends to 0. The values of δ and ˜ chosen
per epoch, guarantee that the overall probability of error is
∞
1
and similarly the overall
not larger than
m=1 m = 2
probability that at any epoch the rate falls below the rate
declared in the lemma is at most 1 . This way the overall
2
probability of having an error or falling below the guaranteed
rate is at most . Note that the epoch durations Nm are ﬁxed
and do not depend on the message or received signal.
The scheme does not need to know the IFB/AFB block
length, rate and error probability, and the exact relation between L, h given by the fading memory condition. Its only
parameters are the input and output alphabets, the number of
symbols N , and .
The claim of Theorem 1, that any positive feedback rate is
sufﬁcient, simply follows from the fact [5] that this is true for
the scheme of Lemma 1.

This implies that the system is IFB universal over the set of
causal fading memory channels, and AFB universal over the
set of causal channels, according to Deﬁnition 8. While the
system does not depend on the channel, the convergence rate
AFB
IFB
of δN , δN does.

W SUBJ

N4

Fig. 3. An illustration of the division into epochs and super-symbols in the
universal scheme.

AFB
IFB
where δN −→ 0 for any causal channel, and δN −→ 0
N →∞
N →∞
for any causal fading memory channel. Furthermore, this can
be attained with any positive rate of the feedback link.

1
=
n

N3
super-symbols

E. The main result

IFB
AFB
RUNI [N ] ≥ max [CIFB − δN , CAFB − δN ] ,

N2

(5)

i=1

B. Proof outline

and
˜
∆C = c∆ ·

ln2 (n)
n

1
4

.

Following is the outline of the proof. The value Pr(Yi =
y|Xi = x, Xi−1 , Yi−1 ) appearing in the deﬁnition of W SUBJ
(5) is the probability of a certain output symbol to appear given
a certain input symbol at time i, where the history of the channel (XY)i−1 attains the speciﬁc value that occurred during the
universal system’s operation. Pr(Yi = y|Xi = x, Xi−1 , Yi−1 )
is a random variable and depends both on the channel and on
the universal communication system behavior. As a result, the
rate WSUBJ guaranteed by Lemma 1 is also a random variable
and depends on the joint input-output distribution induced by
the universal communication scheme.
The baseline for comparison with the reference system is the
“pessimistic average channel capacity”, obtained by replacing
the history (XY)i−1 by an arbitrary state, and taking the
worst-case state sequence (worst case history), i.e. the one

(6)

The universal communication scheme for attaining the
claims of Theorem 1 is as follows. The inﬁnite time is divided
into epochs of increasing length, numbered m = 1, 2, . . .. In
the ﬁrst epoch, the scheme of [5] is operated over N1 symbols.
In the second epoch, the channel inputs and outputs are joined
into pairs, i.e. super-symbols of dimension 2, and the scheme
is operated over N2 such super-symbols. In epoch m, the
scheme is operated over Nm super-symbols of dimension
2m−1 (Fig.3). Since all Nm are ﬁnite, the dimension of the
super-symbols used grows indeﬁnitely with time.
The parameters of the scheme are chosen as follows. Let
> 0 the chosen error probability. Choose any ∆C > 0, and

4

5

that yields the minimum capacity. The rate attained by the
universal system (for a particular state sequence) would be at
least as large. For super-symbols, the averaged channel relates
to the joint distribution over the super-symbol, where the state
(XY)(i−1)q refers to the input and output sequences before
the start of the super-symbol. The universal system is shown
to asymptotically attain a rate which is at least the weighted
average of the pessimistic average channel capacities measured
over the epochs .
Next, the reference system with block size k is compared to
the universal system during epoch m, where the super-symbol
length is q = 2m−1 . Consider a set of super-symbols in hops of
k (l·k+j : l ∈ Z+ , j = 1, . . . , k). Since the number of symbols
between the start of two successive super-symbols in each of
these “alignment” sets divides by k, in each of these supersymbols, the reference system’s blocks and the super-symbols
align, i.e. the IFB/AFB blocks begin at the same location with
respect to the beginning of the super-symbol.
Therefore, there is an equivalence between the average
error probability of the reference system over these supersymbols, and the error probability that would be attained for
the “collapsed” channel, generated by randomly and uniformly
drawing one of the super-symbols in the set and operating the
reference system over this channel. Due to this equivalence,
the reference system’s rate, for a given average error probability, is limited by the capacity of the “collapsed” channel.
For the IFB case, this “collapsed” channel is induced not
only by the channel law, but also by the behavior of the
reference system in previous blocks. When replacing the
collapsed channel with a similar channel, where the history
(XY)(i−1)q before each super-symbol is forced to a speciﬁc
value, then due to the fading memory assumption, from some
point in the block onward, the two channels become similar
(in L1 sense). Due to this similarity, the increase in error
probability, when exchanging the original “collapsed channel”
with the new one, is small. For the AFB case, this transition
is not needed, as the desired relation stems immediately from
the deﬁnition.
Using a variant of Fano’s inequality, the rate of the IFB/AFB
system is related to the capacity of the pessimistic average
channel measured over each of the k alignment sets of supersymbols. The pessimistic average channel over the epoch,
is the average of the k average channels measured over the
alignment sets. Averaging k channels may induce a loss of
at most log k in capacity. This results in a bound on the
pessimistic average channel during each epoch, as a function
of the IFB/AFB capacity, and the IFB/AFB error probability
during the epoch. Note that at this stage, the error probability
of the reference system cannot be dismissed as being small,
since only the average (over growing intervals in time) is
guaranteed to be small. Taking the weighted average of the
pessimistic capacities over the epochs enables relating the
rate of the universal system to the rate and the average error
probability of the reference system, where the latter tends to
zero. All overheads, such as the ones related to alignment of
the blocks to the super-symbols, the time it takes the channel
memory to fade, the log k penalty for mixing k channels,
vanish asymptotically as the super-symbol length increases

indeﬁnitely with time. The full proof can be found in the full
version of this paper [12].
IV. D ISCUSSION
The universal communication system presented does not
require any modeling of the channel, and does not assume
the channel is stationary in any way, and still achieves competitive rates. Although this result is pleasing in terms of
the asymptotical rate, it is theoretical in the sense that the
convergence rate was not optimized and is expected to be slow.
The best convergence rate, and more efﬁcient schemes are left
for further study (see comments in the full paper).
Even if the scheme is improved, the issue remains that
in the setting considered here and in [4], the transmission
lengths N required to obtain a small redundancy compared
to a reference system of block size k, grow exponentially
with k (see the lower bounds on redundancy [4]). Although a
similar issue occurs with Lempel-Ziv universality compared
to ﬁnite state encoders [9] (see also [12]), this makes the
current result theoretical. Complementary results that present
faster convergence rates under simpler models or reference
systems are required in order to show universal communication
schemes can have gains that are realizable in practice (such is
the result of [5], for example).
See the discussion section in the full paper [12] for additional commentary on convergence rates and alternative
models.
R EFERENCES
[1] A. Lapidoth and P. Narayan, “Reliable communication under channel
uncertainty,” IEEE Trans. Information Theory, vol. 44, no. 6, pp. 2148–
2177, Oct. 1998.
[2] O. Shayevitz and M. Feder, “Achieving the empirical capacity using
feedback: Memoryless additive models,” IEEE Trans. Information Theory, vol. 55, no. 3, pp. 1269 –1295, Mar. 2009.
[3] K. Eswaran, A. Sarwate, A. Sahai, and M. Gastpar, “Zero-rate feedback
can achieve the empirical capacity,” IEEE Trans. Information Theory,
vol. 58, no. 1, Jan. 2010.
[4] Y. Lomnitz and M. Feder. (2010, Dec.) Universal communication
over modulo-additive channels with an individual noise sequence.
arXiv:1012.2751v1 [cs.IT]. [Online]. Available: http://arxiv.org/abs/
1012.2751
[5] ——. (2011, Sep.) Universal communication over arbitrarily varying
channels. arXiv:1102.0710 [cs.IT]. [Online]. Available: http://arxiv.org/
abs/1102.0710
[6] A. Lapidoth and I. Telatar, “The compound channel capacity of a class
of ﬁnite-state channels,” IEEE Trans. Information Theory, vol. 44, no. 3,
pp. 973 –983, May 1998.
[7] Y. Lomnitz and M. Feder, “Communication over individual channels,”
IEEE Trans. Information Theory, vol. 57, no. 11, pp. 7333 –7358, Nov.
2011.
[8] S. Verd´ and T. Han, “A general formula for channel capacity,” IEEE
u
Trans. Information Theory, vol. 40, no. 4, pp. 1147 –1157, Jul. 1994.
[9] J. Ziv and A. Lempel, “Compression of individual sequences via
variable-rate coding,” IEEE Trans. Information Theory, vol. 24, no. 5,
pp. 530 – 536, Sep. 1978.
[10] R. Gallager, Information Theory and Reliable Communication. John
Wiley & sons, 1968.
[11] V. Misra and T. Weissman, “The porosity of additive noise sequences,”
in IEEE Int. Symp. Information Theory (ISIT), 2012.
[12] Y. Lomnitz and M. Feder. (2012, Jan.) Universal communication over
channels with memory. arXiv:1202.0417 [cs.IT]. [Online]. Available:
http://arxiv.org/abs/1202.0417

5

