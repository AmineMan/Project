Creator:         TeX output 2012.05.16:1140
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Wed May 16 11:40:33 2012
ModDate:        Tue Jun 19 12:56:10 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      403575 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569565469

A New Ensemble of Rate-Compatible LDPC Codes
∗ Department

Kai Zhang∗ , Xiao Ma∗ , Shancheng Zhao∗ , Baoming Bai† and Xiaoyi Zhang‡

of Electronics and Communication Engineering, Sun Yat-sen University, Guangzhou 510006, GD, China
† State Lab. of ISN, Xidian University, Xi’an 710071, Shaanxi, China
‡ National Digital Switching System Engineering and Technological R&D Center, Zhengzhou 450002, China
Email: maxiao@mail.sysu.edu.cn

p = (p0 , p1 , · · · , pt , · · · ) with 0 < pt < 1 for t ≥ 0. A
codeword c = (v, w) ∈ K[∞, k; p] consists of an information vector v = (v0 , v1 , · · · , vk−1 ) and a parity sequence
w = (w0 , w1 , · · · , wt , · · · ). The parity bit at time t ≥ 0
∑
can be computed recursively by wt = wt−1 + 0≤i<k ht,i vi
with w−1 = 0, where ht,i (0 ≤ i < k) are k independent
realizations of a Bernoulli distributed variable with success
probability pt .
For convenience, the preﬁx code with length n of a Kite
code is also called a Kite code and simply denoted by K[n, k].
A Kite code K[n, k] for n ≥ k is a systematic linear code with
∆
r = n − k parity bits. We can write its parity-check matrix H
as
H = (Hv , Hw ) ,
(1)

Abstract—In this paper, we presented three approaches to
improve the design of Kite codes (newly proposed rateless codes),
resulting in an ensemble of rate-compatible LDPC codes with
code rates varying “continuously” from 0.1 to 0.9 for additive
white Gaussian noise (AWGN) channels. The new ensemble
rate-compatible LDPC codes can be constructed conveniently
with an empirical formula. Simulation results show that, when
applied to incremental redundancy hybrid automatic repeat
request (IR-HARQ) system, the constructed codes (with higher
order modulation) perform well in a wide range of signal-tonoise-ratios (SNRs).

I. I NTRODUCTION
Rate-compatible low-density parity-check (RC-LDPC)
codes, which may ﬁnd applications in hybrid automatic
repeat request (HARQ) systems, can be constructed in at
least two ways. One way is to puncture (or extend) properly
a well-designed mother code [1–6]. Another way is to turn
to rateless coding [7–10], resulting in rate-compatible codes
with incremental redundancies [11].
Recently, the authors proposed a new class of rateless
codes, called Kite codes [12], which are a special class of
preﬁx rateless low-density parity-check (LDPC) codes. Kite
codes have the following nice properties. First, the design
of Kite codes can be conducted progressively using a onedimensional optimization algorithm. Second, the maximumlikelihood decoding performance of Kite codes with binaryphase-shift-keying (BPSK) modulation over AWGN channels
can be analyzed. Third, the deﬁnition of Kite codes can be
easily generalized to groups [13]. In this paper, we attempt
to improve the design of Kite codes and investigate their
performance when combined with high-order modulations.
The rest of this paper is organized as follows. In Section II,
we review the construction of the original Kite codes. The
design of Kite codes and existing issues are discussed. In
Section III, we present three approaches to improve the design
of Kite codes, resulting in good rate-compatible codes with
rates varying continuously from 0.1 to 0.9 for additive white
Gaussian noise (AWGN) channels. In section IV, we present
simulation results for the application of Kite codes to the
HARQ system. Section V concludes this paper.

where Hv is a matrix of size r × k that corresponds to the
information bits, and Hw is a square matrix of size r × r that
corresponds to the parity bits. By construction, we can see
that the sub-matrix Hv is a random-like binary matrix whose
entries are governed by the p-sequence. More speciﬁcally,
{
pt ,
ht,i = 1
Pr{Ht,i = ht,i } =
(2)
1 − pt , ht,i = 0
for t ≥ 0 and 0 ≤ i < k. In contrast, the square matrix Hw is
a dual-diagonal matrix (blanks represent zeros)


1
 1 1





..

.
.
1
Hw = 
(3)



..


. 1
1 1
In the case of pt ≪ 1/2, a Kite code can be decoded as an
LDPC code.
B. Relationships between Kite Codes and Existing Codes
A speciﬁc realization of a Kite code with ﬁnite length can be
considered as a serially concatenated code with a systematic
low-density generator-matrix (LDGM) code [14] as the outer
code and an accumulator as the inner code. Different from
conventional serially concatenated codes, the inner code takes
only the parity bits from the outer code as input bits. A speciﬁc
Kite code is also similar to the generalized irregular repeataccumulate (GeIRA) codes [15][16][17][18].
As an ensemble, Kite codes are new. To clarify this, we
resort to the deﬁnition of a code ensemble [19]. A binary linear

II. R EVIEW OF K ITE C ODES
A. Deﬁnition of Kite Codes
An ensemble of Kite codes, denoted by K[∞, k; p], is
speciﬁed by its dimension k and a so-called p-sequence

1

code ensemble is a probability space (C, Q), which is speciﬁed
by a sample space C and a probability assignment Q(C) to
each C ∈ C. Each sample C ∈ C is a binary linear code,
and the probability Q(C) is usually implicitly determined by
a random construction method. The following examples show
us three code ensembles with length n.
• A code ensemble Cg can be characterized by a generator
matrix G of size k × n, where each element of G is
drawn independently from a uniformly distributed binary
random variable.
• A code ensemble Ch can be characterized by a paritycheck matrix H of size (n − k) × n, where each element
of H is drawn independently from a uniformly distributed
binary random variable.
• A code ensemble Cs can be characterized by a generator
matrix Gs = [Ik , P ] of size k×n, where Ik is the identity
matrix and each element of P is drawn independently
from a uniformly distributed binary random variable. This
ensemble can also be characterized by a random paritycheck matrix Hs = [P T , In−k ].
In a strict sense, the above three ensembles are different.
The ensemble Cg has some samples with code rates less than
k/n, and the ensemble Ch has some samples with code rates
greater than k/n. The code ensemble Cs is systematic and
each sample has the exact code rate k/n. LT-codes (preﬁx
codes with length n) have a slightly different sample space
from that of Cg but, with high probability, have low-density
generator matrices. In contrast, the ensemble of Kite codes (of
length n) with pt ≡ 1/2 is the same as Cs . An ensemble of
Kite codes (of length n) with pt < 1/2 has the same sample
space as that of Cs but different probability assignment to each
code.

Let qℓ be the parameter to be optimized. Since the parameters qj with j > ℓ have been ﬁxed and the parameters qj with
j < ℓ are irrelevant to the current preﬁx code, the problem to
design the current preﬁx code then becomes a one-dimensional
optimization problem, which can be solved, for example, by
the golden search method [20]. What we need to do is to make
′
a choice between any two candidate parameters qℓ and qℓ . This
can be done with the help of simulation, as illustrated in [12].
D. Existing Issues
The above greedy optimization algorithm has been implemented in [12], resulting in good Kite codes. However, we
have also noticed the following issues.
1) In the high-rate region, Kite codes suffer from error-ﬂoors
at BER around 10−4 .
2) In the low-rate region, there exists a relatively large gap
between the performances of the Kite codes and the
Shannon limits.
3) The optimized p-sequence depends on the data length k
and has no closed form. Therefore, we have to search
the p-sequence for different data lengths when required.
This inconvenience deﬁnitely limits the applications of
the Kite codes.
The ﬁrst issue has been partially solved by either taking RS
codes as outer codes in [12] or inserting ﬁxed patterns into
the parity-check matrix in [21]. The objective of this paper is
to provide simple ways to overcome the above issues.
III. I MPROVED D ESIGN OF K ITE C ODES
As mentioned in the preceding section, we consider only
code rates greater than 0.05 and partition equally the interval
(0.05, 1] into 19 sub-intervals. Given a data length k. Deﬁne
k
nℓ = ⌊ 0.05ℓ ⌋ for 1 ≤ ℓ ≤ 20.

C. Design of Kite Codes
Given a data length k. The task to optimize a Kite code is to
select the whole p-sequence such that all the preﬁx codes are
good enough. This is a multi-objective optimization problem
and could be very complex. For simplicity, we consider only
codes with rates greater than 0.05 and partition equally the
code rates into 19 subintervals, that is,
∪
(0.05, 1] =
(0.05ℓ, 0.05(ℓ + 1)].
(4)

A. Constructions of the Parity-Check Matrix
We need to construct a parity-check matrix H = (Hv , Hw )
of size (n1 − k) × n1 , where Hv is a matrix of size (n1 − k) ×
k corresponding to the information bits and Hw is a lower
triangular matrix with non-zero diagonal entries. Let C[n1 , k]
be the code deﬁned by H. We then have a sequence of preﬁx
codes with incremental parity bits. Equivalently, we can have
a sequence of preﬁx codes with rates varying “continuously”
from 0.05 to 1.
To describe the algorithm more clearly, we introduce some
(ℓ)
(ℓ)
deﬁnitions. Let H (ℓ) = (Hv , Hw ) be the parity-check
(ℓ)
matrix for the preﬁx code with length nℓ . Let Hv (·, j)
(ℓ)
(ℓ)
and Hv (t, ·) be the j-th column and t-th row of Hv ,
(ℓ)
respectively. Sometimes, we use Hv (t, j) to represent the
(ℓ)
entry of Hv at the location (t, j). Given {qℓ , 1 ≤ ℓ ≤ 19}, the
parity-check matrix H = H (1) can be constructed as follows.
First, the matrix Hv corresponding to the information bits
can be constructed progressively as shown in the following
algorithm.
Algorithm 1: (Row-weight Concentration)

1≤ℓ≤19

We simply assume that the p-sequence is a step function
of the code rates taking only 19 possibly different values
{qℓ , 1 ≤ ℓ ≤ 19}. That is, we enforce that pt = qℓ whenever
t satisﬁes that the code rate k/(t + k) ∈ (0.05ℓ, 0.05(ℓ + 1)].
Then our task is transformed into selecting the parameters
{qℓ , 1 ≤ ℓ ≤ 19}. One approach to do this is the following
greedy optimization algorithm.
First, we choose q19 such that the preﬁx code of length
⌊k/0.95⌋ is as good as possible. Secondly, we choose q18 with
ﬁxed q19 such that the preﬁx code of length ⌊k/0.90⌋ is as
good as possible. Thirdly, we choose q17 with ﬁxed (q19 , q18 )
such that the preﬁx code of length ⌊k/0.85⌋ is as good as
possible. This process continues until q1 is selected.

(20)

1) Initially, set Hv

2

be the empty matrix and ℓ = 19.

TABLE I
T HE p- SEQUENCES
Code rate k/(k + t)
(0.95, 1.00]
(0.90, 0.95]
(0.85, 0.90]
(0.80, 0.85]
(0.75, 0.80]
(0.70, 0.75]
(0.65, 0.70]
(0.60, 0.65]
(0.55, 0.60]
(0.50, 0.55]
(0.45, 0.50]
(0.40, 0.45]
(0.35, 0.40]
(0.30, 0.35]
(0.25, 0.30]
(0.20, 0.25]
(0.15, 0.20]
(0.10, 0.15]
(0.05, 0.10]

pt (k = 3780)
0.0170
0.0110
0.0050
0.0039
0.0023
0.0020
0.0016
0.0013
0.0010
0.0009
0.0007
0.0007
0.0006
0.0006
0.0005
0.0005
0.0005
0.0004
0.0004

0

edoc etiK deifidoM
edoc etiK

12345678-

8

6

]Bd[ )2σ/1(01gol01 = )oitaR-esioN-ot-langiS( RNS
4
2
0
24-

6-

8-

01-

b) Row-weight concentration:
i) Find t1 (nℓ+1 − k ≤ t1 < nℓ − k) such that
(ℓ)
the row Hv (t1 , ·) has the maximum Hamming
weight, denoted by Wmax ;
ii) Find t0 (nℓ+1 − k ≤ t0 < nℓ − k) such that the
(ℓ)
row Hv (t0 , ·) has the minimum Hamming weight,
denoted by Wmin ;
iii) If Wmax = Wmin or Wmax = Wmin + 1, set ℓ ←
ℓ − 1 and go to Step 2); otherwise, go to the next
step;
(ℓ)
iv) Find j1 (0 ≤ j1 ≤ k−1) such that Hv (t1 , j1 ) = 1
(ℓ)
and that the column Hv (·, j1 ) has the maximum
Hamming weight;
(ℓ)
v) Find j0 (0 ≤ j0 ≤ k−1) such that Hv (t0 , j0 ) = 0
(ℓ)
and that the column Hv (·, j0 ) has the minimum
Hamming weight;
(ℓ)
(ℓ)
vi) Swap Hv (t0 , j0 ) and Hv (t1 , j1 ); go to Step i).
Remarks. From the above algorithm, we can see that the
(δ)
incremental sub-matrix Hv corresponding to the information
vector is ﬁnally modiﬁed into a sub-matrix with rows of weight
Wmin or Wmin + 1. Such a modiﬁcation is motivated by a
theorem as shown in [22] stating that the optimal degree for
check nodes can be selected as a concentrated distribution.
Such a modiﬁcation also excludes columns with extremely
low weight.
Second, the matrix Hw corresponding to the parity bits is
constructed as a random accumulator speciﬁed in the following
algorithm.
Algorithm 2: (Accumulator Randomization)
1) Initially, Hw is set to be the identity matrix of size (n1 −
k) × (n1 − k).
2) For t = 0, 1, · · · , n1 − k − 2, do the following step by
step.
a) Find the maximum integer T such that the code rates
k/(k + T ) and k/(k + t + 1) falls into the same
subinterval, say (0.05ℓ, 0.05(ℓ + 1)];
b) Choose uniformly at random an integer i1 ∈ [t + 1, T ];
c) Set the i1 -th component of the t-th column of Hw to
be 1, that is, set Hw (i1 , t) = 1.
Remarks. The accumulator randomization approach introduces more randomness to the code such that the current parity
bit depends randomly on previous parity bits. We also note
(ℓ)
that, for all ℓ, Hw has the property that each of all columns
but the last one has column weight 2. It is worth pointing
out that both the row-weight concentration algorithm and the

pt (k = 1890)
0.0380
0.0200
0.0130
0.0072
0.0046
0.0038
0.0030
0.0028
0.0018
0.0017
0.0015
0.0014
0.0013
0.0012
0.0012
0.0012
0.0011
0.0011
0.0011

01

2) While ℓ ≥ 1, do the following.
(δ)
a) Initialization: generate a random binary matrix Hv
of size (nℓ − nℓ+1 ) × k, where each entry is independently drawn from a Bernoulli distribution with success
probability qℓ ; form the matrix corresponding to the
information bits as
(
)
(ℓ+1)
Hv
(ℓ)
.
(5)
Hv =
(δ)
Hv

01
01
01
01B
E
R
(
B
t
-i
01E
r
r
o
r
R
a
t
01 e
)
01
01
01

Fig. 1. Performances of the constructed improved Kite code and Kite code
with k = 1890. The maximum iteration number is 50. From left to right,
the curves correspond to rates 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, and 0.9,
respectively.

accumulator randomization algorithm are executed in an offline manner. To construct the preﬁx code of length nℓ , both of
these two algorithms modify only the incremental nℓ − nℓ+1
rows of the parity-check matrix associated with the original
Kite code, which do not affect other rows.
B. Greedy Optimization Algorithms
It has been shown that, given {qℓ , 1 ≤ ℓ ≤ 19}, we can construct a parity-check matrix H by conducting the row-weight
concentration Algorithm 1 and the accumulator randomization
Algorithm 2. Hence, we can use the greedy optimization
algorithm to construct a good parity-check matrix. We have
designed two improved Kite codes with data length k = 1890
and k = 3780. The p-sequences are shown in Table I. Their
performances are shown in Fig. 1 and Fig. 2, respectively.
From Fig. 1 and Fig. 2, we have the following observations.
• The improved Kite codes perform well within a wide
range of SNRs.

3

0

the p-sequence. To this end, we have plotted the optimized
parameters in Table I in Fig. 3. We then have the following
empirical formula
(
)
1
1.65
qℓ =
+ 2.0
(6)
k (1.5 − 0.05ℓ)6

0981 = k
0873 = k

1234-

for 1 ≤ ℓ ≤ 19. From Fig. 3, we can see that the above
formula is well matched to the optimized p-sequence.

5-

5.0 = R

IV. A PPLICATIONS OF K ITE CODES TO IR-HARQ
S YSTEMS

6-

2.0 = R

8.0 = R

In summary, for an arbitrarily given data length k, we
can generate (off-line) a systematic mother code K[n1 , k]
with n1 = ⌊k/0.05⌋ by constructing a parity-check matrix
according to the following procedure.
1) Calculate the q-sequence according to (6);
2) Generate a semi-random parity-check matrix H =
(Hv , Hw ) according to (2) and (3);
3) Modify H by performing Algorithm 1 and Algorithm 2.
We consider to combine the Kite code with two-dimensional
modulations. The coded bits are assumed to be modulated into
a constellation of size 2b by the (near-)Gray mapping and then
transmitted over AWGN channels. The receiver ﬁrst extracts
the a posteriori probabilities of coded bits from each noisy
coded symbol and then performs the iterative sum-product
decoding algorithm. If the receiver can decode successfully, it
feedbacks an “ACK”; otherwise, the transmitter produces more
parity bits and transmits more coded signals. The receiver tries
the decoder again with the incremental noisy coded signals.
This process continues until the decoding is successful. To
guarantee with high probability that the successfully decoded
codeword is the transmitted one, we require that the receiver
starts the decoding only after it receives n18 noisy coded
bits. With this constraint, we have never found erroneously
decoded codewords in our simulations. That is, the decoder
either delivers the transmitted codeword or reports a decoding
failure. If n is the length of the code at which the decoding is
successful, we call η = kb/n bits/symbol the decoding spectral
efﬁciency, which is a random variable and may vary from
frame to frame.
The average decoding spectral efﬁciency of the Kite code
of dimension k = 9450 with different high-order modulations
for AWGN channels are shown in Fig. 4. Also shown are
the capacity curves. Taking into account the performance
loss of shaping gain 1.53 dB caused by conventional QAM
constellations for large SNRs [23], we conclude that the
improved Kite codes perform well essentially in the whole
SNR range.

78-

01

]Bd[ )2σ/1(01gol01 = )oitaR-esioN-ot-langiS( RNS
5
0
5-

01-

01
01
01
B
E
01R
(
B
t
-i
01E
r
r
o
r
R
01 a
t
e
)
01
01
01

Fig. 2. Performance of the constructed improved Kite code with k = 3780.
The maximum iteration number is 50. From left to right, the curves correspond
to rates 0.05, 0.10, 0.15, · · · , 0.90, and 0.95, respectively.
0

noitcnuf ecneirepxE
mhtirogla gnizimitpo ydeerG
1-

0981 = k

24-

9.0

8.0

7.0

01
u
01 el

01 p
3s
e
q
u
e
n
c
e
v
a

0873 = k

1

01

6.0

etaR edoC
5.0
4.0

3.0

2.0

1.0

01

0

Fig. 3. Comparisons of the empirical formula for qℓ with the parameters
obtained by the simulation-based greedy optimizing algorithm.

•

•

•

In the moderate-to-high-rate region, the improved Kite
codes perform almost as well as the original Kite codes
in the water-fall region, while the improved Kite codes
can effectively lower down the error-ﬂoors.
In the low-rate region, the improved Kite codes are better
than the original Kite codes. For example, when the
code rate is 0.1, the improved Kite code can achieve a
performance gain about 1.5 dB over the original Kite code
at BER = 10−5 .
As the data length k increases, the performance of the
improved Kite codes can be improved. For instance, when
the code rate is 0.2, the improved Kite code with data
length 3780 achieves a performance gain about 0.2 dB
over the improved Kite code with data length 1890 around
BER = 10−5 .

V. C ONCLUSION AND F UTURE W ORKS
In this paper, we have presented three approaches to improve the design of Kite codes. In the moderate-to-high-rate
region, the improved Kite codes perform almost as well as
the original Kite codes, but exhibit lower error-ﬂoors. In the
low-rate region, the improved Kite codes are better than the
original ones. In addition, we have presented an empirical

C. Empirical Formula
As shown by the above two examples, the optimized psequence depends on data length k, which makes the design of
improved Kite codes time-consuming. To accelerate the design
of improved Kite codes, we present an empirical formula for

4

[7] M. Luby, “LT-codes,” in Proc. 43rd Annu. IEEE Symp.
Foundations of computer Science (FOCS), Vancouver,
BC, Canada, Nov. 2002, pp. 271–280.
[8] A. Shokrollahi, “Raptor codes,” IEEE Transactions on
Information Theory, vol. 52, no. 6, pp. 2551–2567, June
2006.
[9] O. Etesami and A. Shokrollahi, “Raptor codes on binary
memoryless symmetric channels,” IEEE Transactions on
Information Theory, vol. 52, no. 5, pp. 2033–2051, May
2006.
[10] R. Palanki and J. Yedidia, “Rateless codes on noisy
channels,” in Proc. 2004 IEEE Int. Symp. Inform. Theory,
Chicago, IL, Jun./Jul. 2004, p. 37.
[11] E. Soijanin, N. Varnica, and P. Whiting, “Punctured vs
rateless codes for hybrid ARQ,” in Proc. 2006 IEEE Inform. Theory Workshop, Punta del Este, Uruguay, March
2006, pp. 155–159.
[12] X. Ma, K. Zhang, B. Bai, and X. Zhang, “Serial concatenation of RS codes with Kite codes: performance
analysis, iterative decoding and design,” available at
http://arxiv.org/abs/1104.4927.
[13] X. Ma, S. Zhao, K. Zhang, and B. Bai, “Kite codes
over groups,” in Proc. IEEE Information Theory Workshop (ITW2100), Paraty, Brazil, Oct. 2011, pp. 481–485.
[14] J. Garcia-Frias and W. Zhong, “Approaching Shannon
performance by iterative decoding of linear codes with
low-density generator matrix,” IEEE Communications
Letters, vol. 7, no. 6, pp. 266–268, June 2003.
[15] H. Jin, A. Khandekar, and R. McEliece, “Irregular repeataccumulate codes,” in Proc. 2nd Intern. Symp. on Turbo
Codes and Related Topics, Sept. 2000, pp. 1–8.
[16] M. Yang, W. E. Ryan, and Y. Li, “Design of efﬁciently encodable moderate-length high-rate irregular
LDPC codes,” IEEE Transactions on Communications,
vol. 52, no. 4, pp. 564–571, April 2004.
[17] G. Liva, E. Paolini, and M. Chiani, “Simple reconﬁgurable low-density parity-check codes,” IEEE Communications Letters, vol. 9, no. 3, pp. 258–260, March 2005.
[18] A. Abbasfar, D. Divsalar, and Y. K, “Accumulate-repeataccumulate codes,” IEEE Trans. Commun., vol. 55, no. 4,
pp. 692–702, April 2007.
[19] R. G. Gallager, Information Theory and Reliable Communication. New York: John Wiley and Sons, Inc., 1968.
[20] R. L. Rardin, Optimization in Operations Research. Englewood Cliffs, NJ: Prentice-Hall, 1998.
[21] B. Bai, B. Bai, and X. Ma, “Semi-random Kite codes
over fading channels,” in Proc. IEEE International Conference on Advanced Information Networking and Applications (AINA), Biopolis, Singapore, March 2011, pp.
639–645.
[22] S.-Y. Chung, T. Richardson, and Urbanke, “Analysis of
sum-product decoding of low-density parity-check codes
using Gaussian approximation,” IEEE Trans. Inform.
Theory, vol. 47, no. 2, pp. 619–637, Feb 2001.
[23] G. D. Forney, Jr., “Efﬁcient modulation for band-limited
channels,” IEEE J. Select. Areas Commun., Sept 1984.

9

Bd35.1

yticapaC
stluser noitalumiS

8

MAQ652
7

)RNS+1(gol = C

MAQ821

6

MAQ46

b
ol
)

s/
5m
y
C
a
p
yt
(
bi
st

MAQ23

c
4 ai

MAQ61

3

KSP8

2

KSPQ

1
53

03

52

02

]Bd[ RNS
51
01

5

0

5-

010

Fig. 4. The average decoding spectral efﬁciency (at “zero” error probability)
of the improved Kite code with data length k = 9450 over AWGN channels.
The maximum iteration number is 50.

formula for the p-sequence, which can be utilized to construct
rate-compatible codes of any code rates with arbitrarily given
data length. Simulation results show that, when combined with
high-order modulations, the improved Kite codes perform well
essentially in the whole range of SNRs.
Future works include to compare Kite codes with other
codes such as Raptor codes in terms of both the performance
and the complexity when applied to adaptive coded modulations over noisy channels.
ACKNOWLEDGMENT
This work was supported by the 973 Program (No.2012CB316100) and the NSF under Grants
61172082 and 60972046 of China.
R EFERENCES
[1] J. Ha, J. Kim, and S. W. McLaughlin, “Rate-compatible
puncturing of low-density parity-check codes,” IEEE
Transactions on Information Theory, vol. 50, pp. 2824–
2836, Nov. 2004.
[2] M. R. Yazdani and A. H. Banihashemi, “On construction
of rate-compatible low-density parity-check codes,” IEEE
Communications Letters, vol. 8, pp. 159–161, March
2004.
[3] C.-H. Hsu and A. Anastasopoulos, “Capacity achieving LDPC codes through puncturing,” IEEE Trans. Inform. Theory, vol. 54, pp. 4698–4706, Oct. 2008.
[4] M. El-Khamy, J. Hou, and N. Bhushan, “Design of
rate-compatible structured LDPC codes for hybrid ARQ
applications,” IEEE Journal on Selected Areas in Communications, vol. 27, pp. 965–973, Aug. 2009.
[5] J. Kim, A. Ramamoorthy, and S. W. McLaughlin, “The
design of efﬁciently-encodable rate-compatible LDPC
codes,” IEEE Trans. Comm., vol. 57, pp. 365–375, Feb.
2009.
[6] B. N. Vellambi and F. Fekri, “Finite-length ratecompatible LDPC codes: A novel puncturing scheme,”
IEEE Trans. Comm., vol. 57, pp. 297–301, Feb. 2009.

5

