Title:          Capacity Order.dvi
Creator:        dvips(k) 5.98 Copyright 2009 Radical Eye Software
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Mon May  7 14:27:23 2012
ModDate:        Tue Jun 19 12:54:43 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      316460 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569566449

Ergodic Capacity Ordering of Fading Channels
Adithya Rajan and Cihan Tepedelenlioglu
School of Electrical, Computer and Energy Engineering
Arizona State University
Tempe, Arizona 85287
Email: { arajan2, cihan } @asu.edu
obtained by coding over an i.i.d time extension of the fading
channel, which provides more inherent time diversity; through
coding, it is possible to make one channel offer better error
rates than the other at all SNR, even when this is not possible
in the absence of coding.
For the ﬁrst time in (information theory, and stochastic ordering) literature, we deﬁne and obtain many useful properties
of the capacity order, which can be applied to compare the
performance of wireless communication systems across two
different fading channels. Further, we show that many of the
parametric fading models such as the Nakagami-m, Rician
and Hoyt fading satisfy the capacity order with respect to their
line of sight parameters. For systems involving multiple fading
coefﬁcients, we establish sufﬁcient conditions on when the
ergodic capacity of the composite system is bigger, when each
fading link is capacity ordered. Such comparisons of ergodic
capacities can be made even in cases when a closed-form
expression is not available. As simple illustrative examples,
we investigate diversity combining systems. We also consider
the multi-hop amplify-forward relay, whose ergodic capacity
in fading is intractable in closed form, and show that under
certain conditions, if a better set of channels used to form the
relay system, the composite system has a higher ergodic capacity. Our results also extend to multi-user information theory.
More speciﬁcally, we show that the ergodic capacity region
of a multiple access channel is larger, when the single-input
single-output (SISO) channel between the destination and each
user in the absence of all other users is better. However, for
certain system conﬁgurations, element-wise ergodic capacity
ordering does not imply overall system capacity ordering at
all SNR ρ. Examples include the multi-hop amplify-forward
relay.

Abstract—In this paper, a new stochastic order between two
fading distributions is introduced. A fading channel dominates
another in the capacity ordering sense, if the ergodic capacity
of the ﬁrst is greater than that of the second at all values of
average signal to noise ratio. We show that many parametric
fading models such as the Nakagami-m, Rician and Hoyt fading
satisfy the capacity order, in the sense that the distribution with
a larger line of sight parameter is larger in the ergodic capacity
sense. Further, we obtain closure properties of the capacity order
for the ﬁrst time, because such a stochastic order has not been
considered in either stochastic ordering literature, or information
theory literature. Through these properties, we develop sufﬁcient
conditions for comparing the ergodic capacity of a composite
system involving multiple capacity ordered fading links with coding/decoding capabilities only at the transmitter/receiver, when
operated in two different fading scenarios. Such comparisons
can be made even in cases when a closed form expression for
the ergodic capacity of the composite system is not analytically
tractable. We also show that capacity ordering of point-to-point
links has applications to multiple access channels.

I. I NTRODUCTION
Consider a fading channel with additive white Gaussian
noise (AWGN), where the receiver has perfect channel side
information (CSI). The ergodic capacity in this case is known
to be E [log (1 + ρX)], where ρX is the instantaneous signal
to noise ratio (SNR), and ρ > 0 represents the average SNR.
In this work, we deﬁne a new partial order on the instantaneous SNR of fading channels, which can be used to compare
two different fading channels. A fading channel is said to be
better than another in the ergodic capacity order (or capacity
order, for short), if its corresponding ergodic capacity is bigger
for all ρ. The proposed deﬁnition falls under the general
theory of integral stochastic orders, which is well-studied in
the ﬁeld of reliability analysis [1], actuarial sciences [2] and
economics [3]. There are many stochastic orders which have
been previously established. A comprehensive exposition can
be found in [4]. Previously, the stochastic Laplace transform
(LT) order, which compares the real-valued Laplace transforms
of random variables (RVs) has been used to compare two
fading distributions by comparing the average error rate of
M -QAM modulations [5]. This draws intuition from the fact
that error rates of some modulations are positive mixtures
of decaying exponentials, which can also be viewed as the
Laplace transform. It has been shown in [5] that Laplace
transform ordering of instantaneous SNRs implies ordering of
ergodic capacities, but not conversely. This occurs because
ergodic capacity is the maximum average achievable rate,

II. M ATHEMATICAL P RELIMINARIES
A. Bernstein Functions
A function g : (0, ∞) → R is a Bernstein function, if
g(x) ≥ 0, and g is inﬁnitely differentiable with
dn g(x)
≥ 0 ,x > 0 ,
(1)
dxn
for n ∈ N. An equivalent condition to (1) is that g(x) admits
the representation [6, p. 15]
(−1)n−1

∞

(1 − exp(−sx)) µ(ds) ,

g(x) = a + bx +
0

1

(2)

where E [·] is the expectation. In this case, G is known as
a generator of the order ≤G . We now give two examples of
integral stochastic orders relevant to this paper, by specifying
the corresponding generator set of functions G.
1) Convex Order: In this case G is the set of all convex
functions, and the order is denoted as X ≤cx Y . Applying (6)
using g(x) = x and g(x) = −x (both of which are convex), we
have E [X] = E [Y ] whenever X and Y are convex ordered.
Therefore, convex ordering establishes that the RVs have the
same mean and X is “less variable” than Y .
Performance metrics such as error rates of two-dimensional
modulations, and the negative capacity function − log(1 +
ρx), ρ > 0 are convex functions of the instantaneous SNR.
Therefore, establishing convex ordering of two instantaneous
SNR RVs can enable comparing the average performance of
the same system subject to fading modeled by two RVs.
2) Laplace Transform Order: This partial order compares
random variables based on their Laplace Transforms. Here,
G = {g(x) : g(x) = − exp (−ρx) , ρ ≥ 0}, so that X ≤Lt Y
if and only if

for some a, b ≥ 0, which is a Lebesgue integral with respect
to a positive measure µ on (0, ∞), which satisﬁes the conver1
∞
gence condition 0 µ(ds) + 1 sµ(ds) < ∞. The set of all
Bernstein functions is denoted by BF.
An important property is that the set BF is closed under
conic combinations: if gi ∈ BF, and ai ≥ 0, i = 1, . . . , N ,
N
then i=1 ai gi ∈ BF. Some examples of Bernstein functions
are g(x) = xα , for 0 < α < 1, g(x) = x/(1 + x) and
g(x) = log(1+x). The representation of the capacity function
log(1 + x) in the form (2) is particularly useful, and is given
by
∞

1 − e−sx

log (1 + x) =

e−s
ds .
s

(3)

0

B. Thorin-Bernstein Functions
A Bernstein function g is called a Thorin-Bernstein function
[6, pp. 73-79], if it admits the representation given by (2),
where sµ(s) is completely monotone (c.m.). Recall that a
function g : (0, ∞) → R is c.m. if and only if it satisﬁes
˜
(−1)

nd

E [exp(−ρY )] ≤ E [exp(−ρX)] ∀ ρ ≥ 0 .

n

g (x)
˜
≥ 0, x > 0,
dxn

(4)

One useful property of LT ordered random variables is that
for all c.m. functions g, we have

and n ∈ N ∪ {0}. The family of all Thorin-Bernstein functions
is denoted by T BF. A necessary and sufﬁcient condition for
g : (0, ∞) → (0, ∞) to be in T BF is that g can be represented
as follows [6, p. 73]:

E [g(ρY )] ≤ E [g(ρX)] ∀ ρ ≥ 0 .

log (1 + x/s) µ(ds) ,

(5)

0

for some a, b ≥ 0 and µ is a positive measure on (0, ∞),
1
which satisﬁes the convergence condition 0 | log s|µ(ds) +
∞ −1
s µ(ds) < ∞. Thorin-Bernstein functions are closed
1
under conic combinations, and also under compositions i.e.
for g1 , g2 ∈ T BF, g1 ◦ g2 ∈ T BF. This subclass of BF is of
particular relevance to this paper, since the Shannon capacity
function C(x) := log (1 + x) is not only in BF, but is also
a Thorin-Bernstein function, which can be seen from (3) and
(5).
It is useful to deﬁne a multivariate extension of a ThorinBernstein function as follows: A function g : Rm → R ∈
T BF if g(x1 , . . . , xm ) is in T BF when xj , j = 1, . . . , m, is
treated as the variable, while all other arguments are treated
as constants.

E [g(ρX)] ≤ E [g(ρY )] ∀ ρ ≥ 0 .

(9)

Clearly, for g(x) = log (1 + ρx), (9) provides a method to
compare the ergodic capacities of two fading channels with
X ≤Lt Y .
III. T HE C APACITY O RDER
In this section, we describe a new stochastic order, known
as the capacity order.
A. Deﬁnition
A random variable X is said to be dominated by another
random variable Y in the capacity order sense if and only if
E [log (1 + ρX)] ≤ E [log (1 + ρY )] ,

C. Stochastic Ordering

(10)

∀ρ ≥ 0, and is denoted by X ≤c Y . Here, E [log (1 + ρX)]
can be interpreted as the ergodic capacity of a fading channel
with instantaneous SNR ρX and average SNR ρ. Thus, X ≤c
Y dictates an order between the ergodic capacities of the two
channels for every value of ρ. For this stochastic order, the
generator is chosen as G = {g(x) : g(x) = log (1 + ρx) , ρ ≥
0}. Next, we develop some useful properties of the capacity
order.

In this subsection, we review some of the tools provided by
the stochastic ordering framework.
Let G denote a class of real valued functions g : R+ → R,
and X and Y be random variables (RVs) with distribution
functions FX (·) and FY (·) respectively. We deﬁne the integral
stochastic order with respect to G as [2]:
X ≤G Y ⇔ E [g(X)] ≤ E [g(Y )] , ∀g ∈ G ,

(8)

In other words, the generator G can be replaced by the set of
all c.m. functions without changing the stochastic order [2]. In
a wireless communications context, we interpret ρX and ρY
as the instantaneous SNRs of two fading distributions, and
g(x) as the instantaneous SER of a modulation scheme with
c.m. error rate function. For example, for BPSK modulation,
√
g(x) = Q 2ρx is c.m. in x. Further, for every g ∈ BF,
we have the following useful relation

∞

g(x) = a + bx +

(7)

(6)

2

inconclusive, since the integrals tend to be intractable. Fortunately, using Property 4, we can come up with RVs which
obey capacity ordering.
It has been shown in [5] that when X and Y represent the
instantaneous channel gains corresponding to Rician fading
with parameters K X ≤ K Y , X ≤Lt Y . Using Property
4, we see that under this condition X ≤c Y is also true.
This is true even for the case when X and Y correspond
to the instantaneous channel gains of Nakagami fading with
parameters mX ≤ mY , or Hoyt fading with parameters
qX ≤ qY .
In what follows, we show that capacity ordering of a given
SISO system under two different fading channels (possibly
Rician with K X ≤ K Y ) can be used to make meaningful
conclusions when a number of such systems are combined to
form a system involving multiple random variables.

B. Properties and Examples
For any two independent positive valued RVs X, Y , the
following statements are true:
1) X ≤c Y ⇒ E [X] ≤ E [Y ], if E [X], E [Y ] < ∞.
2) X ≤c Y ⇔ E [g(X)] ≤ E [g(Y )], ∀g ∈ T BF.
3) X ≤c Y ⇔ g(X) ≤c g(Y ), ∀g ∈ T BF.
4) X ≤Lt Y ⇒ X ≤c Y .
5) For X1 , . . . , XM independent and Y1 , . . . , YM independent, if Xm ≤c Ym ∀m = 1, . . . , M , then
g (X1 , . . . , XM ) ≤c g (Y1 , . . . , YM ), for every g :
RM → R which is a multivariate T BF.
The proofs of the properties can be found in the appendix.
We note that properties 1, 2 and 3 can also be seen to hold for
every g ∈ BF, when ≤c is replaced by ≤Lt in these properties.
Interpreting ρX and ρY as the instantaneous SNRs of two
different fading channels, the above properties of capacity
ordered RVs prove to be essential in obtaining the conditions
under which the ergodic capacity of a composite system with
coding/decoding capabilities only at the transmitter/receiver
under the channel Y is greater than that under X at all SNR.
Importantly, Property 4 suggests that every pair of Laplace
transform ordered random variables will also be capacity
ordered, and this fact is used as a sufﬁcient condition to verify
if two random variables are capacity ordered. Interestingly, the
converse is not true, and we now give a counterexample, which
was also given in [5], but we include it here for the sake of
completeness. In an interference dominated system, the instantaneous signal to interference ratio X is distributed according
to the Pareto law FX (x) = xβ /(1 + xβ ), x > 0, β > 0 [7],
for which it can be shown that
∞

E [log (1 + ρX)] =

ρ
dx ,
(1 + ρx)(1 + xβ )

IV. S YSTEMS I NVOLVING M ULTIPLE R ANDOM VARIABLES
In order to illustrate the applicability of the capacity order
to compare the performance of systems, we provide examples
of composite systems where capacity ordering of component
SISO systems can be used to conclude the capacity ordering
of the system, and also some applications where this is not
necessarily the case. Such generic conclusions can be made
even when closed form expressions for the ergodic capacity
are not available.
A. Diversity Combining Systems
To begin with, we consider diversity combining schemes
such as maximum ratio combining (MRC) and equal gain
combining (EGC) using M receive antennas, for which
we wish compare the ergodic capacity under two different
fading channels with instantaneous channel gains Xm ≤c
Ym , m = 1, . . . , M . To simplify the notation, we denote
X := [X1 , . . . , XM ], and likewise for Y.
1) Maximum Ratio Combining: Conditioned on the instantaneous channel gain X = x, the instantaneous channel gain
M
after combining is given by g(x) = m=1 xm . In order to
verify that this is a T BF, treating x1 as the variable, and
all other arguments as constants, we get g(x1 ; x2 , . . . , xM ) =
M
x1 + k, where k =
m=2 xm . Clearly, g(x1 ; x2 , . . . , xM )
is T BF, since it satisﬁes the conditions of (5) with a = k,
b = 1 and µ(u) = 0. Thus, by deﬁnition, g(x) is in T BF.
Now, since Xm ≤c Ym , m = 1, . . . , M , from Property 5,
we have g(X) ≤c g(Y), which by deﬁnition implies that
E [log (1 + ρg(X))] ≤ E [log (1 + ρg(Y))] , ∀ρ > 0. Thus, if
Y is better than X component-wise, in the capacity order
sense, then the MRC system with fading links given by Y will
be better than that with X, in the capacity ordering sense, at
all SNR.
2) Equal Gain Combining: In this case, the combined in2
√
M
,
stantaneous channel gain is given by g(x) =
m=1 xm
where x is obtained by conditioning on X. In order to
verify that g ∈ T BF, treating x1 as the variable and
all the other arguments of g as constants, we see that
√
M
g(x1 ; x2 , . . . , xM ) = x1 +2 x1 k+k 2 , where k = m=2 xm .

(11)

0

which is a decreasing function of β, as seen by differentiating
with respect to β. Thus, if X and Y are Pareto distributed
with parameters βX ≥ βY , the former is dominated by
the latter in the capacity ordering sense. However, it can
be shown through numerical integration that for βX ≥ βY ,
E [exp(−ρY )] E [exp(−ρX)] , ∀ρ > 0 and thus X Lt Y .
Thus, it is possible that the average error rate of M -QAM
modulation in X is less than that in Y at high SNR, while
the situation reverses when the capacity achieving code is
applied on both channels. Interpreting the ergodic capacity
as what is achievable by coding over an i.i.d. time-extension
of the channel, we reach the conclusion that even though Y
offers more diversity than X for an uncoded system, the i.i.d.
extension of X lends itself to more diversity than that of Y . To
put it more simply, at high SNR, it is possible for one channel
to be superior to another in terms of error rates in the absence
of coding, while being inferior when the capacity achieving
code is employed over both channels.
We now give examples of pairs of RVs X, Y relevant
to wireless communications, for which X ≤c Y holds. In
general, establishing capacity ordering using (10) is often

3

0.9
0.8

Fig. 1. M -hop amplify-forward relay. S represents the source, Rm represent
the relays and D represents the destination.
Ergodic Capacity C(ρ)

0.7

Clearly, g(x1 ; x2 , . . . , xM ) is in T BF, since it satisﬁes the
conditions of (5) with a = k 2 , b = 1 and µ(s) = ks−1/2 /π.
Repeating the same argument with all other arguments of g,
we conclude that g ∈ T BF. Now, following similar arguments
as in the MRC case, we infer that if a set of SISO systems
X1 , . . . , XM is component-wise dominated by Y1 , . . . , YM
in the capacity ordering sense, then the EGC system with
components Y will have a higher ergodic capacity than that
formed using X at all SNR.

0.6
0.5
0.4
0.3
X

C (ρ)
0.2
Y

C (ρ)
0.1
0

2

4

6

8

10

ρ (dB)

B. Multi-Hop Amplify-Forward Relay System

Fig. 2.
Ergodic capacity of amplify-forward relay with M = 3. The
instantaneous SINR is Pareto distributed with parameters βX = 1 and
βY = 3.

We now turn our attention to multi-hop amplify-forward
relay systems, for which we show that in certain types of
fading channels, component-wise ergodic capacity ordering of
instantaneous SNRs results in capacity ordered relay system,
while this does not hold in general. Exact expressions for the
ergodic capacity in arbitrary fading channels are intractable,
even for the two-hop case. Previously, the ergodic capacity
of such a relay in fading channels has been obtained as an
inﬁnite series in [8]. We now show through the framework
of capacity ordering of channels, that even in the absence of
closed-form expressions, it is possible for us to compare the
ergodic capacities of the relay in two different fading channels.

satisﬁed. It is observed from Fig. 2 that for ρ < ρ0 , where
ρ0 ≈ 5 dB, X is a better channel than Y in the capacity
order, while for ρ ≥ ρ0 , the situation is reversed.
C. Multiple Access Channel
In this example, we focus on comparing the ergodic capacity
regions of a multi-user Gaussian MAC network in two different fading scenarios. We consider the case where the number
of users M is deterministic and constant for both the scenarios.
Let Xm , m = 1, . . . , M denote the instantaneous channel
gains between each user and the destination. Conditioned on
X = x, the capacity region is deﬁned by [10, pp. 407]

Consider an M -hop amplify-forward (AF) relay (refer Figure 1), impaired by AWGN with variance σ 2 , where the instantaneous channel gain on the mth link is given by Xm in the
ﬁrst system and Ym in the second system, for m = 1, . . . , M .
Assume that Xm ≤c Ym . In this case, conditioned on the instantaneous channel gain X = x, the end-to-end SNR is given
M
by g(x) = ( m=1 [(1+x−1 )]−1)−1 , when the amplitude gain
m
of the ith relay is given by (xi−1 +σ 2 )−1/2 [9]. In order to see
if g ∈ T BF, treating x1 as the variable and all other arguments
of g as constants, we get g(x1 ; x2 , . . . , xM ) = kx1 /(x1 + k),
where k = g(x2 , . . . , xM ), which is not T BF according to
[6, pp. 218]. However by straight-forward differentiation with
respect to x1 , it is observed that g is a Bernstein function
in x1 . The same justiﬁcation is valid for all other arguments
of g. Therefore, g ∈ BF, but g ∈ T BF. As a result,
/
if the instantaneous channel gains also satisfy the stronger
criterion Xm ≤Lt Ym , m = 1, . . . , M , then, using (9), we
get g(X) ≤Lt g(Y), and therefore g(X) ≤c g(Y). However,
if Xm ≤c Ym , while Xm Lt Ym , m = 1, . . . , M then
g(X) c g(Y). The latter is observed in the case where Xm
and Ym are Pareto distributed with parameters βX ≤ βY . For
example, Fig. 2 illustrates the numerically evaluated ergodic
capacities of a multi-hop relay with M = 3 hops under Pareto
distributed signal-to-interference ratio with parameters βX = 1
and βY = 3, so that for each hop Xm ≤c Ym , m = 1, 2, 3 is

m∈S

Rm (ρxm ) ≤ log (1 + ρgS (x)) ,

(12)

where Rm (ρxm ) represents the instantaneous rate of the mth
{1,...,M }
user, gS (x) :=
. Observing that
S xm and S ⊂ 2
gS (x) is T BF in each variable, for Xm ≤c Ym , m =
1, . . . , M , we can deduce that gS (X) ≤c gS (Y), ∀S ⊂
2{1,...,M } . Thus, the ergodic capacity region of an M -user
Gaussian MAC is bigger in one system than another, when
each user of the ﬁrst system has a higher ergodic capacity
than the corresponding user in the second one.
V. C ONCLUSION
In this paper, we deﬁne a new stochastic order known as the
capacity order and obtain many useful properties, which can be
exploited to obtain comparisons of ergodic capacities of composite systems across two different parametric fading channels,
whose instantaneous SNRs satisfy the capacity order. We show
that Nakagami-m, Rician and Hoyt fading are examples of
such parametric fading distributions which satisfy the capacity
order, each with respect to their line of sight parameters. Using
the capacity order, we see that if a set of fading channels Y

4

is better than another set of fading channels X componentwise in the capacity ordering sense, then the MRC or EGC
system with components Y will have a higher ergodic capacity
than that in X. As another application, we consider the multihop amplify-forward relay, and show that the the ergodic
capacity of the relay is higher in a fading scenario, where the
instantaneous SNRs are component-wise better than another in
the Laplace transform ordering sense. Further, we show that if
the instantaneous SNRs satisfy the capacity order, but not the
Laplace transform order, then the previous conclusion need not
hold. As another important example, we show that the ergodic
capacity region of a multiple access channel is larger, when
the SISO channel between the destination and each user in the
absence of all other users is better.

Proof of Property 3
Let X, Y be non-negative RVs, and g, φ : R+ → R ∈
T BF. Since T BF is closed under compositions, we have φ ◦
g ∈ T BF. Now, from Property 2, for X ≤c Y , we have
E [φ ◦ g(X)] ≤ E [φ ◦ g(Y )]. Since φ ∈ T BF, this implies
g(X) ≤c g(Y ).
To prove the converse, consider g(X) ≤c g(Y ) for g ∈
T BF. Choosing g(x) = x, we get X ≤c Y , which completes
the proof.
Proof of Property 4
This property is easily seen to follow from (9) with g(x) :=
log(1 + x).
Proof of Property 5
This property is proved using mathematical induction. To
begin with, let φ : R → R+ ∈ T BF, and X1:M :=
[X1 , . . . , XM ] have independent and non-negative RVs as
components. Assume likewise for Y1:M := [Y1 , . . . , YM ].
Now, for M = 1, Property 5 is true due to Property 3. Next,
let us assume Property 5 to be true for vectors of length M −1.
Thus, we have g(X1:M −1 ) ≤c g(Y1:M −1 ). This implies

VI. ACKNOWLEDGMENT
This work was supported in part by the National Science
Foundation under Grant CCF 1117041.
A PPENDIX
Proof of Property 1

E [φ (g(X1:M −1 ))] ≤ E [φ (g(Y1:M −1 ))] .

Let X, Y be non-negative RVs, such that X ≤c Y . For ρ >
0, we have (1/ρ)E [log (1 + ρX)] ≤ (1/ρ)E [log (1 + ρX)].
Now, moving the 1/ρ term inside the expectation on both
sides, we take the limit as ρ → 0. The limit and expectation
can be commuted, since E [log (1 + ρX)] ≤ E [X] ∀ρ > 0,
and consequently, the dominated convergence criterion is
satisﬁed. Thus, Property 1 follows.

Proceeding with the proof, for vectors of length M , consider
E [φ (g(X1:M )) |X1 = x] = E [φ (g(x, X2:M ))]

where (18) follows from (17) due to (16). Now, taking the
expectation with respect to X1 on the left hand side of (17) and
the right hand side of (18), we get E [φ (g(X1 , . . . , XM ))] ≤
E [φ (g(Y1 , . . . , YM ))]. Equations (17) and (18) can be repeated by conditioning on all the other RVs to complete the
proof.

Let X and Y be non-negative RVs. Using (5), ∀g ∈ T BF
we can write


∞
X
E [g(X)] = E a + bX + log 1 +
µ(s)ds , (13)
s

R EFERENCES
[1] F. Belzunce and M. Shaked, “Failure proﬁles of coherent systems,”
Naval Research Logistics, vol. 51, p. 477, 2004.
[2] A. M¨ ller and D. Stoyan, Comparison methods for stochastic models
u
and risks. John Wiley & Sons Inc, 2002.
[3] J. Quirk and R. Saposnik, “Admissibility and measurable utility functions,” The Review of Economic Studies, vol. 29, pp. 140–146, 1962.
[4] M. Shaked and J. G. Shanthikumar, Stochastic orders and their applications, 1st ed. Springer, Oct. 1994.
[5] C. Tepedelenlioglu, A. Rajan, and Y. Zhang, “Applications of stochastic
ordering to wireless communications,” IEEE Trans. Wireless Commun.,
vol. 10, pp. 4249 –4257, Dec. 2011.
[6] R. Schilling, R. Song, and Z. Vondraˇ ek, Bernstein functions: theory
c
and applications. Walter de Gruyter, 2010.
[7] M. Pun, V. Koivunen, and H. Poor, “Performance analysis of joint opportunistic scheduling and receiver design for MIMO-SDMA downlink
systems,” IEEE Trans. Commun., vol. 59, pp. 268 –280, january 2011.
[8] O. Waqar, D. McLernon, and M. Ghogho, “Exact evaluation of ergodic
capacity for multihop variable-gain relay networks: A uniﬁed framework for generalized fading channels,” IEEE Trans. Vehicular Technol.,
vol. 59, pp. 4181 –4187, oct. 2010.
[9] M. Hasna and M.-S. Alouini, “End-to-end performance of transmission
systems with relays over Rayleigh-fading channels,” IEEE Trans. Wireless Commun., vol. 2, pp. 1126 – 1131, nov. 2003.
[10] T. Cover and J. Thomas, Elements of information theory. Wiley-India,
1999.

0

for some a, b ≥ 0 and µ(s) ≥ 0, which satisﬁes the convergence conditions. Commuting the expectation and integral in
(13), we get
E log 1 +

X
s

µ(s)ds (14)

E log 1 +

E [g(X)] = a + bE [X] +

Y
s

µ(s)ds

0
∞

≤ a + bE [Y ] +
0

= E [g(Y )] ,

(17)

≤ E [φ (g(x, Y2:M ))] = E [φ (g(Y1:M )) |Y1 = x] , (18)

Proof of Property 2

∞

(16)

(15)

where (15) follows from Property 1 and (14), since X ≤c Y .
To prove the converse, we begin with E [g(X)] ≤ E [g(Y )]
for g ∈ T BF. Choosing g(x) = log(1 + x), which is T BF,
we get X ≤c Y . This concludes the proof.

5

