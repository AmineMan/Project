Title:          ISIT_noisy.pdf
Author:         mrahmati
Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Thu May 17 11:46:01 2012
ModDate:        Tue Jun 19 12:54:35 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      339594 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569566425

On the Capacity of Binary Input Symmetric q -ary
Output Channels with Synchronization Errors
Mojtaba Rahmati and Tolga M. Duman
School of Electrical, Computer and Energy Engineering, Fulton Schools of Engineering
Arizona State University, Tempe, AZ 85287–5706, USA
Email: {mojtaba, duman}@asu.edu
Abstract— In this paper, we develop several lower bounds on
the capacity of binary input symmetric q-ary output channels
with synchronization errors, e.g., substitution/erasure channels
with synchronization errors. More precisely, we show that if a
channel with synchronization errors can be decomposed into a
cascade of two independent channels where only the ﬁrst one
suffers from synchronization errors, a lower bound on its capacity
related to the capacity of the one with only synchronization
errors can be given. We present several examples with the
new approach and demonstrate that for certain channels, e.g.,
deletion/substitution channel, it is possible to derive tighter
capacity lower bounds than the existing ones.

rate for the concatenated channel in terms of the capacity of the
ﬁrst channel (the synchronization error only channel) and the
parameters of the second channel (the memoryless channel).
We then apply the resulting bound to several models of
interest. For instance, we consider Gallager’s deletion channel
concatenated with a binary symmetric channel, and utilize the
tightest available bounds on the deletion-only channel capacity to derive an achievable rate for the deletion-substitution
channel. For certain sets of parameters, the new bounds turn
out to be tighter than the existing ones. The result is general,
and other models for synchronization error channels can also
be employed, e.g., Gallager insertion/deletion model [4] or
models adopted in [2, 5, 6].
There are several papers deriving upper and/or lower bounds
on the capacity of the ins/del channels, e.g., [4, 7–12]; however, there are only a few results on upper and/or lower bounds
on the capacity of the ins/del channels with substitution errors,
e.g., [4, 13, 14]. Hence, our results here will provide a tool to
derive additional results that will help in understanding of the
ins/del channels where the effects of noise are also taken into
account.
The paper is organized as follows. In Section II, we give the
general model for a binary input symmetric q-ary output channel with synchronization errors and present several lemmas
that will be used in the proofs of the main results. Achievable
rates over several speciﬁc channel models are presented in
Section III, where we ﬁrst focus on sub/ers channels with
synchronization errors (sub/ers/synch channels) and binary
input symmetric quaternary output channels, then give our
results for arbitrary values of q. We present several numerical
examples and compare our results with the existing ones in
Section IV. Finally, we conclude the paper in Section V.

I. INTRODUCTION
Synchronization errors represent some of the most important impairments encountered in various digital communication systems, for instance, in bit patterned media recording
systems [1] or in other communication systems where the
transmitter and receiver clocks are not perfectly synchronized.
Different models that can capture the effects of the synchronization errors exist, such as a deletion channel where
transmitted bits get deleted randomly with no knowledge of the
deleted bit positions at the transmitter or at the receiver. Other
models include insertion channels, insertion/deletion channels,
etc. It is also of interest to incorporate the effects of the
additive noise present at the receiver leading to more complicated models, such as insertion/deletion/substitution channels,
or synchronization error channels taking into account additive
white Gaussian noise (AWGN) [2].
In this paper, we consider memoryless binary input symmetric q-ary output channels with synchronization errors.
Dobrushin in [3] proved that Shannon’s theorem applies for
general memoryless channels with synchronization errors in
which every transmitted symbol is independently replaced with
a random number of symbols (including the empty string in
the case of a deletion event), and the transmitter and receiver
have no information about the positions of the synchronization
errors. Speciﬁcally, we consider the concatenation of two
independent channels where the ﬁrst one is a binary channel
with only synchronization errors and the second one is a memoryless binary input symmetric q-ary output channel (BSQC).
As a particular example, the ﬁrst channel can be a binary
insertion/deletion (ins/del) channel and the second one can be
a binary symmetric channel (BSC) or a substitution/erasure
(sub/ers) channel (a ternary output channel q = 3 described
precisely in Section II). We compute an achievable information

II. PRELIMINARIES
A. Channel Model
By channels with synchronization errors we refer to the
general model employed by Dobrushin in [3] where memoryless channels with synchronization errors are described by
a channel matrix allowing for the channel outputs to be of
different lengths for different uses of the channel. Neither the
transmitter nor the receiver have any information about the
position or pattern of the synchronization errors. By a binary
input symmetric q-ary output channel with synchronization
errors, we refer to a channel which can be considered as a
concatenation of two independent channels where the ﬁrst
one is a channel with only synchronization errors with the

This research is funded by the National Science Foundation under the
contract NSF-TF 0830611.

1

H(Y ) = H(Y |M ) + H(M ). Therefore, we can write
H(Y (q) ) − H(Y ) = H(Y (q) |M ) − H(Y |M )
p(m) H(Y (q) |m) − H(Y |m) .

=

(3)

m
(a)

On the other hand, using the deﬁnition of the entropy, we have
⎧
⎞ ⎫
⎛

(b)

H(Y (q) |m)−H(Y |m) = E(Y ,Y (q) )

Fig. 1.
(a) Input-output relation in the substitution/erasure channel
(3)
(P (Yi |Yi ) for all 1 ≤ i ≤ |y|). (b ) Input-output relation in the binary
(4)
input quaternary output channel (P (Yi |Yi ) for all 1 ≤ i ≤ |y|).

⎩

− log ⎝

p Y (q)
p (Y )

⎠ m

H(Y (q) |m) − H(Y |m)
⎛
≥ − log ⎝

y (q) y ,p(y )=0
= − log(f (m)).

(4)

(q)

H(Y (q) |X) ≤ H(Y |X) + E{M }H(Yj |Yj ),

(5)

where Yj denotes the j-th output bit of the synchronization
error channel (input to the binary input q-ary output channel)
(q)
and Yj denotes the corresponding output symbol.
Proof: For the conditional output entropy, we have
H(Y (q) , Y |X)

H(Y |X) + H(Y (q) |Y , X)
H(Y |X) + H(Y (q) |Y ),

(6)
(q)

form

H(Y (q) |X) ≤ H(Y |X) + H(Y (q) |Y ).

(7)

On the other hand, using the fact that by knowing Y , M
is also known, we obtain H(Y (q) |Y ) = H(Y (q) |Y , M ).
Furthermore, since the second channel is memoryless, we can
write
H(Y (q) |Y , M )

p(m)H(Y (q) |Y , M = m)

=
m

(1)

(q)

=

(q)

p(y |y, M )p(y |M ), M
y (q) y ,p(y )=0
is the random variable denoting the length of the received
sequence Y (q) , and EM {.} denotes the expected value with
respect to the random variable M .

p(m)mH(Yj |Yj )
m

=

(q)

E {M } H(Yj |Yj ),

(8)

which concludes the proof.
Proposition 1. Let X, Y and Y (q) form a Markov chain,
i.e., X → Y → Y (q) , if I(X; Y (q) ) ≥ I(X; Y ) + A for
any possible joint distribution of X, Y and Y (q) , where A
is a constant then the capacity of the channels X → Y (q)
(CX →Y (q) ) and X → Y (CX →Y ) satisfy

Proof: For H(Y ), we can write
q

H(Y (q) , M ) − H(M |Y (q) )

=

H(Y (q) |X) + H(Y |Y (q) , X)

where the last equality follows since X → Y → Y
a Markov chain. Therefore, we can write

Lemma 1. In any binary input q-ary output channel with
synchronization errors and for all non-negative integer values
of q, we have

=

=
=

In this section, we give two lemmas and one proposition
which will be useful in the proof of our result on BSQC
channels with synchronization errors. Note that the following
two lemmas hold for any binary input q-ary output channel
with synchronization errors, i.e., channel symmetry is not
required.

where f (M ) =

.

⎞
p(y (q) |m) ⎠
p(y (q) |y, m)p(y|m)
p(y|m)

=

(q)

⎭

By substituting this result into (3), the proof is completed.
Lemma 2. In any binary input q-ary output channel with
synchronization errors and for any input distribution, we have

B. Main Lemmas

H(Y (q) ) ≥ H(Y ) − EM {log (f (M ))} ,

⎬

Using the fact that − log(x) is a convex function of x, we
apply Jensen’s inequality to arrive at

input sequence X and the output sequence Y , and the second
one is a BSQC with the input sequence Y and the output
sequence Y (q) . By a symmetric channel, we refer to the
deﬁnition given in [15, p. 94], i.e., a channel is symmetric
if by dividing the columns of the transition matrix into submatrices, in each sub-matrix, each row can be written as
a permutation of any other row and each column can be
written as a permutation of any other column. For example,
a channel with independent substitution, erasure and synchronization errors (sub/ers/synch channel) can be considered
as a concatenation of a channel with only synchronization
errors and a symmetric substitution/erasure channel (a binary
input ternary output channel) with the output sequence Y (3)
depicted in Fig. 1. a. Similarly a binary input symmetric
quaternary output channel with synchronization errors can be
decomposed into two independent channels such that the ﬁrst
one is a memoryless synchronization error channel and the
second one is a memoryless binary input symmetric quaternary
output channel shown in Fig. 1. b.

H(Y (q) )

⎨

H(Y (q) |M ) + H(M ) − H(M |Y (q) ). (2)

Since by knowing Y (q) , random variable M is also known,
i.e., H(M |Y (q) ) = 0, we obtain H(Y (q) ) = H(Y (q) |M ) +
H(M ). By using the same approach for H(Y ), we obtain

CX →Y (q) ≥ CX →Y + A.

(9)

Proof: Using the input distribution which achieves the

2

capacity of the channel X → Y , P (X), we can write
lim

n→∞

1
I(X; Y (q) (X))
n

≥
=

We note that another lower bound for Cids is given in [4]
as Cids ≥ 1 + pd log pd + pi log pi + pc log pc + pf log(pf ),
where pf = ps (1 − pd − pi ) and pc = (1 − ps )(1 − pd − pi ),
obtained for i.i.d. inputs. However, our result allows us to use
any lower bound on Cid from the literature which potentially
improves on the bound in [4] (studied via speciﬁc examples
in Section IV).
To prove Theorem 1, we need the following two lemmas.

1
I(X; Y (X)) + A
n
CX →Y + A.
(10)
lim

n→∞

Hence, for the capacity of the channel X → Y (q) , we obtain
CX →Y (q) ≥ lim

n→∞

1
I(X; Y (q) (X)) ≥ CX →Y + A.
n

Lemma 3. For a sub/ers/synch channel, for any input distribution, we have

III. M AIN R ESULTS ON ACHIEVABLE R ATES

H(Y (3) ) ≥ H(Y ) − E{M } log (1 − pe )2 + 2p2 .
e

A. Achievable Rates over Substitution/Erasure Channels with
Synchronization Errors

Proof: Using the result of Lemma 1, we only need to
obtain an upper bound on
p(y (3) |y, m)p(y (3) |m)
(3) y ,p(y )=0
y
for all values of m. On the other hand, we have

The following theorem gives a lower bound on the capacity
of the substitution/erasure channels (illustrated in Fig. 1. a)
with synchronization errors (sub/ers/synch channel) in terms
of the capacity of the synchronization error-only channel.

p(y (3) |y, m) =

Theorem 1. The capacity of the sub/ers/synch channel Cses
can be lower bounded by
Cses ≥ Cs − r H(ps , pe , 1 − ps − pe ) + log (1 − pe )2 + 2p2
e

(13)

m

(3)

p(Yi

|Yi ) = pj1 pj2 (1 − ps − pe )m−j1 −j2 ,
e s

i=1

where j1 denotes the number of transitions 0 → − or 1 → −
and j2 denotes the number of transitions 0 → 1 or 1 → 0.
E.g., p(011 − |0000) = p(0|0)p(1|0)p(1|0)p(−|0) = pe p2 (1 −
s
pe − ps ). Furthermore, for a ﬁxed output sequence y (3) of
length m with j1 erased symbols − , there are 2j1 m−j1
j2
possibilities among all m-tuples such that d(y (3) )e = j1 , i.e.,
the number of erased symbols in y (3) , and d(y, y (3) )s = j2 ,
i.e., the number of the positions in y and y (3) in which Yj ’s
are the ﬂipped versions of Yj , therefore we can write

,

(11)

where Cs denotes the capacity of the synchronization errorE {M }
only channel, r = limn→∞
, n and m denote the
n
length of the transmitted and received sequences, respectively.
Before giving the proof of Theorem 1, we consider several
special cases of the result. Since we have considered a
general synchronization error channel model (as deﬁned by
Dobrushin [3]), the derived lower bound, holds for different
models on channels with synchronization errors. A popular
model for channels with synchronization errors is the Gallager
ins/del model1 in which every bit is independently deleted
with probability pd or replaced with two random bits with
probability pi or received correctly with probability 1−pd −pi .
If we employ the Gallager model in deriving the lower bounds,
we obtain r = 1 − pd + pi , and by employing it in (11), we
obtain the following two corollaries.

y ,p(y )=0

p(y (3) |y, m)
m−j1

≤

2j1

=

j2 =0
2j1 pj1 (1
e

m − j 1 j1 j2
pe ps (1 − ps − pe )m−j1 −j2
j2
− pe )m−j1 .

(14)

Note that in deriving the inequality in (4), the summation is
taken over the values of y with p(y) = 0. However, in (14)
the summation is taken over all possible values of y of length
m (over all m-tuples), i.e., p(y) = 0 or p(y) = 0, which
results in the upper bound in (14). Furthermore, by using the
fact that the probability of having j1 erasures in a sequence
m
of length m is equal to j1 pj1 (1 − pe )m−j1 , we obtain
e

Corollary 1. The capacity of the sub/ers channel with
ins/del errors (Gallager’s ins/del errors model) Cseid is lower
bounded by
Cseid ≥ Cid − (1 − pd + pi )[H(ps , pe , 1 − ps − pe )
+ log (1 − pe )2 + 2p2 ],
e

y (3)

where Cid denotes the capacity of the Gallager ins/del channel
with parameters pd and pi .

p(y (3) |m)
≤

Corollary 2. The capacity of the ins/del channel with substitution errors (ins/del/sub channel) Cids can be lower bounded
by
(12)
Cids ≥ Cid − (1 − pd + pi )Hb (ps ).

y ,p(y )=0

y (3)

p(y (3) |y, m)

P (d(y (3) )e = j1 |m)2j1 pj1 (1 − pe )m−j1
e

m

=
j1 =0

m j1
p (1 − pe )m−j1 (2pe )j1 (1 − pe )m−j1
j1 e

= (1 − pe )2 + 2p2
e

1 In

fact, Gallager’s model in general refers to a channel with insertion,
deletion and substitution errors, but with Gallager’s ins/del model we refer to
the case with ps = 0 (i.e., substitution error being zero).

m

.

(15)

By substituting this result into (1), we obtain
H(Y (3) ) − H(Y ) ≥ −E{M } log (1 − pe )2 + 2p2 , which
e

3

TABLE I
TRANSITION PROBABILITIES FOR A BINARY INPUT 5-ARY
OUTPUT CHANNEL.

concludes the proof.
Lemma 4. For a sub/ers/synch channel, for any input distribution, we have

Yj
−1
1

H(Y (3) |X) ≤ H(Y |X) + E {M } H(pe , ps , 1 − pe − ps ).
Proof: For the substitution/erasure channel, we have
(3)

H(Yj |Yj ) = H(pe , ps , 1 − pe − ps ).

By substituting (16) into the result of Lemma 2, the proof is
completed.
We can now complete the proof of the main theorem.
Proof of Theorem 1 : By substituting the results of Lemmas
3 and 4 into the deﬁnition of mutual information, for the same
input distribution used for both synchronization error-only and
sub/ers/synch channels, we obtain
+ log (1 − pe ) +

].

B. Achievable Rates over Binary Input Symmetric Quaternary
Output Channels with Synchronization Errors
Theorem 2. The capacity of the binary input symmetric
quaternary output channel with synchronization errors Csq
can be lower bounded by

p−1
p1

(q)

Yj

=2
p−2
p2

b ∈ {−1, 1} and k = {− q−1 , · · · , −1, 0, 1, · · · , q−1 } by
2
2
(q)
¯
P Yj = k|Yj = b = pkb . For instance, Table III-C shows
transition probabilities for a binary input 5-ary output channel.
The main result on the BSQC channel with synchronization
errors with odd q is a generalized version of the result in
Theorem 1.

Csq ≥ Cs − r H(p1 , p2 , p3 , p4 )
,

=1

We now consider a binary input symmetric q-ary output channel with synchronization errors for an arbitrary
odd value of q, where we represent the transition prob(q)
¯
ability values P Yj = k|Yj = b for different values of

Using the result of Proposition 1, the proof is completed.

+ log (p1 + p3 )2 + (p2 + p4 )2

(q)

Yj

C. Achievable Rates over Binary Input Symmetric q-ary Output Channels with Synchronization Errors (Odd q Case)

I(X; Y (3) ) ≥ I(X; Y ) − E{M }[H(ps , pe , 1 − ps − pe )
2p2
e

= −2
p2
p−2

(q)
Yj

Proof:
Substituting
the
straightforward
result
(4)
H(Yj |Yj ) = H(p1 , p2 , p3 , p4 ) into the result of Lemma 2
concludes the proof.
We can now complete the proof of Theorem 2.
Proof of Theorem 2 : By considering the result of Lemmas 5 and 6, and Proposition 1, the proof follows.

(16)

2

¯
P (Yj |Yj )
(q)
= −1 Yj = 0
p1
p0
p−1
p0
(q)

(q)
Yj

Theorem 3. The capacity of the BSQC channel with synchronization errors CQs for an odd q can be lower bounded by

(17)

where Cs denotes the capacity of the synchronization error
only channel.

CQs ≥ Cs − r H(p− q−1 , · · · , p q−1 )
2

⎛

The speciﬁc result by considering Gallager’s ins/del model
as the synchronization error channel model is given in the
following corollary.

+ log ⎝2p2 +
0

2

q−1
2

⎞
(pk + p−k )2 ⎠ ,

k=1

Corollary 3. The capacity of a binary input symmetric quaternary output channel with ins/del errors Cqid is lower bounded
by

where Cs denotes the capacity of the binary input synchronization error channel.
Proof: The proof of the theorem is given in [16].

Cqid ≥ Cid − (1 − pd + pi )[H(p1 , p2 , p3 , p4 )

+ log (p1 + p3 )2 + (p2 + p4 )2 ]. D. Achievable Rates over Binary Input Symmetric q-ary Output Channels with Synchronization Errors (Even q Case)
To prove Theorem 2, we need the two lemmas below.
In this part, we consider the generalization of the result
Lemma 5. For a binary input quaternary output channel with of Theorem 2 for any even q. For the transition probasynchronization errors, for any input distribution, we have
bilities of the binary input q-ary output channel, we de(q)
(4)
2
2
¯
H(Y ) ≥ H(Y ) − E {M } log (p1 + p3 ) + (p2 + p4 ) . ﬁne P Yj = k|Yj = b = pkb , where b ∈ {−1, 1} and
q
q
k = {− 2 , · · · , −1, 1, · · · , 2 }. For instance, Table III-D shows
Proof: By considering the result of Lemma 1 and followtransition probabilities for a binary input 6-ary output channel.
ing the same procedure as in the proof of Lemma 3, the result
follows (for details see [16]).
The main result on the BSQC channel with synchronization
Lemma 6. For a binary input quaternary output channel with errors for any even q is given in the following theorem.
synchronization errors, for any input distribution, we have
Theorem 4. The capacity of the BSQC channel with synchroH(Y (4) |X) ≤ H(Y |X) + E {M } H(p1 , p2 , p3 , p4 ).
nization errors CQs , for any even q can be lower bounded

4

TABLE III
C OMPARING THE LOWER BOUND DERIVED ON THE CAPACITY OF THE
INS / DEL / SUB CHANNEL WITH EXISTING LOWER BOUNDS ( BOLDFACE
NUMBERS SHOW THE BEST BOUND ).

TABLE II
T RANSITION PROBABILITIES FOR A BINARY INPUT SYMMETRIC 6- ARY
OUTPUT CHANNEL .
Yj
-1
1

(q)
Yj

= −3
p3
p−3

(q)
Yj

= −2
p2
p−2

(q) ¯
P (Yj |Yj )
(q)
= −1 Yj = 1
p1
p−1
p−1
p1

(q)
Yj

(q)

Yj

=2

(q)

Yj

p−2
p2

pd
0.001
0.001
0.001
0.01
0.01
0.01
0.10
0.10
0.10
0.10
0.10

=3

p−3
p3

by
CQs ≥ Cs − r H(p− q , · · · , p−1 , p1 , · · · , p q )
2
2
⎛ q
⎞
+ log ⎝

2

2
(pk + p−k ) ⎠ .

k=1

Proof: See [16] for the details of the proof.
IV. N UMERICAL E XAMPLES
In this section, we give several numerical examples of the
lower bounds on the capacity of the ins/del/sub channel and
compare them with the existing ones in the literature.
In Table III, we compare the lower bound (12) on the
capacity of the ins/del/sub channel with the existing lower
bounds in [4, 13]. We employ the lower bound derived in [9]
as the lower bound on the capacity of the deletion-only channel
and the lower bound in [13] as the lower bound on the capacity
of the ins/del channel in (12). Note that the Gallager’s model
in [4] by parameters pd , pi and pf can be considered as
concatenation of an ins/del channel with parameters pd and pi ,
and a BSC channel with cross over probability of ps where ps
is the solution of pc = (1 − ps )(1 − pd − pi ). The advantage
of the new lower bound (12) is in using the tightest lower
bound on the capacity of the synchronization error channel
in lower bounding the capacity of the overall channel, i.e.,
the information rate of the overall channel is lower bounded
for the input distribution which results in the tightest lower
bound on the capacity of the synchronization error channel.
We observe that for pi = 0, a ﬁxed pd and small values of ps ,
the lower bound (12) improves the one given in [13]. We also
observe that the new lower bound (12) outperforms the lower
bound given in [4], but for the case pi = 0 does not improve
the lower bound given in [13], since as the lower bound on
the capacity of ins/del channel we employ the result in [13]
in the ﬁrst place.

pi
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.10
0.10

ps
0.001
0.01
0.1
0.001
0.01
0.10
0.001
0.01
0.10
0.001
0.01

LB from [4]
0.9772
0.9079
0.5201
0.9079
0.839
0.454
0.5207
0.458
0.108
0.0689
0.013

LB (12)
0.9775
0.9082
0.5204
0.9107
0.842
0.458
0.5514
0.489
0.140
0.1678
0.0984

LB from [13]
0.9773
0.9081
0.5210
0.9091
0.842
0.466
0.5346
0.492
0.211
0.1761
0.139

R EFERENCES
[1] G. Hughes, “Patterned Media,” The Physics of Ultra-High-Density
Magnetic Recording, M. L. Plumer, J. V. Ek, and D. Weller, Eds. Berlin,
Germany: Springer-Verlag, 2001, ch.7.
[2] W. Zeng, J. Tokas, R. Motwani, and A. Kavcic, “Bounds on mutual
information rates of noisy channels with timing errors,” in Proceedings
of IEEE International Symposium on Information Theory (ISIT), 2005,
pp. 709–713.
[3] R. L. Dobrushin, “Shannon’s theorems for channels with synchronization
errors,” Probs. Inf. Transm., vol. 3, no. 4, pp. 11–26, 1967.
[4] R. Gallager, “Sequential decoding for binary channels with noise and
synchronization errors,” Tech. Rep., MIT Lincoln Lab. Group Report,
Oct. 1961.
[5] M. Mitzenmacher, “Capacity bounds for sticky channels,” IEEE Trans.
Inf. Theory, vol. 54, no. 1, pp. 72–77, 2008.
[6] Z. Liu and M. Mitzenmacher, “Codes for deletion and insertion channels
with segmented errors,” IEEE Trans. on Inform. Theory, vol. 56, no. 1,
pp. 224–232, 2010.
[7] M. Rahmati and T. M. Duman, “Analytical lower bounds on the capacity
of insertion and deletion channels,” submitted to IEEE Trans. Inf. Theory,
ArXiv e-prints:1101.1310[cs.IT], Jan. 2011.
[8] E. Drinea and M. Mitzenmacher, “Improved lower bounds for the
capacity of i.i.d. deletion and duplication channels,” IEEE Trans. Inf.
Theory, vol. 53, no. 8, pp. 2693–2714, Aug. 2007.
[9] A. Kirsch and E. Drinea, “Directly lower bounding the information
capacity for channels with i.i.d. deletions and duplications,” IEEE Trans.
Inf. Theory, vol. 56, no. 1, pp. 86 –102, Jan. 2010.
[10] D. Fertonani and T. M. Duman, “Novel bounds on the capacity of the
binary deletion channel,” IEEE Trans. Inf. Theory, vol. 56, no. 6, pp.
2753–2765, June 2010.
[11] Y. Kanoria and A. Montanari, “On the deletion channel with small
deletion probability,” in Proc. IEEE Int. Symp. Information Theory, pp.
1002–1006, June 2010.
[12] A. Kalai, M. Mitzenmacher, and M. Sudan, “Tight asymptotic bounds
for the deletion channel with small deletion probabilities,” in Proc. IEEE
Int. Symp. Information Theory, pp. 997 –1001, June 2010.
[13] D. Fertonani, T. M. Duman, and M. F. Erden, “Bounds on the capacity
of channels with insertions, deletions and substitutions,” IEEE Trans. on
Communications, vol. 59, no. 1, pp. 2–6, Jan. 2011.
[14] J. Hu, T. M. Duman, M. F. Erden, and A. Kavcic, “Achievable information rates for channels with insertions, deletions and intersymbol
interference with i.i.d. inputs,” IEEE Trans. Commun., vol. 58, no. 4,
pp. 1102–1111, Apr. 2010.
[15] R. G. Gallager, Information Theory and Reliable Communication. Wiley, 1968.
[16] M. Rahmati and T. M. Duman, “Achievable rates for noisy channels with
synchronization errors,” submitted to IEEE Trans. Inf. Theory, ArXiv eprints:1203.6396[cs.IT], Mar. 2012.

V. C ONCLUSIONS
We presented several lower bounds on the capacity of
memoryless binary input symmetric q-ary output channels
with synchronization errors. We showed that the capacity
of any channel with synchronization errors which can be
considered as a cascade of two channels (where only the ﬁrst
one suffers from synchronization errors and the second one is
a memoryless channel) can be lower bounded in terms of the
capacity of the ﬁrst channel and the parameters of the second
channel. In particular, we considered binary input symmetric
ternary output (sub/ers) and quaternary output channels with
synchronization errors and generalized the results to the case
of a binary input symmetric q-ary output channels.

5

