Title:          isit_2012_minimax_accepted.pdf
Author:         neko
Creator:         TeX output 2012.05.19:1142
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Sat May 19 11:43:58 2012
ModDate:        Tue Jun 19 12:54:53 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      269563 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569565895

Necessary and Sufﬁcient Conditions for Minimax
Strategy in Quantum Signal Detection
Kentaro Kato
Quantum Communication Research Center
Quantum ICT Research Institute, Tamagawa University
6-1-1 Tamagawa-gakuen, Machida, Tokyo 194-8610 JAPAN
Email: kkatop@lab.tamagawa.ac.jp
Abstract—The necessary and sufﬁcient conditions for the
minimax strategy of a ﬁnite number of decisions in quantum
signal detection are derived in the case that the average Bayes
cost is used as a quality function. This is a simple extension of
the result of Hirota and Ikehara [1]. Applying the necessary and
sufﬁcient conditions, a closed-form expression of the minimax
strategy for binary pure state signal is shown. Furthermore, the
minimax strategy for a discrimination problem of the quasi-Bell
states is considered. In this case, the square-root measurement
consisting of the quasi-Bell states yields the minimax strategy.

well-developed and the necessary and sufﬁcient conditions
play a central role in such studies.
Here we take another scenario that the receiver does not
know the probability distribution of the states. In this scenario,
one can apply the so-called minimax strategy. With this
approach, D’Ariano et al. showed some basic properties of
minimax discrimination [16] and discussed its application to
the discrimination problem of two Pauli channels [17]. Hirota
and Ikehara attempted to derive the necessary and sufﬁcient
conditions for the minimax strategy in the case that the average
probability of decision error is used as a quality function [1].
However the set of the conditions shown in the reference
[1] works only when every resulting ‘minimax’ probability is
strictly positive. Therefore the aim of this paper is to derive the
necessary and sufﬁcient conditions for the minimax strategy
in a general form.

I. I NTRODUCTION
The statistical decision theory of quantum system has been
extensively discussed since the pioneering works by Helstrom
[2], Yuen et al. [3], [4] and Holevo [5]. It treats the problems of
optimal measurement of quantum states, using an appropriate
quality function such as the average probability of decision
error. Suppose that there are a ﬁnite number of quantum
states. In many of the cases investigated so far, one takes a
scenario that the receiver knows the probability distribution
of the quantum states and the average probability of decision
error is used as a quality function. From the point of view of
the statistical decision theory, the minimization problem of the
average probability of decision error is a special case of the
minimization problem of the average Bayes cost. An optimal
decision rule that minimizes the average Bayes cost under the
assumption that the receiver knows the probability distribution
of the states is called the Bayes strategy. For the Bayes strategy, Holevo derived the necessary and sufﬁcient conditions
by considering inﬁnitesimal transformations of the detection
operators [5]. On the other hand, Yuen et al. had remarked
this type of problems can be solved by using the principle
of duality in vector space optimization [3], [4]. To this end,
Holevo proved the duality relation for the Bayes strategy [6].
Eldar et al. also showed that a semideﬁnite programming
method is valid for deriving the necessary and sufﬁcient
conditions; moreover, they developed an efﬁcient numerical
computation algorithm for ﬁnding the optimal measurement,
based on the duality argument [7]. Although it is difﬁcult
to ﬁnd an explicit form of the Bayes strategy in general,
many closed-form expressions of the Bayes strategy have been
shown ([8], [9], [10], [11], [12], [13], [14], [15], etc.), using
the necessary and sufﬁcient conditions for the Bayes strategy.
Thus the Bayes strategy in quantum signal detection has been

II. P ROBLEM FORMULATION AND EXISTENCE OF A
SOLUTION

Suppose that there are M hypotheses about states of a
quantum system and the ith hypothesis Hi is the proposition
that the system is in the state ρi , where ρi is a density operator
ˆ
ˆ
on Hilbert space H, that is, ρi ≥ 0 and Trˆi = 1. The prior
ˆ
ρ
probability of hypothesis Hi is denoted by pi . We let
ˆ ˆ
ˆ
Π = (Π1 , Π2 , . . . , ΠM ),

(1)

be a positive operator-valued measure consisting of M detection operators, where
ˆ
Πj ≥ 0 ∀j,

M

ˆ
Πj = ˆ
1,

(2)

j=1

and ˆ is the identity operator on H. Then the conditional
1
probability that the receiver chooses Hj when Hi is true is
given by P (j|i) = Trˆi Πj . The cost incurred by choosing
ρ ˆ
Hj when Hi is true is denoted by Bji , which is a nonnegative number. In general, Bji > Bii if i = j. Letting
ˆ ˆ
P (i, j) = pi TrΠj ρi , the expected value of the costs is given
by
¯
B(Π, p) = E[Bji ] =

M

M

Bji P (i, j),
i=1 j=1

1

(3)

where p = (p1 , p2 , . . . , pM ). Deﬁning the risk operators by
ˆ
Wi =

where 0 ≤ t ≤ 1, and, for ﬁxed Π,

M

pk Bik ρk ,
ˆ

1 ≤ i ≤ M,

¯
¯
¯
B(Π, tp + (1 − t)p ) = tB(Π, p) + (1 − t)B(Π, p ). (17)

(4)

Thus, the average Bayes cost is afﬁne for p and for Π,
respectively. Moreover, since the mapping from D to the set
ˆ ˆ
of all the channel matrices, {(P (j|i))} = {(TrΠj ρi )}, is an
¯
afﬁne continuous mapping [5], B(Π, p) can be regarded as
a continuous convex function of Π for ﬁxed p. At the same
time, it can also be regarded as a continuous concave function
of p for ﬁxed Π. By virtue of the minimax theorem in convex
analysis [18], we obtain the next lemma:
Lemma 1: There exist Π ◦ and p◦ such that

k=1

this average Bayes cost is rewritten as
¯
B(Π, p) = Tr

M

ˆ ˆ
W k Πk .

(5)

k=1

Then the Bayes problem in quantum signal detection is expressed as follows:
¯
min B(Π, p),

(6)

Π∈D

¯
¯
¯
min max B(Π, p) = B ◦ = max min B(Π, p),

where we assume that p is given and where
ˆ
ˆ
D = Π = ( Π1 , . . . , Π M ) ,

Π∈D p∈P

(7)

p∈P Π∈D

(18)

the set of all decision rules consisting of M decision operators.
For this problem, it has been proved [5] that there exists an
optimal decision rule Π bayes such that

¯
¯
where B ◦ = B(Π ◦ , p◦ ).
In what follows we call Π ◦ the minimax strategy, p◦ the
¯
minimax distribution, and B ◦ the minimax value. Note that
◦
p is not necessary to be identical to the true distribution.

¯
¯
min B(Π, p) = B(Π bayes , p).

III. N ECESSARY AND S UFFICIENT C ONDITIONS FOR THE

Π∈D

(8)

MINIMAX STRATEGY

This decision rule Π bayes is called the Bayes strategy, and
the necessary and sufﬁcient conditions for the Bayes strategy
are given as follows [5] (See also [6], [7]): A decision rule
ˆ bayes , Π bayes . . . , Π bayes ) is the Bayes strategy
ˆ
ˆ
Π bayes = (Π1
2
M
at p if and only if
ˆ bayes (Wi − Wj )Π bayes
ˆ
ˆ ˆ
Πi
j
ˆ i − Υ bayes
ˆ
W

= 0
≥

∀(i, j),

0 ∀i,

In the previous section we have seen the existence of the
minimax strategy and the minimax distribution. Our next task
is to characterize such solutions by its necessary and sufﬁcient
conditions, like in the case of the Bayes strategy.
Let p◦ be an optimal distribution and Π ◦ an optimal
decision rule in terms of minimax strategy. Since

(9)
(10)

¯
¯
min B(Π, p◦ ) = Bmin (p◦ ),

Π∈D

where
ˆ bayes

Υ

M

=
k=1

ˆ ˆ bayes .
W k Πk

Π ◦ is the Bayes strategy at p◦ . Hence the conditions (9) and
(10) must be satisﬁed. On the other hand, we have

(11)

¯
¯
max min B(Π, p) = max Bmin (p).

At that time, the minimum average Bayes cost at p is
¯
¯
ˆ
Bmin (p) = min B(Π, p) = TrΥ bayes .
Π∈D

p∈P Π∈D

¯
∂ Bmin (p◦ )
∂p◦
i

≥

¯
¯
tBmin (p) + (1 − t)Bmin (p ).

M

(14)

=

(20)

ˆ◦ˆ
Bji TrΠj ρi

=

(13)

Take two probability vectors p and p in P. Letting p =
tp + (1 − t)p with parameter 0 ≤ t ≤ 1, we obtain
¯
Bmin (p )

p∈P

¯
Since Bmin (p) is concave, the distribution p◦ is optimal if
and only if the conditions

(12)

Let P be the set of all probability vectors:
P = {p = (p1 , . . . , pM )} .

(19)

λ ∀i s.t. p◦ > 0,
i

j=1

(21)

and

¯
That is, Bmin (p) is a concave function of p over P.
From this point, we move our attention to the minimax
problem in quantum signal detection. We assume that the true
probability distribution of the M quantum states is unknown.
Under this assumption, we consider the following optimization
problem.
¯
min max B(Π, p).
(15)

¯
∂ Bmin (p◦ )
∂p◦
i

M

=
j=1

≤

λ

ˆ◦ˆ
Bji TrΠj ρi
∀i s.t. p◦ = 0
i

(22)

hold for some constant λ [19]. Multiplying Eq. (21) by p◦ ,
i
and summing over i, we obtain

Π∈D p∈P

M

Recall that the set P is a bounded and closed convex set, and
the set D is a convex compact set [5]. For ﬁxed p,

M

λ=

ˆ◦ˆ
ˆ
p◦ Bji TrΠj ρi = TrΥ ◦ .
i

(23)

i=1 j=1

¯
¯
¯
B(tΠ + (1 − t)Π , p) = tB(Π, p) + (1 − t)B(Π , p), (16)

Summarizing the above, we obtain the following theorem.

2

Theorem 2: Necessary and sufﬁcient conditions for the
minimax distribution and minimax strategy are
ˆ◦ ˆ
ˆ ˆ◦
Πi (Wi◦ − Wj◦ )Πj
ˆ
ˆ
W◦ − Υ◦
M

i

ˆ◦ˆ
Bji TrΠj ρi

=

0

∀(i, j),

0

∀i,

(25)

=

ˆ
TrΥ ◦

Let us consider the discrimination problem between nonorthogonal pure states ρ1 = |ψ1 ψ1 | and ρ2 = |ψ2 ψ2 | such
ˆ
ˆ
that ψ1 |ψ2 = κeiθ , where 0 < κ < 1, 0 ≤ θ < 2π and i =
√
−1. Then the average Bayes cost is written in the following
form.

(24)

≥

IV. M INI - MAX DISCRIMINATION FOR BINARY PURE STATES

∀i s.t. p◦ > 0,
i

(26)

¯
B(Π, p) = p1 B11 + p2 B22 + p1 Bα α + p2 Bβ β,

j=1
M

ˆ◦ˆ
Bji TrΠj ρi

ˆ
TrΥ ◦

≤

∀i s.t. p◦ = 0,
i

where we have set

(27)

ˆ ˆ
α = P (2|1) = TrΠ2 ρ1 ,

j=1

where
ˆ
Wj◦
ˆ
Υ◦

M

=
k=1
M

=

p◦ Bjk ρk
ˆ
k

B11
B22

(28)
ˆ ◦ ˆ◦
W k Πk .

i

where
ˆ
Γ◦ =

=

0

∀(i, j),

(29)

≥

0

∀i,

(30)

=
≥
M

ˆ
TrΓ ◦
ˆ
TrΓ ◦

∀i s.t. p◦ > 0, (31)
i
∀i s.t.

p◦
i

ˆ◦
p◦ ρk Πk .
kˆ

= 0, (32)

0,
0,

Bα
Bβ

=
=

(37)

B21 − B11 > 0,
B12 − B22 > 0.

ˆ bayes = U |μ2 μ2 |U † ,
ˆ
ˆ
Π2

(38)

with the square-root measurement [8], [22], [23]
=
=

|μ1
|μ2

(33)

whose entries are
1
r11 =
2
1
r12 =
2

¯◦
ˆ
Moreover, the minimax value is given as Pe = 1 − TrΓ ◦ .
Let q = (q1 , q2 , . . . , qM ) denote the true probability distribution of the states, and recall that we have assumed that
the receiver does not know q. As mentioned in the end of the
previous section, the minimax distribution p◦ is not necessary
to be identical to the true distribution q. If p◦ = q, then
¯
¯
we have B(Π ◦ , q) = Bmin (q). That is, the minimax strategy
is the best decision rule in this case. However, if there is
a mismatch between p◦ and q, the receiver has to pay the
¯
¯
penalty B(Π ◦ , q)−Bmin (q) as far as the minimax strategy Π ◦
is used. But such a penalty has an upper bound. The following
lemma tells that the minimax value is an upper bound of the
penalty.
ˆ◦ ˆ◦
ˆ◦
Lemma 3: Let Π ◦ = {Π1 , Π2 , . . . , ΠM } be the minimax
◦
◦ ◦
strategy , and let p = (p1 , p2 , . . . , p◦ ) be the minimax
M
distribution. Then we obtain
∀q ∈ P.

≥
≥

ˆ bayes = U |μ1 μ1 |U † ,
ˆ
ˆ
Π1

k=1

¯
¯
¯
Bmin (q) ≤ B(Π ◦ , q) ≤ B ◦

(36)

In this case, we can obtain the minimum average Bayes cost
and its optimal detection operators by solving the eigenvalue
problem of ρ2 − ζ ρ1 , where ζ = (p1 Bα )/(p2 Bβ ) [2], [20].
ˆ
ˆ
If p = (1, 0), then the Bayes strategy is the so-called
ˆ
ˆ bayes = ρ1 and Π bayes =
ˆ
Kennedy receiver [21] given by Π1
2
¯
ˆ − ρ1 , and the minimum average Bayes cost is Bmin (1, 0) =
1 ˆ
ˆ bayes = ˆ − ρ2 and
B11 . Similarly, if p = (0, 1), then Π1
1
ˆ
ˆ bayes = ρ2 , and Bmin (0, 1) = B22 .
¯
Π2
ˆ
If 0 < p1 < 1, then the Bayes strategy at p = (p1 , p2 ) is
given by

¯
ˆ
The minimax value is given by B ◦ = TrΥ ◦ .
Corollary: Let Bji = 1 − δji , where δji is the Kronecker
delta. Then the average Bayes cost becomes the average prob¯
ability of decision error, Pe (p, Π). In this case, the conditions
(24)-(27) are simpliﬁed to

ˆ◦ˆ
TrΠi ρi
ˆ◦ˆ
TrΠi ρi

ˆ ˆ
β = P (1|2) = TrΠ1 ρ2 ,

and

∀j,

k=1

ˆ◦ i ˆ
ˆ◦
Πi (p◦ ρi − p◦ ρj )Πj
jˆ
ˆ
Γ ◦ − p◦ ρi
ˆ

(35)

r11 |ψ1 + r21 |ψ2 ,
r12 |ψ1 + r22 |ψ2 ,

1
1
+√
1+κ
1−κ
1
1
√
−√
1+κ
1−κ
√

(39)

= r22 ,
∗
eiθ = r21 ,

(40)

and with the unitary operator
ˆ
U

=

u11 |μ1 μ1 | + u21 |μ1 μ2 |
+u12 |μ2 μ1 | + u22 |μ2 μ2 |,

(41)

whose entries are
u11

=

u21

√
Λ + (1 + ζ) 1 − κ2
= u22 ,
√
2Λ2 + 2(1 + ζ)Λ 1 − κ2
κ(1 − ζ)eiθ
= −u∗ ,
12
√
2 + 2(1 + ζ)Λ 1 − κ2
2Λ

=

(42)

where ∗ stands for the complex conjugate and Λ =
(1 + ζ)2 − 4ζκ2 . In this case, the conditional probabilities
α and β are given by

(34)

¯
¯
If p◦ > 0 for all i, then B(Π ◦ , q) = B ◦ for any q in P.
i
Thus, the average Bayes cost of the minimax strategy
¯
never exceeds the minimax value B ◦ even if the minimax
distribution p◦ is not equal to the true probability distribution
¯
q. Moreover, it is immediate from Eq.(34) that B(Π ◦ , q) −
¯
¯
Bmin (q) ≤ B ◦ .

α
β

3

=
=

1 (1 + ζ) − 2κ2
−
,
2
2Λ
1 (1 + ζ) − 2ζκ2
−
.
2
2Λ

(43)
(44)

Hence the minimum average Bayes cost is
¯
Bmin (p) =

p1 B11 + p2 B22 + p1

Bα
Bβ
+ p2
2
2

where
YΔ
ZΔ
Δ

(45)

1
(p1 Bα + p2 Bβ )2 − 4p1 p2 Bα Bβ κ2 .
−
2
Using the necessary and sufﬁcient conditions (24)-(27), we
can obtain the following solutions to the binary pure-state
minimax problem.
Case 1: In the case of B11 = B22 , it is found that 0 < p◦ < 1.
1
Hence by the condition (26), the minimax distribution is given
by
F1 − Y
F2 + Y
p◦ =
, p◦ =
,
(46)
1
2
X
X
where
2
F1 = Bβ − Bα Bβ (1 − 2κ2 ),
2
F2 = Bα − Bα Bβ (1 − 2κ2 ),
(47)
2
2
X = Bα + Bβ − 2Bα Bβ (1 − 2κ2 ),
Y = (Bβ − Bα ) Bα Bβ (1 − κ2 ).

u◦
12
u◦
22

where

K
L
Ξ

(49)

B11 +

B11 − B22
,
Bβ

F1
YΔ
,
−
X
XZΔ

p◦ =
2

F2
YΔ
,
+
X
XZΔ

Δ

Δ

Δ

(55)

Bα (F1 ZΔ − YΔ ),
Bβ (F2 ZΔ + YΔ ),
(KΔ + LΔ )2 − 4KΔ LΔ κ2 .

(56)

B11 − B22
,
Bβ

(58)

ˆ◦
¯
ˆ ˆ
then p◦ = 1, p◦ = 0, Π1 = ρ1 , Π2 = 1 − ρ1 , and B ◦ =
ˆ ˆ◦
1
2
◦
◦
B11 . It is easy to verify that the solution (Π , p ) satisﬁes
ˆ
the conditions (26) and (27). Since Υ ◦ = B11 ρ1 , we obtain
ˆ
ˆ ◦ = B11 . For i = 1, the left-hand side of Eq. (26) is equal
TrΥ
to B11 . For i = 2, the left-hand side of Eq. (27) is B22 +Bβ κ2 .
Since κ satisﬁes the condition (58) and 0 < κ < 1, we obtain
B22 +Bβ κ2 ≤ B11 . Using the solution, the average Bayes cost
by the minimax strategy at an arbitrary probability distribution
p is
¯
¯
B(Π ◦ , p) = p1 B11 + p2 (B22 + Bβ κ2 ) ≤ B11 = B ◦ . (59)
Case 3a: Suppose that B11 < B22 . If
B22 − B11
,
(60)
Bα
then the minimax distribution, the optimal parameters for the
minimax strategy, and the minimax value are given by Eqs.
(53) (55), and (57), respectively.
Case 3b: Suppose that B11 < B22 . If
κ>

B22 − B11
,
(61)
Bα
ˆ◦ ˆ ˆ ˆ◦ ˆ
¯
then p◦ = 0, p◦ = 1, Π1 = 1 − ρ2 , Π2 = ρ2 , and B ◦ = B22 .
1
2
The average Bayes cost by the minimax strategy is

(52)

κ≤

then 0 < p◦ < 1. From the condition (26), the minimax
1
distribution is given by
p◦ =
1

=
=
=

κ≤

= Bα (F1 Bα Bβ − Y ),
= Bβ (F2 Bα Bβ + Y ),
= (K + L)2 − 4KL.

κ>

Δ

Therefore the minimax value is
B11 F1
B22 F2
¯
B◦ =
+
(57)
X
X
√
2
2
(Bα Bβ + Bα Bβ )κ2 − 2Bα Bβ ZΔ κ 1 − κ2
+
,
X
¯
¯
and B(Π ◦ , p) = B ◦ by Lemma 3.
Case 2b: Suppose that B11 > B22 . If

2
2
(Bα Bβ + Bα Bβ )κ2
(50)
X
√
2Bα Bβ Bα Bβ κ2 1 − κ2
,
−
X
¯
¯
and B(Π ◦ , p) = B ◦ by Lemma 3. Particularly, if B21 = B12 ,
the result is simpliﬁed to
√
2
1
◦
◦
¯ ◦ = B11 + Bα 1 − 1 − κ ,
p1 = p2 = , B
(51)
2
2
and the minimax strategy is given by the square-root measurement of Eq. (39).
Case 2a: Suppose that B11 > B22 . If

=

−(u◦ )∗ ,
21
u◦ ,
11

KΔ
LΔ
ΞΔ

Consequently, the minimax value is
¯
B◦

=
=

where

−(u◦ )∗ ,
21
u◦ ,
11

=
=

(54)

Moreover, the minimax strategy is given by the following
parameters.
√
√
1
(KΔ + LΔ ) 1 − κ2 + ΞΔ
◦
u11 = √ ·
,
2
ΞΔ + (KΔ + LΔ ) ΞΔ (1 − κ2 )
(−KΔ + LΔ )eiθ κ
1
u◦ = √ ·
,
21
2
Ξ + (K + L ) Ξ (1 − κ2 )

Substituting this minimax distribution into Eqs.(38)-(42), we
can obtain the minimax strategy. At that time, the parameters
u◦ are given by
ij
√
√
(K + L) 1 − κ2 + Ξ
1
◦
u11 = √ ·
,
2
Ξ + (K + L) Ξ(1 − κ2 )
(−K + L)eiθ κ
1
(48)
u◦ = √ ·
,
21
2
Ξ + (K + L) Ξ(1 − κ2 )
u◦
12
u◦
22

√
(Bβ − Bα − 2Δ)Bα Bβ κ 1 − κ2 ,
(Bβ − Bα )Δ − Δ2 + Bα Bβ κ2 ,
B11 − B22 .

=
=
=

¯
¯
B(Π ◦ , p) = p1 (B11 + Bα κ2 ) + p2 B22 ≤ B22 = B ◦ . (62)

(53)

4

V. M INI - MAX STRATEGY VERSUS SQUARE - ROOT

and the minimax distribution is given by

MEASUREMENT

p◦ =

Various types of the set of quantum states have been investigated in the context of the minimum-error discrimination
problem so far. Especially, it is found that, if the set of
quantum states has a certain symmetry, the optimal decision
rule that minimizes the average probability of decision error at the uniform distribution is given by the square-root
measurement; e.g., ‘equidiagonal’ cases of the set of pure
states [8], ‘symmetric quantum states’ [9] and its extension
[10], ‘geometrically uniform (pure/mixed) states’ [11], [12],
‘doubly symmetric mixed states’ [13], a pure state case of
‘ZN -symmetric states’ [14], linear codeword states [15], and
so on. In each of such cases, the square-root measurement
satisﬁes not only the conditions (29) and (30), also the
condition (31). Therefore, in those symmetric cases treated
in the references listed above, the minimax strategy is the
square-root measurement, and the minimax distribution is the
uniform distribution.
Here we add a new example to the list of the examples
in which the square-root measurement yields the minimax
strategy.
Let us consider the minimax discrimination problem of
the following four pure states ρi = |Hi Hi |, under the
ˆ
assumption that Bji = 1 − δji .
|H1

=

|H2

=

|H3

=

|H4

=

1
2(1 + κ2 )
1
2(1 − κ2 )
1
2(1 + κ2 )
1
2(1 − κ2 )

1
¯◦
Pe =
1 − 1 − D2 .
2
VI. C ONCLUSION

=
=
=
=

R EFERENCES
[1]
[2]
[3]
[4]
[5]
[6]

|α |−α − |−α |α ,
(63)

[7]

|α |α − |−α |−α ,

C|Φ1 + S|Φ3 ,
|Φ2 ,
S|Φ1 + C|Φ3 ,
|Φ4 ,

[8]
[9]
[10]
[11]
[12]
[13]
[14]
[15]
[16]
[17]

(64)

[18]
[19]

where

C
S
D

=
=
=

√
√
√1 + D + √1 − D /2,
1 + D − 1 − D /2,
2κ/(1 + κ2 ).

[20]
[21]

(65)

[22]
[23]

For these states, the minimax strategy is given by the squareroot measurement
ˆ◦
Πj = |Φj Φj |,

1 ≤ j ≤ 4,

(68)

The necessary and sufﬁcient conditions for the minimax
strategy of a ﬁnite number of decisions in quantum signal
detection were derived in the case that the average Bayes
cost is used as a quality function. In this paper, the set of
the necessary and sufﬁcient conditions is shown in Eqs.(24)(27). The ﬁrst two conditions, (24) and (25), come from
the Bayes optimality, so that one may replace them to an
equivalent statement in order to simplify the set of necessary
and sufﬁcient conditions. For instance, the condition (24) may
be removed [6] (See also [25]). To illustrate the utility of
the necessary and sufﬁcient conditions, two examples were
considered. For the binary pure-state case, explicit expressions
of the minimax strategy, minimax distribution, and minimax
value were respectively given. For the quasi-Bell states, it was
shown that the square-root measurement yields the minimax
strategy in terms of the average probability of decision error.

where κ = α|−α and |α stands for the coherent state
of light having amplitude α. These states are called the
quasi-Bell states [24]. Since |Hi are linearly independent,
ˆ
{|Φi = G−1/2 |Hi : 1 ≤ i ≤ 4} is an orthonormal basis for
4
ˆ
H under consideration, where G = i=1 |Hi Hi |. Using the
vectors in this basis, the states are respectively rewritten into
the following form.
|H1
|H2
|H3
|H4

(67)

As a consequence, the minimax value is

|α |−α + |−α |α ,

|α |α + |−α |−α ,

1
1
, 0, , 0 .
2
2

[24]
[25]

(66)

5

O. Hirota and S. Ikehara, Trans. IECE of Japan E65, 627 (1982).
C. W. Helstrom, Inform. Contr. 10, 254 (1967).
H. P. Yuen, R. S. Kennedy, and M. Lax, Proc. IEEE 58, 1770 (1970).
H. P. Yuen, M.I.T. Res. Lab. Electron. Tech. Rep. 482, (1971).
A. S. Holevo, J. Multivar. Analys. 3, 337 (1973).
A. S. Holevo, Probl. Peredachi Inf. 10, 51 (1974); English transl.,
Probl. Inform. Transm. 10, 317 (1976).
Y. C. Eldar, A. Megretski, and G. C. Verghese, IEEE Trans. Inform. Theory 49, 1007 (2003).
V. P. Belavkin, Stochastics 1, 315 (1975).
M. Ban, K. Kurokawa, M. Momose, and O. Hirota, Int. J. Theor. Phys.
36, 1269 (1997).
S. M. Barnett, Phys. Rev. A 64, 030303(R) (2001).
Y. C. Eldar, and D. Forney, Jr., IEEE Trans. Inform. Theory 47, 858
(2001).
Y. C. Eldar, A. Megretski, and G. C. Verghese, IEEE Trans. Inform. Theory 50, 1198 (2004).
K. Kato, and O. Hirota, IEEE Trans. Inform. Theory 49, 3312 (2003).
C. -L. Chou, and L. -Y. Hsu, Phys. Rev. A 68, 042305 (2003).
T. S. Usuda, I. Takumi, M. Hata, and O. Hirota, Phys. Lett. A256, 104
(1999).
G. M. D’Ariano, M. F. Sacchi, and J. Kahn, Phys. Rev. A 72, 032310
(2005).
G. M. D’Ariano, M. F. Sacchi, and J. Kahn, Phys. Rev. A 72, 052302
(2005).
I. Ekeland and R. T´ man, Convex Analysis and Variational Problems,
e
(SIAM, 1999).
R. G. Gallager, Information Theory and Reliable Communication, (Willey, New York, 1968).
M. Ban, M. Osaki, and O. Hirota, Phys. Rev. A 54, 2718 (1996).
R. S. Kennedy, M.I.T. Res. Lab. Electron. Quart. Progr. Rep. 108, 219
(1973).
P. Hausladen, and W. K. Wootters, J. Mod. Opt. 41, 2385 (1994).
P. Hausladen, R. Jozsa, B. Schumacher, M. Westmoreland, and
W. K. Wootters, Phys. Rev. A 54, 1869 (1996).
O. Hirota, S. J. van Enk, K. Nakamura, M. Sohma, and K. Kato, ArXiv
e-print quant-ph/0101096.
S. M. Barnett, and S. Croke, J. Phys. A 42, 062001 (2009).

