Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Wed May 16 19:06:40 2012
ModDate:        Tue Jun 19 12:55:08 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      538779 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569561579

New Achievable Rates for Nonlinear Volterra
Channels via Martingale Inequalities
Kostis Xenoulis

Igal Sason

Nicholas Kalouptsidis

Department of Informatics & Telecommunications
National and Kapodistrian University of Athens
Athens 15784, Greece
E-mails: {kxen, kalou}@di.uoa.gr

Department of Electrical Engineering
Technion-Israel Institute of Technology
Haifa 32000, Israel
E-mail: sason@ee.technion.ac.il

such nonlinear communication channels are derived in this
paper, based on some reﬁned versions of the Azuma-Hoeffding
inequality from [7], [8] and [9] which provide improvements
over the exponential martingale inequalities that were used
in [6]. The resulting new expressions of achievable rates
are exempliﬁed in this work for linear and non-linear timeinvariant channel models.
The paper is structured as follows. Section II provides new
bounds on the error probability and achievable rates under
ML decoding. These bounds are exempliﬁed in Section III to
time-invariant linear channels with memory and memoryless
non-linear channels. These comparisons show a signiﬁcant improvement over the results reported in [6]. Finally, Section IV
concludes our discussion.

Abstract—This paper establishes new achievable rates for nonlinear Volterra communication channels using reﬁned versions
of the Azuma-Hoeffding inequality. The characteristics of these
rates are illuminated in special cases of interest that include timeinvariant linear channels with memory, memoryless non-linear
channels, and Volterra channel models.

I. I NTRODUCTION
Nonlinear effects are typically encountered in wireless communication systems and optical ﬁbers, which degrade the quality of the information transmission. In satellite communication
systems, the ampliﬁers located on board satellites typically
operate at or near the saturation region in order to conserve
energy. Saturation nonlinearities of ampliﬁers introduce nonlinear distortion in the transmitted signals. Similarly, power
ampliﬁers in mobile terminals are designed to operate in a nonlinear region in order to obtain high power efﬁciency in mobile
cellular communications. In optical ﬁbers [1], dispersion noise
and nonlinearities need to be overcome with advanced signal
processing techniques. Nonlinear communication channels can
be represented by Volterra models [2, Chapter 14]. Analytical
foundations of the Volterra series operator were presented in
[3]. The optical ﬁber channel has been alternately studied by
Poisson type models in [4].
Random coding theorems (see, e.g, [5, Chapter 5.5] constitute critical performance measures of coded information
transmission since they describe the exponential behavior of
the decoding error probability. The main difﬁculty in the
derivation of calculable closed-form upper bounds on the
average decoding error probability when transmission takes
place over non-linear channels stems mainly from the difﬁculty
of obtaining the channel output probability density function.
Previous work on the analysis of coded communication for
Volterra channel models is presented, e.g., in [2, Chapter 14.5]
and references therein.
Error probability bounds and achievable rates for Volterra
channel models were recently developed in [6] using exponential martingale inequalities. Improved achievable rates for

II. N EW B OUNDS ON THE E RROR P ROBABILITY AND
ACHIEVABLE R ATES UNDER ML D ECODING
Under the random coding setup in [5, Section 5.5], consider
an ensemble of block codes C where N is the block length,
and R is the code rate in nats per channel use. The codewords
of a codebook from this ensemble are assumed to be selected
independently, and the symbols in each codeword are also
assumed to be i.i.d. with an arbitrary probability assignment
Q. Let M = exp(N R) be the cardinality of the considered
codebook C from the ensemble C. Assume that the relation
between the transmitted codeword u = (u1 , . . . , uN ) ∈ C and
the discrete-time channel output y = (y1 , . . . , yN ) is given by
the equality
y = Du + ν

(1)

where ν = (ν1 , . . . , νN ) is an additive channel noise vector,
and D denotes an operator describing the (linear or nonlinear) communication channel without the additive noise. The
Volterra operator D of order L and memory q is characterized
by the equality (see [6, Eq. (4)])
L

q

[Du]i = h0 +
This research has been co-ﬁnanced by the European Union (European
Social Fund-ESF) and Greek national funds through the Operational Program
“Education and Lifelong Learning” of the National Strategic Reference Framework (NSRF)-Research Funding Program: Thales. Investing in knowledge
society through the European Social Fund.

q

hj (i1 , . . . , ij )ui−i1 · · · ui−ij

...
j=1 i1 =0

ij =0

for i ∈ {1, . . . , N } and, in the above equation, ui
0 for
i ≤ 0. The codeword symbols {ui } are assumed to take values

1

l
Zi given Fi−1 , with respect to any realization of the ﬁltration
Fi−1 .
For the special case where l = 2 it is noted that

in a ﬁnite subset R. Hence, there exits some r > 0 such that
u

max |ui | < r, ∀u ∈ C

∞

(2)

1≤i≤N

and consequently

2
E Zi Fi−1 = Var(Zi |Fi−1 )

Du

∞

≤ gD ( u

∞)

≤ gD (r)

(10)

(3)
since E[Zi |Fi−1 ] = 0, and for ease of notation we set

where
L

hj xj ,

|h0 | +

gD (x)

j=1
q

q

hj

|hj (i1 , . . . , ij )|.

...
i1 =0

1
N

(4)

ij =0



(5)

N R−

ρ
2
4σν

N Dv (Q)

ρ

N
i=1

2
E e 8σν

Zi

,

l=2

Zi





j=i

wj

E exp

2
wj Fi−1 

∀ l ∈ {2, . . . , m},

m!
ym

ϕm

ρd
2
8σν

m!

m−1 y l
l=0 l!

ey −

1

ρ
2
8σν

N

l
E Zi |Fi−1

i ∈ {1, . . . , N }

N
 (12)

if y = 0
.
if y = 0

ρd

Zi

2
≤ 1 + γ2 e 8σν − 1 −

i=1

(7)

max

m

(13)

N

ρd
2
8σν

.

• Second bounding technique (Bennett’s inequality) (see [7,
Lemma 2.4.1] and [9, Eq. (18)]):

j=i

uj ,˜j ,j≤i−1
u

+

ρd
2
8σν

(14)

Remark 1: A typo has been identiﬁed in the denominator
2
of the exponent in [6, eq. (10)], which should be 8σν instead
2
of 4σν .
The martingale difference sequence {Zi }N with respect to
i=0
the ﬁltration Fi satisﬁes E[Zi |Fi−1 ] = 0, ∀i ∈ [1, N ]. Let us
assume (to be later justiﬁed with the calculation of the proper
constants) that for a positive d and a non-negative sequence
{µl }m , where m ≥ 2 is an arbitrary even number,
l=2
max |Zi | ≤ d,

ρd
2
8σν

γm

l



[Du]j − [D˜]j .
u

uj ,˜j ,j≤i
u

Zi
i=1

In the special case where m = 2, the upper bound in (12)
specializes to

0≤ρ≤1

i+q

2
wj Fi  + E 

−E 

N

γl
l!

ϕm (y)

where
i+q

(11)

where the function ϕm is deﬁned in [9, Eq. (41)] as

(6)


m−1

≤ 1 +

j=1

Given two randomly selected codewords from the codebook
˜
u = (u1 , . . . , uN ), u = (˜1 , . . . , uN ), let {Fi }N be a
u
˜
i=1
ﬁltration (i.e., F0 ⊆ F1 ⊆ . . . ⊆ FN ) where Fi
˜
˜
σ(U1 , U1 , . . . , Ui , Ui ) is the minimal σ-algebra that is gener˜1 , . . . , Ui , Ui (for 1 ≤ i ≤ N ), and F0 {∅, Ω}.
˜
ated by U1 , U
The average decoding error probability P e under ML decoding, over the considered ensemble of codes, is upper bounded
(for all possible transmitted codewords) by (see [6, Section II])
Pe ≤ e

ρ
2
8σν

E exp

N

Var (E[Du]j ) .

σ2
.
d2

Then one can upper bound the second term on the right hand
side of (6) in the following two ways:
• First bounding technique ([9, Eq. (44)]): For an even m ≥ 2

Following the notation in [6], let Dv (Q) denote the average
output variance (without the additive noise)
Dv (Q)

σ 2 with γ2 =

µ2

x≥0

E exp

ρ
2
8σν



N

Zi

 γ2 e
≤

i=1

ρd
2
8σν

−γ2

+e
1 + γ2

ρd
2
8σν

N

 .
(15)

The parameters d and γ2 of the martingale {Zi , Fi } depend
on the input probability distribution Q.
Combining the inequalities in (6) and (12) gives the following exponential upper bound on the conditional average error
probability under ML decoding:

≤ µl

(8) P ≤ exp −N R(m) (σ 2 ) − R
e
ν
1

for an arbitrary i ∈ {1, . . . , N }, and set
(m) 2
R1 (σν )
µl
, ∀ l = 2, . . . , m.
(9)
γl
m−1
dl
ρ Dv (Q)
γl ρd
max max
− ln 1 +
2
2
Parameter d denotes the maximum absolute value of the
Q 0≤ρ≤1
4σν
l! 8σν
l=2
samples Zi of the martingale difference sequence with respect
m
γm ρd
ρd
to any realization of the ﬁltration Fi , while µl denotes the
+
ϕm
2
2
m! 8σν
8σν
maximum absolute value of the condition mean value of every

2

l

. (16)

2
Furthermore, letting SNR
A2 /σν , the achievable rates in
(17) and (18) are equivalently expressed as follows:

In the special case where m = 2, it gets the form
ρ Dv (Q)
2
4σν

(2)

2
R1 (σν ) = max max
Q

0≤ρ≤1

− ln 1 + γ2 exp

ρd
2
8σν

(2)

R1 (SNR) = max

max ρf (α) SNR

0≤α≤1 0≤ρ≤1

ρd
−1− 2
8σν

. (17)
− ln 1 +

Similarly, the second bounding technique in (15) gives that
2
P e ≤ exp −N R2 (σν ) − R
ρ
2
R2 (σν ) max max
· Dv (Q)
2
Q 0≤ρ≤1 4σν


ρd
γ2 exp 8σ2 + exp − ργ22d
8σν
ν
 .
− ln 
1 + γ2

−1 −

R2 (SNR) = max
− ln 2f (α) e

Remark 2: When there is no information about the conditional variance of the martingale {Zi , Fi }N or the calculation
i=0
is too complex, then by setting γ2 = 1 in both (17) and (18),
one obtains, respectively, the following achievable rates:
2
R1 (σν ) = max max
Q

0≤ρ≤1

ρd
ρDv (Q)
ρd
2
− ln e 8σν − 2
2
4σν
8σν

max

ρ(1−2f (α)) SNR
2

ρ (1 − 2f (α)) SNR
2

(22)

ρSNRf (α)

0≤α≤1 0≤ρ≤1

(18)

ρ(1−2f (α)) SNR
2f (α)
2
e
1 − 2f (α)

+ (1 − 2f (α))e−ρSNRf (α)

. (23)

The simplicity of the speciﬁc communication channel allows
one to calculate analytically the normalized higher-order conditional moments γl in (9). It gives that for every integer l ≥ 2

(19)

γl = 2f (α)

2f (α)
1 − 2f (α)

l−1

+ (−1)l .

(24)

and
2
R2 (σν ) = max max
Q

0≤ρ≤1

ρd
ρ Dv (Q)
− ln cosh
2
2
4σν
8σν

.

Under the above analysis, one can calculate the achievable rate
provided by (16) for several values of m and compare it with
the one provided by (17) where m = 2. More speciﬁcally, the
achievable rate (16) is expressed in terms of SNR, and it gets
the form:

(20)

Remark 3: According to [9, Proposition 2], the achievable
(2) 2
2
rate R2 (σν ) in (18) is larger than R1 (σν ) in (17).
Remark 4: Following the discussion in [9, Section III.C.1],
a closed form expression for the maximal value of ρ in (17)
leads to the bound in [9, Corollary 4] (see the proof in [9,
Appendix C]).
2
2
Remark 5: Both R1 (σν ) and R2 (σν ) are continuous functions of Q and ρ. Their maxima are attained since Q and ρ
vary over compact sets.

(m)

R1

(SNR) = max
m−1

ln 1 +
l=2

γm
+
m!

III. ACHIEVABLE R ATES FOR R ANDOM C ODING OVER
S OME C HANNEL M ODELS

max ρ SNR 1 − 2f (α) −

0≤α≤1 0≤ρ≤1

γl
l!

ρ (1 − 2f (α)) SNR
2

ρ (1 − 2f (α)) SNR
2

m

ϕm

l

ρ SNR 1 − 2f (α)
2

.
(25)

We next proceed to numerically compare the achievable
(6)
2
rates R2 (SNR) in (23), R1 (SNR) in (25) and R1 (SNR)
in (22), with the achievable rate incorrectly provided in [6,
Eq.(84)] and stated here correctly as:

The achievable rates developed above are exempliﬁed in this
section for certain special cases of interest.
A. Binary-Input AWGN Channel
For the transmission of information through the channel y =
2
u + ν, ν ∼ N (0, σν ), the parameters Dv (Q), d and γ2 deﬁned
in (5), (8), (9) and (11) can be calculated analytically. For the
channel input u ∈ {−A, A} where Q(u = A) = α, one gets
by setting f (α) α(1 − α)

Rl (SNR) = max max 2f (α)
0≤α≤1 0≤ρ≤1

−

e

ρ SNR
2

ρ(1−2f (α)) SNR
2

(α))
− 1 − ρ(1−2f 2 SNR
1 − 2f (α)

.

(26)

2

Zi = − (ui − ui ) + 8A2 f (α)
˜

Figure 1 illustrates that all achievable rates provided in this
analysis are larger than that provided by (26). Note also
(m)
that R1 (SNR) converges fast as m grows. Furthermore,
(6)
the achievable rate R1 (SNR) approximates very well the
achievable rate R2 (SNR) provided in (23), and both of them
are very close to the capacity of the binary-input additive white
Gaussian noise channel for large values of the SNR. The rate
loss in the low SNR regime is mainly due to the use of the

and
d = 4A2 (1 − 2f (α)),
Dv (Q) = 4A2 f (α),
γ2 =

2f (α)
.
1 − 2f (α)

(21)

3

so that

union bound that led to the establishment of (6). Furthermore,
(6)
the achievable rate R1 (SNR) almost coincides numerically
with R2 (SNR). We proceed now to examine more complex

γ2 ≤ 2f (α)

(1 − 2f (α)) h

q
k=1

+4
2
2

(1 − 2f (α)) h

0.7
Achievable rates in nats per channel use

4
2

q
l=1
q
l=1

+2

ˆ ˆ
|hk hl |
2

ˆ
|hl |

. (32)

C. Memoryless Nonlinear Channels

0.6

Consider the transmission of information over a memoryless
nonlinear channel with the following polynomial characteristic
of degree L

0.5
0.4

L

0.2

R12 SNR
Rl SNR

The average output covariance Dv (Q) is given by
L

L

hk hl E uk+l − E uk E ul

Dv (Q) =
0

1

2

3

4

5
SNR

6

7

8

9

10

L

L

hk (uk − uk )
˜i
i

Zi = −



k=1

(35)
while the parameter µ2 deﬁned in (8) is given by


4
L

hk (uk − uk )
˜

µ2 =E 

−

k=1

q

 
(27)

2

L

hk (uk − uk )
˜

E 

k=0

2
 .

(36)

k=1

Suppose that the input to the channel is a binary i.i.d. sequence
with values from the alphabet {−A, A}, with Q(ui = A) = α
for all i ∈ [0, N ]. Then setting h [h0 h1 . . . hq ]
2
2

hk (uk − uk )
˜

+E

k=1

B. Time-Invariant Linear Channels with Memory
Consider a time-invariant linear channel model with ﬁnite
memory q

Dv (Q) = 2 h

(34)

Due to the memoryless nature of the speciﬁc system, the
martingale-difference sequence {Zi }N satisﬁes
i=1


2
2

cases of Volterra channel models where analytic calculation
of the parameters Dv (Q) and γ2 is possible.

hk uj−k .

.

k=1 l=1

Fig. 1. Comparison among the maximal achievable rate (capacity) and the
(6)
(2)
achievable rates R2 (SNR) (23), R1 (SNR) (25), R1 (SNR) (22), and the
(corrected) old bound Rl (SNR) (26) from [6] for the binary-input AWGN
2
channel in terms of SNR A2 /σν . Rates are expressed in nats per channel
use.

[Du]j =

(33)

k=0

R16 SNR

0.1

hk uk .
j

[Du]j =

Capacity
R2 SNR

0.3

E[u2 ] − E[u]2 = 4 h 2 A2 f (α)
2

The parameter d in (8) becomes


2

L

hk (uk − uk )
˜

d = ΛE 

(28)




k=1

where it is reminded that f (α) α(1 − α). Furthermore, the
martingale-difference sequence {Zi }N is proved to satisfy
i=1
with Λ

Zi = − h 2 ((ui − ui )2 − E[(u − u)2 ])−
˜
˜
2

max





q−l

q

ˆ
hl (ui−l − ui−l ),
˜

2(ui − ui )
˜

ˆ
hl

l=1

ˆ
|hl | .

+2

γ2 =

(30)

l=1

Moreover, the conditional variance Var(Zi |Fi−1 ) satisﬁes
Var(Zi |Fi−1 ) = h
q

4
2

4

E (u − u)
˜

2

− E (u − u)
˜

2

hk (uk − uk )
˜

2

1
Λ2

E
E

L
k=1
L
k=1

hk (uk − uk )
˜

hk (uk − uk )
˜

4

2

2

−

1
.
Λ2

(38)

D. Examples of Third-Order Volterra Channels
+

Under the same setup of the previous subsection regarding the channel input characteristics, we consider next the
transmission of information over the Volterra system D1 of
order L = 3 and memory q = 2, whose kernels are depicted
in Table I. Such system models are used in the base-band

q

ˆ ˆ
hk hl (ui−k − ui−k )(ui−l − ui−l )
˜
˜

4E (u − u)2
˜

L
k=1

E

hk (uk − uk )
˜i
i





−1 .




Hence, from (36), (37) and the deﬁnition of γ2 in (11)

q
2
2

maxui ,˜i
u

2

(37)

It then follows that
(1 − 2f (α)) h

1,

L
k=1

hk hk+l .
k=0

(29)

d = 4A2






k=1 l=1

(31)

4

TABLE I
K ERNELS OF THE 3 RD ORDER VOLTERRA SYSTEM D1 WITH MEMORY 2
kernel
value
kernel
value

h1 (0)
1.0

h1 (1)
0.5

h1 (2)
−0.8

h3 (0, 0, 0)
1.0

h2 (0, 0)
1.0

h3 (1, 1, 1)
−0.5

h2 (1, 1)
−0.3

h3 (0, 0, 1)
1.2

Calculation shows that

2
 8σν tanh−1
d
ρopt =
 1

h2 (0, 1)
0.6

, Dv (Q) ≤

d
2

tanh

d
2
8σν

, Dv (Q) >

d
2

tanh

d
2
8σν

h3 (0, 1, 1)
0.8

Concluding the analysis, the upper bound in (39) is expressed
equivalently as

Achievable rates in nats per channel use

2
P e ≤ exp −N Ec (Q, D, σν ) − R

0.2

(41)

where
2
Ec (Q, D, σν )

 2Dv (Q) tanh−1 2Dv (Q)

d
d



2
2Dv (Q)
1
=
+ 2 ln 1 −
d


 Dv (Q)

d

4σ 2 − ln cosh 8σ 2

0.15

0.1
Rp D1,A,Σ2
Ν
R12

0.05

ν

0.2

0.4

0.6

0.8

1
A

1.2

1.4

1.6

1.8

, otherwise

New achievable rates for random coding are derived in
this work for non-linear communication channels. Exponential
martingale inequalities are properly utilized for this purpose.
The achievable rates obtained in this work improve previous
results obtained for the same channel models in [6]. This
improvement is facilitated by the use of some reﬁned versions
of the Azuma-Hoeffding inequality that were introduced in
[8], [10], and more recently in [9]. The analysis presented
here can easily be extended to the case where the noise is
a complex Gaussian or circularly complex Gaussian, and the
parameters of the Volterra system are complex valued as it is
in the Volterra representation of bandpass nonlinear channels
[2, Section 14.3].
R EFERENCES
[1] A. C. Singer, N. R. Shanbhag, and Hyeon–Min Bae, “Electronic dispersion compensation,” IEEE Signal Processing Magazime, vol. 25, no. 6,
pp. 110–130, 2008.
[2] S. Benedetto and E. Biglieri, Principles of Digital Transmission with
Wireless Applications, Kluwer Academic/ Plenum Publishers, 1999.
[3] S. Boyd, L. O. Chua and C. A. Desoer, “Analytical foundations of Volterra
series,” IMA Journal of Mathematical Control & Information, vol. 1,
pp. 243–282, 1984.
[4] M. Davis, “Capacity and cutoff rate for Poisson-type channels,” IEEE
Trans. on Information Theory, vol. 26, no. 6, pp. 710–715, 1980.
[5] R. Gallager, Information Theory and Reliable Communication, John
Wiley and Sons, New York, 1968.
[6] K. Xenoulis and N. Kalouptsidis, “Achievable rates for nonlinear Volterra
channels,” IEEE Trans. on Information Theory, vol. 57, no. 3, pp. 1237–
1248, March 2011.
[7] A. Dembo and O. Zeitouni, Large Deviations Techniques and Applications, Springer, second edition, 1997.
[8] C. McDiarmid, “On the method of bounded differences,” Surveys in
Combinatorics, vol. 141, pp. 148–188, Cambridge University Press,
Cambridge, 1989.
[9] I. Sason, “On reﬁned versions of the Azuma-Hoeffding inequality with
applications in information theory,” last updated on February 2012.
[Online]. Available at http://arxiv.org/abs/1111.1977.
[10] C. McDiarmid, “Concentration,” Probabilistic Methods for Algorithmic
Discrete Mathematics, pp. 195–248, Springer, 1998.

E. General Volterra Channel Models
From the previous analysis it follows that in the case of more
complex Volterra systems, it is preferable to select γ2 = 1.
2
Then the achievable rate R2 (σν ) (20) admits a closed-form
solution according to the analysis. The upper bound (18) on
the average error decoding probability P e is expressed for
0 ≤ ρ ≤ 1 as
−R

d
2
8σν

IV. S UMMARY

2

representation of nonlinear narrow-band communication channels. Due to complexity of the channel model, the calculation
of the achievable rates provided by (17), (18) requires the
numerical calculation of the parameters d and σ 2 and thus
of γ2 for the martingale {Zi , Fi }N . In order to achieve this
i=0
goal, we have to calculate |Zi −Zi−1 | and Var(Zi |Fi−1 ) for all
possible combinations of the input samples which contribute to
the aforementioned expressions. Thus, the analytic calculation
of d and γl increases as the system’s memory q increases.
Numerical results are provided in Figure 2 for the case
(2)
2
2
where σν = 1. The new achievable rates R1 (D1 , A, σν )
2
and R2 (D1 , A, σν ) of (17) and (18), which depend on the
channel input parameter A, are compared to the achievable
rate provided in [6, Fig.2] and shown to be larger than the
latter.

ρd
2
8σν

tanh

2
and Ec (Q, D, σν ) ≥ 0 in both cases.

Fig. 2.
Comparison of the achievable
2
R2 (D1 , A, σν ) (18) with the old bound
the nonlinear channel with kernels depicted in Table I and noise variance
2
σν = 1. Rates are expressed in nats per channel use.

ρDv (Q)
− ln cosh
2
4σν

d
2

(42)

(2)
2
rates R1 (D1 , A, σν ) (17) and
2
Rp (D1 , A, σν ) of [6, Fig.2] for

P e ≤ exp −N

ν

, Dv (Q) ≤

D1,A,Σ2
Ν

R2 D1,A,Σ2
Ν

0

.
(40)

h3 (0, 1, 2)
0.6

kernel
value

2Dv (Q)
d

. (39)

5

