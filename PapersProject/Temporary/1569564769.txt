Creator:         TeX output 2012.05.19:0123
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Sat May 19 01:23:08 2012
ModDate:        Tue Jun 19 12:55:04 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      274662 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569564769

Causal relay networks with causal side information
Ihn-Jung Baik and Sae-Young Chung
Department EE, KAIST, Daejeon, Korea,
Email: ihn jung@kaist.ac.kr, sychung@ee.kaist.ac.kr

1

k

.
..

.
..

p(y1 , y2 , . . . , yK |x1 , x2 , . . . , xK , s)

K

.
..

.
..

Abstract—In this paper, we consider causal discretememoryless relay networks (DMRNs) with causal side information. The networks consist of multiple nodes, each of which can be
a source, relay, and/or destination. There are two types of relays
in the network, i.e., relays with one sample delay (strictly causal
relays) and relays without delay (causal relays) whose transmit
signal depends not only on the past received symbols but also on
the current received symbol. Also, we assume that some nodes can
causally use channel state information (CSI) as side information.
For the network, we derive a new cut-set bound, which recovers
the classical cut-set bound and our previous cut-set bound for
causal DMRNs without side information. Using an example of a
fading relay channel, we show that the new cut-set bound can
be achieved by a simple amplify-and-forward type relaying.

2
Fig. 1.

Causal DMRN with side information

conditions. The remainder of this paper is organized as follow.
In Section II, we introduce our network model. In Section III,
the new cut-set bound for causal DMRNs with causal side
information is provided and compared to other known bounds.
We give some examples of the networks in Section IV and
conclude the paper in Section V.

I. I NTRODUCTION
A model of relay networks was ﬁrst introduced by van der
Meulen in [1], [2]. However, even for a simple three-node
relay channels, the capacity is not known yet. In [3], Cover
and El Gamal provided the cut-set bound for the relay channel
and introduced two coding strategies, decode-and-forward and
compress-and-forward, which can achieve the capacities of
some relay channels including physically degraded channels.
For more complicated networks, a general cut-set bound is
provided in [4]. Lately, El Gamal, Hassanpour, and Mammen
introduced new types of relay channels in [5], which are casual
and noncausal relay channels. Unlike a strictly causal relay, the
causal relay’s transmit symbol depends on both the past and
the current received symbols and the noncausal relay’s transmit
symbol depends on the future symbols as well. These new
types of relays are further studied in [6] for noncausal relay
channels, and in [7] for causal interference relay channels.
Also, a multiple-source and multiple-destination causal relay
network is studied in [8].
In this paper, we focus on the causal case and characterize
an outer bound of the capacity region of a casual DMRN
with causal side information. We assume that every nodes
can act as a source, relay, and/or destination and they are
separated into two types of relays, causal and strictly causal
relays. Also, we assume that the channel state is given for
some nodes. This is a generalized version of network models
with side information in [9], [10]. For this network, we show
a cut-set outer bound. Our bound is reduced to the cut-set
bound without side information for causal DMRNs [8] and
the classical cut-set bound for strictly causal DMRNs [4].
For a causal MIMO fading relay channel with CSI at the
relay and destination, we show that a simple amplify-andforward relaying scheme can achieve the capacity under some

II. N ETWORK MODEL
We consider a multiple-source multiple-destination causal
discrete memoryless relay network with side information consisting of K nodes
(
(
)
)
x1 , . . . ,
X1 × . . . × XK , p y1 , . . . , yK
p(s), Y1 × . . . × YK ,
xK , s
where the channel state S n
{S1 , . . . , Sn } for n ≥ 1 is
independent and identically distributed according to p(s). This
network consists of sender alphabets Xk and receiver alphabets
Yk , k ∈ [1 : K] {1, 2, . . . , K} and a conditional probability
distribution
p(y1 , . . . , yK |x1 , . . . , xK , s)
= p(y(N0S ), y(N0N )|x(N1S ), x(N1N ), s)
(
)
x(N0S ), x(N0N ), x(N1S ),
p y(N1S ), y(N1N )
,
x(N1N ), y(N0S ), y(N0N ), s
where N0S is the set of causal relays with causal side
information, N0N is the set of causal relays without causal
side information, N1S is the set of strictly causal relays
with causal side information, and N1N is the set of strictly
causal relays without causal side information, and N0S ∪
N0N ∪ N1S ∪ N1N = [1 : K]. To avoid inﬁnite loop
among causal relays, we assume the received signal of causal
relay yk , k ∈ N0S ∪ N0N , does not depend on the transmit
signal of the causal relays. A (2nR11 , 2nR12 , . . . , 2nRKK , n)

1

code for this network consists of K 2 message sets, K encoders, where encoder k ∈ N0S assigns an input symi
bol xki to each (mk1 , . . . , mkK , yk , si ), encoder k ∈ N0N
i
assigns an input symbol xki to each (mk1 , . . . , mkK , yk ),
encoder k ∈ N1S assigns an input symbol xki to each
i−1
(mk1 , . . . , mkK , yk , si−1 ), and encoder k ∈ N1N assigns
i−1
an input symbol xki to each (mk1 , . . . , mkK , yk ) at time
i, where mkj is a message from node k to node j, and K
decoders, where decoder k ∈ N0S ∪ N1S assigns a set of
n
messages (m1k , . . . , mKk ) to each received sequence (yk , sn ),
ˆ
ˆ
and decoder k ∈ N0N ∪ N1N assigns a set of messages
n
(m1k , . . . , mKk ) to each received sequence yk . Here, mjk is a
ˆ
ˆ
ˆ
decoded message from nodes j to k. We assume that Rkk = 0
for all k ∈ [1 : K].

= H(M (W ))
(a)

= H(M (W )|M (W c ))

= I(M (W ); Y n (T c ), S n |M (W c ))
+ H(M (W )|Y n (T c ), S n , M (W c ))
(b)

≤ I(M (W ); Y n (T c ), S n |M (W c )) + nϵn
n
∑
I(M (W ); Yi (T c ), Si |M (W c ), Y i−1 (T c ), S i−1 ) + nϵn
=
(c)

=

i=1
n
∑
=
[I(M (W ); Yi (V0N )|M (W c ), Y i−1 (T c ), S i )
i=1

+ I(M (W ); Yi (V0S )|M (W c ), Y i−1 (T c ), S i , Yi (V0N ))
(
)
M (W c ), Y i−1 (T c ),
+ I M (W ); Yi (V1N )
S i , Yi (V0S ), Yi (V0N )


M (W c ), Y i−1 (T c ),
 + nϵn
+I M (W ); Yi (V1S ) S i , Yi (V0S ),
Yi (V0N ), Yi (V1N )
n
∑
=
[H(Yi (V0N )|M (W c ), Y i−1 (T c ), S i )

p(x(N1N ))p(x(N1S )|x(N1N ), s)
p(x(N0N )|y(N0S ), y(N0N ), x(N1S ), x(N1N ), s)

i=1

p(x(N0S )|y(N0S ), y(N0N ), x(N1S ), x(N1N ), x(N0N ), s)
(1)

− H(Yi (V0N )|M, Y i−1 (T c ), S i )
+ H(Yi (V0S )|M (W c ), Y i−1 (T c ), S i , Yi (V0N ))
− H(Yi (V0S )|M, Y i−1 (T c ), S i , Yi (V0N ))

Rjk

+ H(Yi (V1N )|M (W c ), Y i−1 (T c ), S i , Yi (V0S ), Yi (V0N ))

j∈T ,k∈T c

≤ I(X(U1S ), X(U1N ); Y (V0S ), Y (V0N )|S, X(V1S ), X(V1N ))


X(T ),
S, Y (V0S ),
,
+ I  Y (U0S ), ; Y (V1S ), Y (V1N )
Y (V0N ), X(T c )
Y (U0N )
(2)
for the cuts T ⊂ [1 : K] such that V0S ∪ V1S ̸= ∅, and
∑
Rjk

+ I X(T ), Y (U0S ), Y (U0N ); Y (V1N )

− H(Yi (V0N )|M, Y i−1 (T c ), S i , Xi (V1S ), Xi (V1N ))
(
)
M (W c ), Y i−1 (T c ), S i ,
+ H Yi (V0S )
Yi (V0N ), Xi (V1S ), Xi (V1N )
(
)
M, Y i−1 (T c ), S i ,
− H Yi (V0S )
Yi (V0N ), Xi (V1S ), Xi (V1N )
(
)
M (W c ), Y i−1 (T c ), S i ,
+ H Yi (V1N )
Yi (V0S ), Yi (V0N ), Xi (T c )
(
)
M, Y i−1 (T c ), S i ,
− H Yi (V1N )
Yi (V0S ), Yi (V0N ), Xi (T c )
(
)
M (W c ), Y i−1 (T c ), S i , Yi (V0S ),
+ H Yi (V1S )
Yi (V0N ), Yi (V1N ), Xi (T c )
(
)]
.
M, Y i−1 (T c ), S i , Yi (V0S ),
−H Yi (V1S )
+ nϵn
Yi (V0N ), Yi (V1N ), Xi (T c )
n
(f ) ∑
≤
[H(Yi (V0N )|Si , Xi (V1S ), Xi (V1N ))


Y (V0N ),
X(V0N ),  ,
X(V1N )
(3)

for the cuts T ⊂ [1 : K] such that V0S ∪ V1S = ∅, where
T ∩ NiS = UiS , T ∩ NiN = UiN , T c ∩ NiS = ViS , and
T c ∩ NiN = ViN for i = 0, 1.
Proof: First, we show the bound (2). For some ϵn → 0
as n → ∞, we get
∑
Rjk
n
j∈T ,k∈T c

=

∑

− H(Yi (V1N )|M, Y i−1 (T c ), S i , Yi (V0S ), Yi (V0N ))
(
)
M (W c ), Y i−1 (T c ),
+ H Yi (V1S )
S i , Yi (V0S ), Yi (V0N ), Yi (V1N )
(
)]
M, Y i−1 (T c ), S i ,
−H Yi (V1S )
+ nϵn
Yi (V0S ), Yi (V0N ), Yi (V1N )
n
(e) ∑
=
[H(Yi (V0N )|M (W c ), Y i−1 (T c ), S i , Xi (V1S ), Xi (V1N ))
i=1

j∈T ,k∈T c

≤ I(X(U1S ), X(U1N ); Y (V0N )|X(V1N ))


I(M (W ); Yi (T c )|M (W c ), Y i−1 (T c ), S i ) + nϵn

(d)

III. M AIN RESULT
In this section, we provide a new cut-set bound for the
causal DMRN with causal side information. Then, we compare
the bound with other known bounds.
Theorem 1: If the rates Rjk are achievable in the causal
DMRN with causal side information, there exists some joint
probability distribution

such that
∑

i=1
n
∑

H(Mjk )

j∈T ,k∈T c

(
)
M, Y i−1 (T c ), S i , Xi (V1S ),
− H Yi (V0N )
Xi (V1N ), Xi (U1S ), Xi (U1N )

i=1

2

 


SQ ,
X (U ),
≤ n I  Q 1S ; YQ (V0S ), YQ (V0N ) XQ (V1S ), 
XQ (U1N )
XQ (V1N )


SQ ,
XQ (T ),

Y (V ), YQ (V0S ), 
 + nϵn
+I  YQ (U0S ), ; Q 1S

YQ (V1N )
YQ (V0N ), 
YQ (U0N )
XQ (T c )
 

S,
(h)
X(U1S ),
= n I 
; Y (V0S ), Y (V0N ) X(V1S ), 
X(U1N )
X(V1N )


S,
 X(T ),
Y (V0S ), 
Y (V1S ),
 + nϵn ,
+I  Y (U0S ), ;

Y (V0N ), 
Y (V1N )
Y (U0N )
X(T c )

+ H(Yi (V0S )|Si , Yi (V0N ), Xi (V1S ), Xi (V1N ))


M, Y i−1 (T c ), S i ,

− H Yi (V0S ) Yi (V0N ), Xi (V1S ),
Xi (V1N ), Xi (U1S ), Xi (U1N )
+ H(Yi (V1N )|Si , Yi (V0S ), Yi (V0N ), Xi (T c ))


M, Y i−1 (T c ), S i ,
− H Yi (V1N ) Yi (V0S ), Yi (V0N ), Xi (T c ), 
Xi (T ), Yi (U0S ), Yi (U0N )
+ H(Yi (V1S )|Si , Yi (V0S ), Yi (V0N ), Yi (V1N ), Xi (T c ))


M, Y i−1 (T c ), S i ,


Yi (V0S ), Yi (V0N ),
 + nϵn
−H Yi (V1S )
c

Yi (V1N ), Xi (T ), Xi (T ), 
Yi (U0S ), Yi (U0N )
n
∑
(g)
=
[H(Yi (V0N )|Si , Xi (V1S ), Xi (V1N ))
(
− H Yi (V0N )

i=1

Si , Xi (V1S ), Xi (V1N ),
Xi (U1S ), Xi (U1N )

where W = {(j, k) : j ∈ T , k ∈ T c }, Q is a time-sharing
random variable taking values in [1 : n] and independent of
other variables, (a) is because messages are independent, (b)
is because of Fano’s inequality, (c) is because of the Markov
chain M (W ) − (M (W c ), Y i−1 (T c ), S i−1 ) − Si , (d) is
from Yi (T c ) = (Yi (V0S ), Yi (V0N ), Yi (V1S ), Yi (V1N )), (e) is
because Xi (V1S ) is a function of (M (W c ), Y i−1 (V1S ), S i−1 ),
Xi (V1N ) is a function of (M (W c ), Y i−1 (V1N )),
Xi (V0S ) is a function of (M (W c ), Y i (V1S ), S i ),
Xi (V0N ) is a function of (M (W c ), Y i (V0N )), and
Xi (T c ) = (Xi (V1S ), Xi (V1N ), Xi (V0S ), Xi (V0N )), (f )
is because conditioning reduces entropy, (g) is because of the
Markov chains
(
)
Si , Xi (V1S ), Xi (V1N ),
i−1
c
i−1
(M, Y
(T ), S )−
− Yi (V0N )
Xi (U1S ), Xi (U1N )


Si , Yi (V0N ),
(M, Y i−1 (T c ), S i−1 )−  Xi (V1S ), Xi (V1N ),  − Yi (V0S )
Xi (U1S ), Xi (U1N )


Si , Yi (V0S ), Yi (V0N ),
 − Yi (V1N )
(M, Y i−1 (T c ), S i−1 )−  Xi (T ), Xi (T c ),
Yi (U0S ), Yi (U0N )


Si , Yi (V0S ), Yi (V0N ),
 Y (V ), Xi (T ),

 − Yi (V1S ),
(M, Y i−1 (T c ), S i−1 )−  i 1N
 Xi (T c ), Yi (U0S ),

Yi (U0N )

)

+ H(Yi (V0S )|Si , Yi (V0N ), Xi (V1S ), Xi (V1N ))
(
)
Si , Yi (V0N ), Xi (V1S ), Xi (V1N ),
− H Yi (V0S )
Xi (U1S ), Xi (U1N )
+ H(Yi (V1N )|Si , Yi (V0S ), Yi (V0N ), Xi (T c ))
(
)
Si , Yi (V0S ), Yi (V0N ),
− H Yi (V1N )
Xi (T c ), Xi (T ), Yi (U0S ), Yi (U0N )
+ H(Yi (V1S )|Si , Yi (V0S ), Yi (V0N ), Yi (V1N ), Xi (T c ))


Si , Yi (V0S ), Yi (V0N ),
−H Yi (V1S ) Yi (V1N ), Xi (T c ), Xi (T ),  + nϵn
Yi (U0S ), Yi (U0N )
 

n
Si ,
∑
I  Xi (U1S ), ; Yi (V0S ), Yi (V0N ) Xi (V1S ), 
=
Xi (U1N )
i=1
Xi (V1N )


Si ,
 Xi (T ),
Y (V ), Yi (V0S ), 
 + nϵn
+I  Yi (U0S ), ; i 1S

Yi (V1N )
Yi (V0N ), 
Yi (U0N )
Xi (T c )
 

n
Si , Q = i
∑
Xi (U1S ),
I 
=
; Yi (V0S ), Yi (V0N ) Xi (V1S ), 
Xi (U1N )
i=1
Xi (V1N )


Si , Q = i
Xi (T ),

Y (V ), Yi (V0S ), 
 + nϵn
+I  Yi (U0S ), ; i 1S

Yi (V1N )
Yi (V0N ), 
Yi (U0N )
Xi (T c )
 

SQ , Q
X (U ),
= n I  Q 1S ; YQ (V0S ), YQ (V0N ) XQ (V1S ), 
XQ (U1N )
XQ (V1N )


SQ , Q
 XQ (T ),
Y (V ), YQ (V0S ), 
 + nϵn
+I  YQ (U0S ), ; Q 1S

YQ (V1N )
YQ (V0N ), 
YQ (U0N )
XQ (T c )

and (h) is by deﬁning X = XQ , Y = YQ , and S = SQ . We
skip the proof of the bound (3) since it is similar to that of
the main theorem in [8].
Now, we compare the cut-set bound in Theorem 1 with other
known cut-set bounds.
Proposition 1: The cut-set bound in Theorem 1 coincides
with the cut-set bound for the causal DMRN without causal
side information [8] if S = ∅.
Proof: In the case without side information, the probability distribution (1) becomes
p(x(N1S ), x(N1N ))
p(x(N0S ), x(N0N )|y(N0S ), y(N0N ), x(N1S ), x(N1N )).

3

Y2 : X2
2

H21

X1

H32

H31

1
Fig. 2.

The following proposition shows that the capacity of the
causal MIMO fading relay channel can be achieved by simple
amplify-and-forward (AF) relaying under some conditions.
Proposition 2: If the relay transmit power satisﬁes
E[tr[F(H21 Σ∗ H† +I) F† ]] ≤ P2 , then the capacity of the
1
21
fading MIMO relay channel is

3

Y3

R≤

Fading MIMO relay channel

max
tr(Σ1 )≤P1

EH21 ,H31 ,H32 [log |ΛVΣ1 VΛ + I|],

where F = (U† H32 )−1 U† , Σ∗ is chosen among values
1
21
31
satisfying

Then, the mutual information in (2) becomes
∑
Rjk

Σ∗ = arg
1

j∈T ,k∈T c

max
tr(Σ1 )≤P1

EH21 ,H31 ,H32 [log |ΛVΣ1 VΛ + I|]

at each transmission, U21 , U31 , Λ, and V are obtained by
singular value decomposition (SVD) of channel matrices, i.e.,
[
] [
]
H21
U21
=
ΛV† .
H31
U31

(
)
X(V1S ),
≤ I X(U1S ), X(U1N ); Y (V0S ), Y (V0N )
X(V1N )


Y (V0S ),
X(T ),
+ I  Y (U0S ), ; Y (V1S ), Y (V1N ) Y (V0N ),  ,
Y (U0N )
X(T c )

Here, [UT UT ]T , and V are unitary matrices, and Λ is a
21
31
diagonal matrix with nonnegative entries.
Proof: Achievability. Assume that F is chosen as in
the theorem and the power constraint is satisﬁed. Let node
1 transmit a codeword using a vector Gaussian codebook with
a covariance matrix Σ∗ . We apply AF relaying using F, i.e.,
1
the relay’s transmit signal X2 is formed by X2 = F Y2 .
Because X2 satisﬁes the relay power constraint from the given
conditions, it can be transmitted from the relay. Then, the
receive signal at node 3 is

which is the same as the cut-set bound without causal side
information.
In [8], we showed that the cut-set bound for the causal DMRN
without causal side information covers the classical cut-set
bound [4], thus our bound in Theorem 1 also covers the
classical cut-set bound.
IV. E XAMPLE
In this section, we apply the cut-set bound in Theorem 1 for
a causal relay channel with causal side information and show
the bound can be tight under some conditions. In a causal
relay channel with causal side information, node 1 transmits
its message to node 3 with help of causal relay node 2. Here,
we assume that the channel state is not given for source node 1,
i.e., the transmit signal of node 1 depends only on its message.
Let Xk denote the transmit signal of node k = 1, 2 and Yk
denote the receive signal of node k = 2, 3. For this channel,
N1N = {1}, N0S = {2}, and N1S = {3}. Thus, an upper
bound of a causal relay channel with causal side information
is


 I(X1 ; Y2 |S)

+ I(X1 ; Y3 |S, X2 , Y2 ),
R≤
max
min
,


p(x1 )p(x2 |x1 ,y2 ,s)
I(X1 , X2 , Y2 ; Y3 |S)
(4)

Y3 = H31 X1 + H32 X2 + Z3
= H31 X1 + H32 F Y2 + Z3
= (H31 + H32 F H21 ) X1 + H32 F Z2 + Z3 .
Using the knowledge of fading channel matrix at each
˜
transmission, the destination node 3 can calculate Y3 deﬁned
as follows:
˜
Y3 = U† Y3
31
= U† (H31 + H32 F H21 ) X1 + U† (H32 F Z2 + Z3 )
31
31
= (U† U31 + U† U21 )Λ V† X1 + U† Z2 + U† Z3
21
31
21
31

(a)
(b)

˜
= Λ V† X1 +Z3 ,

where (a) is because U† H32 F = U† from the choice of
31
21
˜
F, and (b) is because [UT UT ]T is unitary matrix and Z3 =
21
31
†
†
†
˜ ˜
U21 Z2 + U31 Z3 with E[Z3 Z3 ] = I.
Then, the rate R up to the following is achievable:

which is reduced from Theorem 1. For the causal multipleinput multiple-output (MIMO) fading relay channel as shown
in Fig. 2, the received signals at each node are

˜
I(X1 ; Y3 , H21 , H31 , H32 )
˜
= I(X1 ; Y3 | H21 , H31 , H32 )
[ (
)]
˜ 3 H21 = H21 , H31 = H31 ,
= EH21 ,H31 ,H32 I X1 ; Y
H32 = H32
[
]
˜
h(Y3 |H21 , H31 , H32 )
.
.
= EH21 ,H31 ,H32
˜
−h(Y3 |H21 , H31 , H32 , X1 )
˜
˜
= EH ,H ,H [h(Y3 |H21 , H31 , H32 ) − h(Z3 )]

Y2 = H21 X1 + Z2
Y3 = H31 X1 + H32 X2 + Z3 ,
where Hjk is the fading channel matrix from nodes k to
j, tr(Σk ) ≤ Pk for k = 1, 2, Σk = E[Xk X† ], and
k
Zk ∼ CN (0, I) for k = 2, 3. Also, let the number of transmit
antennas of node k = 1, 2, be tk and the number of receive
antennas of node j = 2, 3 be rj .

21

31

32

= EH21 ,H31 ,H32 [log |Λ V† Σ∗ V Λ + I|],
1

4

where Hjk is the channel realization of Hjk .
Converse. Applying the cut-set bound to the causal MIMO
fading relay channel with channel state information S =
(H21 , H31 , H32 ), the ﬁrst term in the bound can be written
as follows:

antenna channel.
Y2 = h21 X1 + Z2
Y3 = h31 X1 + h32 X2 + Z3
Then, we get the following result.
Corollary 1: If
[(
)
]
|h21 |2
2
P2 ≥ E
(|h21 | P1 + 1)
|h31 |2 |h32 |2

I(X1 ; Y2 | H21 , H31 , H32 )
+ I(X1 ; Y3 | X2 , Y2 , H21 , H31 , H32 )
= I(X1 ; Y2 , H21 , H31 , H32 )

in the causal fading relay channel, then its capacity is given
by E[log{1 + (|h21 |2 + |h31 |2 )P1 }].

+ I(X1 ; Y3 | X2 , Y2 , H21 , H31 , H32 )
= h(Y2 , H21 , H31 , H32 ) − h(Y2 , H21 , H31 , H32 | X1 )

V. C ONCLUSION

+ h(Y3 | X2 , Y2 , H21 , H31 , H32 )
− h(Y3 | X1 , X2 , Y2 , H21 , H31 , H32 )
= h(Y2 , H21 , H31 , H32 ) − h(Y2 , H21 , H31 , H32 | X1 )

In this paper, we studied a causal DMRN with causal side
information consisting of relays with one sample delay and
without delays. The main difference between the network
considered in this paper and a strictly causal relay network
is that there exist relays depending on the current received
symbol as well as on the past received symbols in the proposed
network. This paper investigated an outer bound for the
causal DMRN with causal side information and showed that
the bound covers the classical cut-set bound. Surprisingly,
for a causal MIMO fading relay channel with channel state
information, the obtained outer bound can be achievable based
on a simple AF relaying scheme.

+ h(Y′ | X2 , Y2 , H21 , H31 , H32 )
3
− h(Y′ | X1 , X2 , Y2 , H21 , H31 , H32 )
3
(a)

≤ h(Y2 , H21 , H31 , H32 ) − h(Y2 , H21 , H31 , H32 | X1 )
+ h(Y′ | Y2 , H21 , H31 , H32 )
3
− h(Y′ | X1 , X2 , Y2 , H21 , H31 , H32 )
3

(b)

= h(Y2 , H21 , H31 , H32 ) − h(Y2 , H21 , H31 , H32 | X1 )
+ h(Y′ | Y2 , H21 , H31 , H32 )
3
− h(Y′ | X1 , Y2 , H21 , H31 , H32 )
3

VI. ACKNOWLEDGEMENT

I(X1 ; Y2 , Y′ , H21 , H31 , H32 )
3

This research was supported by Basic Science Research
Program through the S&T Leading Primary Research funded
by KAIST. [N10110050]

=
= I(X1 ; H21 , H31 , H32 ) + I(X1 ; Y2 , Y′ | H21 , H31 , H32 )
3
= I(X1 ; Y2 , Y′ | H21 , H31 , H32 )
3
 


H21 = H21 ,
= EH21 ,H31 ,H32 I X1 ; Y2 , Y′ H31 = H31 , 
3
H32 = H32
]
[
′
h(Y2 , Y3 |H21 , H31 , H32 )
= EH21 ,H31 ,H32
−h(Y2 , Y′ | X1 , H21 , H31 , H32 )
3
= EH21 ,H31 ,H32 [h(Y2 , Y′ |H21 , H31 , H32 ) − h(Z2 , Z3 )]
3

R EFERENCES
[1] E. C. van der Meulen, “Transmission of information in a t-terminal
discrete memoryless channel,” Ph. D. dissertation, Univ. of California,
Berkely, CA, 1968.
[2] ——, “Three-terminal communications channels,” Advances in Applied
Probability, vol. 3, pp. 120–154, 1971.
[3] T. M. Cover and A. El Gamal, “Capacity theorems for the relay channel,”
IEEE Trans. Inf. Theory, vol. 25, pp. 572–584, Sep. 1979.
[4] T. M. Cover and J. A. Thomas, Elements of information theory. New
York: Wiley, 2006.
[5] A. El Gamal, N. Hassanpour, and J. Mammen, “Relay networks with
delays,” IEEE Trans. Inf. Theory, vol. 53, pp. 3413–3431, Oct. 2007.
[6] L. Wang and M. Naghshvar, “On the capacity of the noncausal relay
channel,” in IEEE Int. Symp. Inform. Theory (ISIT), St. Petersburg,
Russia, 2011.
[7] H. Chang and S.-Y. Chung, “Capacity of strong and very strong Gaussian
interference relay-without-delay channels,” submitted to IEEE Transactions of Information Theory. [Online]. Available: arXiv:1108.2846/cs.IT
2011.
[8] I.-J. Baik and S.-Y. Chung, “Causal relay networks and new cut-set
bounds,” in Proc. 49th Annual Allerton Conference on Communication,
Control, and Computing, Allerton House, Monticello, IL, 2011.
[9] A. F. Dana, R. Gowaikar, R. Palanki, B. Hassibi, and M. Effros,
“Capacity of wireless erasure networks,” IEEE Trans. Inf. Theory,
vol. 52, pp. 789–804, March 2006.
[10] B. Smith and S. Vishwanath, “Unicast transmission over multiple access
erasure networks: Capacity and duality,” in IEEE Information Theory
Workshop, Tahoe City, California, 2007.

≤ EH21 ,H31 ,H32 [log(πe)(r2 +r3 ) |K| − log(πe)(r2 +r3 ) ]
= EH21 ,H31 ,H32 [log |K|],
where Y′ = H31 X1 +Z3 , (a) is because conditioning reduces
3
entropy, (b) is because of the Markov chain X2 −(X1 , H31 )−
Y′ , and
3
|K| = ΛV† Σ1 VΛ + I
≤

max
tr(Σ1 )≤P1

ΛV† Σ1 VΛ + I .

Thus, the rate is upper bounded as
R≤

max
tr(Σ1 )≤P1

log |Λ V† Σ1 V Λ + I|.

Since, the achievable rate and the upper bound coincide, the
proof is completed.
As a simpler example, we consider the following single-

5

