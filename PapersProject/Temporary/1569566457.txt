Title:          ISIT2012_CFC.dvi
Author:         Xiaofan He
Creator:        dvips(k) 5.99 Copyright 2010 Radical Eye Software
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Thu May 17 18:23:30 2012
ModDate:        Tue Jun 19 12:54:46 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      556832 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569566457
1

A Byzantine Attack Defender: the Conditional
Frequency Check
Xiaofan He† and Huaiyu Dai†
† Department of ECE
North Carolina State University, USA
Email: {xhe6,hdai}@ncsu.edu

Peng Ning‡
of CSC
North Carolina State University, USA
Email: pning@ncsu.edu
‡ Department

Abstract—Collaborative spectrum sensing is vulnerable to the
Byzantine attack. Existing reputation based countermeasures will
become incapable when malicious users dominate the network.
Also, there is a scarcity of methods that fully explore the Markov
property of the spectrum states to restrain sensors’ statistical misbehaviors. In this paper, a new malicious user detection method
based on two proposed Conditional Frequency Check (CFC)
statistics is developed with a Markovian spectrum model. With
the assistance of one trusted sensor, the proposed method can
achieve high malicious user detection accuracy in the presence
of arbitrary percentage of malicious users, and thus signiﬁcantly
improves collaborative spectrum sensing performance.

(e.g., [10,12,14]), or focus their analysis on one time slot
and ignore the correlation between the spectrum states at
consecutive time slots (e.g., [3,5–8,11]). In [13], the Markov
property of the spectrum is incorporated into the malicious
user detection algorithm; however, it is generally difﬁcult to
obtain the required prior knowledge of the true spectrum in
practice.
In this paper, a global decision independent method, the
Conditional Frequency Check (CFC), is proposed based on a
Markov spectrum model to combat the Byzantine attacks. In
particular, two CFC statistics, which explore the second order
property of the Markov model, are constructed in this paper.
The corresponding analysis proves that these two proposed
CFC statistics together with an auxiliary hamming distance
check are capable of detecting any sensor that misbehaves.
In addition, two consistent histogram estimators based on the
history of sensors’ reports are also developed for these two
CFC statistics. With the aid of one trusted sensor, the proposed
method is capable of detecting any malicious sensor with high
accuracy regardless of the portion of malicious ones in the
sensor group, without requiring any prior knowledge of the
spectrum and sensing models.
The rest of this paper is organized as follows. Section
II formulates the problem. The proposed malicious sensor
detection method and the corresponding theoretical analysis
are presented in Section III. Some supporting simulation
results are presented in Section IV, and Section V concludes
the paper.

I. I NTRODUCTION
Various collaborative spectrum sensing schemes have been
proposed to overcome the unreliability of single user spectrum
sensing [1]. Along with all the beneﬁts, collaborative spectrum
sensing also induces security vulnerabilities [2], among which
the Byzantine attack [3] (a.k.a. spectrum sensing data falsiﬁcation (SSDF) attack [4]) is the focus of this paper.
Many existing defenses against Byzantine attacks are reputation based, e.g., [5–8]. In this type of methods, lower
reputations will be assigned to sensors that deviate from the
global decision to mitigate the negative effects of the malicious
sensors. However, the underlying assumption is that the global
decision is correct, which may not be true when malicious
sensors dominate the network. In fact, it has been shown in
[3] [9] that when Byzantine attackers in the network exceed
a certain fraction, such reputation based methods become
completely incapable. 1 Non-reputation based approaches have
also been proposed, such as [10–12]. However, these methods
still rely on the correctness of the global decision and hence
only investigate the scenarios where a small fraction of users
are malicious. When the majority are not trustworthy, global
decision independent approaches are more suitable. Such type
of works include the prior-probability aided method proposed
in [13], and the user-centric misbehavior detection presented
in [14].
In practice usually there is memory in the spectrum state
evolvement, and the spectrum occupancy is more precisely
modeled by a Markov model. Most of the existing methods
either consider the i.i.d. spectrum state model for simplicity

II. P ROBLEM F ORMULATION
In this paper, the following scenario is considered: 1) The
true spectrum has two states, i.e., 0 (idle) and 1 (occupied), and
follows a homogeneous Markov model with state transition
matrix A = [aij ]2×2 (i, j ∈ {0, 1}) where aij
P r(st+1 =
j|st = i) and st denotes the true spectrum state at time t. The
stationary state distribution is denoted by π = [π 0 , π1 ], which
satisﬁes πA = π. In addition, it is assumed that the Markov
chain of spectrum states is in equilibrium. 2) One trusted
honest sensor exists and is known by the fusion center. 3) All
sensors, including malicious ones, have the same spectrum
sensing capability, i.e., identical detection probabilities P d ’s
and false alarm probabilities P f a ’s.2 4) An honest sensor will
send its local sensing result directly to the fusion center. 5)

This work was supported in part by the National Science Foundation under
Grants CCF-0830462, ECCS-1002258 and CNS-1016260.
1 When all sensors have the same spectrum sensing capability, the reputation
based methods cannot mitigate the effect of Byzantine attacks if more than
50% sensors are malicious [3].

2 This is a common assumption in literature (e.g., [3] [10]). Defense to more
intelligent and powerful attackers remains a future work.

1

2

Proposition 1: For the Markov spectrum model considered
in this paper, any sensor that survives the CFC can pass the
FC.
Proof: A malicious sensor can pass the FC as long as
(M)
(tr)
(M)
(tr)
= 1) = P r(rt = 1), where rt
(rt ) denotes
P r(rt
the malicious (trusted) sensor’s report at time t. However, she
(M)
(tr)
(M)
(tr)
needs to achieve Ψ 0 = Ψ0 and Ψ1 = Ψ1 to survive
the CFC.
(tr)
(tr)
Note that P r(rt = i) = P r(rt−1 = i) (i ∈ {0, 1}) when
(tr)
the true spectrum states are in equilibrium, and P r(r t
=
(tr)
(tr)
(tr)
(tr)
1) = Ψ1 P r(rt−1 = 1) + (1 − Ψ0 )P r(rt−1 = 0).
Consequently, for any sensor that survives the CFC, we have

A malicious sensor, however, will tamper its local inference
before reporting to the fusion center. In particular, she will ﬂip
local inference from 0 to 1 and 1 to 0 with probabilities ϕ 01
and ϕ10 , respectively. The ﬂipping probabilities ϕ may not
necessarily be the same for different malicious sensors. From
the fusion center’s viewpoint, the equivalent detection and
false alarm probabilities of a malicious sensor with ﬂipping
probabilities ϕ [ϕ01 , ϕ10 ] are given by
(M)

Pd

= (1 − ϕ10 )Pd + ϕ01 (1 − Pd ),

(1)

(M)

Pf a = (1 − ϕ10 )Pf a + ϕ01 (1 − Pf a ).

(2)

If a malicious sensor attacks, i.e., {ϕ 01 , ϕ10 } = {0, 0}, her
statistical behaviors will deviate from that of the honest sensor.
The objective of this paper is to detect the malicious sensors
by observing their statistical deviations.

(M)

P r(rt

(M)

= 1) =
=

III. T HE P ROPOSED M ETHOD

Ψ0 =

π 0 Pf a + π 1 Pd

,

(tr)

− Ψ0

= 1),

(5)

which implies that this sensor can also pass the FC.
a Pf a +a01 P d
Proposition 2: If 10 a10 +a01
= 1 , a malicious sensor
2
can never pass the CFC if she attacks, i.e., {ϕ 01 , ϕ10 } =
a Pf a +a01 P d
= 1 , an active malicious sensor can
{0, 0}. If 10 a10 +a01
2
pass the CFC only if she sets {ϕ01 , ϕ10 } to {1, 1}.
Proof: According to Proposition 1, passing the FC is a
necessary condition for a malicious sensor to pass the CFC.
(M)
(M)
(M)
Thus, ϕ must satisfy π0 Pf a + π1 Pd
= P r(rt
= 1) =
(tr)
P r(rt = 1) = π0 Pf a + π1 Pd . Considering (1) and (2), this
implies the following linear constraint on ϕ 01 and ϕ10 :
ϕ01 (π0 (1 − Pf a ) + π1 (1 − Pd )) = ϕ10 (π0 Pf a + π1 Pd ).(6)
(M)

When (6) holds, deﬁne g 1 (ϕ10 ) (π0 Pf a +π1 Pd )·(Ψ1
After some algebra, it can be shown that

(tr)
Ψ1 ).

−

2
(7)
g1 (ϕ10 ) = ϕ2 κ2 [π0 π1 a00 − (π1 a10 + π0 a01 )π1 π0
10 1
2
+π1 π0 a11 ] + ϕ10 κ1 [−2π1 π0 a00 Pf a
+(π1 a10 + π0 a01 )(Pf a π0 − Pd π1 ) + 2π1 π0 a11 Pd ]
P

−P

d
where κ1 = (π0 (1−Pff a 1 (1−Pd )) .
a )+π
Note that the malicious sensor can pass the CFC only if she
could ﬁnd a ϕ∗ = [ϕ∗ , ϕ∗ ] that satisﬁes both g1 (ϕ∗ ) = 0
01
10
10
(M)
(tr)
(i.e., Ψ1 = Ψ1 ) and (6). Denote ϕ ∗ as the non-zero root
10
of g1 (ϕ10 ) = 0, which can be found as:

(3)

π0 a00 (1 − Pf a )2 + (π0 a01 + π1 a10 )(1 − Pd )(1 − Pf a )
π0 (1 − Pf a ) + π1 (1 − Pd )
π1 a11 (1 − Pd )2
.
+
π0 (1 − Pf a ) + π1 (1 − Pd )

(tr)

(tr)

2 − Ψ1

(M)

− Ψ0

1 − Ψ0
(tr)

A. Conditional Frequency Check
According to the preceding model, a malicious sensor has
two degrees of freedom, i.e., two parameters ϕ 01 and ϕ10 , in
launching an attack. The convectional frequency check, which
detects malicious sensors by computing their frequencies of
reporting 1 [10], enforces only one constraint to the attacker’s
behavior as indicated in Eq.(6) below. This is insufﬁcient to
prevent the malicious sensor from attacking. However, when
the true spectrum states are Markovian, the proposed CFC can
enforce two constraints by exploring the correlation between
consecutive spectrum states, and consequently identify any
ﬂipping attack easily. In particular, the CFC consists of two
statistics as deﬁned below.
Deﬁnition 1: The two conditional frequency check statistics
of a sensor are deﬁned as Ψ 1
P r(rt = 1|rt−1 = 1), and
P r(rt = 0|rt−1 = 0), respectively, where r t denotes
Ψ0
the sensor’s report at time t.
According to the deﬁnitions, these two statistics are related
to the model parameters as
2
2
π0 a00 Pf a + (π0 a01 + π1 a10 )Pd Pf a + π1 a11 Pd

(M)

2 − Ψ1

= P r(rt

The proposed malicious sensor detection method consists
of two phases: 1) conditional frequency check (CFC), and 2)
an auxiliary hamming distance check (HDC).

Ψ1 =

1 − Ψ0

ϕ∗ = −
10
(4)

ξ2
,
κ1 ξ1

(8)

2
2
where ξ1 = π0 π1 a00 − (π1 a10 + π0 a01 )π1 π0 + π1 π0 a11 and

In the CFC, the fusion center will evaluate Ψ 1 and Ψ0 for
every sensor and compare the resulting values with those of
the trusted sensor. If the values are sufﬁciently different, the
corresponding sensor will be identiﬁed as malicious. In the
following, the effectiveness of this statistical check is demonstrated through two analytical results, followed by a practical
approach to estimating these two statistics that eliminates the
requirement of any prior knowledge about the sensing and
spectrum models.

ξ2 = −2π1 π0 a00 Pf a + (π1 a10 + π0 a01 ) · (π0 Pf a − π1 Pd )
+2π1 π0 a11 Pd .
According to (6) and (8), ϕ ∗ is given as
01
ϕ∗ = −
01
where κ0 =

2

Pf a −Pd
(π0 Pf a +π1 Pd ) .

ξ2
,
κ0 ξ1

(9)

3

to the same value, i.e., Ψ (tr) . On the other hand, the CFC
statistics of any malicious sensor will converge to some value
Ψ(M) (depending on its ϕ), which is different from Ψ (tr)
according to Proposition 2. Therefore, any sensor whose CFC
statistics differs from that of the trusted sensor is malicious.
In practice, the values of the two CFC statistics between
any two honest sensors may be different due to ﬁnite detection
window length T . For this concern, only when the difference
between the CFC statistics of a sensor and those of the trusted
sensor is larger than a pre-speciﬁed threshold β CF C , will this
sensor be identiﬁed as malicious. The proposed CFC procedure
with threshold βCF C is summarized in Algorithm 1.

Consider the relation πA = π, (8) and (9) can be simpliﬁed
as
ϕ∗ = 2 −
10

2(a10 Pf a + a01 P d)
,
a10 + a01

(10)

2(a10 Pf a + a01 P d)
.
(11)
a10 + a01
As a direct consequence of (10) and (11), ϕ ∗ + ϕ∗ = 2 must
10
01
hold if the malicious sensor wants to pass the CFC. On the
other hand, 0 ≤ ϕ ∗ , ϕ∗ ≤ 1 by deﬁnition. These two condi01
10
2(a10 Pf a +a01 P d)
tions imply that {ϕ∗ , ϕ∗ } exists only if
=1
01
10
a10 +a01
∗
∗
and the corresponding {ϕ 01 , ϕ10 } equals {1, 1}. Otherwise,
there is no valid non-zero solution for both g 1 (ϕ10 ) = 0 and
(6). That is, the malicious sensor cannot pass the CFC if she
attacks.
Deﬁne the error function e(ϕ) ||Ψ (tr) − Ψ(M) ||2 , where
(tr)
(tr)
(M)
(M)
(tr)
[Ψ1 , Ψ0 ] and Ψ(M) [Ψ1 , Ψ0 ] are the CFC
Ψ
statistics of the trusted and the malicious sensor, respectively.
a Pf a +a01 P d
A typical ﬁgure of e(ϕ) when the condition 10 a10 +a01
= 1
2
holds is shown in Fig. 1. As can be seen, {1, 1} is the only
blind spot of the CFC. In contrast, the conventional FC only
enforces a linear constraint (6) on the attacker, thus forming
a blind line as indicated in Fig. 1.
ϕ∗ =
01

Algorithm 1 The CFC procedure
ˆ (tr) and Ψ0 (tr) for the trusted sensor according
ˆ
Compute Ψ1
to (12) and (13).
for sensor i do
ˆ (i)
ˆ (i)
Compute Ψ1 and Ψ0 according to (12) and (13).
ˆ
ˆ
if ||Ψ(tr) − Ψ(i) ||2 > βCF C then
Classify sensor i as malicious.
end if
end for

Pd = 0.9, Pfa = 0.1, a01 = 0.2, a10 = 0.2

B. The Hamming Distance Check

0.8

0.4

As shown in Fig. 1, the CFC fails to detect the malicious
a Pf a +a01 P d
sensor using ϕ = {1, 1} when 10 a10 +a01
= 1 . This may
2
happen when a 10 = a01 and Pd + Pf a = 1. However, in
this case, a large normalized hamming distance between the
report sequences from a malicious sensor i and the trusted

0.3

sensor, which is deﬁned as d h (i, tr)

e(ϕ) = ||Ψ(tr) − Ψ(M) ||2

0.7

The linear constraint
enforced by the frequency check

0.6
0.5

0.1
0
1
0.5

Fig. 1.
holds.

0

0

0.2

0.4
ϕ10

Typical graph of e(ϕ) when the condition

0.8

0.6

1

T −1

a10 Pf a +a01 P d
a10 +a01

=

t=1

ˆ
Ψ0

δrt ,1

(12)

δrt ,0

,

(13)

T −1

δrt+1 ,0 δrt ,0
t=1

,

t=1

T −1

δr(i) ,r(tr) , will
t

t

Two different cases are simulated. In both cases P d = 0.9
0.8 0.2
and Pf a = 0.1, but in the ﬁrst case, A = [ 0.2 0.8 ], and
0.8 0.2 ]. Thus, the condition
in the second case, A = [ 0.4 0.6
a10 Pf a +a01 P d
= 1 is satisﬁed in the ﬁrst case but not in the
a10 +a01
2
second one. Every malicious sensor randomly selects its own
{ϕ01 , ϕ10 } according to uniform distribution over (0, 1] 2 . The
thresholds are set as βCF C = 0.2 and βHDC = 0.3. There
are nH = 8 honest sensors and n M = 13 malicious sensors,
i.e., the malicious sensors dominate the network. The detection
window length is T = 100(time slot). At the fusion center,
the majority voting rule is used.
Simulation results of a typical run of the ﬁrst case are
shown in Fig. 2–Fig. 4. In particular, by comparing Fig. 2
and Fig. 3, it can be seen that two malicious sensors whose
ﬂipping probabilities ϕ 01 and ϕ10 are close to 1 successfully
pass the CFC. However, these two malicious sensors fail to
pass the subsequent HDC. Also, it can be seen by comparing
Fig. 3 and Fig. 4 that there is one malicious user surviving both
CFC and HDC. Further examination reveals that the ﬂipping

1
2

T −1

δrt+1 ,1 δrt ,1

t=1

IV. S IMULATIONS

Deﬁnition 2: For any sensor, two histogram estimators for
Ψ1 and Ψ0 are deﬁned as:
ˆ
Ψ1

T

be expected because of the high local inference ﬂipping
probability at the malicious sensor. Based on this observation,
sensor i will be identiﬁed as malicious if d h (i, tr) is greater
than a pre-speciﬁed threshold β HDC .

0.2

ϕ01

1
T

t=1

respectively, where δ i,j = 1 iff i = j and T is the detection
window length.
ˆ
ˆ
Proposition 3: The two estimators Ψ1 and Ψ0 converge to
Ψ1 and Ψ0 , respectively, as T → ∞.
Proof: The proof is give in the Appendix.
Remark 1: According to Proposition 3, the CFC statistics
of all honest sensors (including the trusted one) will converge

3

4

CFC

Truth

0.9

0.8

0.8

0.7

0.7
Ψ0

1

0.9

Ψ0

1

0.6
0.5

0.5

0.4
0.3
0.2
0.1

0.6

0.4
Honest
Malicious
Trusted
0.2

0.3
0.3

0.4

Ψ

0.5

0.6

0.7

0.2
0.1

0.8

Honest
Malicious
Trusted
0.2

0.3

0.4

1

Fig. 2.

Fig. 4.

F
Pd C (case one)
F
Pf aC (case one)
η (case one)
F
Pd C (case two)
F
Pf aC (case two)
η (case two)

Malicious sensors with flipping
probablities close to 1

Ψ0

0.7
0.6
Miss classified
sensor

0.5
0.4

Fig. 3.

0.8

No detection
0.9448
0.0562

Trusted only
0.8982
0.0990

0.9457
0.0550

0.9015
0.0994

Proposed
0.9956
0.0006
95.09%
0.9958
0.0008
95.03%

sensing performance. The proposed method does not rely on
global decision and thus is effective even when the malicious
sensors dominate the network.

Honest
Malicious
Trusted
0.2

0.7

True sensor types.

0.9

0.2
0.1

0.6

TABLE I
AVERAGE PERFORMANCES COMPARISON OVER 100 RUNS .

CFC and HDC
1

0.3

0.5

1

Malicious sensor detection result using CFC.

0.8

Ψ

0.3

0.4

Ψ

0.5

0.6

0.7

0.8

1

A PPENDIX A
P ROOF OF P ROPOSITION 3
n1
1
ˆ
Proof: It can be seen that Ψ1 = n1
Xti in which Xti

Malicious sensor detection result using CFC and HDC.

probabilities of this malicious user are low: ϕ 01 ≈ 0 and
ϕ10 ≈ 0.1. Although this malicious sensor is not detected,
its negative inﬂuence on the spectrum sensing result of the
fusion center is negligible.
Table I summarizes the simulation results over 100 Monte
Carlo runs for both cases. The proposed method achieves
nearly perfect sensing results in both cases, i.e., P d = 0.9956
and Pf a = 0.0006 in the ﬁrst case, and Pd = 0.9958 and
Pf a = 0.0008 in the second case, which are signiﬁcantly
better than the sensing performances of both the single trusted
sensor and that of using all sensors without malicious sensor
detection. Besides, the proposed algorithm also provides high
malicious sensor detection accuracy (η > 95%) in both cases.

i=1

is deﬁned as
Xti =

1,
0,

if rti +1 = 1, given rti = 1,
if rti +1 = 0, given rti = 1,

(14)

where ti is the time slot for the i-th reported 1 of the
ˆ
sensor. To prove the convergence of Ψ1 , we need to prove
ˆ
1) E(Ψ1 ) = Ψ1 , which is simple to show by noticing that
ˆ
E(Xt ) = P r(rt+1 = 1|rt = 1) = Ψ1 ; 2) lim V ar(Ψ1 ) = 0.
T →∞
In general, X t ’s are not independent due to the correlation
between the consecutive true spectrum states in the Markov
model. Thus, the central limit theorem can not be applied.
However, we will show the second fact is true by ﬁrst proving
that the correlation between X i and Xj (i > j) vanishes as
(i − j) approaches inﬁnity. That is,

V. C ONCLUSIONS
A new method consisting of two CFC statistics and an
auxiliary HDC procedure has been proposed in this paper
for malicious user detection under a Markov spectrum model.
By using the two consistent histogram estimators of the CFC
statistics, the proposed method does not require any prior
knowledge of the spectrum and sensing models for malicious
sensor detection. Both theoretical analysis and simulation
results show that the proposed method, with the assistance of
a trusted sensor, can achieve high malicious user detection accuracy, and thus signiﬁcantly improves collaborative spectrum

lim

(i−j)→∞

E(Xi Xj ) = E(Xi )E(Xj )

(15)

Note that
E(Xi Xj )
= P r(ri+1 = 1, rj+1 = 1|ri = 1, rj = 1)
= P r(rj+1 = 1|rj = 1)P r(ri+1 = 1|ri = 1, rj = 1)
= P r(rj+1 = 1|rj = 1)[P r(si+1 = 1|ri = 1, rj = 1)Pd
+P r(si+1 = 0|ri = 1, rj = 1)Pf a ]

4

5

1
n2
1

and

P r(si+1 = 1|ri = 1)
Pd P r(si+1 = 1, si = 1) + Pf a P r(si+1 = 1, si = 0)
=
Pd P r(si = 1) + Pf a P r(si = 0)
π1 Pd a11 + π0 Pf a a01
=
,
(16)
π1 Pd + π0 Pf a
and P r(si+1 = 1|ri = 1, rj = 1) is given as3
P r(si+1 = 1|ri = 1, rj = 1)
P 2 P r(si+1 = 1, si = 1, sj = 1)
= d
2
Pd P r(si = 1, sj = 1)
+Pd Pf a P r(si+1 = 1, si = 0, sj = 1)
...
+Pd Pf a P r(si = 0, sj = 1)
+Pd Pf a P r(si+1 = 1, si = 1, sj = 0)
...
+Pd Pf a P r(si = 1, sj = 0)
2
+Pf a P r(si+1 = 1, si = 0, sj = 0)
...
2
+Pf a P r(si = 0, sj = 0)
(11)

2
π1 (Pd pi−j a11 + Pd Pf a (1 − pi−j )a01 )
(11)

(11)

2
π1 (Pd pi−j + Pd Pf a (1 − pi−j ))
(00)

...

(00)

2
+π0 (Pf a pi−j a01 + Pd Pf a (1 − pi−j )a11 )
(00)

(00)

2
+π0 (Pf a pi−j + Pd Pf a (1 − pi−j ))

(11)

,

(17)

(00)

P r(sn+j = 1|sj = 1) and pn
P r(sn+j =
where pn
0|sj = 0). According to the deﬁnition, the following recursive
(11)
relation holds for p n ,
p(11) = P r(sj+n = 1|sj = 1)
n
= P r(sj+n = 1, sj+n−1 = 1|sj = 1)
+P r(sj+n = 1, sj+n−1 = 0|sj = 1)
(11)

(11)

= a11 pn−1 + a01 (1 − pn−1 ).
(11)

(18)
(00)

Consequently, p ∞ = 1−aa01 01 . Similarly, we have p ∞ =
11 +a
a10
1−a00 +a10 . Substituting these two expressions into (17), it
can be veriﬁed that P r(s i+1 = 1|ri = 1, rj = 1) =
π1 Pd a11 +π0 Pf a a01
= P r(si+1 |ri = 1) as i − j approaches
π1 Pd +π0 Pf a
inﬁnity. Therefore (15) holds.
ˆ
Now, we will use (15) to prove that lim V ar(Ψ1 ) = 0.
n1 →∞

For any positive δ, ∃ K δ such that |Cov(Xi , Xj )| < δ/2 when
|i − j| > Kδ due to (15). Also, given K δ , ∃ Nδ such that
ˆ
4Kδ < δNδ . Then, for any n 1 > Nδ , we have V ar(Ψ1 ) =
3 Note

that

a
+b
... +y
x

is used to represent

a+b
x+y

δ
n1 1×2Kδ + 2 ×(n1 −2Kδ )

<

[1] I. F. Akyildiz, B. F. Lo, and R. Balakrishnan, “Cooperative spectrum
sensing in cognitive radio networks: A survey,” Physical Communication
(Elsevier) Journal, vol. 4, no. 1, pp. 40–62, Mar. 2011.
[2] G. Baldini, T. Sturman, A. Biswas, R. Leschhorn, G. G´ dor, and M.
o
Street, “Security aspects in software deﬁned radio and cognitive radio
networks: A survey and a way ahead,” IEEE Commun. Surveys Tuts.,
no. 99, pp. 1–25, Apr. 2011.
[3] A. S. Rawat, P. Anand, H. Chen, and P. K. Varshney, “Collaborative
spectrum sensing in the presence of Byzantine attacks in cognitive radio
networks,” IEEE Trans. Signal Process., vol. 59, no. 2, pp. 774–786, Feb.
2011.
[4] R. Chen, J. M. Park, Y. T. Hou, and J. H. Reed, “Toward secure distributed
spectrum sensing in cognitive radio networks,” IEEE Commun. Mag.,
vol. 46, no. 4, pp. 50–55, Apr. 2008.
[5] R. Chen, J. M. Park, and K. Bian, “Robust distributed spectrum sensing
in cognitive radio networks,” Proc. INFOCOM, Phoenix, AZ, May. 2008.
[6] P. Kaligineedi, M. Khabbazian, and V. K. Bhargava, “Malicious user
detection in a cognitive radio cooperative sensing system,” IEEE Trans.
Wireless Commun., vol. 9, no. 8, pp. 2488–2497, Jun. 2010.
[7] W. Wang, H. Li, Y. Sun, and Z. Han, “Securing collaborative spectrum
sensing against untrustworthy secondary users in cognitive radio networks,” EURASIP Journal on Advances in Signal Processing, vol. 2010,
Oct. 2010.
[8] K. Zeng, P. Paweczak, and D. Cabric, “Reputation-based cooperative
spectrum sensing with trusted nodes assistance,” IEEE Commun. Lett.,
vol. 14, no. 3, pp. 226–228, Mar. 2010.
[9] S. Marano, V. Matta, L. Tong, “Distributed detection in the presence of
Byzantine attacks,” IEEE Trans. Signal Process., vol. 57, no. 1, pp. 16–29,
Jan. 2009.
[10] H. Li, and Z. Han, “Catch me if you can: An abnormality detection
approach for collaborative spectrum sensing in cognitive radio networks,”
IEEE Trans. Wireless Commun., vol. 9, no. 11, pp. 3554–3565, Nov. 2010.
[11] F. Adelantado, and C. Verikoukis, “A non-parametric statistical approach
for malicious users detection in cognitive wireless ad-hoc networks,”
Proc. ICC, Kyoto, Japan, Jul. 2011.
[12] A. Vempaty, K. Agrawal, H. Chen, and P. Varshney, “Adaptive learning
of Byzantines’ behavior in cooperative spectrum sensing,” Proc. WCNC,
Quintana Roo, Mexico, May 2011.
[13] D. Zhao, X. Ma, and X. Zhou, “Prior probability-aided secure cooperative spectrum sensing,” Proc. WiCOM, Wuhan, China, Oct. 2011.
[14] S. Li, H. Zhu, B. Yang, C. Chen, and X. Guan, “Believe yourself: A usercentric misbehavior setection scheme for secure collaborative spectrum
sensing,” Proc. ICC, Kyoto, Japan, Jul. 2011.

Note that P r(si+1 = 1|ri = 1) is given as

=

1
n2
1

R EFERENCES

P r(si+1 = 1|ri = 1, rj = 1) = P r(si+1 = 1|ri = 1)

(11)

Cov(Xi Xj ) ≤

2−δ
Nδ Kδ

Comparing the two preceding equations, it can be seen that,
to prove (15), it is sufﬁcient to prove
(i−j)→∞

j

ˆ
+ δ < δ. That is, lim V ar(Ψ1 ) = 0. On the other
2
n1 →∞
hand, for any ﬁnite N δ , n1 > Nδ with probability 1 when
ˆ
T approaches inﬁnity, which implies lim V ar(Ψ1 ) = 0.
T →∞
ˆ
Therefore, Ψ1 converges to Ψ 1 . Following the same approach,
ˆ
it can be shown that Ψ0 converges to Ψ 0 .

E(Xj )E(Xi )
= P r(rj+1 = 1|rj = 1)P r(ri+1 = 1|ri = 1)
= P r(rj+1 = 1|rj = 1)[P r(si+1 = 1|ri = 1)Pd
+P r(si+1 = 0|ri = 1)Pf a ].

lim

i

due to space limitations.

5

