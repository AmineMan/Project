Title:          Journal_Paper_Ver5_ISIT.dvi
Creator:        dvips(k) 5.99 Copyright 2010 Radical Eye Software
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Fri May 18 17:32:52 2012
ModDate:        Tue Jun 19 12:55:08 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      324982 bytes
Optimized:      no
PDF version:    1.7
ISIT'2012 1569566447

Achievable Gains in Peak Power Reduction via
Single-Carrier Distribution Shaping
Stella Achtenberg

Dani Raphaeli

Dept. of EE-Systems, TAU
Tel Aviv, Israel
Email: stellala@post.tau.ac.il

Dept. of EE-Systems, TAU
Tel Aviv, Israel
Email: danr@eng.tau.ac.il

by a reduction of the shaping code. In order to implement
a matched decoder, i.e., a decoder which is aware of the
subcode and its distribution, the decoder may have to repeat
the selection process for each tested codeword, leading to high
complexity decoding.
Several practical shaping methods use this approach. Forney
[3] introduces the Trellis Shaping (TS) technique for average
power reduction. In his scheme, the large code is the composite
code formed by joining the shaping code with the channel
code. Then, given the coded bits, the free shaping bits creates
a set of sequences, i.e., a coset of the large code, from which
one sequence is chosen such that the transmitted codeword
has minimal power in the coset. This is an example of the
general method presented above. For 256QAM constellation,
Forney achieves about 1dB shaping gain. Similar procedures
exist in the compound LDPC-LDGM scheme [4] where given
an information word the compound code creates a coset to
choose the shaped codeword from. The PAR reduction was
also treated using the TS framework. In [2], the authors
propose TS concatenated with Turbo code for PAR reduction.
In [5], PAR reduction of high order QAM signals is the prime
target.
While few papers show practical results on PAR reduction
using TS, an analysis of the available gains is still missing. In
this paper we present two important observations and a method
to make this analysis possible. First, we have found that the
distribution of the nontypical codewords, which are chosen
to satisfy a peak power constraint, can be obtained using the
conditional limit theorem under Markov conditioning [1]. The
knowledge of this distribution is necessary to approximate
the mutual information of this codebook on the AWGN
channel. Secondly, we claim that the mutual information of the
nontypical subcode at the large code SNR (the SNR which can
carry R+Rs bits per symbol with the uniform i.i.d. distributed
codebook) less the average energy reduction, is sometimes
lower that the transmitted rate R, and therefore the decoding
of the subcode using the large code decoder is not error free.
In other cases, this mutual information may be higher than R,
and in this case we can gain SNR by using a matched decoder.
In this latter case, the achievable peak and shaping gains are
much higher. Our analysis includes both the matched and the
mismatched decoder performance bounds.
High peak values occur in single carrier systems as the

Abstract—This paper presents a method to ﬁnd a lower bound
on the peak power reduction of single carrier signals having low
rolloff pulse shaping ﬁlter, and transmitted over the Additive
White Gaussian Noise channel (AWGN). Peak power as well as
any other property can be controlled by judiciously choosing a
codebook, such that the peak power of any of the codewords does
not exceed a threshold (or exceeds in a low probability). One of
the methods to generate such codebook, called shaping, is to start
with a larger codebook with i.i.d. uniform distribution and choose
a subcode which optimizes the property. This approach includes
the popular method of Trellis Shaping. We analyze the limit of the
gains obtainable by the shaping method by using the conditional
limit theorem under Markov conditioning, and by that we can
show achievable peak reduction bounds. We analyze two types of
receivers. The ﬁrst is a receiver that is matched to the subcode,
i.e., it is aware of the dilution made at the transmitter, and
the second is a mismatched decoder, a decoder for the original
large codebook, like in the case of Trellis Shaping. We show that
signiﬁcant peak and Peak to Average (PAR) gains, as large as 1.7
dB, are achievable, even for small constellations such as 16QAM
and 16APSK transmission constellations for Square Root Raised
Cosine ﬁlter (SRRC) with rolloff 0.1.

I. I NTRODUCTION
We study theoretical bounds of average power reduction and
peak reduction of single carrier ﬁnite constellations on AWGN
channel. In many practical communication systems, such as
mobile terminals, economical utilization of energy is necessary
and much effort is invested in achieving this goal. In addition,
narrow pulse shaping ﬁlters are used to control bandwidth,
and the resulting high Peak to Average ratio (PAR) is of
interest since it dictates the backoff of the Power Ampliﬁer
(PA). Backoff reduction in turn increases PA efﬁciency which
is beneﬁcial in power constrained systems.
Many methods have been devised over the years for average power reduction and similar methods can be used for
peak power reduction. One of these methods is to choose
codewords which satisfy a criterion from a larger uniformly
distributed codebook. The chosen subcode consists of nontypical codewords in the larger codebook and therefore peak and
average power shaping is possible. Let the large codebook
have 2n(Rs +R) codewords and is divided into 2nR random
sets of a shaping code of size 2nRs , where R and Rs are
the information rate and shaping rate, respectively, and n
is the codeword length. The decoder, to save complexity,
is usually the decoder for the original large code followed

1

result of using pulse shaping ﬁlter with low rolloff. Our goal in
this work is to reduce peak power, but without compromising
average power. In the rest of this paper we will call the
reduction of peak power as peak gain and the reduction of
average energy as shaping gain, both while maintaining a
speciﬁed error free data rate over the channel.
Our analysis shows that for 16QAM constellation with
information rate R = 3, and raised cosine pulse shape with
rolloff 0.1, the achievable peak gain is 1.7dB with the matched
decoder and 1.45dB with the mismatched decoder at Rs = 0.2.
We conclude that for power constrained systems, where we do
not allow the average power to exceed the average power of
the reference system, low Rs should be used with the matched
decoder. At this working point, the shaping gain is positive,
as required. In other systems, where small gain degradation is
possible, the mismatched decoder may be considered to save
complexity.

III. S UBOPTIMAL M UTUAL I NFORMATION O PTIMIZATION
Let capital letters denote random variables and vectors
and small letters their realizations. Let U be a transmission
sequence, S be the transmission state sequence, PU , PS
be the distribution of U and S respectively, and Y be
the random vector at the receiver. It is easy to see that
PU (u) = PS (s) and that H (U ) = H (S) where H (Z) =
1
limn→∞ n H (Z0 , · · · , Zn−1 ) deﬁnes the entropy rate of a
random vector Z. The mutual information between U and
Y is I (U ; Y |α) = H (S) − H (U |Y , α).
Let us now assume a general constrained transmission,
where later in this paper we consider the special case of peak
power and average power constraints. Let
1
n

n−1

ϕl (α, si , si+1 ) ≤ 1

(1)

i=0

be a set of constraints where ϕl (·), l = 0, · · · , L − 1 are a set
of constraint functions, α is the transmitter gain (parameter)
and (si , si+1 ) are the transmission states as deﬁned in Section
2. We denote the set of all pairs (α, PU ), which satisfy
the constraints in (1), as A. An important question to ask
is which member of A maximizes the mutual information
RA = maxA I (U ; Y |α), i.e., which is the maximal reliable
transmission rate under these constraints. The direct maximization of the mutual information over A has known numeric
solutions in special cases only. For example, in the average
power constraint case, the optimal distribution is i.i.d., and
thus, the optimal solution can be obtained using the modiﬁed
Arimoto-Blahut algorithm [7].
We consider a different, suboptimal approach, which can
be applied to any general constraints of the form (1) and
stationary K − 1 order Markov chain solutions PU . It is
easy to verify that the state sequence distribution PS is a
ﬁrst order stationary Markov chain with two dimensional
distribution P , and transition matrix probability P (si+1 |si ) =
P (si , si+1 ) /P (si ). Instead of maximizing the mutual information we will maximize the entropy rate subject to the
constraints. The entropy rate, in the case of stationary Markov
chain, depends only on consequent state variables [8], i.e.,
H (S) = H (S K−1 |S K−2 ) = H (P ) where H (P ) =
si ,si+1 P (si , si+1 ) log2 P (si+1 |si ). The optimization process is to maximize the mutual information within the entropy
rate maximizing distributions set. More precisely, for each α
we ﬁnd the distribution P ⋆ (α), which maximizes H (S) under
the constraints. Then, the maximization is conducted over α,
i.e., RH = maxα I (U ; Y |α) ≤ RA is a lower bound of the
maximal achievable rate subject to the constraints. Next, we
will show how to obtain the distributions set P ⋆ (α) by using
the conditional limit theorem under the Markov conditioning
[1].

II. S YSTEM M ODEL
Let U be a two dimensional (2D) constellation with cardinality |U| = M . Let u = (u0 , · · · , un−1 ), where ui ∈ U
be a frame of symbols of length n transmitted over the
AWGN channel. The transmission sequence u is passed
through a Square Root Raise Cosine (SRRC) pulse shape
ﬁlter h (t) and ampliﬁed using an ideal power ampliﬁer. The
complex continuous time baseband signal x (t), representing
the RF signal at the output of the power ampliﬁer is x (t) =
n−1
α i=0 ul h (t − lT ) where α represents the gain of the power
ampliﬁer, and T is the symbol duration. At the receiver, x (t)
is processed by a matched ﬁlter. Let y = (y0 , · · · , yn−1 ) be a
frame of received signals at the output of the matched ﬁlter.
Due to the zero ISI property of the RRC, yi = αui +Ni where
Ni ∼ CN (0, 1) are i.i.d. complex Gaussian noise samples,
normalized to unit variance.
We are now interested in the peak power of the transmitted
signal. Let x(t) be approximated by a sampled signal xj =
i
x( jT + iT ), j = 0, · · · , J − 1 where J is the over-sampling
J
K−1
ratio. It is easy to show that xj = α k=0 ui−k hj , where
i
k
j
jT
hk = h( J + kT ) are samples of the pulse shape ﬁlter h (t)
at sampling times jT + kT , where K is the ﬁlter length. The
J
2

power of the sample xj is pj = xj . We deﬁne the power
i
i
i
during the period (iT, (i + 1)T ] as the maximal sample power
pi = maxj pj .
i
Let us deﬁne channel transmission state si by K − 1
consequent symbols si = (ui , · · · , ui+K−2 ), with state space
U K−2 , V as the set of all valid consequent states and the
entire transmission state sequence by s. The power pi can be
expressed by two consequent channel states (si , si+1 ) ∈ V,
such that pi = α2 f (si , si+1 ), i = 0, · · · , n − 1, ignoring edge
effects. The set of all possible peak power values (before the
power ampliﬁer) is denoted by P such that pi ∈ α2 P, where
each value in P is deﬁned by its origin (si , si+1 ) pair and
equal values are considered distinct points.

IV. C ONDITIONAL L IMIT T HEOREM U NDER M ARKOV
C ONDITIONING
We like to brieﬂy review the theory of conditional limit
theorem, generalized for Markov chains [1] which we are

2

for (si , si+1 ) ∈ E and zero otherwise. The Markov Iprojection is obtained by

intending to use for maximizing the entropy rate under a
set of constraints (1). We present the theorem with respect
to our constraints. Let W (· | ·) be a transition probability
matrix of a ﬁrst order stationary Markov chain with state space
W. We deﬁne the set of all possible transitions as S (W ) =
{(si , si+1 ) : W (si+1 |si ) > 0}, where the possible distributions W are restricted to S (W ) ⊂ V, i.e., if (si , si+1 ) ∈ V
/
(not valid consequent states) then W (si+1 |si ) = 0.
Let s = (S 0 = s0 , · · · , S n−1 = sn−1 ) be a state sequence
realization drawn from probability W and let us deﬁne a two
dimensional empirical distribution by the relative frequencies
(2)
1
Ps (w j ) = n |i ∈ {1, · · · , n − 1} : (si , si+1 ) = wj |, ∀w j ∈
S (W ). Let Π be a set of distributions which satisfy a set of
constraints in (1), i.e.,




Π= P :
P (si , si+1 ) ϕl (α, (s, si+1 )) ≤ 1



P ⋆ (si , si+1 ) =

ˆ
ζ = arg min

∀ζl ≥0

P (si , si+1 ) log2
si ,si+1 ∈W

(2)

P (si+1 |si )
(3)
W (si+1 |si )

∈ Π = 2−nD(P

⋆

W)

.

A. The Markov I-projection
As stated, the Markov I-projection P ⋆ maximizes the
entropy under a set of constraints when using Wu . We next
show how to ﬁnd the Markov I-projection following [1]. Let
E be an irreducible subset of W 2 such that E ⊂ S (Wu ). Let
λζ , uζ and vζ be the largest eigenvalue, the normalized left
and right eigenvectors of the matrix Qζ respectively, where
ζ = (ζ0 , ..., ζL−1 ), an arbitrary set of positive variables, and
the entry of Qζ is
1
Qζ (si , si+1 ) =
exp −
M

ζl + log λζ

(6)

l

In previous sections we have established the set of distributions which maximize the entropy rate of U , one for
each ampliﬁer gain α, namely P ⋆ (α) as deﬁned by (5).
Using the procedure that will be described in Section 7 we
ﬁnd the solution of R = RH = maxα I (U ; Y |α). Next, a
codebook should be constructed according to the maximizing
distribution. In this paper, we use random coding to generate
our codebook.
The ﬁrst method to create a random codebook, is to directly
generate 2nR codewords from a desired distribution P ⋆ (α),
and then amplify the transmitted signal by the corresponding
α. Alternatively, we can generate a large codebook from an
i.i.d. uniform distribution on U and then choose from it only
those codewords which satisfy our constraints set. Such a
method is called “shaping” might be more appealing due to its
simplicity. In real life situations, good codes for uniform distribution are readily available, and codeword selection might
be a simple procedure for a properly structured code, for
example using trellis shaping [2], [3], [5]. The conditional limit
theorem has shown that those codewords have the distribution
of the Markov I-projection when n → ∞. Furthermore, it
is easy to verify that an i.i.d. uniform distribution on U is
equivalent to Wu and thus the Markov I-projection maximizes
the entropy rate as we shown. More formally, let C be a
random codebook with i.i.d. uniform distribution on U and
2n(R+Rs ) codewords, where R is the information rate to be
transmitted and Rs is an additional constant, called shaping
rate. This codebook, which we refer to as the large codebook,
is divided into 2nR random sets with 2nRs codewords in each
set. A message m to be transmitted determines the random set.
Out of this random set a single codeword to be transmitted
is selected such that it satisﬁes the constraints in (1). The
design parameter Rs is chosen such that each set contains
at least one codeword which satisﬁes the constraints under
the obvious restriction Rs + R ≤ log2 M . According to
Theorem 4 in [1] the probability that a codeword satisﬁes
⋆
the constraints is Ps = 2−nD(P (α) Wu ) . It can be shown
that Rs = D(P ⋆ (α)
Wu ) + ǫ, where ǫ > 1/n insures
that at least one codeword within a random set satisﬁes the
constraints. The outcome of this process is a subcode Cs with
2nR codewords which can reliably transmit R information bits
per symbol, when ampliﬁed by α.

restricted to {P : S (P ) ⊂ S (W )}. Deﬁnition 2 in [1] deﬁnes
Markov I-projection of the transmission probability matrix
W on Π0 as a unique P ⋆ ∈ Π0 such that D(P ⋆ W ) =
minP ∈Π0 D(P
W ) < ∞. For the special case, where
1/M
(si , si+1 ) ∈ V
W = Wu (si+1 |si ) =
, it can
0
else
⋆
be also shown that Markov I-projection P maximizes the
entropy rate H(P ).
Theorem 4 in [1] states that if P ⋆ exists, and if the empirical
(2)
distribution Ps of the realization s belongs to Π; then
n−1
in the limit of n → ∞, Pr(s) = P ⋆ (s0 ) i=1 P ⋆ (si |
⋆
si−1 ). Furthermore, if P exists, then the probability that
(2)
the empirical distribution Ps
of s belongs to Π is
(2)
1
limn→∞ n log2 Pr Ps ∈ Π = −D(P ⋆ W ) and for very
large n is approximated by Pr Ps

(5)

V. R ANDOM C ODEBOOK C ONSTRUCTION

(2)
with l = 0, ..., L − 1 and let Π0 be a subset of Π such that
the two marginals of P are equal. Let D(P
W ) be the
Kullback-Leibler information divergence
W) =

λζ
ˆ

where

si ,si+1 ∈W

D(P

uζ (si )Qζ (si , si+1 ) vζ (si+1 )
ˆ
ˆ
ˆ

A. Decoder types

L−1

ζl ϕl (α, si , si+1 )

We consider two types of decoders. The ﬁrst, called matched
decoder, is a decoder that is aware of the distribution PU

(4)

l=0

3

16QAM vs 16APSK, R=3

deﬁne a threshold peak function

2.5
PG−M
SG−M
PG−MM
SG−MM

Peak and average power gains

2

ϕ0 (α, si , si+1 ) =

1.5

0.5

0

−0.5

−1

Figure 1.

0.1

0.2

0.3
0.4
0.5
Shaping rate Rs

0.6

0.7

0.8

Peak gain and shaping gain vs Rs, 16QAM, R = 3
CCDF vs PAR, 16QAM, R=3

1
Rs=0.55
Rs=0.2

0.9

ϕ0 (si , si+1 ) =
˜

0.8

and ϕ1 (si , si+1 ) =
˜

CCDF

0.6
0.5
0.4
0.3
0.2
0.1
0.5

1

1.5

2

2.5

PAR

Figure 2.

1
˜
β1

˜
p i ≤ β0
˜
else

1
1/ǫ

i+K−1
k=i

(8)

2

|uk | where pi = pi /α2 =
˜
˜
f (si , si+1 ) is the normalized power and β = β/α2 is the
maximal peak power and average power, both measured before
˜
ampliﬁcation. Let B ⊂ P be the set of equivalent constraints
˜ for which the Markov I-projection P ⋆ β exists. The
˜
β
mutual information I (U ; Y |α) is strictly monotonic in α for
˜
a given distribution P ⋆ β , therefore a unique α satisﬁes
R = I (U ; Y |α). We ﬁnd the corresponding α to each
˜
equivalent constraint in B and this deﬁnes the set β ∈ B of all
possible constraints for which the rate R is achievable. The
knowledge of B allows us to choose the tradeoff between β0
˜
˜
˜
and β1 . Next we ﬁnd P ⋆ β for each β ∈ B using (4)-(6).
For (si , si+1 ) ∈ E, ζ0 > 0 and ǫ → 0, the entry

0.7

0

(7)

where β0 is a threshold to the maximal peak power after the
ampliﬁer and ǫ > 0 is a sufﬁciently small number, such that no
sequence with peak power above β0 satisﬁes the constraint. Let
us also deﬁne an average power function ϕ1 (α, si , si+1 ) =
i+K−1
2
α2
|uk | with average power constraint β1 . At this
k=i
β1
point, we change the problem formulation from maximizing
the rate given a constraint β = (β0 , β1 ) to ﬁnding the set
of all possible β constraints such that the rate is R. For that
purpose, let us deﬁne equivalent functions to ϕ0 and ϕ1 as

1

0

p i ≤ β0
else

1
1/ǫ

CCDF functions for Rs = 0.55 and Rs = 0.2

as well as the codebook set Cs and is performing optimal
decoding. The matched decoder performance is given by the
the mutual information. The second decoder that we will
consider, will be called mismatched decoder, and it is a
decoder that is only aware of the large code C and perform
optimal decoding as if all codewords of C might have been
transmitted. This decoder is suboptimal, but occasionally more
practical than the matched decoder, since the decoder for
the large uniform code is readily available, and adaptation
to the set Cs might be extremely complex. Unfortunately
we cannot provide an accurate performance bounds for the
mismatched decoder. The only performance estimation that we
can provide is ﬁnding the working point of the mismatched
decoder according to the noise level where large code error
probability tend to zero. If all codewords in code C had have
same error probability when transmitted, then this estimate
would have been accurate. This is correct for codes (bad codes)
which their error performance is determined by the minimum
distance. However, for a general code, not all codewords have
same error performance and thus the codewords from the
set Cs might have either higher or lower error performance
compared to the average codeword of C.

Qζ (si , si+1 ) =
=

1
exp (−ζ0 − ζ1 ϕ1 (si , si+1 )) (9)
˜
M
1
exp (−ζ0 ) Qζ1 (si , si+1 )
(10)
M

˜
for f (si , si+1 ) < β0 and Qζ (si , si+1 ) = 0 otherwise,
˜
due to limǫ→0 exp − ζǫ0 − ζ1 ϕ1 (si , si+1 ) = 0. The entry
˜
Qζ1 (si , si+1 ) = exp (−ζ1 ϕ1 (si , si+1 )) for f (si , si+1 ) < β0
˜
and zero otherwise. We use the property that the eigenvalues
of matrices A, B such that A = bB, satisfy λ (A) = bλ (B), to
M K−1
1
show that λζ = M exp(−ζ0 )
λ (Qζ1 ). The optimizaˆ = arg minζ0 ,ζ1 ≥0 ζ0 + ζ1 − ζ0 M K−1 + log λζ1
tion ζ
can be conducted separately for ζ0 and ζ1 where the minimal
ˆ
ζ0 → 0 and ζ1 = arg minζ1 ≥0 (ζ1 + log λζ1 ). Two special
cases exist. The ﬁrst is using only the peak power constraint,
in this case ζ1 = 0. The second case is using only the
average power constraint, for which the solution is i.i.d. and
the maximizing entropy rate distribution is the well known
Maxwell-Boltzmann distribution [8]. In order to choose a
working point in B, we deﬁne a reference system which
transmits i.i.d. symbols from a 2D constellation Uref , with
uniform distribution on Uref . The reference system transmits
reliably the rate R. The average power of the reference system
is β1,ref . The shaping gain in deﬁned as γs = [β1,ref /β1 ]dB .

VI. P EAK A ND AVERAGE P OWER C ONSTRAINTS
We proceed our analysis by using peak and average power
reduction constraints as the Markov constraints in (1). Let us

4

Two constraints, 16QAM vs 16QAM, R=3, two filter samples

preferable due to higher peak power gain and positive shaping
gain. Furthermore, we clearly see that the matched decoder
outperforms the mismatched in both peak and shaping gain,
but the loss of the mismatched decoder is only signiﬁcant in
high Rs . The maximal peak gain using the matched decoder
is 1.7dB and 1.45dB when using the mismatched at Rs = 0.2.
The 16APSK simulation (not given here) shows maximal peak
gain of 1.9dB at Rs = 0.26 for the matched and 1.6dB for
the mismatched, with negative shaping gain in both cases.
Fig. 2 presents the CCDF function deﬁned by CCDF (x) =
1 − a≤x P (a) of two different shaping rates for 16QAM
versus PAR. We observe that the CCDF, which corresponds to
the higher rate, has the lower maximal PAR (2.2 dB), which is
a direct result of the shaping loss. This kind of PAR reduction
is less preferable, but can be used in systems where the average
power is not the prime concern. The lower rate CCDF has
higher maximal PAR (2.4dB), however we can observe that
more probability is concentrated at the lower PAR values, as
opposed to the smoother CCDF of the higher rate.
Fig. 3 presents the results for the two dimensional optimization (β0 , β1 ) for 16QAM versus uniform 16QAM and pulse
shape of two samples. The different curves represent different
˜
˜
peak thresholds β0 while changing β1 . Each curve starts with
no average power constraint (ζ2 = 0), and proceeds such that
˜
the average power β1 decreases. We can see that the average
power constraint increases the shaping gain but also decreases
the peak gain, at some point it becomes not worthwhile since
both peak and shaping gains decrease. Nevertheless, the two
dimensional search allows more working points with better
peak gain-shaping gain tradeoff. This can be observed by the
curve corresponding to Rs = 0.17, in which for peak gain
between 1.1dB and 0.3dB, it present the maximal shaping gain
compared to the other curves for the same peak power gain.

1.4
Rs = 0.57
Rs = 0.49
Rs = 0.41
Rs = 0.17
Rs = 0.12

1.2

Peak power gain

1

0.8

0.6

0.4

0.2

0

Figure 3.

−0.6

−0.4

−0.2

0
Shaping gain

0.2

0.4

0.6

Peak gain - shaping gain tradeoff 16QAM, matched decoder

In a similar manner, the peak power gain is deﬁned as
γp = [β0,ref /β0 ]dB . The peak power and the shaping gains
are calculated for each β ∈ B. This allows us to choose
the preferable working point with respect to the reference
system. Another interesting parameter is the PAR, that can
be calculated using P AR = γp − γs . The PAR is mostly
important for determining the dynamic range of the transmitter.
Maximizing the peak gain while not compromising the shaping
gain, obviously reduces also the PAR.
VII. M UTUAL

INFORMATION APPROXIMATION

Finally we are resorting to ﬁnding a unique α which
satisﬁes R = I (U ; Y |α) for a given distribution PU . It
is difﬁcult to calculate the mutual information of correlated
sources over the AWGN. For that reason, we use a Monte
Carlo approximation [5]. For very long sequences the mutual
information is approximated by
1
ˆu ˜
I(˜; y , α) = H(˜) − H(˜i | ui ) = − log2 p(˜) − H(˜i | ui )
y
y ˜
y
y ˜
n
(11)
where u is a long sequence sampled from the Markov I˜
projection P ⋆ , N is n noise samples from CN (0, 1) and
˜
y = α˜ +N . The numerical computation of log2 p(˜) is made
u
y
using p(˜) = s p(˜, s) by forward sum-product recursion
y
y ˜
˜
˜
of the BCJR algorithm, where s corresponds to u. Once the
˜
block length is long enough, this approximation becomes very
accurate. Due to the monotonicity of I (U ; Y |α) in α (for a
given distribution), efﬁcient search methods are used to obtain
the correct α.

R EFERENCES
[1]
[2]

[3]
[4]
[5]

VIII. R ESULTS
For simulations, we consider 16QAM and 16APSK constellations single carrier with root raised cosine ﬁlter with
rolloff 0.1. For reducing complexity we truncate the pulse
shape to 4 symbols window. We use oversampling J = 8. Fig.
1 presents the peak gain (PG) and shaping gain (SG) results
obtained by the Markov I-projection, each corresponding to
˜
unique constraint β0 ∈ P and shaping rate Rs , for 16QAM
using uniform 16APSK as reference scheme. The data rate
is R = 3. The results are shown for the matched (M) and
mismatched (MM) decoders. We can observe two distinct Rs
regions, with local maxima at each. The low Rs region is

[5]

[7]

[8]

5

I. Csiszár, T. M. Cover, and B. S. Choi, “Conditional limit
theorems under Markov conditioning,” IEEE Trans. Inform.
Theory, vol. IT-33, pp. 788–801, Nov. 1987.
M. Tanahashi and H. Ochiai, "Turbo decoding of concatenated
channel coding and trellis shaping for peak power controlled
single-carrier systems," IEEE Transactions on Communications,
vol. 58, no. 1, pp. 9-15, Jan. 2010.
G. D. Forney, “Trellis shaping,” IEEE Trans. Inform. Theory,
vol. 38, pp. 281–300, Mar. 1992.
Q. Wang and C. He, “Practical dirty paper coding with nested
binary LDGM-LDPC codes,” in Proc. ICC, June 2009.
D.M. Arnold, H.A. Loeliger, P.O. Vontobel, A. Kavˇ i` , and W.
cc
Zeng, “Simulation-Based Computation of Information Rates for
Channels With Memory,” IEEE Trans. Inform. Theory, vol. 52,
no. 8, pp. 3509–3532, Aug. 2006.
M. Tanahashi and H. Ochiai, "Trellis Shaping for Controlling
Envelope of Single-Carrier High-Order QAM Signals," IEEE
Journal of Selected Topics in Signal Processing, vol. 3, no. 3,
pp. 430-437, June 2009
N. Varnica, X. Ma, and A. Kavcic, “Capacity of power constrained memoryless AWGN channels with ﬁxed input constellations,” IEEE Global Communications Conference, Taipei,
Taiwan, 2002.
T. Cover, J. Thomas, “Elements of Information Theory,” 1991.

