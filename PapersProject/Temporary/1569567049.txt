Title:          ThreeUserInterference.pdf
Author:         ariaghs
Creator:        Adobe Acrobat 10.1.2
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Tue Jun 12 00:15:00 2012
ModDate:        Tue Jun 19 12:55:54 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      333825 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569567049

A new achievable rate region for the 3-user discrete
memoryless interference channel
Arun Padakandla, Aria G. Sahebi and S. Sandeep Pradhan
Dept of Electrical Engineering and Computer Science
University of Michigan, Ann Arbor, MI 48109, USA
Email: {arunpr,ariaghs,pradhanv}@umich.edu

We consider a general discrete memoryless case and
provide an inner bound to the capacity region for this
channel. This is based on our recent work on a new
class of algebraic code ensembles called nested linear code
ensemble. We build a framework based on reconstructions
of bivariate functions. This is similar to the framework
developed in [14] for the problem of distributed source
coding. In our ﬁrst step, which is the current paper, we
restrict our attention to bivariate functions which are ﬁnite
ﬁelds. In our ongoing work, we are extending this to the
case of Abelian groups. In the following, we express all
rates in bits, and all logarithms are with base 2.

Abstract—The 3-user discrete memoryless interference channel is considered in this paper. We provide a
new inner bound (achievable rate region) to the capacity region for this channel. This inner bound is based
on a new class of code ensembles based on asymptotically good nested linear codes. This achievable region
is strictly superior to the straightforward extension
of Han-Kobayashi rate region from the case of twousers to three-users. This rate region is characterized
using single-letter information quantities. We consider
examples to illustrate the rate region.

I. Introduction
In this paper we consider the problem of reliable communication over the discrete memoryless interference channel
with 3 users. A schematic of of such a channel is shown in
Fig. 1. In this model, 3 transmitters wish to communicate
to the corresponding 3 receivers simultaneously over a
channel which has three inputs and three outputs. Each
output is aﬀected by all the three inputs. This channel
was ﬁrst considered by Carleial in [1] and later in [3]–[5].
The capacity of this channel is still not known even in
the case of two-users. It is known in several special cases
such as the strong and very strong interference channels.
The best known inner bound to the capacity region is
given by the Han-Kobayashi achievable rate region [2].
Recently, there has been a lot of activity for the three
user channel in special cases such as the additive white
Gaussian noise model with and without fading [6]–[10],
[13]. For the Gaussian 3-user interference channel it has
been shown in [8]–[10] that random lattice codes can
provide rates that are beyond what can be obtained using
random code ensembles. This approach is called as lattice
alignment. We show that even when the channel does
not have the additive structure, algebraic structured code
ensembles provide superior performance as compared to
unstructured code ensembles. In related work, Bresler,
Parekh and Tse [11] demonstrate the need for lattice codes
in order to achieve within a constant gap of the capacity
for the many-to-one interference channels. We build on
this approach and consider a framework for the general
interference channel. The interested reader is referred to
[12], where the authors exploit structure of the interfering
signals to provide the largest known rate region for the
three user deterministic IC.

W
1

Y1

X1

Decoder 1

Interference
W
2

Encoder 2

W3

Encoder 3

X2

Fig. 1.

W2

Decoder 3

W3

Y2

Channel
X3

W1

Decoder 2

Encoder 1

Y3

3-user interference channel model

II. Preliminaries
A three-user discrete memoryless Interference Channel (DMIC) used without feedback is a septuple
(X1 , X2 , X3 , Y1 , Y2 , Y3 , PY1 ,Y2 ,Y3 |X1 ,X2 ,X3 ) of three input
and output alphabets Xi , Yi for i = 1, 2, 3, and a set of
probability distributions PY1 ,Y2 ,Y3 |X1 ,X2 ,X3 (.|x1 , x2 , x3 ) on
Y1 × Y2 × Y3 for all xi ∈ Xi , for i = 1, 2, 3. The channel is
assumed to be memoryless.
Deﬁnition II.1. An (N, M1 , M2 , M3 ) transmission system for a given DMIC consists of a mapping for each
n
encoder ei : {1, . . . , Mi } → Xin and decoder gi : Yi →
{1, . . . , Mi } for i = 1, 2, and 3.
We assume that the messages (W1 , W2 , W3 ) are drawn
uniformly from the set {1, . . . , M1 } × {1, . . . , M2 } ×
{1, . . . , M3 }. The average error probability of the above

1

transmission system is given by
τ=

1
M1 M 2 M 3

M1

M2

In the following we give an outline of the coding scheme
used to achieve this rate region. We omit the formal proof
due to lack of space.

M3

Pr((g1 (Y1n ), g2 (Y2n ), g3 (Y3n )
w1 =1 w2 =1 w3 =1

B. Outline of the coding scheme
Note that only the ﬁrst receiver suﬀers from the interference. The other two user wish to act as helpers to
facilitate partial decoding of the interfering signals at the
ﬁrst receiver. Let U2 and U3 denote these parts of the
interfering signals X2 , and X3 , respectively, that the ﬁrst
receiver wish to decode. In the standard extension of the
Han-Kobayashi scheme from the two to three users, the
ﬁrst receiver decodes the pair (U2 , U3 ). However in the approach considered in this paper, we make the ﬁrst receiver
decode a bivariate function of the pair. In particular, we
let the ﬁrst receiver decoder U2 + U3 , where + denotes the
addition operation of a ﬁnite ﬁeld. We make the following
fundamentally new observation. It turns out that if the
codebooks containing information about U2 and U3 has
the algebraic structure of the corresponding ﬁnite ﬁeld,
(i.e., codebook is linear), then irrespective of the structure
of the channel transition probability PY1 |X1 ,X2 ,X3 , the ﬁrst
receiver can decode the information U2 + U3 as long as as
the rate of the codebook is not too large. This induces a
uniform single-letter distribution on U2 and U3 . To induce
a general non-uniform distribution on U2 and U3 we use
nested linear codes.

= (w1 , w2 , w3 )|(W1 , W2 , W3 ) = (w1 , w2 , w3 ).
Deﬁnition II.2. A triple (R1 , R2 , R3 ) is said to be achievable for a given DMIC if ∀ > 0, there exists an N ( )
such that for all N > N ( ) there exists an (n, M1 , M2 , M3 )
transmission systems that satisﬁes the following conditions
1
log Mi ≥ Ri − , for i = 1, 2, 3, τ ≤ .
n
The set of all achievable rate pairs is the capacity region of
the DMIC.
III. Three-to-one IC: First Main Result
A. Coding Theorem
For clarity of exposition, we ﬁrst consider a special
class of interference channels which we call 3-to-1 IC.
In this channel, the channel output of the only one of
the receivers experiences the interference. We will ﬁrst
describe our new approach to the problem for this class.
Then we will consider the more general case. The 3-to-1 IC
can be characterized without loss of generality as follows:
PY1 ,Y2 ,Y3 |X1 ,X2 ,X3 satisﬁes the following Markov chains:
(X1 , Y1 , X3 , Y3 ) → X2 → Y2

Deﬁnition III.1. Given a ﬁnite ﬁeld (G, +, ·), a nested
linear code of block-length n is a pair of codes (C1 , C2 ),
where Ci is a coset of a linear code 1 for i = 1, 2, with
additional constraint being that C2 ⊂ C1 , where a linear
code is a vector space over Gn .

(X1 , Y1 , X2 , Y2 ) → X3 → Y3
Following is the ﬁrst main result of this article. For a 3-to-1 interference channel described by
PY1 ,Y2 ,Y3 |X1 ,X2 ,X3 , let P1 denote set of probability distributions PX1 ,U2 ,X2 ,U3 ,X3 deﬁned over X1 ×U2 ×X2 ×U3 ×X3 ,
having the following property: X1 , (U2 , X2 ) and (U3 , X3 )
are mutually independent, where U2 , and U3 are arbitrary
ﬁnite sets such that maxi |Xi | ≤ |U2 | = |U3 | = pr , where pr
is a prime power. Let U1 + U2 denote sum of two random
variables U1 and U2 , where addition is with respect to the
unique ﬁnite ﬁeld of size pr . For every such distribution
PX1 ,U2 ,X2 ,U3 ,X3 let the induced distribution on the set
X1 × U2 × X2 × U3 × X3 × Y1 × Y2 × Y3 be given by

When we use a pair of nested linear codes for a communication problem, we use a carefully chosen set of coset
representatives of C2 in C1 as the codebook, denoted as
C1 /C2 . Consider the following fact about the asymptotic
performance of nested linear codes for point-to-point channel coding that proved in [16].
Fact 1: For any discrete memoryless point-to-point channel PY |X having input alphabet X with |X | ≤ |G|, there
exists a sequence of nested linear codes indexed by the
block-length n, such that

PX1 ,U2 ,X2 ,U3 ,X3 PY1 ,Y2 ,Y3 |X1 ,X2 ,X3 .
Theorem 1. For every PX1 ,U2 ,X2 ,U3 ,X3 in P1 , the following rate region is achievable:

lim
n→

1
log |C1 | = log |G| − H(X|Y )
n

from below,

R1 ≤ min{0, H(U2 ) − H(U2 + U3 |Y1 ),
H(U3 ) − H(U2 + U3 |Y1 )} + I(X1 ; U2 + U3 , Y1 )
R2 ≤ I(U2 , X2 ; Y2 )

1
log |C2 | = log |G| − H(X),
n
from above, and set of coset representatives of C2 in C1
forms a good channel code in the usual Shannon sense
(probability of decoding error approach 0 as n → ∞).
We call C1 as the packing code and C2 as the shaping
code. Now coming back to the 3-to-1 interference channel,
lim
n→

R3 ≤ I(U3 , X3 ; Y3 )
R1 + R2 ≤ I(X2 ; Y2 |U2 ) + I(X1 ; U2 + U3 , Y1 ) + H(U2 )
− H(U2 + U3 |Y1 )
R1 + R3 ≤ I(X3 ; Y3 |U3 ) + I(X1 ; U2 + U3 , Y1 ) + H(U3 )

1 There is a slight abuse of notation here. Strictly speaking, we
should call them nested coset codes.

− H(U2 + U3 |Y1 )

2

for users 2 and 3, the corresponding information is encoded in pairs (U2 , X2 ) and (U3 , X3 ), respectively. The two
corresponding receivers decode the corresponding pairs.
The ﬁrst receiver ﬁrst decodes the sum of parts of the
interference U2 + U3 , and then decodes the corresponding
information bearing signal X1 . We construct a nested
linear code for each of these 5 variables. We denote the
shaping and packing codes for the variable U2 as C1 (U1 )
and C2 (U1 ), and similarly for other variables. Let Si and
Si + Ti denote the rates of the shaping codes, and the
packing codes associated with the nested linear codes
of Ui for i = 1, 2, respectively. Similarly let Ki and
Ki + Li denote the rates of the shaping and packing codes
associated with the nested linear code of Xi for i = 1, 2, 3.
The 5 pairs of nested linear codes are constructed by
choosing the elements of their corresponding generator
matrices uniformly and independently from the unique
ﬁnite ﬁeld of size pr with replacement, while enforcing the
corresponding nested structure. Moreover, we also enforce
the condition that C1 (U2 ) ⊂ C1 (U3 ) or C1 (U3 ) ⊂ C1 (U2 ),
depending on the rate of these codes. It turns out that
this is crucial to facilitating the ﬁrst decoder to recover
U2 + U3 . We also choose 5 random dither vectors, where a
dither is added to all codewords of a nested linear code. Let
Ri denote the transmission rate of the ith encoder. Note
that R1 = L1 , R2 = L2 + T2 and R3 = L3 + T3 . Fix the
input distribution PX1 ,U2 ,X2 ,U3 ,X3 = PX1 PU2 ,X2 PU3 ,X3 .
Encoding: The ﬁrst encoder, after observing the message W1 , looks for a strongly typical (with respect to PX1 )
n
[15] vector X1 from the W1 th coset of C2 (X1 ) in C1 (X1 ),
and sends this vector as the channel input. The second
encoder partitions its message into two indexes W21 and
n
n
W22 , and looks for a pair of vectors (U2 , X2 ) that are
strongly typical (with respect to PU2 ,X2 ) with ﬁrst vector
in the W21 th coset of C2 (U2 ) in C1 (U2 ), and ﬁrst vector in
the W22 th coset of C2 (X2 ) in C1 (X2 ). Then the encoder
n
sends the vector X2 over the channel. Similar encoding
is performed at the third encoder. If any encoder is not
successful in the corresponding endeavors, it will declare
error and sends a random sequence over the channel.
We have shown that the probability of encoding error
goes to zero if the rates of shaping codes satisfy the
following conditions: for i = 2, 3
Si ≥ log pr − H(Ui ), Si + Ki ≥ log p2r − H(Xi )

PU2 +U3 ,Y1 . If successful, the decoder looks for a unique
n
n ˜
vector X1 in C1 (X1 ) such that (X1 , U n , Y1n ) is strongly
jointly typical with respect to PX1 ,U2 +U3 ,Y1 . If any decoder
is not successful in the corresponding endeavor, it will
declare error.
We have shown that the probability of decoding error
goes to zero if the rates of packing codes satisfy the
following conditions: for i = 2, 3
Ki + Li ≤ log pr − H(Xi |Ui , Yi )
r

Si + Ti ≤ log p − H(U2 + U3 |Y1 )

(4)

Ki + Li + Si + Ti ≤ log p2r − H(Ui , Xi |Yi )

(5)

K1 + L1 ≤ log p2r − H(X1 |U2 + U3 , Y1 )

(6)

and
After running a Fourier-Motzkin elimination on equations (1)-(6), we get the rate region presented in the
theorem.
IV. General Case: Second Main Result
After going through the basic idea for the case of 3-to1 interference channel, we are ready to discuss the more
general interference channel. We obtain an inner bound
to the capacity region that can be characterized using
single-letter information quantities. When potentially ever
channel output has an interference component, each user
may wish to act as a helper to the other two users. We
give a brief outline of the coding scheme and omit proof
due to lack of space.
Here each user has a pair of auxiliary random variables
which will be used to facilitate the other users to decode
the interference. The pair (U12 , U13 ) is associated with
the ﬁrst encoder and decoder. Similarly (U21 , U23 ) and
(U31 , U32 ) are associated with the second and the third
encoder-decoder pairs. The ﬁrst decoder wishes to recover
U21 + U31 ﬁrst before decoding its own message contained
in (U12 , U13 , X1 ). Similarly U12 + U32 and U13 + U23 are
recovered ﬁrst at the second and third decoders respectively. In other words, each encoder has three layers, with
the ﬁrst two being the helper layers. We will use 9 nested
linear codes one for each of 6 auxiliary variables and 3
channel input variable. The following is the second main
result of this paper.
For a given interference channel described by
PY1 ,Y2 ,Y3 |X1 ,X2 ,X3 , let P2 denote the set of all triples
of probability distributions PU12 ,U13 ,X1 , PU21 ,U23 ,X2 , and
PU31 ,U32 ,X3 deﬁned over U12 × U13 × X1 U21 × U23 × X2
and U31 × U32 × X3 . Here Uij is an arbitrary ﬁnite set
for i, j ∈ {1, 2, 3} such that |X1 | ≤ |U21 | = |U31 | = pr1 ,
1
|X2 | ≤ |U12 | = |U32 | = pr2 , and |X3 | ≤ |U13 | = |U23 | = pr3 ,
2
3
where pri is a prime power. Let U21 + U31 denote the
i
sum of the two random variables U21 and U31 , where
addition is with respect to the unique ﬁnite ﬁeld of size
pr1 , and similarly for other cases. For every such triple
1
of distributions, let the induced joint distribution of the

(1)

and
K1 ≥ log pr − H(X1 ).

(3)

(2)

Decoding: The second decoder observes the channel
n
n
output Y2n and looks for a unique sequence pair (U2 , X2 )
with the ﬁrst vector in C1 (U2 ) and the second vector in
n
n
C2 (X2 ) such that (U2 , X2 , Y2n ) is strongly typical with
respect to PU2 ,X2 ,Y2 . Similar decoding is performed at
the third decoder. The ﬁrst decoder observes Y1n and
˜
looks for a unique vector U n in C1 (U1 ) + C1 (U2 ) such
˜
that (U n , Y1n ) is strongly jointly typical with respect to

3

denotes modulo-2 sum, N1 , N2 and N3 are mutually independent Bernoulli random variables with P (N1 = 1) = δ,
P (N2 = 1) = P (N3 = 1) = . We assume an average
Hamming weight constraint q on the input of user 1. i.e.,
n
1
i=1 1{X1i =1} ≤ q.
nE

auxiliary variables, channel input and channel output be
given by
PU12 ,U13 ,X1 PU21 ,U23 ,X2 PU31 ,U32 ,X3 PY1 ,Y2 ,Y3 |X1 ,X2 ,X3 .
We will use the following notation for a compact description of the rate region. We will use double indexed rates
such as Sij and double indexed random variables such as
Uij , where each index can take values in I {1, 2, 3} and
i = j. For a given pair (i, j) let k denote the element
in I such that k = i and k = j. For example when
(i, j) = (1, 3), k = 2. Let Ui¯ denote the collection of
i
random variables {Uij , Uik }. Let Si¯ denote the sum rate
i
˜
Sij + Sik . For example S1¯ = S13 + S12 . Let Ui denote the
1
sum Uji + Uki , where + is the addition operation of the
˜
corresponding ﬁnite ﬁeld. Let Ti denote max{Tji , Tki }. For
˜
example T1 = max{T21 , T31 }. Observe that in ˜ notation,
·
the index i becomes the second index. Let Ai = log pri ,
i
and let A¯ = Aj + Ak , and AI = A1 + A2 + A3 .
i

N1
X1
X2

X3

Fig. 2.

Y1

W2

Y2

W3

Y3

A simple many to one interference channel.

We now state the rate region achievable for this 3-to1 IC using structured codes. Consider the rate region described in theorem 1. Let X1 , X2 , X3 be mutually independent with P (X1 = 1) = q, P (X2 = 1) = P (X3 = 1) = 1 .
2
Let U2 = X2 , U3 = X3 . It can be veriﬁed that if q ∗ δ < ,
then (hb (q ∗ δ) − hb (δ), 1 − hb ( ), 1 − hb ( )) is achievable,
where hb (q) = −q log2 q − (1 − q) log2 (1 − q) is the binary
entropy function and q ∗ δ = δ(1 − q) + q(1 − δ). Indeed, we
employ the same linear code of rate 1 − hb ( ) for users
2 and 3. Since 1 − hb ( )) < 1 − hb (q ∗ δ), user 1 can
n
n
decode X2 + X3 , the sum of the codewords transmitted
by users 2 and 3. After subtracting oﬀ the interference,
decoder 1 decodes user 1’s message at rate hb (q ∗δ)−hb (δ).
Therefore, each transmitter receiver pair communicates at
their respective point to point capacities as if there were
no interference.
We now prove the rate region achievable using the natural extension of Han-Kobayashi is strictly sub optimal. We
begin with a characterization of Han-Kobayashi region for
3-to-1 IC. A rate triple (R1 , R2 , R3 ) is achievable using
the Han-Kobayashi scheme if there exists a distribution
pX1 U2 X2 U3 X3 Y1 Y2 Y3 = pX1 pU2 X2 pU3 X3 pY1 Y2 Y3 |X1 X2 X3 such
that

Theorem 2. For every triple of distributions in P2 , the
following rate region is achievable: for all (i, j) such that
i, j ∈ {1, 2, 3} and i = j: Ri = Li −Ki +Ti¯ −Si¯, Tij ≥ Sij ,
i
i
Li ≥ Ki , Sij ≤ 1 and Ki ≤ 1,
Sij ≥ Aj − H(Uij )
Si¯ ≥ A¯ − H(Ui¯)
i
i
i
Si¯ + Ki ≥ AI − H(Xi )
i
˜
Li ≤ Ai − H(Xi |Ui¯, Ui , Yi )
i
˜
Li + Tij ≤ Ak − H(Xi , Uij |Uik , Ui , Yi )
¯
˜
Li + Ti¯ ≤ AI − H(Xi , Ui¯|Ui , Yi )
i
i
˜
˜
Li + Ti ≤ 2Ai − H(Xi , Ui |Ui¯, Yi )
i
˜
˜
Li + Tij + Ti ≤ 2Ai + Aj − H(Xi , Uij , Ui |Uik , Yi )
˜
˜
Li + Ti¯ + Ti ≤ AI + Ai − H(X1 , Ui¯, Ui |Yi ).
i
i
Remark: It is not yet clear to us whether this is
amenable to Fourier-Motzkin elimination. This rate region
has a structure that is similar to polymatroids and could
potentially be exploited in Fourier-Motzkin elimination for
a compact description. The ﬁrst 3 equations are shaping
constraints, and the next 6 are packing constraints. The
above compact description has 12 bounds related to shaping codes, 36 bounds related to packing codes, and 15 nonnegativity bounds.

R1 ≤ min{I(X1 ; Y1 |U2 U3 ), I(X1 U3 ; Y1 |U2 ), I(X1 U2 ; Y1 |U3 )}
Rj ≤ I(Xj ; Yj ) : j = 2, 3
R1 + R2 ≤ I(X2 ; Y2 |U2 ) + I(X1 U2 ; Y1 |U3 )
R1 + R3 ≤ I(X3 ; Y3 |U3 ) + I(X1 U3 ; Y1 |U2 )
3

R1 +R2 +R3 ≤ I(X1 U2 U3 ; Y1 )+
V. Example

I(Xj ; Yj |Uj ).

(7)

j=2

Lemmas V.1 enables us in proving strict suboptimality of
the above rate region.

In this section, we provide a simple example for which
the rate region achievable using nested linear codes is
strictly larger than that achievable using the natural extension of Han-Kobayashi region for three users.
Consider the binary 3-to-1 interference channel depicted
in Figure 2 whose input output relationship is described
through the equations Y1 = X1 ⊕ X2 ⊕ X3 ⊕ N1 ,
Y2 = X2 ⊕ N2 (depicted as W2 in the ﬁgure) and
Y3 = X3 ⊕ N3 (depicted as W3 in the ﬁgure), where ⊕

Lemma V.1. For any collection (U2 , X2 , U3 , X3 , X1 , Y1 )
of random variables that satisfy, (i) X1 , X2 , X3 are binary and mutually independent, (ii) pU2 X2 U3 X3 X1 Y1 =
pU2 X2 pU3 X3 pX1 1{Y1 =X1 ⊕X2 ⊕X3 ⊕N1 } where X1 , X2 , X3 , N1
,are mutually independent and P (N1 = 1) = δ, and
(iii) H(X2 ⊕ X3 |U2 , U3 ) > 0, we have I(X1 ; Y1 |U2 , U3 ) <
I(X1 ; Y1 |X2 ⊕ X3 ).

4

simplest form. Our main contribution lies in being able
to generalize this idea to arbitrary 3-to-1 and general
interference channels. For example, if W2 and W3 are
asymmetric channels, then linear codes do not achieve
their respective capacities. The ensemble of nested linear
codes achieve capacity of asymmetric channels without
compromising linearity and can therefore be employed to
obtain interference alignment at decoder 1.

Proof: The proof is based on a simple observation
that if Zj : j = 1, 2, 3 are binary random variables such
that (Z1 , Z2 ) is independent of Z3 , then |H(Z1 ⊕ Z3 ) −
H(Z2 ⊕ Z3 )| ≤ |H(Z1 ) − H(Z2 )| with the inequality being
strict if H(Z3 ) > 0. This can be proved by using the strict
concavity of the binary entropy function and is omitted.
We now prove the lemma.
I(X1 ; Y1 |U2 U3 ) = H(Y1 |U2 U3 ) − H(Y1 |X1 U2 U3 )
=

Acknowledgment

pU2 U3 (u2 , u3 )H(Y1 |U2 = u2 , U3 = u3 )

The authors would like to thank Viveck Cadambe for
several discussions on the topic of interference channels.
This work was supported by NSF grants CCF-0915619 and
CCF-1116021.

u2 ,u3
1 ,U2
pX1 U2 U3 (x1, u2 , u3 )H(Y1 |X1 =x3 =u3=u2 ,)
U

−
x1 ,u2 ,u3

pU2 U3 (u2 , u3 )H

=
u2 ,u3

(X1 ⊕N1 )
⊕
|U2
(X2 ⊕X3 )

pX1 U2 U3 (x1, u2 , u3 )H

−

x1 ,u2 ,u3

=

pU2 U3 (u2 , u3 )H
u2 ,u3

−

x1 ,u2 ,u3

=

pU2 U3 (u2 , u3 )H
u2 ,u3

pU2 U3 (u2 , u3 )H

−

u2 ,u3

References

(x1 ⊕N1 )
1 ,U2
⊕
|X1 =x3 =u3=u2 ,
U
(X2 ⊕X3 )

(X1 ⊕N1 )
⊕
|U2
(X2 ⊕X3 )

pX1 U2 U3 (x1, u2 , u3 )H

= u2 , U3 = u 3

= u2 , U3 = u 3

(N1 )
⊕
|U2 =u2 ,
(X2 ⊕X3 ) U3 =u3

(X1 ⊕N1 )
⊕
|U2
(X2 ⊕X3 )

= u2 , U3 = u 3

N1
⊕
|U2 =u2 ,
(X2 ⊕X3 ) U3 =u3

pU2 U3 (u2 , u3 )H ((X1 ⊕ N1 )|U2 = u2 , U3 = u3 )

≤
u2 ,u3

−

pU2 U3 (u2 , u3 )H (N1 |U2 = u2 , U3 = u3 )

(8)

u2 ,u3

=

H ((X1 ⊕ N1 )|U2 , U3 ) − H (N1 |U2 , U3 )

=

H (X1 ⊕ N1 ) − H (N1 ) = I(X1 ; Y1 |X2 ⊕ X3 ),

where (8) follows from substituting pX1 ⊕N1 |U2 U3 (·|u2 , u3 )
for
pZ 1 ,
for
pZ 2
pN1 |U2 U3 (·|u2 , u3 )
and
pX2 ⊕X3 |U2 U3 (·|u2 , u3 ) for pZ3 in the above observation.
The import of lemma V.1 is that I(X1 ; Y1 |U2 , U3 ) =
I(X1 ; Y1 |X2 ⊕ X3 ) only if H(X2 ⊕ X3 |U2 , U3 ) = 0. This
implies H(Xj |Uj ) = 0 for j = 1, 2. Substituting this for
the sum bound in (7), we obtain
3

R1 + R2 + R 3

≤ I(X1 U2 U3 ; Y1 )+

I(Xj ; Yj |Uj )
j=2

≤

1 − hb (δ) + 0 + 0 = 1 − hb (δ)

The sum rate achievable using linear codes is hb (q ∗ δ) −
hb (δ) + 2 − 2hb ( ) < hb (q ∗ δ) − hb (δ) + 2 − 2hb (q ∗ δ) =
(1 − hb (δ)) + (1 − hb (q ∗ δ)), where the ﬁrst inequality
follows from our assumption q ∗ δ < . Clearly, the sum
rate achievable using linear codes is strictly larger than
that achievable using the Han-Kobayashi scheme.
This example illustrates our coding technique in it’s

5

[1] A. B. Carleial, “A case where interference does not reduce capacity,” IEEE Trans. on Inform. Theory, vol. 21, no. 5, pp. 569-570,
Sept. 1975.
[2] T. S. Han and K. Kobayashi, “A new achievable rate region for
the interference channel,” IEEE Trans. Inform. Theory, vol. 27,
no. 1, pp. 49-60, Jan. 1981.
[3] H. Sato, “The capacity of the Gaussian interference channel under
strong interference,” IEEE Trans. Inform. Theory, vol. 27, no. 6,
pp. 786-788, Nov. 1981.
[4] M. Costa, “On the Gaussian Interference Channel,” IEEE Trans.
Inform. Theory, vol. 31, no. 5, pp. 607–615, Sep. 1985.
[5] M. H. M. Costa and A. A. E. Gamal “The Capacity Region
of the Discrete Memoryless Interference Channel with Strong
Interference” IEEE Trans. Inform. Theory, vol. 33, no. 5, pp. 710711, Sept. 1987.
[6] I. Sason “On Achievable Rate Regions for the Gaussian Interference Channel” IEEE Trans. Inform. Theory, vol. 50, no. 6, pp.
1345-1356, June 2004.
[7] V. S. Annapureddy and V. Veeravalli, “Gaussian interference
networks: sum capacity in the low interference regime and new
outer bounds on the capacity region,” Feb. 2008, submitted to
IEEE Trans. Inform. Theory.
[8] A. Jafarian and S. Vishwanath, “Achievable Rates for Gaussian
Interference Channels”, IEEE Trans. on Inf. Th., October 2010.
[9] S. Shridharan, A. Jafarian, S. Vishwanath, and S. A. Jafar,
“Lattice Coding for K User Gaussian Interference Channels”,
IEEE Trans. on Inf. Th., April 2010.
[10] A. Jafarian, S. Vishwanath, “Gaussian Interference Networks:
Lattice Alignment”, IEEE Inf. Th. Workshop, January 2010.
[11] Bresler, G.; Parekh, A.; Tse, D.N.C.; , ”The Approximate Capacity of the Many-to-One and One-to-Many Gaussian Interference Channels,” Inf. Th., IEEE Transactions on , vol.56, no.9,
pp.4566-4592, Sept. 2010 doi: 10.1109/TIT.2010.2054590.
[12] Bandemer, B.; El Gamal, A.; , ”An achievable rate region for
the 3-user-pair deterministic interference channel,” Communication, Control, and Computing (Allerton), 2011 49th Annual
Allerton Conference on , vol., no., pp.38-44, 28-30 Sept. 2011 doi:
10.1109/Allerton.2011.6120147.
[13] V. Cadambe, Syed A. Jafar, C. Wang, “Interference Alignment
with Asymmetric Complex Signaling – Settling the Host-MadsenNosratinia Conjecture”, IEEE Trans. on Inf. Th., Sep. 2010, Vol.
56, Issue: 9, Pages: 4552-4565.
[14] D. Krithivasan and S. S. Pradhan, “distributed source coding
using abelian group codes: A new achievable rate-distortion function”, IEEE Trans. on Inform. Theory, vol. 57, March 2011.
[15] I. Csisz´r and J. Korner, Inf. Th.: Coding Theorems for Discrete
a
Memoryless Systems. Academic Press Inc. Ltd., 1981.
[16] A. Padakandla and S. S. Pradhan, “Nested linear codes achieve
Marton’s inner bound for general broadcast channels”, ISIT 2011,
St. Petersburg, Russia.

