Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Fri May 18 13:42:15 2012
ModDate:        Tue Jun 19 12:56:38 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      554788 bytes
Optimized:      no
PDF version:    1.7
ISIT'2012 1569565427

Matrix Exponential Learning:
Distributed Optimization in MIMO systems
Panayotis Mertikopoulos, E. Veronica Belmega, and Aris L. Moustakas

The most recent and general incarnations of waterﬁlling
[5] are fully distributed and thus apply to large, unregulated
networks where users cannot be assumed to adhere to central
control. Unfortunately however, the convergence of these algorithms typically depends on the channel satisfying certain
“mild-interference” conditions [6] which, quite often, fail to
hold: in fact, in the simple case of a single receiver and several
transmitters who communicate over non-overlapping channels
(the parallel multiple access channel (PMAC) model), it was
shown that these conditions always fail [7]. Furthermore, if
the channels are not static but evolve over time following a
stationary ergodic process (e.g. due to fading), then the problem
becomes signiﬁcantly more di cult (see e.g. [8] for a survey or
[9] for some recent results in the asymptotic regime).
Instead of taking a waterﬁlling approach, we present here an
optimization method for problems deﬁned over sets of positivedeﬁnite matrices which works by tracking the gradient of the
objective function in an unconstrained space, and then maps the
resulting orbits back to the original (constrained) state space via
exponentiating (an approach similar to the one used in [10] for
learning a positive semidiﬁnite matrix online). In this manner,
if the function to be minimized is convex, we show that this
method of “exponential learning” converges exponentially fast
to a global minimum (Theorem 1).
Obviously, this method applies to a wide array of MIMO
problems, but for concreteness, we will focus on the MIMO
multiple access channel (MAC) with transmit power constraints. In this setting, we show that exponential learning
converges to the system’s maximum achievable sum rate, and
this convergence is independent of whether the channels are
static or ergodic (Theorem 2). More importantly, the speed of
this convergence can be controlled by a learning rate parameter,
allowing the system to equilibrate within a few iterations even
for very large numbers of users and/or antennas per user.

Abstract—We analyze the problem of ﬁnding the optimal signal
covariance matrix for multiple-input multiple-output (MIMO)
multiple access channels by using an approach based on ”exponential learning”, a novel optimization method which applies
more generally to (quasi-)convex problems deﬁned over sets of
positive-deﬁnite matrices (with or without trace constraints). If
the channels are static, the system users converge to a power
allocation proﬁle which attains the sum capacity of the channel
exponentially fast (in practice, within a few iterations); otherwise,
if the channels ﬂuctuate stochastically over time (following e.g.
a stationary ergodic process), users converge to a power proﬁle
which attains their ergodic sum capacity instead.
An important feature of the algorithm is that its speed can be
controlled by tuning the users’ learning rate; correspondingly, the
algorithm converges within a few iterations even when the number
of users and/or antennas per user in the system is large.
Index Terms—Distributed optimization; exponential learning;
multiple access channel; MIMO; sum rate.

F

I. Introduction

OLLOWING the seminal prediction that the use of
multiple-input multiple-output (MIMO) technologies in
signal transmission and reception can lead to substantial performance gains [1], [2], MIMO has become an integral component
of numerous state-of-the-art wireless protocols (4G, HSPA+,
802.11n WiFi and WiMAX to name but a few). As a result, considerable impetus has been a↵orded to developing distributed
algorithms that would allow the users of a MIMO system to
attain their performance limits at a network level.
On that account, since the actual theoretical limits of MIMO
models still elude us even in basic network models (such as the
interference channel), it is useful to start instead with the mutual
information for Gaussian input and noise, and to optimize the
input covariance matrix of each transmitter in the presence of
interference from other network users. In this way, one obtains
a nonlinear (and possibly non-convex) optimization problem
deﬁned over a set of positive-deﬁnite matrices, representing the
users’ power allocation policies (i.e. the spread of their symbol
distributions over their antennas). However, given the nonexplicit nature of the problem’s constraints, standard gradient
descent or interior point methods do not apply, so these problems are usually solved by means of the classical waterﬁlling
algorithm [3], properly adapted to multi-user environments [4].

II. System Model
We begin by considering a vector Gaussian multiple access
channel with a ﬁnite set K = {1, . . . , K} of K wireless users,
each of whom transmits simultaneously over mk antennas to an
n-antenna receiver who decodes individual messages by treating the signals of other users as interference. More speciﬁcally,
this corresponds to the familiar baseband signal model:
P
y = k Hk xk + z,
(1)

P. Mertikopoulos is with the Centre National de la Recherche Scientiﬁque
(CNRS) and the Laboratoire d’Informatique de Grenoble; E.V. Belmega is with
ETIS/ENSEA – Universit´ de Cergy-Pontoise – CNRS; A. L. Moustakas is
e
with the Physics Department of the University of Athens, Greece. The authors
gratefully acknowledge ﬁnancial support from the Pˆ le de Recherche en Matho
matiques, Sciences et Technologies de l’Information et de la Communication
under grant no. C-UJF-LACODS MSTIC 2012.

where y 2 Cn is the aggregate message reaching the receiver,
xk 2 Cmk is the individual message transmitted by user k 2 K,
Hk 2 Cn⇥mk is the corresponding n ⇥ mk channel matrix and

1

z 2 Cn is the channel noise (assumed zero-mean Gaussian, and
without loss of generality, with identity covariance matrix).
In this context, the total transmit power of user k is simply
⇥
⇤
E kxk k2 = tr(Pk ), where the expectation is taken over the
codebook of user k (assumed Gaussian), and Pk denotes the
⇥
⇤
covariance matrix Pk = cov(xk ) = E xk x† . As is then cusk
tomary, the performance metric that we will be using is the
system’s achievable sum rate, i.e. the maximum information
transmission rate for a given set of covariance matrices.
This objective naturally depends on the variability of the
channel matrices H over time, so we will consider two di↵erent
(and diametrically opposed) scenarios:
a) Static Channels: the channel matrices Hk , k 2 K are
drawn randomly at the outset of the transmission but remain
ﬁxed for its duration. In this case, the system’s sum rate is [2]:
⇣ P
⌘
(P) = log det I + k Hk Pk H† ,
(2)
k

receiver treats the signal of all other users as interference, the
achievable rate of user k 2 K for static channels is just:

uk (P) = log det I + Hk Pk H† Wk 1 ,
(4)
k
P
where Wk = I + `,k H` P` H† is the interference-plus-noise
`
matrix for user k; on the other hand, for ergodically ﬂuctuating
channels, we have the expression:
⇥
⇤
uk (P) = E uk (P) .
(5)

The sum rate functions (2)–(3) obviously do not correspond
to the sums of (4)–(5) over all transmitters k 2 K, but, as was
shown in [13], any solution Q of (MP) with the static objective
(2) (resp. the ergodic objective (3)) will satisfy:
uk (Q)

uk (Q0 ; Q k )),
k

(6)

III. Exponential Learning
The main challenge in solving (MP) is that the positivity
constraints Pk < 0 cannot be expressed in functional form, so
(Lagrangian) descent or interior point methods do not readily
apply; instead, the static MIMO problem (2) is usually solved
by the well-known method of waterﬁlling [4], [5], [9]. Our aim
here will be to overcome this di culty and present an interior
point method which does apply to the problem, in both the static
and ergodic incarnation of Eqs. (2) and (3) respectively.

where the expectation is now taken over the variables Hk .
In both the static and the ergodic case, higher transmit powers
lead to higher sum rates (individually at least), so users can
be assumed to saturate their power constraints.In this way, we
obtain the optimization problem:
(k = 1, . . . , K),

(resp. uk (Q)

for all k 2 K, i.e. it will be at Nash equilibrium.3 In other words,
users are aligned with their global objective in the MIMO
multiple access channel, so solving (MP) is both globally and
individually optimal: even selﬁsh users have nothing to gain by
unilaterally deviating from the global optimum of (MP).

where P denotes the collective proﬁle P = (P1 , . . . , PK ).
b) Fast-fading Channels: in the presence of fast fading,
the channel matrices Hk are stationary ergodic processes with
a characteristic time-scale much faster than the typical transmission block (for simplicity, we will also assume that they are
temporally uncorrelated).1 Under these assumptions, we have
the following expression for the users’ achievable sum rate [12]:
⇥
⇤
(P) = E (P) ,
(3)

minimize F(P),
subject to Pk < 0, tr(Pk ) = Pk

uk (Q0 ; Q k )
k

A. Exponential learning in parallel multiple access channels
One special case of (MP) which can be solved by a variant
gradient descent method is the so-called “parallel MAC” where
the channels do not overlap and the matrices Pk are diagonal:
P k
Pk = diag(pk,1 , . . . , pk,mk ), with pk↵ 0 and m=1 pk = Pk . In
this setting, the system’s conﬁguration space X is a product of
@F
simplices, and if we let vk↵ = @pk↵ denote (minus) the gradient
of F, then all interior orbits of the dynamics
⇣
⌘
P k
pk↵ = pk↵ vk↵ Pk 1 m=1 pk vk , ↵ = 1, . . . , mk ,
˙
(7)

(MP)

where F =
or F =
depending on the channel model,
and the power levels Pk are non-negative real numbers.
As is well-known,
and
are both concave, so F is
convex; furthermore, if we denote each user’s state space by
Xk = {Pk 2 Cmk ⇥mk : Pk < 0, tr(Pk ) = Pk }, then it is easy to see
Q
that the problem’s state space X ⌘ k Xk of (MP) is also convex
P
(viewed as a subset of the complex space CQ , Q = k m2 ),
k
making (MP) itself convex. Our goal will thus be to present a
general solution method for problems of the type (MP), which
when restricted to the objectives (2)-(3), will allow the users of
the channel to attain their sum capacity.2
It is important to remark here that any solution of (MP) with
respect to the sum rate objectives (2)-(3) is also individually
optimal in the sense that users cannot improve their individual
rates by unilaterally changing their power matrices Pk . Indeed,
under the single user decoding (SUD) scheme in which the

converge to the minimum of F exponentially fast [11].4
This dynamical system is known in game theory and biology
as the replicator equation, and it is one of the most wellstudied models for the evolution of biological populations under
natural selection [15], [16]. Regrettably however, this approach
cannot be extended to the MIMO case because there is no
obvious way to treat (7) as a matrix equation. On the other
hand, the replicator dynamics (7) can also be derived from the
“exponential learning” scheme [17]:
yk↵ = vk↵
˙

1 In

fact, the time-uncorrelated case can be seen as a worst-case scenario:
temporally correlated models (such as Jakes fading) typically yield much faster
convergence times because the channels evolve at a smoother pace [11].
2 We should stress here that the trace constraint will not be important in our
analysis; in fact, it can be easily replaced by any number of (convex) functional
constraints of the form G(P) = 0 without a↵ecting the validity of our results.

pk↵
3 Recall

exp(yk↵ )
,
= Pk Pmk
=1 exp(yk )

(8a)
(8b)

here that the shorthand (Q0 ; Q k ) stands for (Q1 , . . . , Q0 , . . . , QK ).
k
k
4 See also [14] for a Lagrangian approach in the presence of estimation errors.

2

by substituting (8a) in the time derivative of (8b).
In this learning context (related itself to the inverse logit
choice model of [18]), the auxiliary “score” variable yk↵ 2 R
simply measures how well the eigenvalue pk↵ has “learned”
the gradient vector v which leads to higher sum rates in the
unconstrained y-space. Hence, the only di↵erence between the
replicator dynamics and exponential learning is one of viewpoint: (7) is written directly on the state space of the system
(so extra care must be taken in order to satisfy the problem’s
constraints),5 while the otherwise equivalent scheme of (8a) is
an unconstrained descent which relies on the Gibbs distribution
(8b) to map solutions back to the system’s original state space.

Remark 2. We also see that exponential learning does not
di↵erentiate between the static and fast-fading regime: the
matrices Hk (and obviously W) are simply the ones measured
at the t-th iteration of the algorithm. In the next section, we
will show that if the channel is static, exponential learning
converges to the maximum of the static sum rate ; otherwise,
if the channel matrices evolve ergodically over time, the users
converge to the maximum of the ergodic sum rate .
Remark 3. The discrete-time implementation of the exponential
learning dynamics has two additional (and important) components that are not present in (9): i) the users “learning rates”
k > 0; and ii) the step sequence (t). The time-step sequence (t) is a standard feature of both deterministic [19] and
stochastic [20] optimization algorithms and its role is to ensure
convergence when passing from the continuous to the discrete.
On the other hand, the role of the learning rate parameter k
is much more interesting. Indeed, k can be interpreted as the
inverse temperature of the (matrix-valued) Gibbs distribution
(9b), and as in simulated annealing, it controls the algorithm’s
speed: for small , learning is slower and smoother, while for
larger , the algorithm induces rapid changes and then freezes
(see also Fig. 1).

B. Exponential learning in the full matrix problem
Motivated by the above, we introduce the following exponential learning method for the matrix program (MP):
˙
Yk = Vk ,

(9a)

exp(Yk )
Pk = Pk
,
tr(exp(Yk ))

(9b)

where Vk ⌘ @F @P⇤ is the conjugate derivative of F w.r.t. Pk .6
k
Needless to say, in a MIMO setting, this scheme hinges on
users being able to calculate the gradient matrices Vk . To that
end, a di↵erentiation of the static sum rate of (2) gives:
Vk =

@F
@
= H† W 1 Hk ,
⇤ =
k
@Pk
@P⇤
k

IV. Analysis and Convergence Properties
In this section, we will focus on the behavior and convergence properties of the exponential learning dynamics (9)
and the corresponding discrete-time algorithm. We thus begin
by establishing that the dynamics (9) are consistent, i.e. they
respect the structure of the matrix state space X:

(10)

P
where W = I + ` H` P` H† is the aggregate signal-plus-noise
`
covariance matrix, assumed to be measured at the receiver end
and then made known to the transmitters (e.g. by broadcasting) under the same hypotheses used in standard water-ﬁlling
schemes [4], [5]. We thus obtain:

Proposition 1. For any Hermitian initialization Yk (0), k 2 K,
the corresponding solution P(t) of the exponential learning
dynamics (9) remains in X for all t; in particular, Pk (t) < 0
and tr(Pk (t)) = Pk for all k 2 K and for all t 0.

Algorithm 1 Exponential Learning
Require: For all k 2 K, pick Hermitian initial score matrices
Yk 2 Cmk ⇥mk and positive learning rates k > 0.
t
0;
repeat
t
t + 1;
for all k 2 K do
Yk
Yk + (t)Vk ;
Pk
exp( k Yk ) tr(exp( k Yk ));
end for
until required accuracy is reached or transmission ends.

Sketch of proof: Note that Vk is Hermitian whenever
the Yk are, so if we start with Hermitian initial conditions in
(9a), Yk (t) will remain Hermitian for all time. As a result,
Pk (t) / exp(Yk (t)) will be positive-deﬁnite as well, and the trace
condition tr(Pk (t)) = Pk follows immediately from (9b).
Proposition 1 allows us to overcome the important hurdle of
consistence in a surprisingly painless way: instead of specifying
the dynamics directly on X (a very hard task given the implicit
nature of the positivity constraints Pk < 0), the scheme (9)
evolves in an unconstrained space and trajectories are then
mapped to the original state space via the Gibbs map (9b).
That said, it is only natural to ask what are the dynamics that
govern the evolution of P(t) in X; to that end, we have:

Remark 1. We ﬁrst note that exponential learning as deﬁned
above has the following desirable properties:
(P1) It is distributed: users may update the algorithm based on
local measurements and information.
(P2) It is reinforcing: users move along a direction which
increases their individual rates (see also Proposition 3).
(P3) It is stateless: users are oblivious to the state of the
algorithm, even to the existence of other users.
5
PmkNote that constraint satisfaction is built into (7) by virtue of the
=1 d pk dt = 0 and that d pk dt = 0 when pk = 0.
@F
6 Namely, if P
⇤
↵ = X↵ + iY↵ , then the elements of @F @P are @X↵

Proposition 2. Let P(t) be an interior solution orbit of the dynamics (9). If {pk↵ (t), uk↵ (t)}, ↵ = 1, . . . , mk , is an eigensystem
k
of Pk , k 2 K, and we set V↵ ⌘ u† Vk uk , then:
k↵
⇣
⌘
k
1 Pmk
k
pk↵ = pk↵ V↵↵ Pk
˙
,
(11a)
=1 pk V
X
⇣
⌘ 1
˙
uk↵ =
V k↵ log pk↵ log pk
uk .
(11b)
,↵

From a mathematical viewpoint, Proposition 2 (proven by
taking the Fr´ chet derivative of (9b) in an eigen-decomposition
e
of P) is a reformulation of the exponential learning dynamics

fact that
@F
+ i @Y↵ .

3

System efficiency over time Hstatic channelsL

100

Ê

‡
Ï

Ê

Ù
Ú

Ê
‡
Ï
Ú
Ù

Ê
‡
Ï
Ú
Ù

Ê

‡
Ï
Ú
Ù

Ê
‡
Ï

System efficiency over time (ergodic channels)
Ê
‡
Ï
Ú
Ù

100

Ê
‡
Ï
Ú
Ù

Ù
Ú

‡
Ï

Ù
Ú

90

System efficiency (%)

System Efficiency H%L

90
Ï
Ù
Ú
Ê
‡

80

Number of Users
Ê

K = 25

Ú

K = 50

Ù

Ù

K = 10

Ï

70

K=5

‡

K = 100

Ú

60

K = 5 users
K = 10 users
K = 25 users
K = 50 users
K = 100 users

80

70

60

Ï
‡
Ê

2

4

6
Iterations

8

50
0

10

5

10

15

20

25

30

Iterations

Fig. 1. Convergence of exponential learning (with a constant step size) in static (left) and ergodic channels (right). We plotted the e ciency ratio e↵(t) =
(F(t) Fmin ) (Fmax Fmin ) for a MIMO MAC system with n = 5 receiver antennas and K = 5, 10, 25, 50 and 100 users (for simplicity, we only considered
diagonal allocations in the ergodic case). In all cases, the system equilibrates rapidly and the convergence rate scales well with the number of users.

divergence,8 which, for P, Q 2 X, is deﬁned as:
X ⇥
⇤
DKL (Q k P) ⌘
tr Qk (log Qk log Pk ) .

(9), so its importance lies in that it illuminates the evolution of
the actual state variables Pk .7 On the other hand, from a computational standpoint, (11) represents a signiﬁcant simpliﬁcation
of the exponential learning algorithm because users can employ
it to update their power allocation policies directly, and without
ﬁrst having to diagonalize/exponentiate the score matrices Yk .
This computational beneﬁt is obviously key when one needs
to operate with sizable antenna arrays; putting such computational issues aside however, the key property of exponential
learning is that its trajectories always descend the objective F:

k

By Klein’s inequality [21], we have that DKL (Q k P) is strictly
convex in P and positive, except at Q where it vanishes; more
importantly, a di↵erentiation of (13) yields the key expression:
X ⇥
⇤
d
DKL (Q k P(t)) =
tr (Qk Pk ) Vk ,
(14)
k
dt

d
which shows that dt DKL (Q k P(t))  0 if Q is a minimum point
of F (recall that F is convex so dF(Q) · Z 0 for all Z tangent
to X at a minimum point Q).9 Thus, given that P(t) converges
to the minimum set X⇤ of F by Proposition 3, it follows (by
compactness of X) that the orbit P(t) will have an !-limit Q⇤ 2
X⇤ , i.e. P(tn ) ! Q⇤ for some increasing sequence of times {tn },
tn ! 1. Consequently, we will also have DKL (Q⇤ k P(tn )) ! 0,
and since the function DKL (Q⇤ k P(t)) is itself decreasing, we
obtain P(t) ! Q⇤ , which proves that P(t) converges to a point.
The convergence rate (12) can then be proven as in [11] (which
essentially covers the diagonal case), the details being omitted
for lack of space.
The above theorem ensures that the continuous exponential
learning dynamics (9) always converge to a (global) minimum
point of the program’s objective (MP). Thus, specializing to the
discretized version of the exponential learning algorithm and
the MIMO sum rates (2) and (3), we obtain:

Proposition 3. If P(t) is a (non-stationary) solution of the
exponential learning dynamics (9), then F(P(t)) is decreasing.
Sketch of proof: By the chain rule for matrices, we obtain
P
P
˙
˙
dF dt = k tr @F @P⇤ · P† = k tr Vk Pk ). It can then be
k
k
˙
shown that this quantity is negative unless Pk = 0 (in which
case dF/dt vanishes), so our assertion follows.
Proposition 3 shows that the system’s sum rate always increases along the trajectories of exponential learning; hence,
with F convex, we immediately see that exponential learning
converges to the minimum set of F (i.e. attains its sum capacity).
Nonetheless, F need not be strictly convex (and in the static
case it isn’t [7]), so this convergence result does not imply that
exponentially learning actually converges to a point.
From a systems point of view, this is an important question
because it is crucial to predict the users’ end power allocation
policies (and not only the system’s sum capacity). To that end,
our next result is that exponential learning does converge to a
point, and, in fact, it converges exponentially fast:

Theorem 2. Let Yk (0), k 2 K, be a Hermitian initialization
of the exponential learning algorithm with time-steps (t) such
P
P
that t (t) = 1 and t 2 (t) < 1. Then:
1) In static channels, users converge to a power allocation
proﬁle Q which maximizes the sum rate (2).
2) In ergodic (fast-fading) channels, users converge (a.s.) to
the proﬁle Q which maximizes their ergodic sum rate (3).

Theorem 1. For any initial Hermitian initialization Yk (0),
k 2 K, the exponential learning dynamics (9) converge to a
(possibly initialization-dependent) point Q⇤ which minimizes F.
Moreover, there exists a positive constant c > 0 such that:
kP(t)

Q⇤ k  kP(0)

Q⇤ k e

ct

.

(13)

Sketch of proof: The static case is an Euler approximation
scheme with vanishing step size and is thus trivial to dispatch.
As for the fast fading regime, recall that exponential learning
can be viewed as a dynamical system on X, evolving according

(12)

Sketch of proof: The basic ingredient for our proof is
the quantum-theoretic generalization of the Kullback-Leibler

8 Note that in the diagonal PMAC case, X is just a product of simplices so
power allocation matrices can be interpreted as probability distributions.
9 Interestingly, this is an alternative proof that P(t) converges to arg min F.
X

7 Importantly, if P is diagonal, then the dynamics (11) reduce to the ordinary
k
replicator dynamics – simply compare (11a) to (7). Note also that if pk↵ ! 0,
˙
then uk↵ ! 0, so uk↵ decouples from the other eigenvectors.

4

to the dynamics (11) of Proposition 2. In particular, if the channel matrices Hk = Hk (t) are time-dependent (but uncorrelated
over time), the eigenvalue dynamics (11a) can be written in
discrete time as:
h
i
P k
k
pk↵ (t + 1) = pk↵ (t) + (t)pk↵ (t) V↵↵ (t) Pk 1 m=1 pk (t)V k (t) ,

References
[1] G. J. Foschini and M. J. Gans, “On limits of wireless communications in
a fading environment when using multiple antennas,” Wireless Personal
Communications, vol. 6, pp. 311–335, 1998.
[2] I. E. Telatar, “Capacity of multi-antenna Gaussian channels,” European
Transactions on Telecommunications and Related Technologies, vol. 10,
no. 6, pp. 585–596, 1999.
[3] R. S. Cheng and S. Verd´ , “Gaussian multiaccess channels with ISI:
u
capacity region and multiuser water-ﬁlling,” IEEE Trans. Inf. Theory,
vol. 39, no. 3, pp. 773–785, May 1993.
[4] W. Yu, W. Rhee, S. Boyd, and J. M. Cio , “Iterative water-ﬁlling for
Gaussian vector multiple-access channels,” IEEE Trans. Inf. Theory,
vol. 50, no. 1, pp. 145–152, 2004.
[5] G. Scutari, D. P. Palomar, and S. Barbarossa, “The MIMO iterative
waterﬁlling algorithm,” IEEE Trans. Signal Process., vol. 57, no. 5, pp.
1917–1935, May 2009.
[6] ——, “Competitive design of multiuser MIMO systems based on game
theory: a uniﬁed view,” IEEE J. Sel. Areas Commun., vol. 26, no. 7, pp.
1089–1103, September 2008.
[7] P. Mertikopoulos, E. V. Belmega, A. L. Moustakas, and S. Lasaulce,
“Dynamic power allocation games in parallel multiple access channels,”
in ValueTools ’11: ACM Proceedings of the 5th International Conference
on Performance Evaluation Methodologies and Tools, 2011.
[8] A. M. Tulino and S. Verd´ , “Random matrix theory and wireless commuu
nications,” Foundations and Trends in Communications and Information,
vol. 1, no. 1, pp. 1–182, 2004.
[9] F. Dupuy and P. Loubaton, “On the capacity achieving covariance matrix
for frequency selective MIMO channels using the asymptotic approach,”
IEEE Trans. Inf. Theory, vol. 57, no. 9, pp. 5737–5753, September 2011.
[10] K. Tsuda, G. R¨ tsch, and M. K. Warmuth, “Matrix exponentiated gradient
a
updates for on-line Bregman projection,” Journal of Machine Learning
Research, vol. 6, pp. 995–1018, 2005.
[11] P. Mertikopoulos, E. V. Belmega, A. L. Moustakas, and S. Lasaulce,
“Distributed learning policies for power allication in multiple access
channels,” IEEE J. Sel. Areas Commun., vol. 30, no. 1, pp. 96–106,
January 2012.
[12] A. Soysal and S. Ulukus, “Optimality of beamforming in fading MIMO
multiple access channels,” IEEE Trans. Commun., vol. 57, no. 4, pp.
1171–1183, April 2009.
[13] E. V. Belmega, S. Lasaulce, M. Debbah, and A. Hjørungnes, “Distributed
power allocation policies in MIMO channels,” in EUSIPCO ’10: Proceedings of the 2010 European Signal Processing Conference, 2010.
[14] X. Lin and T.-M. Lok, “Learning equilibrium play for stochastic
parallel Gaussian interference channels,” submitted. [Online]. Available:
http://arxiv.org/abs/1103.3782v1
[15] P. D. Taylor and L. B. Jonker, “Evolutionary stable strategies and game
dynamics,” Mathematical Biosciences, vol. 40, no. 1-2, pp. 145–156,
1978.
[16] W. H. Sandholm, Population Games and Evolutionary Dynamics, ser.
Economic learning and social evolution. Cambridge, MA: MIT Press,
2011.
[17] P. Mertikopoulos and A. L. Moustakas, “Learning in the presence of
noise,” in GameNets ’09: Proceedings of the 1st International Conference
on Game Theory for Networks, 2009.
[18] L. E. Blume, “The statistical mechanics of strategic interaction,” Games
and Economic Behavior, vol. 5, pp. 387–424, 1993.
[19] J. A. Snyman, Practical mathematical optimization: an introduction to
basic optimization theory and classical and new gradient-based algorithms, ser. Applied Optimization. Springer, 2005, vol. 97.
[20] V. S. Borkar, Stochastic approximation. Cambridge University Press and
Hindustan Book Agency, 2008.
[21] V. Vedral, “The role of relative entropy in quantum information theory,”
Reviews of Modern Physics, vol. 74, no. 1, pp. 197–234, 2002.

k
where the V↵↵ depend on t through both P(t) and H(t). Thus, if
h i
k
k
k
k
we set V ↵ = E V↵ and Rk = V↵ V ↵ , we will have:
↵
h k
i
P k
k
pk↵ (t + 1) = pk↵ (t) + (t)pk↵ (t) V ↵↵ (t) Pk 1 m=1 pk (t)V (t)
h
i
P k
+ (t)pk↵ (t) Rk (t) Pk 1 m=1 pk (t)Rk (t) , (15)
↵↵

and similarly for the eigenvector dynamics (11b). Then, by
interchanging expectation with di↵erentiation, the resulting mak
trix Vk = {V↵ } of the previous equation corresponds precisely
to (minus) the gradient @ @P⇤ of the ergodic sum rate .
k
Hence, with Hk stationary and ergodic, the general theory of
stochastic approximation (see e.g. Thm. 2 in Chap. 2 of [20])
shows that (15) will track the mean dynamics:
◆
✓
P k
k
pk↵ = pk↵ V ↵↵ Pk 1 m=1 pk V ,
˙
(16)

and similarly for the eigenvectors of P. Consequently, since (16)
converges to the (globally) minimum point of by Theorem 1,
the exponential algorithm will also converge there (a.s.).
Remark. A diminishing step size ensures the convergence of
the algorithm, but at the expense of convergence speed. With
a bit more work however (which we reserve for the future due
to space limitations), it can be shown that exponential learning
with a constant step still converges, always in static channels
and with high probability in ergodic ones (see also Fig. 1).
V. Conclusions and Future Work
In this paper, we analyzed the power allocation problem
in MIMO multiple access channels by means of an approach
based on “exponential learning”, a distributed optimization
method which applies to general nonlinear problems deﬁned
over sets of positive-deﬁnite matrices (where traditional optimization methods do not apply because of the form of the
problem’s constraints). Focusing on the case at hand, we
showed that if the system’s channels are static, then exponential
learning converges to a power allocation proﬁle which attains
the sum capacity of the channel exponentially fast; otherwise,
if the channels ﬂuctuate stochastically over time following a
stationary ergodic process, users converge to a power proﬁle
which maximizes their ergodic sum rate instead. Importantly,
the algorithm’s speed can be controlled by tuning the users’
learning rate; as a result, the algorithm converges within a few
iterations, even when the number of users and/or antennas per
user in the system is very large.
Since the method of exponential learning is a rather general
one, future applications include the interference channel framework of [5] where the method can be used to attain the Nash
equilibria of the channel (in both static and ergodic channels).
Moreover, it can also be shown that via the Gibbs transform
(9b), exponential learning induces a Riemannian structure on
the space of positive-deﬁnite matrices, and this structure can
be further exploited to yield other learning algorithms, possibly
with even faster convergence rates.

5

