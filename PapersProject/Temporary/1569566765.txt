Title:          untitled
Creator:        'Certified by IEEE PDFeXpress at 05/17/2012 4:24:24 PM'
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Thu May 17 16:24:18 2012
ModDate:        Tue Jun 19 12:55:22 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      595 x 842 pts (A4)
File size:      324096 bytes
Optimized:      no
PDF version:    1.7
ISIT'2012 1569566765

Capacity Lower Bound of MIMO Channels with
Output Quantization and Correlated Noise
Amine Mezghani and Josef A. Nossek
Institute for Circuit Theory and Signal Processing
Munich University of Technology, 80290 Munich, Germany
E-Mail: {Mezghani, Nossek}@nws.ei.tum.de
structure of the quantization process, usually leads to a loose
lower bound especially in the high SNR regime, it provides
a good approximation in the low SNR regime. In fact many
previous results (such as the 2/𝜋 result) can be re-proved in
a substantially easier and more elegant way. Moreover, we
extensively handle the 1-bit case with noise correlation and
show that depending on the correlation structure of the noise,
the low SNR capacity loss can be higher or smaller than 2/𝜋
compared to the unquantized case. Surprisingly, we observed
that even for simple SIMO channels with 1-bit output, the
mutual information achieved by QPSK can be exceeded.
Our paper is organized as follows. Section II describes the
general system model. In Sections III and IV, an (approximate)
lower bound of the mutual information with Gaussian input
is derived based on the Bussgang decomposition. Finally, we
handle the 1-bit symmetric quantizer case in more detail in
Section V.
Notation: Vectors and matrices are denoted by lower and
upper case italic bold letters. The operators (∙)T , (∙)H and
tr(∙) stand for transpose, Hermitian transpose and trace of a
matrix, respectively. 1 𝑀 denote the (𝑀 × 𝑀 ) identity matrix.
𝑎 𝑖 denotes the 𝑖-th element of the vector 𝒂 and 𝑎 𝑖,𝑐 with
𝑐 ∈ {𝑅, 𝐼} is the real or imaginary part of 𝑎 𝑖 . The operator E[∙]
stands for expectation with respect to the random variables.
Finally, diag(𝑨) denotes a diagonal matrix containing only
the diagonal elements of 𝑨 and nondiag(𝑨) = 𝑨 − diag(𝑨).

Abstract— We investigate the effect of quantization on the
performance of multiple-input multiple-output (MIMO) channels
in terms of achievable communication rates. To this end, we
derive a lower bound on the channel capacity of quantized MIMO
channels based on the Bussgang decomposition. The work is of
interest in the case when low resolution A/D-converters (ADCs)
have to be used to enable higher sampling rate and to simplify
the hardware. An essential aspect of our derivation is that we
take into account possible noise correlation. The low signal-tonoise ratio (SNR) analysis of the special case of 1-bit quantization
reveals that noise correlation might reduce the capacity loss due
to quantization when compared to the uncorrelated noise case,
where it is well known that the capacity decreases by the factor
2/𝜋 after the 1-bit quantization at low SNR.

Index Terms: Quantization, MIMO channel, Noise Correlation, Capacity Lower Bound, Low SNR analysis.
I. I NTRODUCTION
In future multiple-input multiple-output (MIMO) communication systems, low power and low cost are becoming key
requirements. Among other things, it is desirable to reduce the
analog-to-digital converter (ADC) resolution in order to save
power and chip area [1]. In fact, in high speed systems the
sampling/conversion power may reach values in the order of
the processing power. Therefore, coarse ADCs, acting as lowresolution scalar quantizers, may be a cost-effective solution
for such applications, especially when the array size becomes
very large or when the sampling rate becomes very high (in the
GHz range) [2]. Unfortunately, most of the contributions on
MIMO communications assume that the receiver has access
to the channel data with inﬁnite precision. In [3], [4], the
effects of 1-bit quantization are studied from an information
theoretical point of view for MIMO systems, where the
channel is perfectly known at the receiver and the noise is
uncorrelated. It turns out that the well known reduction of low
SNR channel capacity by factor 2/𝜋 due to 1-bit quantization
holds also for the general MIMO case with uncorrelated noise.
In [5], the non-coherent MIMO channel was studied in detail
and a similar conclusion has been made. On the other hand,
[6] and [7] showed that the channel capacity loss due to
the 1-bit quantization of the single-input single-output (SISO)
AWGN channel can be reduced at low SNR by using a 1-bit
asymmetric quantizer or by oversampling, while [8] studied
the SISO capacity problem with multi-bit quantization.
In this work, we provided a lower bound on the channel
capacity based on the Bussgang decomposition [9] of the
quantized output for the general case of correlated noise.
Although this simple method, which neglects the deterministic

II. S YSTEM M ODEL
We start from a general system model of a MIMO channel
with 𝑀 transmit antennas and 𝑁 receive antennas shown in
Fig. 1 and described by
𝒓 = 𝑄(𝒚), with

(1)

𝒚 = 𝑯𝒙 + 𝜼,

(2)

where 𝒚 is the unquantized receive vector of dimension 𝑁 ,
𝑯 ∈ ℂ 𝑁 ×𝑀 is the channel matrix and 𝒙 is the unknown data
vector, while 𝜼 is an i.i.d. Gaussian noise with covariance matrix 𝑹 𝜂𝜂 . The operator 𝑄(⋅) represents the scalar quantization
process, where the real parts 𝑦 𝑖,𝑅 and the imaginary parts 𝑦 𝑖,𝐼
of each signal component 𝑦 𝑖 is mapped to a quantized value
from a ﬁnite set of code words as follows
𝑟 𝑖,𝑐 = 𝑄(𝑦 𝑖,𝑐 ), if 𝑦 𝑖,𝑐 ∈ [𝑟lo , 𝑟up ), 𝑐 ∈ {𝑅, 𝐼}, 1 ≤ 𝑖 ≤ 𝑁.
𝑖,𝑐
𝑖,𝑐
(3)
Thereby, 𝑟lo and 𝑟up are the lower value and the upper limits
𝑖,𝑐
𝑖,𝑐
associated to the quantized value 𝑟 𝑖,𝑐 . The restriction to scalar

1

quantization is motivated by the fact that vector quantization
is rather uncommon for ADC implementations.
Our goal is to derive a lower bound on the achievable
rates, where we assume for analytical tractability a Gaussian
input distribution. Evidently, this distribution is not necessarily
the capacity achieving distribution and just provides a lower
bound for it. The analysis that follows considers the case
where perfect channel state (𝑯 and 𝑹 𝜂𝜂 ) is available at
the receiver, which is principally possible even with coarse
quantization [10]. However, the presented framework can be
applied independently of the kind of channel state information
at the transmitter.

Next, we introduce a new MIMO Gaussian channel that is
described by the same effective channel matrix 𝑯 ′ and the
same effective noise covariance matrix
𝒓 𝐺 = 𝑯 ′ 𝒙 + 𝜼 𝐺,

(10)

but differs from the original channel by the fact, that the noise
vector 𝜼 𝐺 is Gaussian distributed with the same covariance
matrix 𝑹 𝜂′ 𝜂′ = E[𝜼 𝐺 𝜼 H ]. In [11], it was shown that, for
𝐺
a given noise covariance matrix (known at the receiver), the
Gaussian distributed noise minimizes the mutual information,
which leads to the following lower bound
𝐼(𝒙; 𝒓) ≥ 𝐼(𝒙; 𝒓 𝐺 ).

(11)

𝐼(𝒙; 𝒓 𝐺 ) corresponds to the mutual information of the MIMO
Gaussian channel, that reads as
𝐼(𝒙; 𝒓 𝐺 ) = log2 1 𝑁 + 𝑹−1𝜂′ 𝑯 ′ 𝑹 𝑥𝑥 𝑯 ′H ,
𝜂′
Fig. 1.

when the channel input 𝒙 is Gaussian distributed with the
covariance matrix 𝑹 𝑥𝑥 . Again, 𝑯 ′ and 𝑹 𝜂′ 𝜂′ are given in (8)
and (9) respectively.
Now, the main difﬁculty consists of deriving the covariance
matrices 𝑹 𝑟𝑟 and 𝑹 𝑟𝑦 assuming a Gaussian input. For the
1-bit quantizer, these matrices can be found in a closed form
(see Section V). However, for general scalar quantizers, we
get an approximate evaluation, which will be described in the
following section.

Quantized MIMO Channel.

III. G AUSSIAN M ODEL OF T HE Q UANTIZED MIMO
C HANNEL USING THE B USSGANG D ECOMPOSITION
The Bussgang theorem implies that one can decompose the
output of the nonlinear quantizer 𝒓 = 𝑄(𝒚) into a desired
signal component and an uncorrelated distortion 𝒆
𝒓 = 𝑭 𝒚 + 𝒆,

IV. A PPROXIMATION OF THE C OVARIANCE M ATRICES FOR
GENERAL SCALAR Q UANTIZERS

(4)

where 𝑭 can be obtained from the linear MMSE estimation
of 𝒓 from 𝒚
𝑭 = E[𝒓𝒚 H ]E[𝒚𝒚 H ]−1 = 𝑹 𝑟𝑦 𝑹−1 ,
𝑦𝑦

Each quantization process can be given a distortion factor
(𝑖,𝑐)
𝜌𝑞
to indicate the relative amount of quantization noise
generated, which is deﬁned as follows

(5)

𝜌(𝑖,𝑐) =
𝑞

and the distortion error 𝒆 has the following correlation matrix
𝑹 𝑒𝑒 = E[(𝒓 − 𝑭 𝒚)(𝒓 − 𝑭 𝒚)H ]
= 𝑹 𝑟𝑟 − 𝑹 𝑟𝑦 𝑭

𝐻

− 𝑭 𝑹 𝑦𝑟 + 𝑭 𝑹 𝑦𝑦 𝑭

𝐻

Based on this decomposition, the channel output 𝒓 can be
written as function of the channel input in the following form
𝒓= 𝑭 𝒚+ 𝒆
(7)

= 𝑹 𝑟𝑦 𝑹−1 𝑯,
𝑦𝑦

(8)

E[𝑞 𝑖,𝑐 ]
E[𝑟 𝑖,𝑐 𝑞 𝑖,𝑐 ]

=
=

0
0

(15)
(16)

E[𝑦 𝑖,𝑐 𝑞 𝑖,𝑐 ]

and the non-Gaussian effective noise 𝜼 ′ with the covariance
matrix
𝑹 𝜂′ 𝜂′ = 𝑹 𝑒𝑒 + 𝑭 𝑹 𝜂𝜂 𝑭

(13)

For a symmetric input probability density function and a
symmetric quantizer, we can assume without loss of generality
that the following properties holds for all 0 ≤ 𝑖 ≤ 𝑁
𝑐 ∈ {𝑅, 𝐼}:1

where we introduced the effective channel
𝑯′ = 𝑭 𝑯

E[𝑞 2 ]
𝑖,𝑐
,
𝑟 𝑦 𝑖,𝑐 𝑦 𝑖,𝑐

where 𝑞 𝑖,𝑐 = 𝑟 𝑖,𝑐 −𝑦 𝑖,𝑐 is the quantization error and 𝑟 𝑦 𝑖,𝑐 𝑦 𝑖,𝑐 =
(𝑖,𝑐)
E[𝑦 2 ] is the variance of 𝑦 𝑖,𝑐 . The distortion factor 𝜌 𝑞
𝑖,𝑐
depends on the quantizer characteristics and the probability
density function of 𝑦 𝑖,𝑐 . Note that the signal-to-quantization
noise ratio (SQR) has an inverse relationship with regard to
the distortion factor
1
(14)
SQR(𝑖,𝑐) = (𝑖,𝑐) .
𝜌𝑞

(6)

= 𝑹 𝑟𝑟 − 𝑹 𝑟𝑦 𝑹−1 𝑹 𝑦𝑟 .
𝑦𝑦

= 𝑭 𝑯𝒙 + 𝑭 𝜼 + 𝒆
= 𝑯 ′ 𝒙 + 𝜼′ ,

(12)

=

−𝜌(𝑖,𝑐) 𝑟 𝑦 𝑖,𝑐 𝑦 𝑖,𝑐 ,
𝑞

(17)

𝐻

= 𝑹 𝑟𝑟 − 𝑹 𝑟𝑦 𝑹−1 𝑹 𝑦𝑟 + 𝑹 𝑟𝑦 𝑹−1 𝑹 𝜂𝜂 𝑹−1 𝑹 𝑦𝑟 .
𝑦𝑦
𝑦𝑦
𝑦𝑦

1 These properties can be always enforced by scaling each quantizer output
by an appropriate factor.

(9)

2

In a similar way, we evaluate 𝑟 𝑞 𝑖 𝑞 𝑗 for 𝑖 ∕= 𝑗:
[
]
E[𝑞 𝑖 𝑞 ∗ ] = E 𝑦 𝑗 E[𝑞 𝑖 𝑞 ∗ ∣𝑦 𝑗 ]
𝑗
𝑗
[
]
= E 𝑦 𝑗 E[𝑞 𝑖 ∣𝑦 𝑗 ]E[𝑞 ∗ ∣𝑦 𝑗 ]
𝑗
[
]
≈ E 𝑦 𝑗 𝑟 𝑞 𝑖 𝑦 𝑗 𝑟−1𝑦 𝑗 𝑦 𝑗 E[𝑞 ∗ ∣𝑦 𝑗 ]
𝑦𝑗
𝑗

which are for instance valid for a uniform or non-uniform
quantizer minimizing the mean square error (distortion) between the input 𝑦 𝑖,𝑐 and the output 𝑟 𝑖,𝑐 . Obviously, Eq. (17)
follows from Eqs (13) and (16). Assuming now that the
channel input is Gaussian then the quantizer input signals
𝑦 𝑖,𝑐 are Gaussian distributed and thus, they undergo the same
(𝑖,𝑐)
= 𝜌 𝑞 ∀𝑖∀𝑐. Furthermore, the
distortion factor 𝜌 𝑞 , i.e., 𝜌 𝑞
optimal parameters of the uniform as well as the non-uniform
quantizer and the resulting distortion factor 𝜌 𝑞 for Gaussian
distributed signals are tabulated in [12] for different bit resolutions 𝑏. Recent research work on the optimal quantization
of a Gaussian source can be found in [13], [14], [15]. Now,
let 𝑞 𝑖 = 𝑞 𝑖,𝑅 + 𝑗𝑞 𝑖,𝐼 be the complex quantization error. Under
the assumption of uncorrelated real and imaginary part of 𝑦 𝑖 ,
we obtain:
𝑟 𝑞 𝑖 𝑞 𝑖 = E[𝑞 𝑖 𝑞 ∗ ] =𝜌 𝑞 𝑟 𝑦 𝑖 𝑦 𝑖 ,
𝑖
(18)
𝑟 𝑦 𝑖 𝑞 𝑖 = E[𝑦 𝑖 𝑞 ∗ ] = − 𝜌 𝑞 𝑟 𝑦 𝑖 𝑦 𝑖 .
𝑖

=
=

𝑹 𝑦𝑟 = E[𝒚𝒓 ] = E[𝒚(𝒚 + 𝒒) ] = 𝑹 𝑦𝑦 + 𝑹 𝑦𝑞 ,
H

𝑹 𝑟𝑟 = E[(𝒚 + 𝒒)(𝒚 + 𝒒) ] = 𝑹 𝑦𝑦 + 𝑹 𝑦𝑞 +

𝑹H +
𝑦𝑞

= 𝜌 𝑞 𝑹 𝑦𝑦 − (1 − 𝜌 𝑞 )𝜌 𝑞 nondiag(𝑹 𝑦𝑦 ).

In summary, using (25), the effective channel from (8) becomes
𝑯 ′ = (1 − 𝜌 𝑞 )𝑯,
(29)
while the effective noise covariance matrix from (9) can be
obtained by means of (25) and (28)
𝑹 𝜂′ 𝜂′ ≈ 𝑹 𝑟𝑟 − (1 − 𝜌)2 𝑹 𝑦𝑦 + (1 − 𝜌)2 𝑹 𝜂𝜂
= (1 − 𝜌 𝑞 ) ((1 − 𝜌 𝑞 )𝑹 𝜂𝜂 + 𝜌 𝑞 diag(𝑹 𝑦𝑦 )) .

log2 1+(1−𝜌 𝑞 ) ((1−𝜌 𝑞 )𝑹 𝜂𝜂 +𝜌 𝑞 diag(𝑹 𝑦𝑦 ))

𝑹 𝑞𝑞 . (21)

𝑹 𝑦𝑦

𝑯𝑹 𝑥𝑥 𝑯 H ,
(31)

=

𝑹 𝜂𝜂 + 𝑯𝑹 𝑥𝑥 𝑯 H .

(32)

With these result, we can study the asymptotic of the mutual
information at low and high SNR. In fact, for the low SNR
regime we have
(33)
𝑹 𝑦𝑦 ≈ 𝑹 𝜂𝜂 ,
and thus we get a ﬁrst order approximate lower bound
𝐼(𝒙; 𝒓 𝐺 )∣low SNR ≈
)
(
−1
𝑯𝑹 𝑥𝑥 𝑯 H .
tr (1−𝜌 𝑞 ) ((1−𝜌 𝑞 )𝑹 𝜂𝜂 + 𝜌 𝑞 diag(𝑹 𝜂𝜂 ))
(34)
On the other hand, at the high SNR regime, the approximate
lower bound converges to the value

(23)

𝐼(𝒙; 𝒓 𝐺 )∣high SNR ≈

(24)

(
)−1
1
− 1) diag(𝑯𝑹 𝑥𝑥 𝑯 H )
𝑯𝑹 𝑥𝑥 𝑯 H .
𝜌𝑞
(35)

(25)

2 Due to the non-exact computation of 𝑹 ′ ′ , the derived approximate
𝜂 𝜂
lower bound expression (31) is not guaranteed to be still a lower bound for
𝐼(𝒙; 𝒓) ≥ 𝐼(𝒙; 𝒓 𝐺 ).

log2 (

and therefore, we get
𝑹 𝑦𝑟 = 𝑹 𝑦𝑦 + 𝑹 𝑦𝑞 = (1 − 𝜌 𝑞 )𝑹 𝑦𝑦 = 𝑹 𝑟𝑦 .

−1

where

In (22), the Bayesian estimator E[𝑦 𝑖 ∣𝑦 𝑗 ] corresponds to the
linear estimator 𝑟 𝑦 𝑖 𝑦 𝑗 𝑟−1𝑦 𝑗 𝑦 𝑗 since the vector 𝒚 is jointly
𝑦𝑗
Gaussian distributed. Eq. (23) follows from (18).
Summarizing the results of (18) and (23), we obtain
𝑹 𝑦𝑞 = −𝜌 𝑞 𝑹 𝑦𝑦 ,

(30)

Finally, we obtain the approximate lower bound on the mutual
information as 2
𝐼(𝒙; 𝒓 𝐺 ) ≈

(20)

−𝜌 𝑞 𝑟 𝑦 𝑖 𝑦 𝑗 .

(27)

Inserting the expressions (24) and (27) into Eq. (21), we
obtain:
𝑹 𝑟𝑟 ≈ (1 − 𝜌 𝑞 )(𝑹 𝑦𝑦 − 𝜌 𝑞 nondiag(𝑹 𝑦𝑦 ))
(28)
= (1 − 𝜌 𝑞 ) ((1 − 𝜌 𝑞 )𝑹 𝑦𝑦 + 𝜌 𝑞 diag(𝑹 𝑦𝑦 )) .

𝑟 𝑦 𝑖 𝑦 𝑗 𝑟−1𝑦 𝑗 E[𝑦 𝑗 𝑞 ∗ ]
𝑦𝑗
𝑗

=

(26)

𝑹 𝑞𝑞 ≈ 𝜌 𝑞 diag(𝑹 𝑦𝑦 ) + 𝜌2 nondiag(𝑹 𝑦𝑦 )
𝑞

We now derive all required covariance matrices by using
the fact that the quantization error 𝑞 𝑖 , conditioned on 𝑦 𝑖 , is
statistically independent of all other random variables of the
system.
First we calculate 𝑟 𝑦 𝑖 𝑞 𝑗 = E[𝑦 𝑖 𝑞 ∗ ] for 𝑖 ∕= 𝑗:
𝑗
[
]
∗
∗
E[𝑦 𝑖 𝑞 𝑗 ] = E 𝑦 𝑗 E[𝑦 𝑖 𝑞 𝑗 ∣𝑦 𝑗 ]
[
]
= E 𝑦 𝑗 E[𝑦 𝑖 ∣𝑦 𝑗 ]E[𝑞 ∗ ∣𝑦 𝑗 ]
𝑗
[
]
(22)
= E 𝑦 𝑗 𝑟 𝑦 𝑖 𝑦 𝑗 𝑟−1𝑦 𝑗 𝑦 𝑗 E[𝑞 ∗ ∣𝑦 𝑗 ]
𝑦𝑗
𝑗
=

𝜌2 𝑟∗ 𝑗 𝑦 𝑖 = 𝜌2 𝑟 𝑦 𝑖 𝑦 𝑗 ,
𝑞 𝑦
𝑞

where we used Eq. (24) and (18) and we approximated
the Bayesian estimator E[𝑞 𝑖 ∣𝑦 𝑗 ] with the linear estimator.
From (26) and (18) we deduce the covariance matrix of the
quantization error:

and 𝑹 𝑟𝑟 can be expressed as
H

−𝜌 𝑞 𝑟∗ 𝑗 𝑦 𝑖 𝑟−1𝑦 𝑗 ⋅ (−𝜌 𝑞 𝑟 𝑦 𝑗 𝑦 𝑗 )
𝑦
𝑦𝑗

=

For the uniform quantizer case, it was shown in [15], that the
optimal quantization step Δ for a Gaussian source decreases
√
as 𝑏2−𝑏 and that 𝜌 𝑞 is asymptotically well approximated by
Δ2
−2𝑏
.
12 and decreases as 𝑏2
On the other hand, the optimal non-uniform quantizer
achieves, under high-resolution assumption, approximately the
following distortion [16]
√
𝜋 3 −2𝑏
2 .
(19)
𝜌𝑞 ≈
2
Based on these considerations, we aim at approximating the
required correlation matrices 𝑹 𝑦𝑟 and 𝑹 𝑟𝑟 based on the scalar
𝜌 𝑞 . In fact, we have
H

𝑟∗ 𝑗 𝑞 𝑖 𝑟−1𝑦 𝑗 E[𝑦 𝑗 𝑞 ∗ ]
𝑦
𝑦𝑗
𝑗

3

V. A NALYSIS OF THE 1- BIT Q UANTIZATION

and the following noise covariance matrix
[
]
1 𝑟
,
𝑹 𝜂𝜂 =
𝑟 1

In this section, we deal with the special case of symmetric
1-bit quantization, where, fortunately, the required correlation
matrices can be obtained in an exact way. In fact, it is
known from the classical arcsine law [17] that the output of a
decision device 𝑟 𝑖,𝑐 = sign[𝑦 𝑖,𝑐 ] ∈ {−1, 1} has the following
correlation matrix
)]
(
1
1
2[
arcsin diag(𝑹 𝑦𝑦 )− 2 𝑹 𝑦𝑦 diag(𝑹 𝑦𝑦 )− 2 , (36)
𝑹 𝑟𝑟 =
𝜋
where the arcsine function is applied element-wise to its matrix
argument. Additionally, the correlation matrix between the
input and the output of the 1-bit quantizer can be obtained
as [17]
√
1
2
diag(𝑹 𝑦𝑦 )− 2 𝑹 𝑦𝑦 .
(37)
𝑹 𝑟𝑦 =
𝜋
Then, we get the effective channel from (8) as
√
1
2
′
diag(𝑹 𝑦𝑦 )− 2 𝑯,
(38)
𝑯 =
𝜋
while the effective noise covariance in (9) becomes
)]
(
1
1
2[
𝑹 𝜂′ 𝜂′ = arcsin diag(𝑹 𝑦𝑦 )− 2 𝑹 𝑦𝑦 diag(𝑹 𝑦𝑦 )− 2 −
𝜋
1
1
2
diag(𝑹 𝑦𝑦 )− 2 𝑹 𝑦𝑦 diag(𝑹 𝑦𝑦 )− 2 +
𝜋
1
1
2
diag(𝑹 𝑦𝑦 )− 2 𝑹 𝜂𝜂 diag(𝑹 𝑦𝑦 )− 2 .
𝜋
(39)
Finally, the lower bound on the mutual information of the 1bit quantized MIMO channel with Gaussian input is computed
from (12).
Again, we can consider the low SNR regime where 𝑹 𝑦𝑦 ≈
𝑹 𝜂𝜂 to obtain the following asymptotic lower bound of the
mutual information
(

(43)

parametrized by the noise correlation factor 𝑟 fulﬁlling ∣𝑟∣ ≤
1. Further, the power of the scalar input is denoted by
𝑃 = E[∣𝑥∣2 ]. For the case 𝑟 = −1 (the two noise components are oppositely correlated), and under 1-bit quantization,
the obtained lower bound on the mutual information with
Gaussian input is shown in Fig. 2 as function of the input
power. Interestingly, the lower bound exhibits a non-monotonic
behavior with respect to the signal power (i.e. the SNR),
which leads to the conclusion that noise might be favorable
for the mutual information of quantized output channel. For
comparison, the achievable rate of the same channel with
QPSK input is depicted. It can be shown that this corresponds
to the capacity of two parallel erasure channels with an erasure
√
probability of erfc( 𝑃/2) [18]
𝐼 QPSK (𝑥, 𝒓) = 2(1 − erfc(

√

𝑃/2)).

(44)

We can observe that for certain range of the input power,
the Gaussian symbol alphabet can achieve higher mutual
information than the QPSK schemes despite of the 1-bit output
quantization. Other numerical experiments shows that this
interesting phenomenon usually occurs in quantized MIMO
channels, where the number of outputs exceed the number of
inputs.
Next, Fig. 3 shows, for the same channel, the ratio of the low
SNR mutual information with 1-bit output to the one without
quantization as function of the noise correlation coefﬁcient 𝑟.
Thereby, we make use of the asymptotic value of the mutual
information from (41) as well as the approximation given in
(34) with 𝜌 𝑞 = 1 − 2/𝜋. First of all, the delivered approximation seems to be accurate when the correlation factor is
1
1-bit
𝐼(𝒙; 𝒓)∣low SNR ≥ tr 𝑯𝑹 𝑥𝑥 𝑯 H diag(𝑹 𝜂𝜂 )− 2
not near to 1. Then, for 𝑟 > 0 the rate ratio is obviously
) higher that the value 2/𝜋 and reaches its maximum around
[
(
)]−1
1
1
1
arcsin diag(𝑹 𝜂𝜂 )− 2 𝑹 𝜂𝜂 diag(𝑹 𝜂𝜂 )− 2
diag(𝑹 𝜂𝜂 )− 2 . 𝑟 = 0.7, whereas for 𝑟 < 0 the loss in terms of achievable
information rate becomes more pronounced. Consequently, if
(40)
the signal subspace 𝒉𝒉H and the noise subspace 𝑹 𝜂𝜂 exhibits
For the case that the noise covariance matrix is diagonal, this
a certain similarity then the channel capacity reduction due
ﬁrst order asymptotic of the mutual information simpliﬁes to
to quantization is quite small. However, if they are nearly
)
2 (
1-bit, uncorr. noise
H −1
(41) orthogonal then the loss becomes substantial.
⪆ tr 𝑯𝑹 𝑥𝑥 𝑯 𝑹 𝜂𝜂 ,
𝐼(𝒙; 𝒓)∣low SNR
𝜋
VI. C ONCLUSION
which coincides with the result that has been shown in [3],
stating that the MIMO achievable rate under 1-bit quantization
We studied the mutual information of MIMO channels
reduces by the factor 2/𝜋 at the low SNR regime and therefore with output quantization and correlated noise. Based on the
the derived lower bound (41) is asymptotically tight, when the Bussgang decomposition, a lower bound on the achievable
noise is uncorrelated.
rate has been derived, which is useful when analyzing the low
SNR behavior of the mutual information. We dealt also with
A. A simple example
the 1-bit quantizer case and showed that the reduction of the
We now consider a simple example, where interesting mutual information becomes smaller than 2/𝜋 under certain
effects of noise correlation and quantization can be observed. It conditions for the channel matrix and the noise covariance
consists of a 1×2 single-input multiple-output (SIMO) channel matrix. Additionally, we observed that the additive noise
with the following channel vector
might, at certain level, be favorable when the observation are
[
]
quantized, since the lower bound on the mutual information
1
𝒉=
,
(42)
curves is not necessary monotonic with the SNR. Although,
1

4

0.8

1.8

0.7

𝐼(𝑥; 𝒓)/𝐼(𝑥; 𝒚) at low SNR

2

1.6

𝐼(𝑥; 𝒓)

1.4
1.2
1
0.8
0.6
0.4 −1
10

0

1

Input power 𝑃

10

0.4
0.3
0.2

0
−0.5

2

10

Max. at 𝑟 ∗ ≈ 0.7

0.5

0.1

Gaussian Input (Lower Bound)
QPSK Input (Exact)
10

2/π
0.6

2/π benchmark
Exact lower bound
Approx. from (34)
0

0.5

Noise Correlation Coefﬁcient 𝑟

1

Fig. 2. Achievable rates of the 1×2 MISO channel with oppositely correlated
noise and sign (1-bit) quantization.

Fig. 3. Low SNR capacity reduction due to 1-bit quantization as function
of the noise correlation coefﬁcient.

we focused on the single user scenario, similar analysis can
be carried out for the multi-user broadcast channel.

[9] J. J. Bussgang, “Crosscorrelation functions of amplitude-distorted
Gaussian signals,” Technical Report No. 216, MIT, Cambridge, MA,
March 1952.
[10] A. Mezghani, F. Antreich, and J. A. Nossek, “Multiple Parameter
Estimation With Quantized Channel Output,” in Proceedings of the
International ITG/IEEE Workshop on Smart Antennas WSA, Bremen,
Germany, February 2010.
[11] S. N. Diggavi and T. M. Cover, “Worst additive noise under covariance
constraints,” IEEE Transactions on Information Theory, vol. 47, no. 7,
pp. 3072–3081, November 2001.
[12] J. Max, “Quantizing for Minimum Distortion,” IEEE Trans. Inf. Theory,
vol. 6, no. 1, pp. 7–12, March 1960.
[13] N. Al-Dhahir and J. M. Ciofﬁ, “On the Uniform ADC Bit Precision and
Clip Level Computation for a Gaussian Signal,” IEEE Trans. on Sig.
Proc., vol. 44, no. 2, February 1996.
[14] Sangsin Na and David L. Neuhoff, “On the Support of MSE-Optimal,
Fixed-Rate, Scalar Quantizers,” IEEE Trans. Inform. Theory, vol. 47,
no. 7, pp. 2972–2982, November 2001.
[15] D. Hui and D. L. Neuhoff, “Asymptotic Analysis of Optimal Fixed-Rate
Uniform Scalar Quantization,” IEEE Trans. Inform. Theory, vol. 47, no.
3, pp. 957–977, March 2001.
[16] A. Gersho and R. M. Gray, Vector Quantization and Signal Compression,
Kluwer Academic Publishers, Dordrecht, Niederlande, ﬁrst edition,
1992.
[17] A. Papoulis, Probability, random variables, and stochastic processes,
McGraw-Hill, fourth edition, 2002.
[18] T. M. Cover and J. A. Thomas, Elements of Information Theory, John
Wiley and Son, New York, 1991.

R EFERENCES
[1] R. Schreier and G. C. Temes, “Understanding Delta-Sigma Data
Converters,” IEEE Computer Society Press, 2004.
[2] D. D. Wentzloff, R. Bl´ zquez, F. S. Lee, B. P. Ginsburg, J. Powell, and
a
A. P. Chandrakasan, “System design considerations for ultra-wideband
communication,” IEEE Commun. Mag., vol. 43, no. 8, pp. 114–121,
Aug. 2005.
[3] A. Mezghani and J. A. Nossek, “On Ultra-Wideband MIMO Systems
with 1-bit Quantized Outputs: Performance Analysis and Input Optimization,” IEEE International Symposium on Information Theory (ISIT),
Nice, France, June 2007.
[4] J. A. Nossek and M. T. Ivrlaˇ , “Capacity and coding for quantized
c
MIMO systems,” in Intern. Wireless Commun. and Mobile Computing
Conf. (IWCMC), Vancouver, Canada, July 2006, pp. 1387–1392, invited.
[5] A. Mezghani and J. A. Nossek, “Analysis of 1-bit Output Noncoherent
Fading Channels in the Low SNR Regime,” IEEE International
Symposium on Information Theory (ISIT), Seoul, Korea, June 2009.
[6] T. Koch and A. Lapidoth, “Asymmetric Quantizers are Better At Low
SNR,” IEEE International Symposium on Information Theory (ISIT),
Saint Petersburg, Russia, August 2011.
[7] T. Koch and A. Lapidoth, “Increased Capacity per Unit-Cost by
Oversampling,” Sep. 2010, Available: http://arxiv.org/abs/1008.539.
[8] J. Singh, O. Dabeer, and U. Madhow, “On the limits of communication
with low-precision analog-to-digital conversion at the receiver,” Communications, IEEE Transactions on, vol. 57, no. 12, pp. 3629–3639,
December 2009.

5

