Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Thu May 17 15:03:56 2012
ModDate:        Tue Jun 19 12:56:23 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      402387 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569566857

Allocations for Heterogenous Distributed Storage
Vasileios Ntranos

Giuseppe Caire

Alexandros G. Dimakis

University of Southern California
Los Angeles, CA 90089, USA
ntranos@usc.edu

University of Southern California
Los Angeles, CA 90089, USA
caire@usc.edu

University of Southern California
Los Angeles, CA 90089, USA
dimakis@usc.edu

The probability of successful recovery for an allocation
(x1 , . . . , xn ) can be written as

Abstract—We study the problem of storing a data object in a
set of data nodes that fail independently with given probabilities.
Our problem is a natural generalization of a homogenous storage
allocation problem where all the nodes had the same reliability
and is naturally motivated for peer-to-peer and cloud storage
systems with different types of nodes. Assuming optimal erasure
coding (MDS), the goal is to ﬁnd a storage allocation (i.e, how
much to store in each node) to maximize the probability of
successful recovery. This problem turns out to be a challenging
combinatorial optimization problem. In this work we introduce
an approximation framework based on large deviation inequalities and convex optimization. We propose two approximation
algorithms and study the asymptotic performance of the resulting
allocations.

xi ≥ 1 =

Ps = P
i∈r

P(r)

1

xi ≥ 1
i∈r

r⊆{1,...,n}

where 1{·} is the indicator function. 1{S} = 1 if the statement
S is true and zero otherwise.
A more concrete way to see this problem is by introducing
a Yi ∼ Bernoulli(pi ) random variable for each storage node:
Yi = 1 when node i is accessed by the data collector and
Yi = 0 when node i has failed. Deﬁne the random variable
n

Z=

I. I NTRODUCTION

(1 − pj ).

pi
i∈r

(2)

where xi is the amount of data stored in node i. Then,
obviously, we have Ps = P[Z ≥ 1].
Our goal is to ﬁnd a storage allocation (x1 , . . . , xn ), that
maximizes the probability of successful recovery, or equivalently, minimizes the probability of failure, P[Z < 1].

We are interested in heterogenous storage systems where
storage nodes have different reliability parameters. This problem is relevant for heterogenous peer-to-peer storage networks
and cloud storage systems that use multiple types of storage
devices, e.g. solid state drives along with standard hard disks.
We model this problem by considering n storage nodes and
a data collector that accesses a random subset r of them.
The probability distribution of r ⊆ {1, . . . , n} models random
node failures and we assume that node i fails independently
with probability 1 − pi . The probability of a set r of nodes
being accessed is therefore:
P(r) =

xi Yi
i=1

II. O PTIMIZATION P ROBLEM
Put in optimization form, we would like to ﬁnd a solution
to the following problem.
Q1 :

(1)

minimize
xi

P(r)
r⊆{1,...,n}
n

xi < 1
i∈r

xi ≤ T

subject to:

j ∈r
/

1

i=1

xi ≥ 0, i = 1, . . . , n.

Assume now that we have a single data ﬁle of unit size
that we wish to code and store over these nodes to maximize
the probability of recovery after a random set of nodes fail.
The problem becomes trivial if we do not put a constraint on
the maximum size T of coded data and hence, we will work
with a maximum storage budget of size T < n: If xi is the
n
amount of coded data stored in node i, then i=1 xi ≤ T . We
further assume that our ﬁle is optimally coded, in the sense
that successful recovery occurs whenever the total amount of
data accessed by the data collector is at least the size of
the original ﬁle. This is possible in practice when we use
Maximum Distance Separable (MDS) codes [1].

Authors in [1] consider a special case of problem Q1 in
which pi = p, ∀i. Even in this symmetric case the problem
appears to be very difﬁcult to solve due to its non-convex
and combinatorial nature. In fact, even for a given allocation
{xi } and parameter p, computing the objective function is
computationally intractable (#P -hard , See [1]).
A very interesting observation about this problem follows
directly from Markov’s Inequality: P[Z ≥ 1] ≤ E[Z] = pT . If
pT < 1, then the probability of successful recovery is bounded
away from 1. This has motivated the deﬁnition of a region of
parameters for which high probability of recovery is possible:
RHP = {(p, T ) : pT ≥ 1}. The budget T should be more than
1/p if we want to aim for high reliability and the authors in
[1] showed that in the above region of parameters, maximally

This research was supported in part by NSF Career Grant CCF-1055099
and research gifts by Intel and Microsoft Research.

1

spreading the budget to all nodes (i.e, xi = T /n, ∀i) is an
asymptotically optimal allocation as n → ∞.
In the general case, when the node access probabilities, pi ,
are not equal, one could follow similar steps to characterize
a region of high probability of recovery. Markov’s Inequality
yields:

for any δ > 0.
We can use Lemma 1 to upper bound the probability of
failure, P[Z < 1] ≤ P[Z ≤ 1], for an arbitrary allocation,
n
since Z = i=1 xi Yi can be seen as the sum of n independent
almost surely bounded random variables Vi = xi Yi , with
n
P Vi ∈ [0, xi ] = 1. Let δ =
i=1 xi pi − 1 /n and require
n
δ > 0 ⇔ i=1 xi pi > 1. Lemma 1 yields:

n

xi pi = pT x

P[Z ≥ 1] ≤ E[Z] =
i=1
T

where p = [p1 , p2 , . . . , pn ] and x = [x1 , x2 , . . . , xn ]T . If we
don’t want P[Z ≥ 1] to be bounded away from 1 we have
to require now that pT x ≥ 1. We see that in this case, high
reliability is not a matter of sufﬁcient budget, as it depends on
the allocation x itself.
Let S(p, T ) = x ∈ Rn : pT x ≥ 1, 1T x ≤ T be the set
+
of all allocations x with a given budget constraint T that satisfy
pT x ≥ 1 for a given p. We call these allocations reliable for
a system with parameters p, T , in the sense that the resulting
probability of successful recovery is not bounded away from 1.
Then the region of high probability of recovery can be deﬁned
as the region of parameters p, T , such that the set S(p, T ) is
non-empty.

P[Z < 1] ≤ exp −

n
i=1 xi pi −
n
2
i=1 xi

1

2

n

,

xi pi > 1.
i=1

(3)
n
Notice that the constraint i=1 xi pi > 1 requires the allocation (x1 , x2 , . . . , xn ) to be reliable and S(p, T ) = ∅.
In view of the above, a sufﬁcient condition for a strictly
reliable allocation to be -optimal is the following.
exp −

2

n
i=1 xi pi −
n
2
i=1 xi

1

2

≤

⇐⇒
(4)

ln 1/
≤ pT x − 1 ,
pT x > 1
2
We say that all allocations satisfying the above equation are
Hoeffding -optimal, due to the use of Hoeffding’s Inequality
in Lemma 1.
||x||2

RHP = (p, T ) ∈ Rn+1 : S(p, T ) = ∅
+
This generalizes the region described in [1]. If all pi ’s are
equal then the set S(p, T ) is non-empty when pT x = pT ≥ 1.
In the general case, the minimum budget such that S(p, T )
is non-empty is T = 1/pmax , with pmax = max{pi }, and
S(p, 1/pmax ) contains only one allocation xp−1 : xj =
max
1
pmax , j = arg maxi {pi }, xi = 0 , ∀i = j.
Even though RHP provides a lower bound on the minimum
budget T required to allocate for high reliability, it doesn’t
provide any insights on how to design allocations that achieve
high probability of recovery in a distributed storage system.
This motivates us to move one step further and deﬁne a region
of -optimal allocations in the next section.

Deﬁnition 1. “The Region of Hoeffding -optimal allocations”
Hn (p, T, ) =

x ∈ Rn : pT x > 1, 1T x ≤ T,
+
(5)
||x||2

ln 1/
2

T

≤p x−1

The above region is strictly smaller En (p, T, ) for any ﬁnite
n, because the bound in (3) is not generally tight. However,
Hn (p, T, ) is a convex set: Equation (4) can be seen as a
second order cone constraint on the allocation x ∈ Rn .
+

III. T HE REGION OF - OPTIMAL ALLOCATIONS
We say that an allocation (x1 , x2 , . . . , xn ) is -optimal if the
corresponding probability of successful recovery, P[Z ≥ 1], is
greater than 1 − .
Let En (p, T, ) = { x ∈ Rn : P[Z < 1] ≤ , 1T x ≤ T }
+
be the set of all -optimal allocations. Note that if we could
efﬁciently characterize this set for all problem parameters, we
would be able to solve problem Q1 exactly: Find the smallest
such that En (p, T, ) is non-empty.
In this section we will derive a sufﬁcient condition for an
allocation to be -optimal and provide an efﬁcient characterization for a region Hn ⊆ En (p, T, ). We begin with a very
useful lemma.

Theorem 1. The region of Hoeffding -optimal allocations
Hn (p, T, ) is convex in x.
This interesting result allows us to formulate and efﬁciently
solve optimization problems over Hn (p, T, ). Finding the
smallest ∗ such that Hn (p, T, ) is non-empty will produce
an ∗ -optimal solution to problem Q1.
A. Hoeffding Approximation of Q1
If we ﬁx p, T, n as the problem parameters, then the
following optimization problem can be solved efﬁciently, to
any desired accuracy 1/α, by solving a sequence of O(log α)
convex feasibility problems (bisection on ).

Lemma 1. (Hoeffding’s Inequality [2], [3])
n
Consider the random variable W = i=1 Vi , where Vi are
independent almost surely bounded random variables with
P (Vi ∈ [ai , bi ]) = 1. Then,
P W ≤ E[W ] − nδ ≤ exp −

2

H1 :

min
x,

s.t.:

x ∈ Hn (p, T, )

We will see next that if T is sufﬁciently large, ∗ goes to
zero exponentially fast as n grows, and hence the solution to
the aforementioned problem is asymptotically optimal.

2n2 δ 2
− ai )2

n
i=1 (bi

2

B. Maximal Spreading Allocations and the Asymptotic Optimality of H1

= et

P(r) exp −t

First, we will focus on maximal spreading allocations, xn
T
{x ∈ Rn : xi = T /n }, and derive their asymptotic optimality
for Q1, in the sense that P[Z < 1] → 0, as n → ∞. Let
n
1
p = n i=1 pi be the average access probability across all
¯
nodes. We have the following lemma.

P(r) exp −t

=

Note that gt (x) is a weighted sum of convex functions with
linear arguments, and hence convex in x. Equation (7) makes
the convex relaxation of the objective function apparent:

1

x < α ≤ e−t(x−α) , for any t ≥ 0.

B. The Relaxed Optimization Problem

Corollary 1. The probability of failed recovery, Pe P[Z <
2
¯
1], for a maximal spreading allocation is Pe ≤ e−2n(p−1/T ) .
When T > 1/¯, Pe → 0, as n → ∞.
p

Before we move forward and state the relaxed optimization
problem, we take a closer look at the constraint set S = {x ∈
Rn : 1T x ≤ T } of the original problem Q1. From a practical
+
perspective, it should be wasteful to allocate more than one
unit of data (ﬁlesize) on a single node. If the node survives,
then the data collector can always recover the ﬁle using only
one unit of data and hence any additional storage does not
help. Also, an allocation using less than the available budget
cannot have larger probability of successful recovery.
In the following lemma, we show that it is sufﬁcient to
n
consider allocations with xi ∈ [0, 1] and i=1 xi = T .

The fact that Hn (p, T, ) contains maximal spreading allocations for T > 1/¯, provides a sufﬁcient condition on the
p
asymptotic optimality of H1.
Theorem 2. Let ∗ be the optimal value of H1. If T > 1/¯,
p
then ∗ = O(exp(−n)).
Proof: Let T > 1/¯ and consider the maximal spreading
p
allocation xn . Then, ∗ ≤ s , where s is the minimum such
T
2
¯
that xn ∈ Hn (p, T, ). That is s = e−2n(p−1/T ) , and since
T
T > 1/¯, ∗ ≤ s = O(exp(−n)).
p

Lemma 4. For any x ∈ S, ∃x ∈ S = {x ∈ Rn : 1T x =
+
n
T, xi ≤ 1, i = 1, . . . , n} such that P [ i=1 xi Yi < 1] ≤
n
P [ i=1 xi Yi < 1].

IV. C HERNOFF R ELAXATION

Proof: See the long version of this paper [4].
The relaxed optimization problem can be formulated as
follows.

In this section we take a different approach to obtain a
tractable convex relaxation for Q1 by minimizing an appropriate Chernoff upper bound.

R1 :

A. Upper Bounding the Objective Function

minimize
xi

i=1

xi ∈ [0, 1], i = 1, . . . , n.
Note that, in general, one would like to minimize
inf t≥0 {gt (x)} instead of gt (x) for some t ≥ 0. However,
for now, we will let t be a free parameter and carry on with
the optimization.
The important drawback of the above formulation hides
in the objective function: Although convex, gt (x) has an
exponentially long description in the number of storage nodes:
The sum is still over all subsets r ⊆ {1, . . . , n}. This can
be circumvented if we consider minimizing log gt (x) = t +
n
−txi
) instead of gt (x) over the same
i=1 log (1 − pi + pi e
set.

xi − 1
i∈r

P[Z ≤ 1] = P e−tZ ≥ e−t
n

≤

et E e−tZ

e−txi Yi

= et E
i=1

n

E e−txi Yi

= et

Lemma 5. log gt (x) is convex in x.

i=1
n

1 − pi + pi e−txi

= et

xi = T

subject to:

Proof: For any t ≥ 0 we have:
P[Z < 1] ≤

gt (x)
n

n

Lemma 3. (Upper Bound) Let Z = i=1 xi Yi , xi ≥ 0, Yi ∼
Bernoulli(pi ) and t ≥ 0. The probability of failed recovery,
P[Z < 1], is upper bounded by

r⊆{1,...,n}

(7)

gt (x)

Proof: This follows directly from the deﬁnition of
ln 1/
Hn (p, T, ): n = 2(p−1/T )2 .
¯
The above lemma establishes the asymptotic optimality of
maximal spreading allocations through the following corollary.

P(r) exp −t

xi − 1
i∈r

r⊆{1,...,n}

Lemma 2. If T > 1/¯, for any > 0, ∃n : xn ∈ Hn (p, T, ),
p
T
for all n ≥ n .

P[Z < 1] ≤ gt (x) =

xi
i∈r

r⊆{1,...,n}

Proof: See the long version of this paper [4].

(6)

i=1

3

Lemma 6. For any t ≥ 0

 0
∗
1
xi =
 1

n

pi −txi
arg min gt (x) = arg min
e
log 1 +
x∈S
x∈S
1 − pi
i=1
where S = {x ∈ Rn : 1T x ≤ T, x
+

,

t

1}.

n

t+

minimize
xi

log 1 +
i=1

n

i=1

xi = T

n

xi − T
i=1
n

n

vi (xi − 1)

ui xi +
i=1

i=1

where λ ∈ R, u, v ∈ Rn are the corresponding Lagrange
+
multipliers. The gradient is given by xi L(x, u, v, λ) =
ri t
−
+λ−ui +vi , and the KKT necessary and sufﬁcient
ri + etxi
conditions for optimality yield:
−

ri t
∗ + λ − ui + vi = 0 , ∀i
ri + etxi

(8)

n

x∗ = T
i

(9)

0 ≤ x∗ ≤ 1 , ∀i
i

(10)

λ ∈ R , vi , ui ≥ 0 , ∀i

(11)

vi (xi − 1) = 0 , ui xi = 0 , ∀i

1

et

ri t
ri t
,
+ ri 1 + ri

λ∗ ≤

et

ri t
+ ri

= T (14)

t→∞

Here, we move one step further and take the KKT conditions
for R2 in order to take a closer look at the structure of the
pi
optimal solutions. Let ri
1−pi .
The Lagrangian for R2 is:

i=1

λ∗ ∈

(14) yields x∗ = T , ∀i and hence the maximal spreading
i
n
allocation becomes optimal for R2 as t → ∞. Even though
this motivates the choice of maximal spreading allocations as
approximate “one-shot” solutions 1 for the original problem
Q1, explicitly tuning the parameter t can provide signiﬁcantly
better approximations.
In order to obtain the tightest bound from Lemma 3, we
have to jointly minimize the objective in R2 with respect to
t ≥ 0 and x. Towards this end, one can iteratively optimize
R2 by ﬁxing the value of one variable (t or x) at each
step and minimizing over the other. After each iteration the
objective function decreases and hence the above procedure
converges to a (possibly local) minimum. The above algorithm
iteratively tunes the Chernoff bound introduced in this section
and produces a minimizing allocation that can serve as an
approximate solution to the original problem Q1.
For analytic purposes though, we can choose a value for t as
follows. Recall from Lemma 3 that P[Z < 1] ≤ gt (x) for any
t ≥ 0. After taking logarithms, we would like to ﬁnd a value
n
for t ≥ 0 that minimizes b(t)
t + i=1 log(1 + ri e−txi ).
Notice that b(t) is a convex function of t, with b(t) > 0, ∀t ≥
n
0, b(0) = i=1 log(1 + ri ) and limt→∞ b(t) = ∞. The slope
n
n
ri x
of b(t) at zero is b (0) = 1 − i=1 1+rii = 1 − i=1 pi xi ,
which is negative if the allocation is reliable.
When t is large, log(1 + ri e−txi ) ≈ 0, whereas for small
values of t, log(1+ri e−txi ) ≈ −txi +log ri and hence b(t) ≈
n
n
t + i=1 max{−txi + log ri , 0} ≥ t + max{− i=1 txi +
log ri , 0}. One way to choose t that does not depend on xi is
n
n
1
to make − i=1 txi + log ri = 0 ⇒ t = T i=1 log ri .

C. Insights from Optimality Conditions for R2

log 1 + ri e−txi + λ

1

D. The choice of parameter t ≥ 0
It is clear that the optimal solution to R2 depends on our
ri t
it
choice of t ≥ 0. For example, etr+ri → 0, 1+ri → ∞, as
∗
−1
∗
t → ∞ and xi = lim t log (ri t/λ − ri ), ∀i. Equation

R2 is a convex separable optimization problem with polynomial size description and in terms of complexity, it is “not
much harder” than linear programming [5]. One can solve such
problems numerically in a very efﬁcient way using standard,
“off-the-shelf” algorithms and optimization packages such as
CVX [6], [7].

−

(13)
ri t
1+ri

Numerically, λ∗ can be computed via an iterative O(n2 )
algorithm described in [8], and hence this approach gives an
even more efﬁcient way to solve R2.
However, the most important aspect of the above result is
that we can use equations (13), (14) to obtain closed form
solutions for a certain region of problem parameters and
analyze the performance of the resulting allocations.

pi −txi
e
1 − pi

n

ri t
− ri
λ∗

i=1

xi ∈ [0, 1], i = 1, . . . , n.

=

1
log
t

n

i=1

L(x, u, v, λ)

− ri

+

n

subject to:

ri t
λ∗

where λ∗ is chosen such that Eq.(9) is satisﬁed, i.e,

Proof: Let x∗ = arg minx∈S gt (x). Then gt (x∗ ) ≤
gt (x), ∀x ∈ S. Taking the logarithm on both sides preserves the inequality since log(·) is strictly increasing. Hence,
log gt (x∗ ) ≤ log gt (x), ∀x ∈ S and subtracting t +
n
i=1 log(1 − pi ) from both sides yields the desired result
and completes the proof.
In view of Lemmas 5 and 6, we can solve R1 through the
following equivalent optimization problem.

R2 :

log

ri t
if 1+ri ≤ λ∗
it
if λ∗ ≤ etr+ri
it
if etr+ri < λ∗ <

(12)

i=1

1 Here, “one shot” refers to a solution that can be given in closed form in
terms of n functions fi : Rn+1 → R, such that for any problem instance,
xi = fi (p, T ), ∀i. For maximal spreading allocations, fi (p, T ) = T /n, ∀i.

Using the results from [8], the optimal solution to R2 is
given by

4

ˆT
E. A closed-form allocation: xn
In view of the above results we provide here a closed form
allocation (each xi is given as a function of p and T) that can
be used to study the asymptotic performance of R2 and serve
as a better “one-shot” approximate solution to Q1.
Let E(·) be a shorthand notation for the sample average
n
1
such that n i=1 f (xi ) ≡ Ef (x), in order to simplify the
n
1
expressions. For the above choice of t = T i=1 log ri =
nElog r/T , equation (13) becomes:

−1

10

−2

Probability of failed recovery (Pe)


 0


∗
1
xi =




ri
if 1+ri nElog r ≤ λ∗
T
if λ∗ ≤ eri nElog r/T i
nElog r/T +r

T
nElog r

log

nri Elog r
T λ∗

− ri

otherwise

10

−3

10

−4

10

−5

10

−6

10

(15)
−7

1
2,

Lemma 7. If pi > ∀i and T <
T
then x∗ = nElog r log ri , ∀i.
i

Approximate DSA
(filesize = 1, N=100)

0

10

nElog r
log rmax ,

10

rmax = max{ri },

ri nElog r/T
, ri nElog r .
T
enElog r/T +ri 1+ri
T
Then from Eq.(14), λ∗ = nElog r and x∗ = nElog r log ri . λ∗
i
2T
ri
is indeed in the required interval if nElog r < 1+ri nElog r , ∀i
2T
T
ri nElog r/T
nElog r
⇒ ri > 1, ∀i ⇒ pi > 1/2, ∀i and 2T < enElog r/T +ri , ∀i
nElog r
⇒ ri < enElog r /T, ∀i ⇒ T < log rmax .
T
n
ˆ
Clearly, when all pi > 1/2, xT : xi = nElog r log ri , ∀i, is a

1.2

MaxSpread (Pe)
Chernoff CF (Pe)
Hoeffding (Pe)
Chernoff IT (Pe)
MaxSpread (Bound)
Chernoff CF (Bound)
Hoeffding (Bound)
Chernoff IT (Bound)
1.3

1.4

1.5
1.6
1.7
Maximum Available Storage Budget (T)

1.8

1.9

2

Fig. 1.
Performance of the proposed approximate distributed storage
allocations and their corresponding upper bounds for a system with n = 100
nodes and pi ∼ U (0.5, 1).

Proof: Assume that λ∗ ∈

bounds. In our simulations we consider an ensemble of distributed storage systems with n = 100 nodes, in which the
corresponding access probabilities, pi ∼ U(0.5, 1), are drawn
uniformly at random from the interval (0.5, 1).
We consider the following allocations. 1) Maximal spreading: xi = T , ∀i. 2) Chernoff closed-form: xi =
n
(T /nElog r) log ri , ∀i. 3) Hoeffding -optimal: obtained by
solving H1. 4) Chernoff iterative: obtained by solving R2
and iteratively tuning the parameter t.
Fig.1 shows, in solid lines, the ensemble average probability
n
of failed recovery of each allocation, P [ i=1 xi Yi < 1], versus the maximum available budget T . In dashed lines, Fig.1
plots the corresponding bounds on Pe obtained from Corollary
1, Lemma 8 and the objective functions of H1, R1.

feasible suboptimal allocation for Q1. It is also suboptimal for
R2 in general, since solving R2 via the proposed algorithms
can only achieve a smaller probability of failed recovery. We
n
T
have Pe {Q1} ≤ Pe {R2} ≤ P
i=1 nElog r log ri Yi < 1 .
In the following lemma we give an upper bound on the probˆT
ability of failed recovery for xn and establish its asymptotic
optimality.
Elog r
ˆT
, the allocation xn :
Ep log r
T
xi = nElog r log ri , ∀i, is strictly reliable, and the probability
of failed recovery, Pe = P[Z < 1], is upper bounded by


2
Elog r




Ep log r − T
Pe ≤ exp −2n


Elog2 r


1
Lemma 8. If pi > 2 , ∀i and T >

R EFERENCES
[1] D. Leong, A. Dimakis, and T. Ho. Distributed storage allocations. CoRR,
abs/1011.5287, 2010.
[2] W. Hoeffding. Probability inequalities for sums of bounded random
variables. Journal of the American Stat. Association, 58(301):13–30,
March 1963.
[3] M. Mitzenmacher and E. Upfal. Probability and Computing: Randomized
Algorithms and Probabilistic Analysis. Cambridge University Press, New
York, NY, USA, 2005.
[4] V. Ntranos, G. Caire, and A. Dimakis. Allocations for heterogenous
distributed storage (long version).
http://www-scf.usc.edu/∼ntranos/docs/HDS-long.pdf, January 2012.
[5] D. S. Hochbaum and J. George Shanthikumar. Convex separable optimization is not much harder than linear optimization. J. ACM, 37:843–
862, October 1990.
[6] M. Grant and S. Boyd. CVX: Matlab software for disciplined convex
programming, version 1.21. http://cvxr.com/cvx, April 2011.
[7] M. Grant and S. Boyd. Graph implementations for nonsmooth convex
programs. In Recent Advances in Learning and Control, pages 95–110.
Springer-Verlag Limited, 2008.
[8] S. M. Stefanov. Convex separable minimization subject to bounded
variables. Comp. Optimization and Applications, 18, 2001.

and hence Pe → 0 as n → ∞.
Proof:
The proof follows directly from Lemma 1 and Equation (3).
ˆT
Notice that xn is reliable for values of T for which a
Elog
1
maximal spreading allocation xn is not, since p ≥ Ep logrr ,
T
¯
and hence its probability of failed recovery Pe goes to zero
exponentially fast for smaller values of T .
V. N UMERICAL E XPERIMENTS
In this section we evaluate the performance of the proposed
approximate distributed storage allocations in terms of their
probability of failed recovery and plot the corresponding

5

