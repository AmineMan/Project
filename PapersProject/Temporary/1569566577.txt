Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Fri May 18 18:20:06 2012
ModDate:        Tue Jun 19 12:56:31 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      404965 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569566577

On Reliability Functions for Single-Message
Unequal Error Protection
Da Wang

Venkat Chandar

Sae-Young Chung

Gregory W. Wornell

EECS Dept., MIT
Cambridge, MA, USA
Email: dawang@mit.edu

Lincoln Laboratory, MIT
Lexington, MA, USA
Email: vchandar@mit.edu

EE Dept., KAIST
Daejeon, Korea
Email: sychung@ee.kaist.ac.kr

EECS Dept., MIT
Cambridge, MA, USA
Email: gww@mit.edu

em without constraining ef and ed , and similarly, the maximal
attainable ef without constraining em and ed . These two values
correspond to the strongest protection for the special codeword
and that for regular codewords respectively, and are denoted
by Em and Ef .

Abstract—Single-message unequal error protection (UEP) is
a channel coding scheme that protects one special message
differently from other (regular) messages. This induces three
different types of errors in the system: 1) miss (where we decode
the special codeword as a regular codeword), 2) false alarm
(where we decode a regular codeword as the special codeword),
and 3) decoding error (where we decode a regular codeword
to another regular codeword). In this paper, we investigate the
fundamental limits of single-message UEP, in the context of
discrete memoryless channels (DMCs) without feedback. Similar
to Borade et al., we use error exponents as the performance
metric, and discuss maximizing the miss error exponent and
the false alarm error exponent, respectively. We provide a new
converse proof for the miss reliability function, i.e., the optimal
miss error exponent as a function of communication rate, and
extend the inner and outer bound results for the false alarm
reliability function in Borade et al. from rates close to capacity
to all rates up to capacity.

A. Related work
Some earlier information-theoretic analysis of singlemessage UEP is motivated by communication with delay
requirements, such as distributed control or streaming media
applications. In this setting, going beyond block coding, i.e.,
allowing non-blocking encoding schemes, improves performance. For example, one of the earliest work [1] uses a singlemessage UEP code in a variable-delay communication setting.
In [2], the authors consider delay in streaming communication
with noisy feedback, and use the special message in UEP as
an NACK signal. This achieves an error exponent that is much
higher than the traditional channel coding error exponent. In
a related work [3], error probability of the special message
is interpreted as “the best-case probability of (undetected)
block error across messages” and the miss exponent (called
hallucination exponent therein) “gives an upper bound on the
maximum probability of bit error in a non-blocking streaming
context where noiseless feedback is available and the destination is (occasionally) allowed to declare erasures.” There
the authors characterize the miss exponent Em for the binary
symmetric channel (BSC) at all rates up to capacity.
Another example application of UEP is frame synchronization. In [4], a slotted asynchronous channel model is proposed,
and the channel output induced by noise can be viewed as that
induced by a special codeword with repeated symbols. This
corresponds to a UEP problem with a design constraint on the
special message.
Finally, [5] provides a detailed introduction to the information theoretic perspectives of UEP and investigates the
fundamental limits of UEP on the discrete memoryless channel
(DMC). The authors characterize the miss exponent (red-alert
exponent therein) at capacity and provide lower and upper
bounds for the false alarm error exponent at capacity. In
addition, the miss error exponent for DMC at all rates up
to capacity is mentioned after [5, Lemma 1], and a proof is
given in [6, Theorem 34]. This result also follows from [7,
Lemma 1,Lemma 5]. Recently, [8] characterizes the miss error

I. I NTRODUCTION
Classical information theory assumes all messages are
equally important and protects them uniformly. However,
in certain communication scenarios it may be advantageous
to relax this uniformity assumption and to protect certain
information more than others, which leads to the framework of
unequal error protection (UEP). In this paper we investigate the
fundamental limits of single-message unequal error protection,
the problem of protecting a special codeword differently from
other regular codewords in the codebook.
This codeword classiﬁcation leads naturally to three different types of errors in the system: 1) miss (where we
decode the special codeword as a regular codeword), 2)
false alarm (where we decode a regular codeword as the
special codeword), and 3) decoding error (where we decode a
regular codeword to another regular codeword). We denote
the probabilities of these three events by Pm , Pf and Pd
respectively. In most applications, we are interested in the
regime that Pm , Pf and Pd can be made arbitrarily small by
increasing the codeword block length n. Given this reliability
condition, we can deﬁne the error exponents em , ef and ed for
these three probabilities, which tell us asymptotically how fast
these error probabilities decay as the codeword block length
increases. Speciﬁcally, we investigate the maximal attainable
This work was supported in part by NSF under Grant No. CCF-1017772,
by AFOSR under Grant No. FA9550-11-1-0183, and by MKE under Grant
No. NIPA-2012-(C1090-1211-0005).

1

where D (V W |P ) is the conditional information divergence
between V (·|·) and W (·|·) under P (·), and D (Q W |P )
is the conditional information divergence between Q(·) and
W (·|·) under P (·).
Our proofs make use of the method of types [9] and follow
the notations therein. Speciﬁcally, the type of a sequence
ˆ
xn with length n is denoted by Pxn , where the type is
ˆ
the empirical distribution of this sequence, i.e., Pxn (a) =
n
n
N (a|x )/n, ∀a ∈ X , where N (a|x ) is the number of
n
occurrences of symbol a in sequence xn . A type class TP
n
is the set of sequences that have type P ; a typical set T[P ] is
δ
the set of sequences that have type P ∈ [P ]δ ; and a typical
n
shell T[W ] (xn ) is the set of sequences y n such that

exponent for the AWGN channel with both peak and average
power constraints at all rates up to capacity.
In this paper, we further investigate the problem of singlemessage unequal error protection for the general DMC in the
absence of feedback. We provide a new converse proof for the
miss error exponent at all rates up to capacity. Furthermore,
we provide lower and upper bounds for the false alarm error
exponent at all rates up to capacity, and both bounds match
the results at capacity in [5]. All results are obtained via a few
generalizations of standard results in the method of types [9].
II. N OTATIONS AND P ROBLEM F ORMULATION
A. Notations
This paper uses lower case letters (e.g., x) to denote a
particular value of the corresponding random variable, which
is denoted in capital letters (e.g., X). A vector is denoted by its
length as a superscript (e.g., xn ). Calligraphic fonts (e.g., X )
represent a set and P (X ) denotes all probability distributions
on the alphabet X . Z+ and Z+ denote the set of non-negative
integers . and the set of positive integers respectively. We
deﬁne ≤ in the exponential sense, i.e., for a sequence an ,
.
.
.
1
an ≤ enF ⇔ F ≥ limn→∞ n log an , and we deﬁne ≥ and =
similarly.
We deﬁne the index set of a certain element a in a sequence
xn by
Ia (xn ) {i : xi = a} ,

δ

ˆ
ˆ
Pxn ,yn (a, b) − Pxn (a)W (b|a) ≤ δ.
A constant composition code is a code whose codewords all
have the same type, i.e., lie in the same type class.
Finally, we extend the notion of typical shell and deﬁne the
tightly typical shell with respect to a sequence xn as
˚n
T[W ]δ (xn )

∞

We follow the standard deﬁnition of the discrete memoryless
channel (DMC) W : X → Y, which has input alphabet X =
{1, 2, . . . , |X |} and output alphabet Y = {1, 2, . . . , |Y|}. The
conditional distribution of output letter Y when the channel
input letter X equals x ∈ X is denoted by WY |X (·|x):
WY |X (y|x) = P [Y = y | X = x]

W ( y | x) P (x),
W ( y | x) P (x),

P W (y)
x∈X

H (W |P )

P (x)H (W ( · | x)) ,
x∈X

I (P, W )

P (x)W (y|x) log
x∈X ,y∈Y

D (P Q)

P (x) log
x∈X

D (V

W |P )

W (y|x)
,
P W (y)

P (x)
,
Q(x)

EP [D (V ( · | P ) W ( · | P ))]
P (x)D (V ( · | x) W ( · | x)) ,
x∈X

D (Q W |P )

∀ x ∈ X , ∀ y ∈ Y.

When the input and output alphabets are clear from context,
W is used instead of WY |X . Also, for simplicity, we denote
Wx W ( · | x).
In this paper, we only consider the case that the support of
W ( · | x) is Y for all x ∈ X , i.e., for any x ∈ X and any
y ∈ Y, W ( y | x) > 0, because the analysis for other cases is
either simple or can be reduced to this case.
For a DMC, a length n block code with input alphabet
X , output alphabet Y and some ﬁnite message set Mfn =
{0, 1, 2, . . . , |Mfn |} is composed of a pair of mappings,
encoder mapping fn : Mfn → X n and decoder mapping
gn : Y n → Mfn . Given a message m, the encoder maps it to
a sequence xn (m) ∈ X n and transmits this sequence through
the channel, where we call xn (m) the codeword for message
m and the entire set of codewords {xn (m), m ∈ Mfn } a
codebook. The receiver receives a sequence y n ∈ Y n , where
n
W n ( y n | xn (m))
i=1 W ( yi | xi (m)). We denote (fn , gn )
by C (n) .
In the context of unequal error protection, we use message
0 to denote the special message and refer to the collection of regular codewords as the regular codebook. We use
An ∪m=0 g −1 (m) to denote the decoding region for regular
−1
codewords and use Bn
gn (m = 0) to denote decoding
region for the special codeword. If y n ∈ An , we consider

< δ},

where P (·) ∞ maxx∈X |P (x)| is the inﬁnity norm.
For distributions P (·) ∈ P (X ), Q(·) ∈ P (Y) and conditional distributions W ( · | ·) : X → Y, V ( · | ·) : X → Y,
deﬁne:
[P × W ] (x, y)

∀a ∈ X ,
(1)

B. Problem formulation

{P ∈ P (X ) : Support(P ) ⊂ Support(P )
and P − P

δ

where Ia = Ia (xn ).

and we may denote this simply by Ia when the sequence is
clear from context. The subsequence of xn formed from index
set Ia is denoted by xIa .
We deﬁne the shell of a probability distribution as
[P ]δ

na
y n ∈ Y n : yIa ∈ T[W ] (xIa ) ,

EP [D (Q W ( · | P ))]
P (x)D (Q W ( · | x)) .
x∈X

2

2

the channel input to be a regular codeword xn (m), m ∈
{1, 2, · · · , |Mfn |}, otherwise we consider the channel input
to be the special message m = 0.
ˆ ˆ
ˆ
A code C (n) = (fn , gn ) is called a subcode of C (n) =
ˆ
(fn , gn ) if Mfn ⊂ Mfn , fn (0) = fn (0) and for any m ∈
ˆ
Mfn and m = 0, there is some m ∈ Mfn and m = 0 such
ˆ
ˆ
that fn (m) = fn (m ).
The performance of a codebook over a channel W can
be characterized by three types of error: 1) miss, where we
decode a special codeword as a regular codeword; 2) false
alarm, where we decode a regular codeword as a special
codeword; 3) decoding error, where we decode a regular
codeword incorrectly into another regular codeword. Formally,
we deﬁne
Pm C (n)

The most general problem—characterization of the achievable error exponent region E(R)—is open and this paper
focuses on the false alarm and miss errors by putting no
constraints on ed . In particular, this paper investigates the
reliability functions for false alarm and miss errors:
Deﬁnition 3 (Reliability functions). For a DMC (X , Y, W ),
given a rate R, we deﬁne the miss reliability function and the
false alarm reliability function as
Em (R)
Ef (R)

max Pf (m)

(n)

m=0

m=0

m=0

Theorem 1 (Miss reliability function, Theorem 34 in [6]). A
DMC (X , Y, W ) has miss reliability function

−1
W n gn (m) fn (m) .
ˆ

max
m=m,m=0
ˆ
ˆ

Em (R)

In addition, we deﬁne the rate of a code C (n) as R(C (n) )
log |Mfn | /n. For a sequence of codebooks Q = {C (n) , n ∈
Z+ }, we deﬁne its rate as RQ = lim inf n→∞ R(C (n) ). When
the codebook sequence is clear from context, we denote
(n)
(n)
(n)
Pd C (n) , Pm C (n) and Pf C (n) by Pd , Pm and Pf ,
(n)
and use Rn and R instead of R(C ) and RQ .
In this paper, unless otherwise mentioned, all rates
are between 0 and the channel capacity C(W )
maxPX ∈P(X ) I (PX , W ).

=

(n)

where PY |S=b

,

PX|S=b W .

Specializing Theorem 1 to R = C, we have the miss error
exponent at capacity.
∗
Corollary 2 (Miss reliability function at capacity). Let PY be
the (unique) capacity-achieving output distribution, then
∗
Em (R = C) = arg max D (PY Wx ) .

= 0,

(3)

x∈X

The converse argument to Theorem 1 is implied by a
converse proof for UEP with feedback in [6]. Below we
present the sketch of an alternative converse proof, based on
a few generalizations of the method of types.
In the method of types, it is known that for every reliable
channel code, there exists a constant composition subcode
with essentially the same rate [9, Collrollary 6.3 and Exercise
6.19]. Lemma 3 below shows that a similar argument holds
when we replace constant composition code by a code whose
subsequences are constant composition.

(n)
lim sup Pm = 0,
n→∞

(n)

PS (b)D PY |S=b Wb
b∈X

(2)

n→∞

lim sup Pf

max
PX,S :EPS [I (PX|S ,W )]=R

Deﬁnition 1 (Reliable codebook sequence). A codebook sequence Q = {C (n) , n ∈ Z+ } is called reliable if
lim sup Pd

ef .

This section presents a characterization of the miss reliability function in Theorem 1. While this result is not new, we
present it for completeness, and provide a new, conceptually
simpler, converse proof based on a few generalizations of the
method of types.

max Pd (m)

Pd C

sup

III. M ISS RELIABILITY FUNCTION

max W n ( Bn | xn (m)) ,

m=0

em ,

(em ≥0,ef ,ed ≥0)∈E(R)

W n ( An | xn (0)) ,

Pf C (n)

sup
(em ,ef ≥0,ed ≥0)∈E(R)

= 0.

n→∞

To investigate how the above error probabilities decay with
the codeword block length n, we deﬁne their error exponents.
Deﬁnition 2 (Miss, false alarm, and decoding error exponents).
Given a reliable codebook sequence Q = {C (n) , n ∈ Z+ } with
rate R and a DMC (X , Y, W ), deﬁne its miss error exponent
as
1
(n)
em (Q) lim inf − log Pm
n→∞
n

Lemma 3. For any λ > 0, if a code (fn , gn ) satisﬁes
|Mfn | ≥ en(R−λ)

Similarly, we deﬁne its false alarm error exponent ef and
(n)
(n)
decoding error exponent ed in terms of Pf and Pd .
A triplet of numbers (em (Q), ef (Q), ed (Q)) is called
achievable if they can be achieved simultaneously, and the
set of achievable triples is denoted by E(Q, R). In addition,
we deﬁne E(R) ∪Q:RQ ≥R E(Q, R).

(4)

and Pd < ε for a given channel W , then for any given sn
with type PS and Ib
Ib (sn ), there exists a collection of
ˆ ˆ
types {Pb , b ∈ X } and a subcode (fn , gn ) with all regular
codewords in the set
ˆ
C
3

3

n
xn : xIb ∈ TPbb ,

IV. FALSE ALARM RELIABILITY FUNCTION
In this section we investigate the false alarm reliability
function of a DMC (X , Y, W ). We start with the case of a
special codeword consisting of a repeated symbol, then extend
the results to an unconstrained special codeword. Unlike the
case of miss detection, the exact characterization of the false
alarm reliability function is open, but we are able to provide
inner and outer bounds.

where such that
Mfn ≥ exp {n [R − 2λ]}
ˆ

(5)

and
PS (b)I (Pb , W ) ≥ R − 3λ.

(6)

b∈X

when n sufﬁciently large.
The proof of Lemma 3 is omitted due to space constraint.
Lemma 3 enables us to focus the converse argument on the
ˆ
(more structured) subcode C that satisﬁes
n
xIb ∈ TPbb .

Theorem 5 (Bounds for the false alarm reliability function).
The false alarm reliability function of an DMC (X , Y, W )
satisﬁes
Ef (R) ≤ Ef (R) ≤ Ef (R),

(7)

where

Deﬁne a collection of disjoint sets {Fm }, where Fm
˚n
∩ T[W ] (xn (m)) (see (1)). It can be shown that for
δ
any ε > 0, when n sufﬁciently large,
−1
gn (m)

W n ( Fm | xn (m)) ≥ 1 − 2ε.

Ef (R)

·

min

V :PX|S=b V =Wb

PX|S=b (a)D (Va Wa ) ,
a∈X

(10)

with type PS and Ib

Lemma 4. Given a sequence s
Ib (sn ), if a set B ⊂ Y n satisﬁes

PS (b)
b∈X

(8)

Now we generalize [9, Lemma 2.14] to the subcode in
Lemma 3 and obtain the following lemma:
n

max
PX,S :EPS [I (PX|S ,W )]≥R

Ef (R)

max
PX,S :EPS [I (PX|S ,W )]≥R

PX,S (a, b)D (Wb Wa ) .

W n ( B| xn ) ≥ η,

(11)

a,b∈X

then for any τ > 0

Specializing Theorem 5 to R = C, we obtain bounds for
the false alarm error exponent at capacity.

ˆ
nb H W |PxIb − τ

|B| ≥ exp

.

Corollary 6 (Bounds for the false alarm reliability function at
capacity). Let the set of capacity-achieving input distributions
be Π = {PX : I (PX , W ) = C}, then

b∈X

The proof of Lemma 4 is omitted due to space constraint.
Noting (7) and (8), Lemma 4 indicates
.
|Fm | ≥ exp

nb H (W |Pb )

Ef (R = C) = max max
∗

.

PX ∈Π b∈X

n
Note that for any y n ∈ Fm ⊆ T[W ] (xn (m)),

∗
W |PX ) , (12)

(13)

a∈X

Remark 4. Corollary 6 agrees with [5, Theorem 10], which
speciﬁes the false alarm error exponent at capacity. Therefore,
Theorem 5 generalizes [5, Theorem 10] from at capacity to
all rates up to capacity.

δ

n
yIb ∈ T[Pb W ]δ ,

and
n
Wb b (yIb )

W nb ( yIb | sIb ) =

D (V

∗
PX (a)D (Wb Wa ) .

Ef (R = C) = max max
∗

b∈X

W n ( y n | sn ) =

min

∗
PX ∈Π b∈X V :PX V =Wb

.

A. Special codeword with a repeated symbol
This section assumes the special codeword to be n and
investigates the corresponding performance, which is summarized in Theorem 7.

ˆ
Pm C = W n ( An | sn ) ≥ W n ( ∪m Fm | sn )
.
˜
≥ e−n[ b PS (b)Em (Pb ,R,Wb )] ,

Theorem 7 (False alarm reliability function for special codeword with repeated symbol ). Given a special codeword n
where ∈ X , the false alarm reliability function of an DMC
(X , Y, W ) satisﬁes

.
≥

b∈X

b∈X

e{−nb [D(Pb W

Wb )+H(Pb W )]}

b∈X

Therefore,

Efrep (R) ≤ Efrep (R) ≤ Efrep (R),

where
˜
Em (P, R, Wx )

D (P W Wx ) + I (P, W ) − R.

where

(9)

V

Note that using a subcode reduces Pm , hence any lower
ˆ
bound to Pm C is a lower bound to Pm (C). Finally, we

Efrep (R)

let PX|S=b
Pb and maximize over PX,S to complete the
converse argument.

Efrep (R)

4

4

{V : PX V = W } ,
max

min D (V

min

D (W

PX :I(PX ,W )≥R V ∈V
PX :I(PX ,W )≥R

W |PX ) ,

W |PX ) .

We can show that for each y n ∈ G(xn , sn ), W n ( y n | xn ) are
not too small:

The detailed proofs are omitted due to space limits and a
sketch of the proof is provided in [4], where this corresponds
to ﬁnding the miss error exponent in asynchronous communication.

W n ( y n | xn ) =
a,b∈X

B. Unconstrained special codeword
For the case of unconstrained special codeword, the inner
and outer bounds of the false alarm reliability function are
given in Theorem 5. Omitting the detailed proof due to space
limits, here we provide proof sketches of the outer bound
argument and the achievability scheme for the inner bound
derivation, which is constructed via the achievability scheme
for the repeated-symbol special message.
1) Achievability: To achieve (10), we choose a special
codeword sn with type PS and let Ib = Ib (sn ), and accordingly a set of distributions {Pb ∈ Pnb (X ) , b ∈ X } such that

=
.
≥

n

n

a,b
Wb a,b (T[Wb ] ) ≥ 1 − ε/2,
δ

when n sufﬁciently large. Then applying [9, Lemma 2.14],
.
|B ∩ G(xn , sn )| ≥ enH(W |PS ) .
Therefore,
ˆ
Pf C = W n ( Bn | xn ) ≥ |G(xn , sn ) ∩ Bn | · W n ( y n | xn )





.
≥ exp −n 
PX,S (a, b)D (Wb Wa ) .


a,b∈X

ACKNOWLEDGEMENT

≤

b∈X

The authors would like to thank the anonymous reviewers
for helpful comments.
R EFERENCES
[1] B. D. Kudryashov, “On message transmission over a discrete channel
with noiseless feedback,” Problemy Peredachi Informatsii, vol. 15, no. 1,
pp. 3–13, 1979.
[2] S. Draper and A. Sahai, “Beating Burnashev in delay with noisy feedback,” in Allerton Conference in Communication, Control and Computing,
2006.
[3] A. Sahai and S. C. Draper, “The “hallucination” bound for the BSC,” in
Proc. IEEE Int. Symp. Inform. Th. (ISIT), Toronto, ON, Canada, 2008,
pp. 717–721.
[4] D. Wang, V. Chandar, S. Chung, and G. W. Wornell, “Error exponents
for asynchronous communication,” in Proc. IEEE Int. Symp. Inform. Th.
(ISIT), St. Petersburg, Russia, 2011, pp. 1071–1075.
[5] S. Borade, B. Nakibo˘ lu, and L. Zheng, “Unequal error protection: An
g
Information-Theoretic perspective,” IEEE Trans. Inf. Theory, vol. 55,
no. 12, pp. 5511–5539, 2009.
[6] S. P. Borade, “When all information is not created equal,” Thesis,
Massachusetts Institute of Technology, 2008.
[7] S. Gorantla, B. Nakibo˘ lu, T. Coleman, and L. Zheng, “Bit-wise unequal
g
error protection for variable length blockcodes with feedback,” in Proc.
IEEE Int. Symp. Inform. Th. (ISIT), Jun. 2010, pp. 241–245.
[8] B. Nazer, Y. Shkel, and S. C. Draper, “The AWGN red alert problem,”
1102.4411, Feb. 2011. [Online]. Available: http://arxiv.org/abs/1102.4411
[9] I. Csisz´ r and J. K¨ rner, Information Theory: Coding Theorems for
a
o
Discrete Memoryless Systems, 2nd ed. Cambridge University Press,
Aug. 2011.

Pm (Cb ) ,
b∈X

Pf (Cb )
b∈X

PS (b) min D (V
V ∈Vb

W |Pb )

.

Therefore, we can choose PS and {Pb } to maximize this
expression. Finally, we construct a joint distribution PX,S
where PX|S=b Pb and obtain (10).
2) Outer bound argument: Following Lemma 3 in Section III, for any given sn with type PS and Ib Ib (sn ), we
ˆ
only need to show the Ef outer bound for a subcode C that has
n
essentially the same rate and xIb ∈ TPbb for b ∈ X . Given an
arbitrary codeword xn and the special codeword sn , we deﬁne
Ja,b {i : xi = a, si = b} , and consider the following set
G(xn , sn )

W na,b yJa,b sJa,b

a,b∈X

with the corresponding error probabilities

b∈X

W n ( y n | sn )

=

Ef = gb (yIb ) = 0, ∀ b ∈ X | i1 i2 · · · i|X | = 0 ,

.
≤ exp −n

,

y n ∈G(xn ,sn ) a,b∈X

Em = gb (yIb ) = 0, ∃ b ∈ X | i1 = i2 = i|X | = 0 ,

Pf C (n) =

Wa )+H(W |PS )]}

=

with ˆb = gb (yIb ) ∀ b ∈ X .
i

Pd (Cb ) , Pm C

PX,S (a,b)D(Wb

y n ∈G(xn ,sn )

Ee = {any gb reports an error } ,

≤

a,b∈X

W n ( G(xn , sn )| sn ) =

This leads to the following error events

Pd C

exp {−na,b [D (Wb Wa ) + H (Wb )]}

because W n ( B| sn ) ≥ 1 − ε and

xn with xIb = fb (ib ) when ib > 0 ∀ b ∈ X
,
sn
when ib = 0 ∀ b ∈ X

(n)

a,b∈X

W n ( B ∩ G(xn , sn )| sn ) ≥ ε/2

i1 , i2 , . . . , i|X |

(n)

Wa a,b (yJa,b )

where PX,S is the joint type of (xn , sn ). Furthermore, we
show that |B ∩ G(xn , sn )| is not too small either. First,

Then for each b ∈ X , we follow Theorem 7 to construct
a codebook Cb = (fb , gb ) that is constant composition with
type Pb and rate I (Pb , W ). Using these codebooks as building
blocks, we design the encoding and decoding schemes below.
Denote each message m by a |X |-tuple (i1 , i2 , . . . , i|X | ),
where ib ∈ {0, 1, 2, . . . , |Cb |} , b ∈ X . Then we deﬁne the
following encoding and decoding functions for C (n) = (f, g):

g (y n ) = ˆ1 , ˆ2 , . . . , ˆ|X |
i i
i

n

yJa,b ana,b =

a,b∈X

.
= e{−n[

b∈X

=

W

na,b

a,b∈X

PS (b)I (Pb , W ) ≥ R.

f

W na,b yJa,b xJa,b

n
y n : yJa,b ∈ T[Wb ]δ .

5

5

