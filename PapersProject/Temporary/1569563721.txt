Creator:        TeX
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Thu May 17 17:30:24 2012
ModDate:        Tue Jun 19 12:56:02 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      461369 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569563721

Systematic DFT Frames: Principle and
Eigenvalues Structure
Mojtaba Vaezi and Fabrice Labeau
Department of Electrical and Computer Engineering
McGill University
Montreal, Quebec H3A 2A7, Canada
Email: mojtaba.vaezi@mail.mcgill.ca, fabrice.labeau@mcgill.ca
reconstruction error [2], [1], we explore systematic tight DFT
frames. Although it is straightforward to come up with systematic DFT frames, we show that systematic “tight” DFT
frames exist only for speciﬁc DFT codes. When such a frame
does not exist, we will be looking for systematic DFT frames
with the “best” performance, from minimum mean-squared
reconstruction error standpoint. We also demonstrate which
systematic frames are the “worst” in this sense.
Central to this paper is the properties of the eigenvalues
of V H V , in which V is a square or non-square submatrix of
a DFT frame.1 Speciﬁcally, we present some bounds on the
extreme eigenvalues of such matrices. These bounds are used
to determine the conditions required for a systematic frame so
as to be tight. Besides, eigenvalues are crucial in establishing
the best and worst systematic frames.
The paper is organized as follows. In Section II, we review
two set of inequalities on the eigenvalues of Hermitian matrices which are frequently used in this paper. In Section III, we
introduce systematic DFT frames and set the ground to study
their extreme eigenvalues in Section IV. Section V is devoted
to the evaluation of reconstruction error and classiﬁcation of
systematic frames based on that. We conclude in Section VI.

Abstract—Motivated by a host of recent applications requiring
some amount of redundancy, frames are becoming a standard tool
in the signal processing toolbox. In this paper, we study a speciﬁc
class of frames, known as discrete Fourier transform (DFT) codes,
and introduce the notion of systematic frames for this class. This is
encouraged by application of systematic DFT codes in distributed
source coding using DFT codes, a new application for frames.
Studying their extreme eigenvalues, we show that, unlike DFT
frames, systematic DFT frames are not necessarily tight. Then, we
come up with conditions for which these frames can be tight. In
either case, the best and worst systematic frames are established
from reconstruction error point of view. Eigenvalues of DFT
frames, and their subframes, play a pivotal role in this work.

I. I NTRODUCTION
A basis is a set of vectors that is used to “uniquely”
represent any vector as a linear combination of basis elements.
Frames, as opposed to bases, are “redundant” set of vectors
which are used for signal representation. Therefore, frames are
more general than bases as they are not necessarily linearly
independent, but are complete. What would be the beneﬁt of
representing a signal with more than the minimum number of
vectors required for completeness? Frames offer ﬂexibility in
design and have variety of applications. They show resilience
to additive noise (including quantization noise), robustness to
erasure (loss), and numerical stability of reconstruction [1],
[2]. With increasing applications, frames are becoming more
prevalent in signal processing.
Frames are generally motivated by applications requiring
some level of redundancy. Among them is distributed source
coding (DSC) that uses DFT codes, recently introduced in [3].
This provides a new application for frame expansion, viewing
the generator matrix of a DFT code as a frame operator [4].
In this paper, we consider this speciﬁc type of tight frames
which are known as DFT codes and used for erasure and error
correction in the real ﬁeld [2]–[5].
Motivated by its application in parity-based DSC that uses
DFT codes [3], we introduce the notion of systematic frames.
A systematic frame is deﬁned to be a frame that includes the
identity matrix as a subframe. Since tight frames minimize

II. D EFINITIONS AND PRELIMINARIES
An n × n Vandermonde matrix with unit complex entries is
deﬁned by


1
1
···
1

ejθ1
ejθ2
···
ejθn
1 


√ 
W
 (1)
.
.
.
..
.
.
.

n
.
.
.
.
j(n−1)θ1
j(n−1)θ2
j(n−1)θn
e
e
··· e
in which θp ∈ [0, 2π) and θp = θq for p = q, 1 ≤ p, q ≤ n.
If θp = 2π (p − 1), W becomes the well-known IDFT matrix
n
[6]. For this Vandermonde matrix we can write [7], [8]
1
det(W W H ) = | det(W )|2 = n
|eiθp − eiθq |2 (2)
n
1≤p<q≤n

Let A be a Hermitian k × k matrix with real eigenvalues
{λ1 (A), . . . , λk (A)} which are collectively called the spectrum of A, and assume λ1 (A) ≥ λ2 (A) ≥ · · · ≥ λk (A).

This work was supported by Hydro-Qu´ bec, the Natural Sciences and
e
Engineering Research Council of Canada and McGill University in the
framework of the NSERC/Hydro-Qu´ bec/McGill Industrial Research Chair
e
in Interactive Information Infrastructure for the Power Grid.

1 Note that eigenvalues of V H V and V V H are equal for a square V ; also,
V H V and V V H have the same nonzero eigenvalues for a non-square V .

1

Schur-Horn inequalities show to what extent the eigenvalues
of a Hermitian matrix constraint its diagonal entries.

Then, it is easy to see that,
n
GH G = Ik ,
(11)
k
n H
GGH = Wn ΣΣH Wn .
(12)
k
One can view the generator matrix G in (8) as an analysis
frame operator. The following lemma presents some properties
of GGH which are central for our results in the next section.

Proposition 1. Schur-Horn inequalities [9]
Let A be a Hermitian k × k matrix with real eigenvalues
λ1 (A) ≥ λ2 (A) ≥ · · · ≥ λk (A). Then, for any 1 ≤ i1 < i2 <
· · · < il ≤ k,
λk−l+1 (A) + · · · + λk (A) ≤ ai1 i1 + · · · + ail il
≤ λ1 (A) + · · · + λl (A),

(3)

Lemma 1. Let Gp×k be a matrix consisting of p arbitrary
rows of G deﬁned by (8). Then, the following statements hold:
i. GGH is a Toeplitz and circulant matrix
ii. Gp×k GH , 1 < p < n is a Toeplitz matrix
p×k
iii. All principal diagonal entries of Gp×k GH , 1 ≤ p ≤ n
p×k
are equal to 1.

where a11 , . . . , akk are the diagonal entries of A. Particularly,
for l = 1 and l = k we obtain
λk (A) ≤ a11 ≤ λ1 (A),
k

λi (A) =
i=1

(4)

k

aii .

(5)

Proof: Let ar,s be the (r, s) entry of the matrix GGH
then it can readily be shown that

i=1

Another basic question in linear algebra asks the degree to
which the eigenvalues of two Hermitian matrices constrain the
eigenvalues of their sum. Weyl’s theorem gives an answer to
this question in the following set of inequalities.

ar,s =

for

j ≤ i,

(6)

λi (A + B) ≥ λj (A) + λk+i−j (B)

for

j ≥ i.

(7)

III. DFT F RAMES
A. BCH-DFT Codes
DFT codes [5], are linear block codes over the complex
ﬁeld whose parity-check matrix H is deﬁned based on the
DFT matrix. A Bose-Chaudhuri-Hocquenghem (BCH) DFT
code is a DFT code that insert d − 1 cyclically adjacent zeros
in the spectrum of any codevector where d is the designed
distance of that code [10]. Real BCH-DFT codes, a subset
of complex BCH-DFT codes, beneﬁt from a generator matrix
with real entries. The generator matrix of an (n, k) real2 BCHDFT code is typically deﬁned by
G=

n H
W ΣWk ,
k n

ejm(θr −θs ) +
m=0

1
k

n−1

ejm(θr −θs ) ,

(13)

m=n−β

B. Systematic DFT Frames
In the context of channel coding, there is a special interest
in systematic codes so as to simplify the decoding algorithm.
This is more pronounced in “parity-based” DSC as it requires
distinction between parity and data. The parity-based approach
becomes even more worthwhile in the DSC that uses DFT
codes because it is more “efﬁcient” than the syndrome-based
approach [3]. This is due to the fact that syndrome, even in
a real DFT code, is a complex vector whereas parity is real.
This encourages a systematic generator matrix for DFT codes.
A systematic generator matrix for a real BCH-DFT code
can be obtained by [3]

(8)

in which Wl represents the DFT matrix of size l, and Σ is


Iα 0
Σn×k =  0 0  ,
(9)
0 Iβ
where α = n/2 − (n − k)/2 , β = k − α, and the sizes of
zero blocks are such that Σ is an n × k matrix [11]. One can
check that ΣH Σ = Ik , and ΣΣH is an n × n matrix given by


Iα 0 0
ΣΣH =  0 0 0  .
(10)
0 0 Iβ
2 In

α−1

in which θx = 2π (x − 1). From this equation, it is clear
n
that ar,s = ar+i,s+i ; that is, the elements of each diagonal are
equal, which means that GGH is a Toeplitz matrix. In addition,
we can check that ar,n = ar+1,1 , i.e., the last entry in each
row is equal to the ﬁrst entry of the next row. This proves
that the Toeplitz matrix GGH is circulant as well [12]. Also,
a quick look at (13) reveals that the elements of the principal
diagonal (r = s) are equal to 1. Similarly, one can see that
for any 1 < p < n, the square matrix Gp×k GH is also a
p×k
Toeplitz matrix; it is not necessarily circulant, however.
Removing Wk from (8) we end up with a complex G,
representing a complex BCH-DFT code. In such a code, α
and β can be any nonnegative integers such that α + β = k.
Remark 1. Lemma 1 also holds for complex BCH-DFT codes.
As a result, all properties that we prove in the remainder of
this paper are valid for “any” BCH-DFT code, although they
are formally proved for “real” BCH-DFT codes, which we
simply refer to as “DFT codes” or “DFT frames” hereafter.

Proposition 2. Weyl inequalities [9]
Let A and B be two Hermitian k × k matrices with spectrums
{λ1 (A), . . . , λk (A)} and {λ1 (B), . . . , λk (B)}, respectively.
Then, for i, j ≤ k, we have
λi (A + B) ≤ λj (A) + λi−j+1 (B)

1
k

Gsys = GG−1 ,
k

(14)

in which Gk is a submatrix (subframe) of G including k
arbitrary rows of G. Note that Gk is invertible since it can

a real BCH-DFT code, n and k cannot be even simultaneously [5].

2

k

H
H
be represented as Gk = n Wk×n ΣWk = Vk Wk , in which
k
n
H
H
Vk
k Wk×n Σ is a Vandermonde matrix. Remember that
Wk is also invertible as it is a DFT matrix. This proves
that systematic DFT frames exist for any DFT frame. It
also shows that there are many (but, a ﬁnite number of)
systematic frames for each frame, because the rows of Gk can
be arbitrarily chosen from those of G. These systematic frames
differ in the “position” of systematic samples (input data) in
resulting codewords. This implies that the parity samples are
not restricted to form a consecutive block in codewords. Such
a degree of freedom is useful in the sense that one can ﬁnd
the most suitable systematic frames for speciﬁc applications
(e.g., one with the smallest reconstruction error.)

where, the constraint
i=1 λi = k is achieved in light of
Lemma 1 and (5).
By using the Lagrangian method, we can show that the
optimal eigenvalues are λi = 1; this implies a tight frame
[2]. In the sequel, we analyze the eigenvalues of Gp×k GH ,
p×k
p ≤ n, that helps us characterize tight systematic frames, so
as to minimize the variance of transmitted codevectors.
Theorem 1. Let Gp×k , 1 ≤ p ≤ n be any p × k submatrix
of G. Then, the smallest eigenvalue of Gp×k GH is no more
p×k
than one, and the largest eigenvalue of Gp×k GH is at least
p×k
one.
Proof: From Lemma 1, we know that all principal diagonal entries of Gp×k GH are unity. As a result, using the
p×k
Schur-Horn inequality in (4), we obtain λmin (Gp×k GH ) ≤
p×k
1 ≤ λmax (Gp×k GH ). This proves the claim. Also, note that
p×k
for any Gp×k , λmax (Gp×k GH ) = λmax (GH Gp×k ).
p×k
p×k
We use the above results to ﬁnd better bounds for the extreme
eigenvalues of Gk GH in the following theorem.
k

IV. M AIN R ESULTS ON THE E XTREME E IGENVALUES
From rate-distortion theory, it is well known that the rate
required to transmit a source, with a given distortion, increases as the variance of the source becomes larger [13].
Particularly, for Gaussian sources this relation is logarithmic
with variance, under the mean-squared error (MSE) distortion
measure. In DSC that uses real-number codes [3], since coding
is performed before quantization, the variance of transmitted
sequence depends on the behavior of the encoding matrix. In
view of rate-distortion theory, it makes a lot of sense to keep
this variance as small as possible. Not surprisingly, we will
show that using a tight frame (tight Gsys ) for encoding is
optimal.
Let x be the message vector and y = Gsys x represent
the codevector generated using the systematic frame, then the
variance of y is given as
1
1
E{y H y} = E{xH GH Gsys x}
sys
n
n
1 2
= σx tr (GH Gsys ),
sys
n

Theorem 2. For any Gk , a square submatrix of G in (8) in
which n = M k, the smallest (largest) eigenvalue of Gk GH is
k
strictly upper (lower) bounded by 1.
Proof: We ﬁrst investigate a bound for the smallest
eigenvalue. Let n = M k + l, 0 < l < k, then G can be
(M −1)H
| GM H ]H . In
partitioned as G = [GH | G1H | · · · | Gk
k×l
k
k
M −1
1
M
general, Gk , Gk , . . . , Gk
and Gk×l include arbitrary rows
of G, hence they have different spectrums, i.e., different sets of
eigenvalues. We consider the case with largest λk for GH Gk ;
k
this occurs when Gk consist of the rows of G such that the
distance between each two successive rows is as large as
possible and at least M . The latter guarantees existence of
G1 , . . . , GM −1 such that GmH Gm , for any 1 ≤ m ≤ M − 1,
k
k
k
k
has the same spectrum as GH Gk . To ﬁnd the row indices
k
corresponding to Gm , we can simply add m to each row
k
index of Gk . Then, to show these matrices have the same
spectrum, we use Lemma 3 [8] which states that any Hermitian
ci
n × n matrices E and F with Fi,j = cj Ei,j have the same
eigenvalues. Now, given a Gk , one can verify that (G1 )i,j =
k
aj (Gk )i,j and thus (G1 )H = a∗ (Gk )H = 1/ai (Gk )H .
i
i,j
i,j
k i,j
Therefore, G1H G1 and GH Gk have the same spectrum. The
k
k
k
same argument is valid for G2 , . . . , GM −1 . Next, we see that
k
k
(M −1)H M −1
GH G = A + B in which A = GH Gk + · · · + Gk
Gk
k
MH M
and B = Gk×l Gk×l . Then, in consideration of the above
discussion, λi (A) = M λi (GH Gk ) for any 1 ≤ i ≤ k. Hence,
k
from (7), for i = 1, j = k, we will have

2
σy =

and

tr GH Gsys = tr G−1H GH GG−1
sys
k
k
n
H −1
= tr (Gk Gk )
k
n
H
= tr (Vk Vk )−1
k
k
n
1
=
,
k i=1 λi

(15)

(16)

in which λ1 ≥ λ2 ≥ · · · ≥ λk > 0 are the eigenvalues of
H
Gk GH (or Vk Vk equivalently).
k
This shows that the variance of codevectors, generated by a
systematic frame, depends on the submatrix Gk which is used
to create Gsys . Gk , in turn, is fully known once the position of
systematic (data) samples is ﬁxed in the codevector. In other
words, the “position” of systematic samples, determines the
variance of codevectors generated by a systematic DFT frame.
From (15), (16), to minimize the effective range of transmitted
signal, we need to do the following optimization problem.
k

minimize
λi

i=1

1
λi

λk (A) + λ1 (B) ≤ λ1 (A + B)
n
⇔ M λk (GH Gk ) ≤ − λ1 (B)
k
k
n
n
−1
−1
H
⇔ λk (Gk Gk ) ≤ k
= k n < 1,
M
k

where the last line follows using λ1 (B) ≥ 1 from Theorem 1.
This completes the proof for the worst case, i.e., the largest
possible λk (GH Gk ), and implies that (18) holds for any other
k

k

λi = k, λi > 0,

s.t.

(18)

(17)

i=1

3

Gk . Hence, the ﬁst part of the proof is completed; that is, the
smallest eigenvalue of GH Gk where Gk is an arbitrary square
k
submatrix of G in (8) with n = M k is strictly less than one.
k
k
Finally, knowing that
λ (GH Gk ) =
a = k
k
i=1 i
i=1 ii
H
and using (18), it is obvious that λ1 (Gk Gk ) > 1. This proves
the bound for the largest eigenvalue.

DFT frames of same size, provided that the effective range
codevectors generated by different Gsys is equal. This implies
2
a same σq for a given number of quantization levels. However,
2
for a ﬁxed number of quantization levels, σq depends on the
variance of transmitted codevectors, which, in turn, varies for
different systematic frames, as shown in (15).
As we discussed in Section IV, the optimal Gsys is achieved
from the optimization problem (17). Similarly, to ﬁnd the
worst Gsys , we can maximize (17) instead of minimizing it.
The optimal eigenvalues are known to be λi = 1. But, how
can we ﬁnd the corresponding Gsys , or Gk equivalently?
We approach this problem by studying another optimization
problem. By using the Lagrangian method, one can check the
optimal arguments of the optimization problem in (17) are
equal to those of

Theorem 2 implies that for n = M k we cannot have “tight”
systematic frames. This is due to the fact that for a tight frame
with frame operator F , λmin (F H F ) = λmax (F H F ); i.e., the
eigenvalues of F H F are equal [2].
Corollary 1. For n = M k, where M is a positive integer,
“tight” systematic DFT frames do not exist.
Note that systematic DFT frames are not necessarily tight
for n = M k. Evaluating the performance of systematic frames
in the next section, we prove that tight systematic DFT frames
exist for n = M k and show how to construct such frames.

k

k

λi

maximize
λi

V. P ERFORMANCE A NALYSIS AND C LASSIFICATION OF
S YSTEMATIC F RAMES
A. Performance Evaluation
In this section, we analyze the performance of quantized
systematic DFT codes using the quantization model proposed
in [2], which assumes that noise components are uncorrelated
2
and each noise component qi has mean 0 and variance σq . We
assume the quantizer range covers the dynamic range of all
codevectors encoded using the systematic DFT code in (14).
The codevectors are generated by y = Gsys x. We also consider linear reconstruction of x form y using the pseudoinverse
[2] of Gsys , which is deﬁned as G† = (GH Gsys )−1 GH .
sys
sys
sys
k
It is easy to check that G† = n Gk GH , then the linear
sys
reconstruction is given by

λi = k, λi > 0,

s.t.

i=1

(22)

i=1

H
in which {λi }k are the eigenvalues of Gk GH (or Vk Vk ).
i=1
k
In other words, subject to the above constraints
k

k

argmin
λi

i=1

1
= argmax
λi .
λi
λi
i=1

(23)

Problem (22) has the maximum of 1 and inﬁmum of 0. Then,
k
H
considering that i=1 λi = det(Vk Vk ) = det(Gk GH ), we
k
conclude that the “best” submatrix is the one with the largest
determinant (possibly 1) and the “worst” submatrix is the one
with smallest determinant. Next, we evaluate the determinant
H
of Vk Vk so as to ﬁnd the matrices corresponding to these
extreme cases.
B. The Best and Worst Systematic Frames

k
(19)
x = G† y = Gk GH y.
sys
n
ˆ
Now, suppose we want to estimate x from y = Gsys x + q,
where q represents quantization error. From (19) we obtain

In this section, we ﬁrst evaluate the determinate of W W H
where W is the Vandermonde matrix with unit complex entries
as deﬁned in (1). From (2) we can write
det(W W H ) =

k
k
ˆ
ˆ
x = Gk GH y = x + Gk GH q.
(20)
n
n
Then, the mean-squared reconstruction error, due to the quantization noise, using a systematic frame can be written as
1
1
MSEq = E{ x − x 2 } = E{ G† q 2 }
ˆ
sys
k
k
1
= E{q H G†H G† q}
sys sys
k
1 2
= σq tr G†H G†
sys sys
k
(21)
k 2
= 2 σq tr GGH Gk GH
k
n
k 2
= 2 σq tr GH Gk GH G
k
n
1 2
k 2
= σq tr GH Gk = σq ,
k
n
n
where the last step follows because of Lemma 1. The above
analysis indicates that the MSE is the same for all systematic

1
nn

|eiθp − eiθq |2
1≤p<q≤n

1
= n
n

4 sin2

2

sin2

=

1≤p<q≤n
n(n−1) n−1

nn

r=1

π
(q − p)
n
π
r
n

(24)

n−r

in which θx = 2π (x − 1), r = q − p, and n(n − 1)/2 is the
n
total number of terms that satisfy 1 ≤ p < q ≤ n. But, we see
that W is a DFT matrix, and thus, its determinant must be 1.
Therefore, we have
n−1

sin2
r=1

π
r
n

n−r

=

nn
2n(n−1)

.

(25)

The above analysis helps us evaluate the determinant of Vk
or Gk , deﬁned in (14). Let Ir = {ir1 , ir2 , . . . , irk } be those
rows of G used to build Gk . Also, without loss of generality,

4

TABLE I
E IGENVALUES STRUCTURE FOR TWO SYSTEMATIC DFT FRAMES WITH
DIFFERENT CODEWORD PATTERNS . A “×” AND “−” RESPECTIVELY
REPRESENT DATA ( SYSTEMATIC ) AND PARITY SAMPLES .

assume ir1 < ir2 < · · · < irk . Clearly, ir1 ≥ 1, irk ≤ n, and
we obtain
1
H
det(Vk Vk ) = k
|eiθp − eiθq |2
k
1
= k
k

π
4 sin (q − p).
n

H
det(Vk Vk ) =

2k(k−1)
kk

k−1

sin2
r=1

.

2k(k−1)
kk

k−1

sin2

r=1
k(k−1) k−1

=

2

kk

r=1

π
Mr
n

0.1111

5.5

0.4444

0.2546

1.7454

5.5

0.4444

1

1

3

1

0.0396

1.4

28.70

0.0827

××××−×−

0.1506

1.4

10.32

0.2684

0.3110

1.4

7.40

0.4173

0.3110

1.4

7.40

0.4173

Systematic DFT frames as well as the approach to make
such a frame out of the generator matrix of a BCH-DFT
code has been introduced. Further, we found the conditions
for which a systematic DFT frame can be tight, too. We
then related the performance of these frames to the position
of systematic samples in the codevector. The analysis shows
that evenly spaced systematic (parity) samples result in the
minimum reconstruction error, whereas the worst performance
is achieved when systematic samples are circularly successive.
Finally, we found the conditions for which a DFT frame
becomes both systematic and tight.

(27)

k−r

R EFERENCES
[1] J. Kovacevic and A. Chebira, “Life beyond bases: The advent of frames
(Part I),” IEEE Signal Processing Magazine, vol. 24, pp. 86–104, Sept.
2007.
[2] V. K. Goyal, J. Kovacevic, and J. A. Kelner, “Quantized frame expansions with erasures,” Applied and Computational Harmonic Analysis,
vol. 10, no. 3, pp. 203–233, 2001.
[3] M. Vaezi and F. Labeau, “Distributed lossy source coding using realnumber codes,” to appear in VTC-Fall, 2012. [Online]. Available:
http://arxiv.org/abs/1111.0654.
[4] G. Rath and C. Guillemot, “Frame-theoretic analysis of DFT codes with
erasures,” IEEE Transactions on Signal Processing, vol. 52, pp. 447–
460, Feb. 2004.
[5] T. Marshall Jr., “Coding of real-number sequences for error correction:
A digital signal processing problem,” IEEE Journal on Selected Areas
in Communications, vol. 2, pp. 381–392, March 1984.
[6] S. K. Mitra and Y. Kuo, Digital Signal Processing: A Computer-Based
Approach. New York: McGraw-Hill, 2006.
[7] G. H. Tucci and P. A. Whiting, “Asymptotic results on generalized
vandermonde matrices and their extreme eigenvalues,” in Proc. the
49th Annual Allerton Conference on Communication, Control, and
Computing, pp. 1816–1823, 2011.
[8] G. H. Tucci and P. A. Whiting, “Eigenvalue results for large scale
random vandermonde matrices with unit complex entries,” IEEE Transactions on Information Theory, vol. 57, pp. 3938–3954, June 2011.
[9] G. A. F. Seber, A Matrix Handbook for Statisticians. New Jersey: John
Wiley & Sons, 2008.
[10] R. E. Blahut, Algebraic Codes for Data Transmission. New York:
Cambridge Univ. Press, 2003.
[11] A. Gabay, M. Kieffer, and P. Duhamel, “Joint source-channel coding
using real BCH codes for robust image transmission,” IEEE Transactions
on Image Processing, vol. 16, pp. 1568–1583, June 2007.
[12] R. M. Gray, Toeplitz and Circulant Matrices: A Review. Now Publishers,
2006.
[13] T. M. Cover and J. A. Thomas, Elements of Information Theory. New
York: John Wiley & Sons, 2006.

(28)
π
sin2 r
k

λi

VI. C ONCLUSIONS

The other extreme case comes up when n = M k (M is a
positive integer) provided that Gk consists of every M th row
of G. In such a case (26) simpliﬁes to 1 because
H
det(Vk Vk ) =

19

1.7454

×−×××−×

k−r

π
r
n

1.9428

0.2546

××−××−×

(7, 5)

0.0572

× × − × −−

×××××−−

π
π
Then, since sin n u = sin n (n − u), one can see that this
determinant depends on the circular distance between rows in
Ir . For a matrix with n rows, we deﬁne the circular distance
between rows p and q as min {|q − p|, n − |q − p|}. In this
sense, for example, the distance between rows 1 and n is one,
i.e., they are circularly successive. Now, we can see that (26) is
minimized when the selected rows are (circularly) successive.
Note that sin u is strictly increasing for u ∈ [0, π/2] and the
circular distance cannot be greater than n/2, in this problem.
In such circumstances where all rows in Ir are (circularly)
successive, (26) is minimal and reduces to

λmax

× × − − ×−

(6, 3)

1/λi

k
i=1

λmin

× × × − −−

(26)

2

1≤p<q≤n
p,q∈Ir

k
i=1

Codeword
patern

× − × − ×−

1≤p<q≤n
p,q∈Ir

Code

k−r

= 1,

where the last step follows from (25). Recall that this gives
the best Vk (and equivalently Gk ), in light of (22). For
such a Gk , it is easy to see that Gsys stands for a “tight”
systematic frame and minimizes the MSE for a given number
of quantization levels. Effectively, such a frame is performing
integer oversampling. There are M such frames; they all have
the same spectrum, though.
C. Numerical Examples
Numerical calculations conﬁrm that “evenly” spaced data
samples gives rise to systematic frames with the best performance. When a systematic code is doing integer oversampling,
we end up with tight systematic frames. The ﬁrst code in
Table I is an example of this case. When n = M k, data
samples cannot be equally spaced; however, as it can be seen
from the second code in Table I, still the best performance is
achieved when they are as equally spaced as possible. Note
that, circular shift of codewords pattern does not change the
spectrum of corresponding matrices. For example, in the (7, 5)
code, frames with pattern × − × × × − × and × × − × × − ×
have the same properties. Also, reversal of a frame yields a
frame with similar properties (e.g., × × − × −− is shifted
version of reversed × × − − ×−).

5

