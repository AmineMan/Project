Title:          CR_isit_10.pdf
Author:         Behzadmina
Creator:         TeX output 2012.05.09:1152
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Wed May  9 11:54:16 2012
ModDate:        Tue Jun 19 12:54:14 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      612 x 792 pts (letter)
File size:      365374 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569553909

On the Heegard-Berger Problem with Common
Reconstruction Constraints
Behzad Ahmadi

Ravi Tandon

Osvaldo Simeone

H. Vincent Poor

CWCSPR, ECE Dept.
NJIT

Dept. of Electrical Engineering
Princeton University

CWCSPR, ECE Dept.
NJIT

Dept. of Electrical Engineering
Princeton University

Y1n

Abstract—In lossy source coding with side information at
the decoder (i.e., the Wyner-Ziv problem), the estimate of the
source obtained at the decoder cannot be generally reproduced
at the encoder, due to its dependence on the side information.
In some applications this may be undesirable, and a Common
Reconstruction (CR) requirement, whereby one imposes that
encoder and decoder be able to agree on the decoder’s estimate,
may be instead in order. The rate-distortion function under
the CR constraint has been recently derived for the point-topoint (Wyner-Ziv) problem. In this paper, this result is extended
to the Heegard-Berger (HB) problem and to its variant with
cooperating decoders. Speciﬁcally, for the HB problem, the ratedistortion function is derived under the assumption that the
side information sequences at the two decoders are stochastically
degraded. The rate-distortion function is also calculated explicitly
for the special case of binary source and erased side information
with Hamming distortion metric. The rate-distortion function is
then characterized also for the HB problem with cooperating
decoders and physically degraded side information.

Decoder 1

Xn

ψ1

ˆ
I(X; X|Y ),

ψ2

ψ 1( X n ) ψ 2 ( X n )

Decoder 2

ˆn
X2

Y2n

Figure 1. Heegard-Berger source coding problem with common reconstruction (switch open). Closing the switch enables decoder cooperation.

(1) with the conventional Wyner-Ziv rate-distortion function,
WZ
namely RX|Y (D) = minI(X; U |Y ) with minimum overall
all pmfs p(u|x) and deterministic functions x(u, y) such that
ˆ
E[d(X, x(U, Y ))] ≤ D, it can be seen that the additional CR
ˆ
constraint prevents the decoder from using the side information
ˆ
as a means to improve its estimate X.
In this paper, we extend the characterization of the ratedistortion function under the CR constraint of [2] from the
point-to-point setting to the HB problem [1] (Fig. 1, switch
open), and its variant, studied in [3], in which decoder cooperation is enabled by a limited capacity link from one decoder,
Decoder 1, to the other, Decoder 2 (Fig. 1, switch closed).
We recall that [1] derived the rate-distortion function for the
HB problem (without CR constraints) under the assumption
that the side information sequences are stochastically degraded
versions of the source X n . Instead, for the case with decoder
cooperation, inner and outer bounds on the rate distortion
region for this problem are obtained in [3] (without CR
constraints) under the assumption that the side information
of Decoder 2 is physically degraded with respect to that of
Decoder 1.
For the HB problem with the CR constraint, in Sec. II, we
derive the rate-distortion function under the assumption that
the side information sequences are stochastically degraded.
We also calculate this function explicitly for binary source
and erased side information with the Hamming distortion
metric. Moreover, for the HB problem with the CR constraint
and decoder cooperation, we derive the rate-distortion region

In source coding problems with side information at a single
decoder, such as in the Wyner-Ziv problem, or at multiple
decoders, such as in the Heegard-Berger (HB) problem [1],
the side information sequences are, in general, used in two
different ways. The ﬁrst is as a means to reduce the rate
required for communication between encoder and decoders via
binning. The second is, instead, as an additional observation
that the decoders can leverage, along with the bits received
from the encoder, in order to improve their local estimates.
Leveraging the side information in this latter way, while
advantageous in terms of rate-distortion trade-off, may have
unacceptable consequences for some applications. In fact, this
ˆ
use of the side information entails that the reconstruction X at
a decoder cannot be reproduced at the encoder. In applications
such as transmission of sensitive medical information, this may
not be desirable. Instead, one may want to add the constraint
that the reconstruction at the decoder be reproducible by the
encoder [2].
This idea, referred to as the Common Reconstruction (CR)
constraint, was ﬁrst proposed in [2], where it is shown that
for the Wyner-Ziv problem the rate-distortion function under
the CR constraint is given by
= min

R1
R2

I. I NTRODUCTION

CR
RX|Y (D)

Encoder

ˆ
X 1n

(1)

where the minimum is taken over all probability mass funcˆ
tions (pmfs) p(ˆ|x) such that E[d(X, X)] ≤ D. Comparing
x

1

under the assumption that the side information sequences are
(physically) degraded in either direction (Sec. III-A and Sec.
III-B). We emphasize that the corresponding problem without
the CR constraint is still open as per the discussion above.

which map the source sequence into the estimated sequences at
the encoder, namely ψ1 (X n ) and ψ2 (X n ), respectively; such
that the distortion constraints are satisﬁed, i.e.,
1
n

II. H EEGARD -B ERGER P ROBLEM WITH C OMMON
R ECONSTRUCTION
In this section, we ﬁrst detail the system model for the HB
source coding problem in Fig. 1 (switch open) with CR in
Sec. II-A. Next, the characterization of the corresponding ratedistortion performance is derived under the assumption that
one of the two side information sequences is a stochastically
degraded version of the other in the sense of [1]. Finally, an
example with binary sources is worked out in Sec. II-C. The
case of Gaussian sources under quadratic distortion is tackled
in [4]. The proofs of the results presented in the paper are
omitted due to space limitations and can be found in [4].

g: X → [1, 2

],

≤

, j = 1, 2.

(7)

In this section, a single-letter characterization of the ratedistortion function for the HB problem with CR is derived,
under the assumption that the joint pmf p(x, y1 , y2 ) is such
that there exists a conditional pmf p(y1 |y2 ) for which
˜
p(x, y1 ) =

p(x, y2 )˜(y1 |y2 ).
p

(8)

y2 ∈Y2

In other words, the side information Y1 is a stochastically
degraded version of Y2 .
Proposition 2. If the side information Y1 is stochastically
degraded with respect to Y2 , the rate-distortion function for
the HB problem with CR is given by
CR
ˆ
ˆ
ˆ
RHB (D1 , D2 ) = min I(X; X1 |Y1 ) + I(X; X2 |Y2 X1 )
ˆ ˆ
ˆ
= min I(X; X1 X2 |Y2 )+I(X1 ; Y2 |Y1 ), (9a)

where the mutual information terms are evaluated with respect
to the joint pmf
ˆ ˆ
x ˆ
p(x, y1 , y2 , x1 , x2 ) = p(x, y1 , y2 )p(ˆ1 , x2 |x),

(10)

and minimization is performed with respect to the conditional
pmf p(ˆ1 , x2 |x) under the constraints
x ˆ
ˆ
E[dj (X, Xj )] ≤ Dj , for j = 1, 2.

(11)

The proof of the converse can be found in [4]. Achievability
follows as a special case of Theorem 3 of [1] and can be easily
shown using standard arguments. In particular, the encoder
ˆn
randomly generates a standard lossy source code X1 for
ˆ
the source X n with rate I(X; X1 ) bits per source symbol.
ˆ
Random binning is used to reduce the rate to I(X; X1 |Y1 ).
By the Wyner-Ziv theorem, this guarantees that both Decoder 1
ˆn
and Decoder 2 are able to recover X1 (since Y1 is a degraded
version of Y2 ). The encoder then maps the source X n into
ˆn
the reconstruction sequence X2 using a codebook that is
ˆn
ˆ ˆ
generated conditional on X1 with rate I(X; X2 |X1 ) bits per
source symbol. Random binning is again used to reduce the
ˆ
ˆ
rate to I(X; X2 |Y2 X1 ). From the Wyner-Ziv theorem, and
ˆn
the fact that Decoder 2 knows the sequence X1 , it follows
ˆn
that Decoder 2 can recover the reconstruction X2 as well.

(3)
Y1n

which maps the message J and the side information
into
ˆn
the estimated sequence X1 ; a decoding function for Decoder
2
(4)
Y2n

which maps message J and the side information
into the
ˆn
estimated sequence X2 ; and two reconstruction functions
ˆn
ψ1 : X n → X1
ˆn
and ψ2 : X n → X2 ,

(6)

B. Rate-Distortion Function

which maps the source sequence X n into a message J; a
decoding function for Decoder 1,

n
ˆn
h2 : [1, 2nR ] × Y2 → X2

Dj for j = 1, 2,

Given distortion pairs (D1 , D2 ), a rate pair R is said to be
achievable if, for any > 0 and sufﬁciently large n, there a
exists an (n, R, D1 + , D2 + , ) code. The rate-distortion
function R(D1 , D2 ) is deﬁned as R(D1 , D2 ) =inf{R : the
triple (R, D1 , D2 ) is achievable}.

(2)

n
ˆn
h1 : [1, 2nR ] × Y1 → X1 ,

≤

Pr ψj (X n ) = hj (g(X n ), Yjn )

Deﬁnition 1. An (n, R, D1 , D2 , ) code for the HB problem
with CR consists of an encoding function
nR

ˆ
E dj (X, Xj )

i=1

and the CR requirements hold, namely,

A. System Model
In this section the system model for the HB problem
with CR is detailed. The system is deﬁned by the pmf
ˆ
pXY1 Y2 (x, y1 , y2 ) and discrete alphabets X , Y1 , Y2 , X1 , and
ˆ2 as follows. The source sequence X n and side information
X
n
sequences Y1n and Y2n , with X n ∈ X n , Y1n ∈ Y1 , and
n
n
Y2 ∈ Y2 are such that the tuples (Xi , Y1i , Y2i ) for i ∈ [1, n]
are independent and identically distributed (i.i.d.) with joint
pmf pXY1 Y2 (x, y1 , y2 ). The encoder observes a sequence X n
and encodes it into a message J of nR bits, which is delivered
to the decoders. Decoders 1 and 2 wish to reconstruct the
source sequence X n within given distortion requirements,
ˆn
ˆn
ˆn
ˆn
to be discussed below, as X1 ∈ X1 and X2 ∈ X2 ,
ˆ n is obtained as a
respectively. The estimated sequence Xj
function of the message J and the side information sequence
Yjn for j = 1, 2. The estimates are constrained to satisfy
distortion constraints deﬁned by per-symbol distortion metrics
ˆ
dj (x, xj ) : X × Xj → [0, Dmax ] with 0 < Dmax < ∞. The
ˆ
ˆ
ˆ n and X n are also required to satisfy the
reconstructions X2
2
CR constraints, as formalized below.

n

n

(5a)
(5b)

2

ˆn
ˆn
Note that, since the reconstruction sequences X1 and X2 are
generated by the encoder, functions ψ1 and ψ2 that guarantee
the CR constraints (7) exist by construction.

ˆ
ˆ
the reconstruction alphabets are binary, X1 = X2 = {0, 1},
and we have dj (x, xj ) = 0 if x = xj and dj (x, xj ) = 1
ˆ
ˆ
ˆ
otherwise for j = 1, 2. Instead, for the erasure distortion the
ˆ
ˆ
reconstruction alphabets are X1 = X2 = {0, 1, e}, and we
have for j = 1, 2: dj (x, xj ) = 0 if xj = x, dj (x, xj ) = 1 if
ˆ
ˆ
ˆ
xj = e and dj (x, xj ) = ∞ otherwise.
ˆ
ˆ

Remark 3. If we remove the CR constraint, then the ratedistortion function under the assumption of Proposition 2 is
given by [1]
RHB (D1 , D2 ) = min I(X; U1 |Y1 ) + I(X; U2 |Y2 U1 ), (12)

Xn

where the mutual information terms are evaluated with respect
to the joint pmf
p(x, y1 , y2 , u1 , u2 ) = p(x, y1 , y2 )p(u1 , u2 |x),

py 2 |x
1 − p2

0

(13)

p2
p2

and minimization is performed with respect to the conditional pmf p(u1 , u2 |x) and the deterministic functions
xj (uj , yj ), for j = 1, 2, such that distortion constraints
ˆ
E[dj (X, xj (Uj , Yj ))] ≤ Dj , for j = 1, 2 are satisﬁed. Comˆ
parison of (9) with (12) reveals that, similar to the discussion
for the point-to-point set-up, the CR constraint permits the use
of side information only to reduce the rate via binning, but not
to improve the decoder’s estimates via the use of the auxiliary
codebooks represented by variables U1 and U2 , and functions
xj (uj , yj ), for j = 1, 2, in (13).
ˆ

1

1 − p2

Yn
2
0
e
1

~( y | y )
p 1 2

~
1 − p1
~
p1

1

~

~
p1

1 − p1

Yn
1
0
e
1

Figure 2.
Illustration of the pmfs in the factorization (8) of the joint
distribution p(x, y1 , y2 ) for a binary source X and erased side information
sequences (Y1 , Y2 ).

In [4, Appendix C], it is proved that for the point-to-point
set-up with X ∼ Ber( 1 ) and erased side information Y with
2
erasure probability p, the rate-distortion function with CR
under Hamming distortion is given by

Remark 4. Consider the case in which the side information
sequences are available in a causal fashion in the sense of
[5]; that is, the decoding functions (3)-(4) are modiﬁed as
i
ˆ
hji : [1, 2nR ] × Yj → Xji , for i ∈ [1, n] and j = 1, 2,
respectively. Following similar steps as in [5], it can be
concluded that the rate-distortion function in this case is
the same as if the two side information sequences were not
available at the decoders, and is thus given by (9) upon
removing the conditioning on the side information. Note that
this is true irrespective of the joint pmf p(x, y1 , y2 ) and
hence it holds also for non-degraded side information. This
result can be explained by noting that, as explained in [5],
causal side information prevents the possibility of reducing
the rate via binning. Since the CR constraint also prevents the
side information from being used to improve the decoders’
estimates, it follows that the side information is useless in
terms of rate-distortion performance, if used causally.

CR
RX|Y (D)=

CR
RB (D, p) = p(1 − H(D))
0

for D ≤ 1/2
for D > 1/2,
(14)

while under erasure distortion we get
CR
RX|Y (D) =

CR
RBE (D, p) = p(1 − D),

(15)

where H(x) denotes the binary entropy function. Note that
the rate-distortion function with erased side information and
Hamming distortion without the CR constraint is derived in
[7].
Proposition 5. The rate-distortion function for the HB problem with CR for the binary source with the stochastically
degraded erased side information sequences illustrated in Fig.
2 under Hamming distortion is given by

C. Binary Source with Erased Side Information and Hamming
or Erasure Distortion

⎧
⎪ 0
⎪
⎪
⎪
if
⎪
⎪ CR D1 ≥ 1/2 and D2 ≥ 1/2
⎪
⎪ RB (D1 , p1 )
⎪
⎪
⎨ if D ≤ 1/2 and D ≥ min(D , 1/2)
1
2
1
CR
RHB (D1 , D2 )=
(16)
CR
⎪ RB (D2 , p2 )
⎪
⎪
⎪
if D1 ≥ 1/2 and D2 ≤ 1/2
⎪
⎪
⎪ ˜ CR
⎪ R (D1 , D2 )
⎪ HB
⎪
⎩
if D2 ≤ D1 ≤ 1/2

In this section, we consider a binary source X ∼ Ber( 1 )
2
with erased side information sequences Y1 and Y2 . The source
Y2 is an erased version of the source X with erasure probability p2 and Y1 is an erased version of X with erasure probability
p1 > p2 . This means that Yj = e, where e represents an
erasure, with probability pj and Yj = X with probability
1 − pj . Note that, with these assumptions, the side information
Y1 is stochastically degraded with respect to Y2 . In fact,
we have the factorization (8), where additional distributions
p(y2 |y1 ) and p(y1 |y2 ) are illustrated in Fig. 2. As seen in
˜
Fig. 2, the pmf p(y1 |y2 ) is characterized by the probability p1
˜
˜
that satisﬁes the equality p1 = p2 + p1 (1 − p2 ). We focus on
˜
˜
Hamming and erasure distortions. For the Hamming distortion,

CR
where RB (D, N ) is deﬁned in (14) and

˜ CR
RHB (D1 , D2 ) = p1 (1 − H(D1 )) + p2 (H(D1 ) − H(D2 )).
(17)

3

D2

R CRp 1 , D 1 
B

where the ﬁrst inequality in (19) accounts for the impact of
the availability of the side information at the encoder, while
the second reﬂects the potential performance loss due to the
CR constraint.
Fig. 4 shows the aforementioned rate-distortion functions
with p1 = 1 and p2 = 0.35, which corresponds to the case
where Decoder 1 has no side information, for two values of the
distortion D2 versus the distortion D1 . For D2 ≥ p/2 = 0.175,
the given settings reduce to one in which the encoder needs to
communicate information only to Decoder 1. Since Decoder
1 has no side information, the Kaspi and HB settings yield
the same performance i.e., RKaspi (D1 , D2 ) = RHB (D1 , D2 ).
Moreover, if D1 is sufﬁciently smaller than D2 , the operation
of the encoder is limited by the distortion requirements of
Decoder 1. In this case, Decoder 2 can in fact reconstruct
ˆ
ˆ
as X1 = X2 while still satisfying its distortion constraints.
Therefore, we obtain the same performance in all of the
three settings, i.e., RKaspi (D1 , D2 ) = RHB (D1 , D2 ) =
CR
RHB (D1 , D2 ). We also note the general performance loss due
to the CR constraint, unless, as discussed above, distortion D1
is sufﬁciently smaller than D2 .

0

1
2

R CRp 2 , D 2 
B
~ CR
R HB ( D 1 , D 2 )

1
2

D1

Figure 3. Illustration of the distortion regions in the rate-distortion function
(16) for a binary source with degraded erased side information and Hamming
distortion.

Moreover, for the same source under erasure distortion
the rate-distortion function is given by (16) by substituting
CR
CR
RBE (Dj , pj ) as deﬁned in (15) for RB (Dj , pj ) for j = 1, 2
CR
˜
and by substituting RHB,E (D1 , D2 ) = p1 (1 − D1 ) + p2 (D1 −
D2 ) for (17).

1
CR

0.9
0.8

Characterization of the rate distortion function (16) requires different considerations for the four subregions of
the (D1 , D2 ) plane sketched in Fig. 3. In fact, for D1 ≥
1/2 and D2 ≥ 1/2, the required rate is zero, since the distorˆ
ˆ
tion constraints are trivially met by setting X1 = X2 = 0 in
the achievable rate (9). For the case D1 ≥ 1/2 and D2 ≤ 1/2,
ˆ
it is sufﬁcient to cater only to Decoder 2 by setting X1 = 0
ˆ 2 ⊕ Q2 , with Q2 ∼ Ber(D2 ) independent of X,
and X = X
in the achievable rate (9). That this rate cannot be improved
upon is a consequence of the trivial converse

RHB
RHB

RKaspi

R( D1, D2)

0.7
0.6
0.5
0.4

D2=0.05

0.3
0.2
0.1

CR
CR
CR
RHB (D1 , D2 ) ≥ max{RB (D1 , p1 ), RB (D2 , p2 )}, (18)

0
0

D2=0.3

0.05

0.1

0.15

0.2

0.25

0.3

0.35

0.4

0.45

0.5

D1

which follows by cut-set arguments. The same converse sufﬁces also for the regime D1 ≤ 1/2 and D2 ≥ min(D1 , 1/2).
ˆ
For this case, achievability follows by setting X = X2 ⊕ Q2
ˆ
ˆ
and X1 = X2 in (9), where Q2 ∼ Ber(D2 ) is independent
of X. In the remaining case, namely D2 ≤ D1 ≤ 1/2, the
rate-distortion function does not follow from the point-to-point
result (14) as for the regimes discussed thus far. The analysis of
this case can be found in [4, Appendix D]. Similar arguments
apply also for the erasure distortion metric.
We now compare the rate-distortion function above with the
following related settings: (i) the Kaspi model [8], in which
the encoder knows the side information, and for which the
rate-distortion function RKaspi (D1 , D2 ) for the example at
hand was calculated in [7]; and (ii) the HB setting with no
CR constraint, whose rate-distortion function RHB (D1 , D2 )
for the example at hand was derived in [6]. We clearly have
the inequalities

Figure 4. Rate-distortion functions RKaspi (D1 , D2 ) [7], RHB (D1 , D2 )
CR
[6] and RHB (D1 , D2 ) (16) for a binary source under erased side information
versus distortion D1 (p1 = 1, p2 = 0.35, D2 = 0.05 and D2 = 0.3).

III. H EEGARD -B ERGER P ROBLEM WITH C OOPERATIVE
D ECODERS AND C OMMON R ECONSTRUCTION
The system model for the HB problem with CR and decoder
cooperation is similar to the one provided in Sec. II-A with the
following differences. Here, in addition to encoding function
given in (2) which maps the source sequence X n into a message J1 of nR1 bits, there is an encoder at Decoder 1 given by
n
g1 : [1, 2nR1 ] × Y1 → [1, 2nR2 ], which maps message J1 and
the source sequence Y1n into a message J2 . Moreover, instead
of the decoding function given in (3), we have the decoding
n
ˆn
function for Decoder 2, h2 : [1, 2nR1 ] × [1, 2nR2 ] × Y2 → X2 ,
which maps the messages J1 and J2 and the side information
ˆn
Y2n into the estimated sequence X2 .

CR
RKaspi (D1 , D2 ) ≤ RHB (D1 , D2 ) ≤ RHB (D1 , D2 ), (19)

4

A. Rate-Distortion Region for X − Y1 − Y2

scheme of Proposition 2. The converse follows by considering
an enhanced system in which Decoder 2 is provided with the
side information of Decoder 1. In this system, link R2 becomes
useless since Decoder 2 possesses all the information available
at Decoder 1. It follows that the system reduces to the HB
problem with degraded sources studied in the previous section
and the bound (22a) follows immediately from Proposition 2.
Remark 9. In the case without CR, the rate-distortion function
is given similarly to (22), but with the HB rate-distortion
function (12) in lieu of the rate-distortion function of the HB
problem with CR in (22a).

In this section, a single-letter characterization of the ratedistortion region is derived under the assumption that the joint
pmf p(x, y1 , y2 ) is such that the Markov chain relationship
X − Y1 − Y2 holds.
Proposition 6. The rate-distortion region RCR (D1 , D2 ) for
the HB source coding problem with CR and cooperative
decoders under the assumption that X − Y1 − Y2 forms a
Markov chain is given by the union of all rate pairs (R1 , R2 )
that satisfy the conditions
ˆ ˆ
R1 ≥ I(X; X1 X2 |Y1 )
(20a)
ˆ
ˆ
ˆ
and R1 + R2 ≥ I(X; X2 |Y2 ) + I(X; X1 |Y1 , X2 ),(20b)

IV. C ONCLUDING R EMARKS
The Common Reconstruction requirement [2], substantially
modiﬁes the problem of source coding in the presence of side
information at the decoders. A general subject of theoretical
interest is identifying those models for which the CR requirements enables a solution of problems that have otherwise
resisted solutions for some time. For instance, reference [4]
extends the result of this paper to cascade models in the sense
of [9]. Other examples that are worth investigating include
the Heegard-Berger and cascade source coding problems with
no assumptions on side information degradedness and the
one-helper lossy source coding problem. Applications of the
generalized CR constraint of [10] are also of interest (see [4]).

where the mutual information terms are evaluated with respect
to the joint pmf
p(x, y1 , y2 , x1 , x2 ) = p(x, y1 )p(y2 |y1 )p(ˆ1 , x2 |x),
ˆ ˆ
x ˆ

(21)

for some pmf p(ˆ1 , x2 |x) such that the constraints (11) are
x ˆ
satisﬁed.
The proof of the converse can be found in [4]. As for
the achievability, it follows as a straightforward extension
of [3, Sec. III] to the setup at hand where Decoder 2 has
side information as well. It is worth emphasizing that the
ˆ
reconstruction X2 for Decoder 2, which has degraded side
information, is conveyed by using both the direct link from
the Encoder, of rate R1 , and the path Encoder-Decoder 1Decoder 2. The latter path leverages the better side information
at Decoder 1 and the cooperative link of rate R2 .
Remark 7. If we remove the CR constraint, the problem of
determining the rate-distortion region for the setting of Fig. 1
under the Markov assumption X − Y1 − Y2 is still open [3].

ACKNOWLEDGMENT
The work of O. Simeone was supported by the U.S. National
Science Foundation under grant CCF-0914899, and the work
of H. V. Poor and R. Tandon was supported in part by the U.S.
Air Force Ofﬁce of Scientiﬁc Research under MURI Grant
FA9550-09-1-0643 and in part by the U.S. National Science
Foundation under Grant CNS-09-05398.
R EFERENCES

B. Rate-Distortion Region for X − Y2 − Y1

[1] C. Heegard and T. Berger, “Rate distortion when side information may
be absent,” IEEE Trans. Inform. Theory, vol. 31, no. 6, pp.727–734, Nov.
1985.
[2] Y. Steinberg, “Coding and common reconstruction,” IEEE Trans. Inform.
Theory, vol. 55, no. 11, 2009.
[3] D. Vasudevan, “On the Heegard-Berger/Kaspi problem with decoder
cooperation,” in Proc. IEEE Int’l Conf. on Telecommunications, St.
Petersburg, Russia, June 2008.
[4] B. Ahmadi, R. Tandon, O. Simeone and H. V. Poor, “Heegard-Berger
and cascade source coding problems with common reconstruction constraints,” submitted [arXiv:1112.1762].
[5] T. Weissman and A. El Gamal, “Source coding with limited-look-ahead
side information at the decoder," IEEE Trans. on Inform. Theory, vol. 52,
no. 12, pp. 5218-5239, Dec. 2006.
[6] R. Tandon, S. Mohajer, and H. V. Poor, “Cascade source coding with
erased side information,” in Proc. IEEE Int’l Symp. Inform. Theory, St.
Petersburg, Russia, Aug. 2011.
[7] E. Perron, S. N. Diggavi, and E. Telatar, “Lossy source coding with
Gaussian or erased side-information,” in Proc. IEEE Int’l Symp. Inform.
Theory, Seoul, South Korea, Jul. 2009.
[8] A. H. Kaspi, “Rate-distortion function when side-information may be
present at the decoder,” IEEE Trans. Inform. Theory, vol. 40, pp.
2031–2034, Nov. 1994.
[9] Y. K. Chia, H. Permuter and T. Weissman, “Cascade, triangular and two
way source coding with degraded side information at the second user,”
submitted [http://arxiv.org/abs/1010.3726].
[10] A. Lapidoth, A. Malar, and M. Wigger, “Constrained Wyner-Ziv coding,”
in Proc. IEEE Int’l Symp. Inform. Theory, St. Petersburg, Russia, Aug.
2011.

In this section, a single-letter characterization of the ratedistortion region is derived under the assumption that the joint
pmf p(x, y1 , y2 ) is such that the Markov chain relationship
X − Y2 − Y1 holds.
Proposition 8. The rate-distortion region RCR (D1 , D2 ) for
the HB source coding problem with CR and cooperative
decoders under the assumption the Markov chain relationship
X − Y2 − Y1 is given by the union of all rate pairs (R1 , R2 )
that satisfy the conditions
R1
and R2

≥
≥

ˆ
ˆ
ˆ
I(X; X1 |Y1 ) + I(X; X2 |Y2 , X1 ) (22a)
0,
(22b)

where the mutual information terms are evaluated with respect
to the joint pmf
p(x, y1 , y2 , x1 , x2 ) = p(x, y2 )p(y1 |y2 )p(ˆ1 , x2 |x),
ˆ ˆ
x ˆ

(23)

for some pmf p(ˆ1 , x2 |x) such that the constraints (11) are
x ˆ
satisﬁed.
The proof of achievability follows immediately by neglecting the link of rate R2 and using rate R1 as per the HB

5

