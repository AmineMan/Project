Title:          ISIT_BC_sec.pdf
Author:         Sadaf
Creator:        Adobe Acrobat 9.0.0
Producer:       Appligent StampPDF Batch, version 5.1
CreationDate:   Mon May 14 15:24:27 2012
ModDate:        Tue Jun 19 12:54:56 2012
Tagged:         no
Pages:          5
Encrypted:      no
Page size:      595 x 842 pts (A4)
File size:      317952 bytes
Optimized:      no
PDF version:    1.6
ISIT'2012 1569556713

On the Secrecy Capacity of 3-Receiver Broadcast
Channel With Causal States and Conferencing
Sadaf Salehkalaibar and Mohammad Reza Aref
Information Systems and Security Lab (ISSL),
Department of Electrical Engineering,
Sharif University of Technology, Tehran, Iran
E-mails: s saleh@ee.sharif.edu, aref@sharif.edu
1

wiretap coding. Khisti, Diggavi and Wornell [5] considered the
WTC with state known causally or noncausally at the encoder
and decoder and established the secret key capacity. Chia and
El Gamal [6] investigated the WTC when the state is causally
available at the encoder and decoder. They found an inner
bound on the secrecy capacity of this channel using block
Markov encoding and Shannon strategy [7].
In this paper, we consider the 2-rec., 1-eav. BC with two
causal states and conferencing decoders. Each state is known
causally at the corresponding receiver, while both states are
causally available at the encoder. Each receiver wishes to send
the state which is not available at the other receiver, through
the noiseless link. We obtain an inner bound on the secrecy
capacity region of this channel. In the achievability scheme, we
use block Markov encoding [6], [8] and Shannon strategy for
channels with state [7]. We make use of the states to generate
two secret keys [6]. We employ the secret keys generated in
one transmission block to increase the secrecy rate in the next
block. The main idea in this paper is to employ the cooperation
of the receivers in recovering the keys to increase the secrecy
rate. This implies that if a party does not have access to both
keys, it may not recover the messages. On the other hand,
each receiver tries to ensure secrecy while sending the state
through the noiseless link. Therefore, we consider different
cases in the decoding procedure based on the cooperationsecrecy trade-off. We also establish an outer bound on the
secrecy capacity region of the 2-rec., 1-eav. BC with Causal

Abstract—We investigate the secrecy capacity region of
2-receiver, 1-eavesdropper Broadcast Channel (BC) with two
causal states and conferencing decoders. The encoder sends two
messages, one of them for both legitimate receivers and the other
one for the ﬁrst legitimate receiver. It keeps these messages secret
from the eavesdropper. Each state is causally available at the
corresponding receiver, while both states are known causally at
the encoder. Each receiver wishes to send the state which is
not available at the other receiver, through a noiseless link with
limited capacity. We ﬁnd an inner bound on the secrecy capacity
region of this channel. The achievability scheme employs block
Markov coding and Shannon strategy for channels with state.
In each block, we make use of the states to generate two keys
which will be used in the next block. The idea is to utilize the
cooperation of both receivers to recover both keys at each receiver
while ensuring secrecy. We also establish an outer bound on
the secrecy capacity region of the 2-rec., 1-eav. BC with Causal
Channel State Information (CCSI) and conferencing. We prove
that the proposed bounds coincide for a special case.

I. I NTRODUCTION
Consider the 2-receiver, 1-eavesdropper Broadcast Channel
(BC) with two states and conferencing decoders shown in
Figure 1. The sender X wishes to send two messages, one
of them for the legitimate receivers Y1 and Y2 , and the
other one for the ﬁrst legitimate receiver Y1 . It also tries to
keep these messages secret from the eavesdropper Z. There
are two noiseless links between Y1 and Y2 with capacities
C1 and C2 . There are some special cases of this channel
where the secrecy capacity has been obtained. When the state
information is not available, Csiszar and Korner [1] considered
the general WireTap Channel (WTC), which consists of a
sender, a receiver and an eavesdropper, and established the
secrecy capacity. Chia and El Gamal [2] found a lower bound
on the secrecy capacity of the 2-rec., 1-eav. BC. Salehkalaibar
and Aref [3] established the secrecy capacity of a special class
of 3-rec. BCs where the receivers exhibit a degradedness order.
When the state information is available at the encoder and
decoders, the parties can use this information to increase the
secrecy rate. In the case of the WTC with state known noncausally at the encoder, Chen and Vinck [4] found an inner
bound to the secrecy capacity. The coding scheme is based
on the combination of Gelfand-Pinsker binning and Wyner

6WDWH
6HOHFWRU 

s

1,

i

Yn
1

M

1

M

(QFRGHU

8VHU 

X n p(y , y ,z| x,s ,s ) Z n(DYHVGURSSHU VHFUHW
1

2

1

M ,M )

2

(

0

s

Yn
2

0

1

M M

( ˆ 0 , ˆ 1)

C C
ˆ
M
1

8VHU 

2

0

i

2,

6WDWH
6HOHFWRU 

1 This work was partially supported by Iranian NSF under contract no.
88114/46 and by Iran Telecom Research Center (ITRC) and by Iranian NSFcryptography chair.

Fig. 1. 2-receiver, 1-eavesdropper Broadcast Channel (BC) with CCSI and
conferencing

1

min{C1 , H(S1 |S2 )} − I(U ; Z|S1 , S2 ),
I(U ; Y1 |S1 ) + H(S1 |S2 ) + C2 − I(U ; Z|S1 , S2 ),
I(U ; Y2 |S2 ) + H(S2 |S1 ) + C1 − I(U ; Z|S1 , S2 ),
min{I(U ; Y2 |S2 ), I(U ; Y1 |S1 )} + min{C1 + C2 , H(S1 , S2 |Z)}
−I(U ; Z|S1 , S2 )
(1)

Channel State Information (CCSI) and conferencing. We show
that the proposed bounds are tight for the 2-rec., 1-eav. BC
with two keys and conferencing, when Z is a degraded version
of Y2 and Y2 is a degraded version of Y1 .
The paper is organized as follows: In Section II, we present
a mathematical framework for our work. In Section III, we
ﬁnd inner and outer bounds on the secrecy capacity of the 2rec., 1-eav. BC with CCSI and conferencing, and discuss some
special cases. In Section IV, the proofs of theorems are given.
Conclusions are provided in Section V.

for all distributions of the form p(s1 , s2 )p(u, v)p(x|u, v, s1 ,
s2 ).
Proof: See Section IV-A.
Theorem 2: Rout is an outer bound on the secrecy capacity
region of the 2-rec., 1-eav. BC with CCSI and conferencing
where Rout is the union of all (R0 , R1 ) satisfying

II. P RELIMINARIES AND D EFINITIONS
We denote discrete random variables with capital letters e.g.,
j
X, Y , and their realizations with lower case letters x, y. Xi
indicates a sequence of random variables (Xi , ..., Xj ). We use
H(.) to denote the entropy of a discrete random variable and
I(.; .) to denote the mutual information between two discrete
random variables. We denote by An (X, Y ), the set of εε
strongly jointly typical sequences of length n, on p(x, y). A
random variable X takes values in a set X . Finally, we denote
the probability density function of X over X with p(x) and
the conditional probability density function of X given Y by
p(x|y).
Deﬁnition 1: A (2nR0 , 2nR1 , n) code for the 2-receiver, 1eavesdropper Broadcast Channel (BC) with Causal Channel
State Information (CCSI) and conferencing (Fig. 1) consists of: i) two message sets as M0 = {1, ..., 2nR0 } and
M1 = {1, ..., 2nR1 }, ii) two conference message sets as
M12 = {1, ..., 2nC1 } and M21 = {1, ..., 2nC2 }, iii) an
encoder that generates a symbol Xi (m0 , m1 ) according to the
conditional pmf p(xi |m0 , m1 , si , si , xi−1 ) for i ∈ [1 : n], iv)
1 2
n
two conference mappings, one at each user, h1 : S1 → M12
n
and h2 : S2 → M21 , v) two decoders, one at each user
n
n
with the mappings g1 : M21 × Y1 × S1 → M0 × M1 and
n
n
g2 : M12 × Y2 × S2 → M0 . The messages M0 , M1 , M12 and
M21 are uniformly distributed over the message sets. The probn
n
ability of error is deﬁned as, Pe = Pr(g1 (M21 , Y1n , S1 ) =
n
(M0 , M1 ) or g2 (M12 , Y2n , S2 ) = M0 ). The information leak1
age rate at the eavesdropper is deﬁned as n I(M0 , M1 ; Z n ).
A secrecy rate pair (R0 , R1 ) is said to be achievable if
n
there exists a sequence of codes with limn→∞ Pe = 0 and
1
n
limn→∞ inf n I(M0 , M1 ; Z ) = 0.

R0 ≤ min{I(U ; Y2 |S2 ), I(U ; Y1 |S1 )}

(2)

R0 ≤ I(U0 ; Y2 , S2 |W ) − I(U0 ; Z|W )
+ min{C1 , H(S1 |S2 , Y2 )} + min{C2 , H(S2 |S1 , Y2 )}

(3)

R0 ≤ I(U0 ; Y2 |W, S2 ) − I(U0 ; Z|W, S2 ) + C1 + H(S2 |Z)
(4)
R1 ≤ I(V0 ; Y1 , S1 |U1 ) − I(V0 ; Z|U1 ) + C2
R1 ≤ I(V ; Y1 , S1 , S2 |U2 ) − I(V ; Z|U2 )
R1 ≤ I(V ; Y1 , S1 |U2 ) − I(V ; Z|U2 ) + H(S2 |S1 , Y1 )

(5)
(6)
(7)

for all joint distributions of the form p(w|s1 , s2 ).
p(u0 |w, s1 , s2 ).p(u|u0 , s1 , s2 ).p(u1 |u0 , s1 , s2 ).p(u2 |u1 , s1 ,
s2 ).p(v0 |u1 , s1 , s2 ).p(v|v0 , u2 , s1 , s2 ).p(x|u2 , v, s1 , s2 ).
Proof: See Section IV-B.
Remark 1: Let Y2 = Y, S2 = S, S1 = 0, Y1 = (Y, S),
R1 = 0, U = (X, S) and C1 = 0, C2 → ∞ in Theorems 1
and 2. Then, Rin and Rout specialize to the secrecy capacity
of the less noisy WTC with CCSI [6]
C1 = max min{I(X; Y |S) − I(X; Z|S) + H(S|Z), I(X; Y |S)}.
p(x|s)

(8)
To show this, consider the terms in Rin . Note that
I(U ; Y |S) = I(X; Y |S). Also, the other term can be written as I(U ; Y |S) − I(U ; Z|S) + H(S|Z) = I(X; Y |S) −
I(X; Z|S) + H(S|Z). Now consider the term (4) in Rout .
This term satisﬁes the following inequalities
I(U0 ; Y |W, S) − I(U0 ; Z|W, S) + H(S|Z)
(a)

≤ I(U0 ; Y |S) − I(U0 ; Z|S) + H(S|Z)

(b)

≤ I(X; Y |S) − I(X; Z|S) + H(S|Z).

III. S UMMARY OF M AIN R ESULTS

where (a) and (b) follow from the less noisy assumption
where I(U ; Y |S) ≥ I(U ; Z|S), for all U such that (U, S) →
(X, S) → (Y, Z) form a Markov chain.
Secrecy Capacity Result
We show that Theorems 1 and 2 are tight for a special case.
Consider the case where p(y1 , y2 , z|x, s1 , s2 ) = p(y1 , y2 , z|x),
Z is a degraded version of Y2 and Y2 is a degraded version of
Y1 , i.e., Y1 → Y2 → Z form a Markov chain. Also, suppose
that R1 = 0. Therefore, we ﬁnd the secrecy capacity of the
2-rec., 1-eav. BC with two secret keys.
Theorem 3: C is the secrecy capacity of the 2-rec., 1-eav.
BC with CCSI and conferencing when p(y1 , y2 , z|x, s1 , s2 ) =

In this section, we ﬁrst obtain inner and outer bounds to the
secrecy capacity region of the 2-rec., 1-eav. BC with CCSI and
conferencing. Then, we discuss a special case where the two
bounds determine the secrecy capacity.
Theorem 1: Rin is an inner bound to the secrecy capacity
region of the 2-rec., 1-eav. BC with CCSI and conferencing
where Rin is the union of all (R0 , R1 ) satisfying
R1 ≤ I(V ; Y1 |U, S1 ) − I(V ; Z|U, S1 , S2 )
R0 ≤ min{I(U ; Y2 |S2 ), I(U ; Y1 |S1 ),
I(U ; Y2 |S1 , S2 ) + H(S1 |S2 ) + min{C2 , H(S2 |S1 )}−
I(U ; Z|S1 , S2 ), I(U ; Y1 |S1 , S2 ) + H(S2 |S1 )+

2

p(y1 , y2 , z|x), R1 = 0 and Y1 → Y2 → Z form a Markov
chain where,


 I(X; Y2 ), I(X; Y2 |Z)+ 
min{C1 , H(S1 |S2 )}+
C = max min
.
(9)


p(x)
min{C2 , H(S2 |S1 )}

Shannon’s strategy and sends a randomly generated symbol
Xi ∼ p(xi |u1,i , v1,i , s1,i , s2,i ) for i ∈ [(b − 1)n + 1 :
bn]. The ﬁrst and second users send indices k1 (b − 1) and
k2 (b − 1), respectively. At the end of block b, the encoder
and users declare bin indices (k1 (b), k2 (b)) of state sequences
(sn (b), sn (b)) as the key to be used in block b + 1. Mes1
2
sage parts m00 (b) and m1 (b) are transmitted using Wyner
wiretap coding. These messages can be kept secret from
the eavesdropper provided that R0 − R00 ≥ I(U ; Z, S1 , S2 )
and R1 − R1 ≥ I(V ; Z, S1 , S2 |U ), therefore (R0 − R00 ) +
(R1 − R1 ) ≥ I(V ; Z, S1 , S2 ). The secrecy analysis of the
message part m01 (b) involves keeping k(b − 1) secret from
the eavesdropper. We show that this step can be done if
Rk1 + Rk2 ≤ H(S1 , S2 |Z), using the approach of [6]. For
the analysis of the information leakage rate, see Appendix A.
The main part of the proof is the decoding procedure. We
consider different cases based on the capacities of conferencing links and the secrecy constraint obtained above. In the ﬁrst
case, each user may be able to reconstruct the state sequence
which is available at the other user, while ensuring the secrecy
constraint, i.e.,
• H(S1 |S2 )+H(S2 |S1 ) ≤ H(S1 , S2 |Z), H(S1 |S2 ) ≤ C1 ,
H(S2 |S1 ) ≤ C2
In block b, user 1 upon receiving k2 (b−1), ﬁnds sn (b−1) such
2
that sn (b − 1) ∈ B21 (k2 (b − 1)) and (sn (b − 1), sn (b − 1)) ∈
2
2
1
An . This can be done with an arbitrarily small probability of
error if Rk1 = H(S1 |S2 ) and Rk2 = H(S2 |S1 ). User 1 then
ﬁnds l0 (b − 1) and l1 (b − 1) such that (v n (l0 (b − 1), l1 (b −
n
1)), un (l0 (b − 1)), sn (b − 1), sn (b − 1), y1 (b − 1)) ∈ An . This
1
2
can be done with an arbitrarily small probability of error if

Proof: Achievability follows from Theorem 1 by setting
R1 = 0, V = U = X and considering the fact that I(X; Y2 ) ≤
I(X; Y1 ) for all distributions of the form p(x)p(s1 , s2 ). To
establish the converse, we use the degradedness assumption to
strengthen the terms in (3). For example consider the following
term
I(U0 ; Y2 , S2 |W ) − I(U0 ; Z|W ) + C1 + H(S2 |S1 , Y2 )
(a)

= I(U0 ; Y2 |W ) − I(U0 ; Z|W ) + C1 + H(S2 |S1 )

(b)

≤ I(U0 ; Y2 ) − I(U0 ; Z) + C1 + H(S2 |S1 )

(c)

≤ I(X; Y2 ) − I(X; Z) + C1 + H(S2 |S1 )
= I(X; Y2 |Z) + C1 + H(S2 |S1 ).

where (a) follows from the distribution p(y1 , y2 , z|x, s1 , s2 ) =
p(y1 , y2 , z|x). (b) and (c) follow from the degradedness assumption. Similarly, other terms of (9) can be obtained.
The proofs of Theorems 1 and 2 are provided in the next
section.
IV. P ROOFS
A. Proof of Theorem 1
We outline the coding scheme. We send B − 1 independent
messages over B n−transmission blocks. Split message M0
into two independent messages M00 ∈ [1 : 2nR00 ], and M01 ∈
[1 : 2nR01 ], thus R0 = R00 +R01 . Let R0 ≥ R0 and R1 ≥ R1 .
Also, choose two rates Rk1 and Rk2 such that Rk1 ≤ C1 and
Rk2 ≤ C2 . Message codebook is generated as follows. We
randomly generate 2nR0 sequences un (l0 ), l0 ∈ [1 : 2nR0 ]
and partition these sequences into 2nR00 bins. The codewords
in each bin are further partitioned into 2nR01 equal size subbins B1 (m00 , m01 ). For each un (l0 ), we randomly generate
2nR1 sequences v n (l0 , l1 ), l1 ∈ [1 : 2nR1 ] and partition these
sequences into 2nR1 bins B2 (l0 , m1 ). We then generate key
codebook. We randomly partition the set of sn sequences into
1
2nRk1 bins B12 (k1 ), k1 ∈ [1 : 2nRk1 ] and then generate a
n
sequence w1 (k1 ) for each index k1 ∈ [1 : 2nRk1 ]. We also
randomly partition the set of sn sequences into 2nRk2 bins
2
B21 (k2 ), k2 ∈ [1 : 2nRk2 ] and then generate a sequence
n
w2 (k2 ) for each index k2 ∈ [1 : 2nRk2 ]. The key which is
used in block b is k(b − 1) = (k1 (b − 1), k2 (b − 1)), where
k1 (b − 1) and k2 (b − 1) are bin indices of sn (b − 1) and
1
sn (b − 1) in block b − 1, respectively.
2
Encoding in block b is as follows. To send messages
(m0 (b), m1 (b)) = (m00 (b), m01 (b), m1 (b)), m01 (b) is encrypted with k(b − 1) to ﬁnd the index m01 (b) = m01 (b) ⊕
(k1 (b − 1), k2 (b − 1)). To ensure secrecy, we must have
R01 ≤ Rk1 + Rk2 [7]. The transmitter selects sequences
un (l0 (b)) ∈ B1 (m00 (b), m01 (b)) and v n (l0 (b), l1 (b)) ∈
B2 (l0 (b), m1 (b)). The transmitter then computes u1,i =
u1 (ui (l0 ), s1,i , s2,i ) and v1,i = v1 (vi (l0 , l1 ), s1,i , s2,i ) using

R0 + R1 ≤ I(V ; Y1 , S1 , S2 )

(10)

R1 ≤ I(V ; Y1 , S1 , S2 |U ).

(11)

Using l0 (b−1) and (k1 (b−2), k2 (b−2)), it recovers m01 (b−1)
where m01 (b−1) is the bin index of l0 (b−1) and m01 (b−1) =
m01 (b − 1) ⊕ (k1 (b − 2), k2 (b − 2)). Similarly, the following
condition can be found for user 2,
R0

≤ I(U ; Y2 , S1 , S2 ).

(12)

In another case, a user may only reconstruct the unknown part
of the key which is not necessarily the entire state sequence
available at the other user, i.e.,
• H(S1 |S2 ) + H(S2 |S1 ) ≥ H(S1 , S2 |Z) or
• H(S1 |S2 )+H(S2 |S1 ) ≤ H(S1 , S2 |Z), H(S1 |S2 ) ≥ C1 ,
H(S2 |S1 ) ≥ C2
In block b, user 1 ﬁnds l0 (b − 1) and l1 (b − 1) such that
n
(v n (l1 (b − 1), l0 (b − 1)), un (l0 (b − 1)), sn (b − 1), y1 (b − 1)) ∈
1
n
A . Using l0 (b − 1) and (k1 (b − 2), k2 (b − 2)), it recovers
m01 (b − 1) where m01 (b − 1) is the bin index of l0 (b − 1)
and m01 (b − 1) = m01 (b − 1) ⊕ (k1 (b − 2), k2 (b − 2)). In this
case, Rk1 and Rk2 should be chosen such that Rk1 + Rk2 =
min{C1 + C2 , H(S1 , S2 |Z)}. Also, we have
R0 + R1 ≤ I(V ; Y1 , S1 )
R1 ≤ I(V ; Y1 , S1 |U )

3

(13)
(14)

R0 ≤ I(U ; Y2 , S2 ).

Next consider the following bound on R1 :

(15)

nR1 = H(M1 ) = H(M1 |M0 )
n
n
≤ I(M1 ; Y1n , S1 , M21 (S2 )|M0 ) + nδ
n
n
n
n
≤ I(M1 ; Y1 , S1 , M21 (S2 ), S2 |M0 ) + nδ
n
n
n
= I(M1 ; Y1 , S1 , S2 |M0 ) + nδ
n
n
≤ I(M1 ; Y1n , S1 , S2 |M0 ) − I(M0 , M1 ; Z n ) + 2nδ
n
n
n
≤ I(M1 ; Y1 , S1 , S2 |M0 ) − I(M1 ; Z n |M0 ) + 2nδ
n
n
n
n
= i=1 I(M1 ; Y1,i , S1,i , S2,i |M0 , Y1,i+1 , S1,i+1 , S2,i+1 )
n
i−1
− i=1 I(M1 ; Zi |M0 , Z ) + 2nδ

Finally, a user may be able to reconstruct the entire sequence
while the other user only reconstructs the unknown part of the
key which is not necessarily the entire sequence, i.e.,
• H(S1 |S2 )+H(S2 |S1 ) ≤ H(S1 , S2 |Z), H(S1 |S2 ) ≤ C1 ,
H(S2 |S1 ) ≥ C2
• H(S1 |S2 )+H(S2 |S1 ) ≤ H(S1 , S2 |Z), H(S1 |S2 ) ≥ C1 ,
H(S2 |S1 ) ≤ C2 .
In the ﬁrst case, one should choose Rk1 = H(S1 |S2 ) and
Rk2 = C2 . The analysis of probability of error yields conditions (12)-(14). For the second case, the rates Rk1 = C1
and Rk2 = H(S2 |S1 ) should be chosen. The analysis of the
probabaility of error yields (10)-(11) and (15). Considering
(10)-(15) with their corresponding key rates and the following,

(a)

=

I(V ; Y1 , S1 , S2 |U2 ) − I(V ; Z|U2 )
= I(V ; Y1 , S1 |U2 ) + I(V ; S2 |Y1 , S1 , U2 ) − I(V ; Z|U2 )
≤ I(V ; Y1 , S1 |U2 ) + H(S2 |Y1 , S1 , U2 ) − I(V ; Z|U2 )
≤ I(V ; Y1 , S1 |U2 ) + H(S2 |Y1 , S1 ) − I(V ; Z|U2 )
Now consider the rate R0 :

and also performing Fourier-Motzkin elimination, we obtain
the terms in Theorem 1.

n
n
nR0 = H(M0 ) ≤ I(M0 ; Y2n , S2 , M12 (S1 )) + nδ
n
n
≤ I(M0 ; Y2n , S2 , M12 (S1 )) − I(M0 ; Z n ) + 2nδ

B. Proof of Theorem 2

n
n
V0,i = (M1 , M0 , Y1,i+1 , S1,i+1 , Z i−1 )
n
n
n
Vi = (M1 , M0 , Y1,i+1 , S1,i+1 , S2,i+1 , Z i−1 )
n
n
n
n
U1,i = (M0 , Y1,i+1 , Y2,i+1 , S1,i+1 , S2,i+1 , Z i−1 )
n
n
n
U2,i = (M0 , Y1,i+1 , S1,i+1 , S2,i+1 , Z i−1 )
n
n
U0,i = (M0 , Y2,i+1 , S2,i+1 , Z i−1 )
n
n
Wi = (Y2,i+1 , S2,i+1 , Z i−1 )
n
n
n
n
Ui = (M0 , Y1,i+1 , Y2,i+1 , S1 , S2 , Z i−1 )

nR1 = H(M1 ) = H(M1 |M0 )
(a)

n
n
≤ I(M1 ; Y1n , S1 , M21 (S2 )|M0 ) + nδ
n
n
n
n
= I(M1 ; Y1 , S1 |M0 ) + I(M1 ; M21 (S2 )|Y1n , S1 , M0 ) + nδ
n
n
n
≤ I(M1 ; Y1 , S1 |M0 ) + H(M21 (S2 )) + nδ
n
= I(M1 ; Y1n , S1 |M0 ) + nC2 + nδ

2nδ

where (a) follows from the same steps in (16)-(18). In the
following we obtain three outer bounds on R0 . Consider the
terms in (21):
n
n
n
n
H(M12 (S1 )|Y2n , S2 ) + H(M21 (S2 )|Y2n , S1 )
n
n
n
n
≤ H(M12 (S1 )) + H(M21 (S2 )|Y2 , S1 )
n
n
n
≤ nC1 + H(S2 |Y2n , S1 ) ≤ nC1 + i=1 H(S2,i |Y2,i , S1,i )

(b)

n
≤ I(M1 ; Y1n , S1 |M0 ) − I(M0 , M1 ; Z n ) + nC2 + 2nδ
n
n
≤ I(M1 ; Y1 , S1 |M0 ) − I(M1 ; Z n |M0 ) + nC2 + 2nδ
n
n
n
= i=1 [I(M1 ; Y1,i , S1,i |M0 , Y1,i+1 , S1,i+1 )

Therefore, one of the terms in (3) can be derived. In a similar
fashion, the other terms in (3) are obtained. To ﬁnd the
n
n
bound in (4), consider (20) where I(M0 ; M12 (S1 )|Y2n , S2 ) ≤
n
n
n
H(M12 (S1 )|Y2 , S2 ) ≤ nC1 . Also, note that I(U0 ; Z|W ) =
I(U0 ; Z, S2 |W ) − I(U0 ; S2 |Z, W ) ≥ I(U0 ; Z, S2 |W ) −
H(S2 |Z). Finally, we have the following bound on R0 :

(16)

(c)

=

(17)

(d)

n
n
n
i−1
)
i=1 [I(M1 ; Y1,i , S1,i |M0 , Y1,i+1 , S1,i+1 , Z
i−1
n
n
− I(M1 ; Zi |M0 , Z , Y1,i+1 , S1,i+1 )] + nC2 + 2nδ
n
= i=1 [I(V0,i ; Y1,i , S1,i |U1,i ) − I(V0,i ; Zi |U1,i ) + C2 ]

+ 2nδ

(21)
n
≤ I(M0 ; Y2n , S2 ) − I(M0 ; Z n )
n
n
n
n
n
+H(S1 |Y2 , S2 ) + H(S2 |Y2n , S1 ) + 2nδ
(a)
n
= i=1 [I(U0,i ; Y2,i , S2,i |Wi ) − I(U0,i ; Zi |Wi )]
n
n
n
n
+H(S1 |Y2n , S2 ) + H(S2 |Y2n , S1 ) + 2nδ
n
≤ i=1 [I(U0,i ; Y2,i , S2,i |Wi ) − I(U0,i ; Zi |Wi )]
n
+ i=1 [H(S1,i |Y2,i , S2,i ) + H(S2,i |Y2,i , S1,i )] +

First consider the rate R1 :

−

(20)

n
n
n
≤ I(M0 ; Y2n , S2 , S1 , M12 (S1 )) − I(M0 ; Z n ) + 2nδ
n
n
n
n
n
= I(M0 ; Y2 , S2 , S1 , M12 (S1 ), M21 (S2 )) − I(M0 ; Z n )
n
n
n
= I(M0 ; Y2 , S2 ) − I(M0 ; Z )
n
n
n
n
+I(M0 ; M12 (S1 ), S1 , M21 (S2 )|Y2n , S2 ) + 2nδ
n
n
n
≤ I(M0 ; Y2 , S2 ) − I(M0 ; Z )
n
n
n
n
+ H(M12 (S1 )|Y2n , S2 ) + H(M21 (S2 )|Y2n , S1 ) + 2nδ

Deﬁne the following random variables:

n
i−1
n
n
; Y1,i , S1,i |M0 , Y1,i+1 , S1,i+1 )
i=1 [I(M1 , Z
n
n
I(M1 , Y1,i+1 , S1,i+1 ; Zi |M0 , Z i−1 )] + nC2 + 2nδ

− I(Vi ; Zi |U2,i )] + 2nδ
(19)

where (a) follows from the same steps in (17) and (18).
Finally, we have the following bound on R1 . Consider the
term in (19):

R0 ≥ R0 , R1 ≥ R1 , R0 = R00 + R01 , R01 ≤ Rk1 + Rk2
R0 − R00 ≥ I(U ; Z, S1 , S2 )
R1 − R1 ≥ I(V ; Z, S1 , S2 |U )
Rk1 + Rk2 ≤ H(S1 , S2 |Z),

− I(M1 ; Zi |M0 , Z i−1 )] + nC2 + 2nδ

n
i=1 [I(Vi ; Y1,i , S1,i , S2,i |U2,i )

=

(18)
+ 2nδ

where (a) follows from Fano’s inequality. (b) follows from the
secrecy condition. (c) and (d) follow the Csiszar sum identity.

n
n
nR0 = H(M0 ) ≤ I(M0 ; Y2n , S2 , M12 (S1 )) + nδ
n
n
n
n n
n
≤ I(M0 ; Y2 , S1 , S2 ) + nδ = I(M0 ; Y2 |S1 , S2 ) + nδ
n
n
n
n
= i=1 I(M0 ; Y2,i |S1 , S2 , Y2,i+1 ) + nδ
n
≤ i=1 I(Ui ; Y2,i |S2,i ) + nδ

Similarly, the ﬁrst term in (2) can be obtained.

4

is independent of (M00,i , M1,i , Ki−1 , Si , C) and uniformly
distributed on [1 : 2n(Rk1 +Rk2 ) ]. Consider the second term:

V. C ONCLUSION
We obtained bounds on the secrecy capacity region of the
2-rec., 1-eav. BC with CCSI and conferencing. We have shown
that the proposed bounds determine the secrecy capacity for a
special case.

n
n
n
I(M01,i ; Zi |M00,i , M1,i , Z1 , ..., Zi−1 , Si , C)
n
n
n
= I(L1 , L0 ; Zi |M00,i , M1,i , Z1 , ..., Zi−1 , Si , C)
n
n
n
−I(L1 , L0 ; Zi |M00,i , M1,i , M01,i , Z1 , ..., Zi−1 , Si , C)
n
n
n
≤ I(Vin ; Zi |M00,i , M1,i , Z1 , ..., Zi−1 , Si , C)
n
n
n
−I(L1 , L0 ; Zi |M00,i , M1,i , M01,i , Z1 , ..., Zi−1 , Si , C)
≤ nI(V ; Z|S)
n
n
−H(L1 , L0 |M00,i , M1,i , M01,i , Z1 , ..., Zi−1 , Si , C)
n
n
+H(L1 , L0 |M00,i , M1,i , M01,i , Z1 , ..., Zi , Si , C)
n
= nI(V ; Z|S) + H(L1 , L0 |M00,i , M1,i , M01,i , Zi , Si , C)
n
n
−H(L1 , L0 |M00,i , M1,i , M01,i , Z1 , ..., Zi−1 , Si , C)

A PPENDIX A
A NALYSIS OF THE I NFORMATION L EAKAGE R ATE
n
We use Zi to denote the received sequence, (M0,i , M1,i )
to denote the messages sent and Ki = (K1,i , K2,i ) to denote
the key used in block i. Deﬁne M.,i = (M0,i , M1,i ) and Si =
(S1,i , S2,i ). Consider

(a)

≤ nI(V ; Z|S) + n((R0 − R00 ) + (R1 − R1 ) − I(V ; Z, S))
n
n
−H(L1 , L0 |M00,i , M1,i , M01,i , Z1 , ..., Zi−1 , Si , C) + nδ
= n(R0 − R00 ) + n(R1 − R1 )
n
n
−H(L1 , L0 |M00,i , M1,i , M01,i , Z1 , ..., Zi−1 , Si , C) + nδ

n
n
I(M.,2 , M.,3 , ..., M.,B ; Z1 , ..., ZB |C)
B
n
n
= i=2 I(M.,i ; Z1 , ..., ZB |M.,i+1 , ..., M.,B , C)
(a)
B
n
n
≤ i=2 I(M.,i ; Z1 , ..., ZB |M.,i+1 , ..., M.,B , Si , C)
(b)
B
n
n
= i=2 I(M.,i ; Z1 , ..., Zi |Si , C)
B
n
n
n
= i=2 I(M00,i , M1,i ; Zi |Z1 , ..., Zi−1 , Si , C)
B
n
n
n
+ i=2 I(M01,i ; Zi |M00,i , M1,i , Z1 , ..., Zi−1 , Si , C)

where (a) follows if the condition (R0 − R00 ) + (R1 − R1 ) ≥
I(V ; Z, S) holds. Now consider the following term:
n
n
H(L1 , L0 |M00,i , M1,i , M01,i , Z1 , ..., Zi−1 , Si , C)
n
n
= H(M01,i ⊕ Ki−1 |M00,i , M1,i , M01,i , Z1 , ..., Zi−1 , Si , C)+
n
n
H(L1 , L0 |M00,i , M1,i , M01,i , M01,i ⊕ Ki−1 , Z1 , ..., Zi−1 ,
n
n
Si , C) = H(Ki−1 |M00,i , M1,i , M01,i , Z1 , ..., Zi−1 , Si , C)
n
n
+H(L1 , L0 |M00,i , M1,i , M01,i , Ki−1 , Z1 , ..., Zi−1 , Si , C)
n
n
= H(Ki−1 |Z1 , ..., Zi−1 , Si , C) + n(R0 − R00 − Rk1 − Rk2 )

where (a) follows by the independence of M.,i and
B
n
n
(Si , M.,i+1 ). (b) follows because (Zi+1 , ..., ZB , M.,i+1 , ...,
n
n
M.,B , C) → (Z1 , ..., Zi , Si , C) → (M.,i , C) form a Markov
chain. We bound each term separately. Consider the ﬁrst term:
n
n
n
I(M00,i , M1,i ; Zi |Z1 , ..., Zi−1 , Si , C)
n
n
n
= I(L1 , L0 ; Zi |Z1 , ..., Zi−1 , Si , C)
n
n
n
−I(L1 , L0 ; Zi |M00,i , M1,i , Z1 , ..., Zi−1 , Si , C)
n
n
n
n
≤ I(V ; Zi |Z1 , ..., Zi−1 , Si , C)
n
n
−H(L1 , L0 |M00,i , M1,i , Z1 , ..., Zi−1 , Si , C)
n
+H(L1 , L0 |M00,i , M1,i , Zi , Si , C)

(a)

+n(R1 − R1 ) ≥ n(R0 − R00 ) + n(R1 − R1 )
where (a) follows because if (R0 − R00 ) + (R1 − R1 ) ≥
I(V ; Z, S1 , S2 ) and H(S1 , S2 |Z) ≥ Rk1 + Rk2 then n(Rk1 +
n
n
Rk2 ) ≤ H(Ki |Z1 , ..., Zi , C) + nδ. For the proof, see [6].
R EFERENCES

(a)

n
n
≤ nI(V ; Z|S) − H(L1 , L0 |M00,i , M1,i , Z1 , ..., Zi−1 , Si , C)
n
+H(L1 , L0 |M00,i , M1,i , Zi , Si , C)
(b)

n
n
≤ nI(V ; Z|S) − H(L1 , L0 |M00,i , M1,i , Z1 , ..., Zi−1 , Si , C)
+n((R0 − R00 ) + (R1 − R1 ) − I(V ; Z, S) + δ)

(c)

= n(R0 − R00 ) + n(R1 − R1 )
n
n
−H(L1 , L0 |M00,i , M1,i , Z1 , ..., Zi−1 , Si , C) + nδ
= nδ + n(R0 − R00 ) + n(R1 − R1 )
n
n
−H(M01,i ⊕ Ki−1 |M00,i , M1,i , Z1 , ..., Zi−1 , Si , C)
n
n
−H(L1 , L0 |M00,i , M1,i , M01,i ⊕ Ki−1 , Z1 , ..., Zi−1 , Si , C)
≤ n(R0 − R00 ) + n(R1 − R1 )
n
n
−H(M01,i ⊕ Ki−1 |M00,i , M1,i , Ki−1 , Z1 , ..., Zi−1 , Si , C)
−n(R0 − R00 − Rk1 − Rk2 ) − n(R1 − R1 ) + nδ
(d)

= n(Rk1 + Rk2 ) − H(M01,i ⊕ Ki−1 |M00,i , M1,i , Ki−1 , Si , C)
(e)

+nδ = nδ
n
n
where (a) follows from the Markov chain (Z1 , ..., Zi−1 , C) →
n
n
(Zi , Si , C) → (V , C) and also the memoryless property
of the channel. (b) follows if the condition (R0 − R00 ) +
(R1 − R1 ) ≥ I(V ; Z, S) holds. (c) follows from the independence of V and S. (d) follows from the Markov chain
n
n
(Z1 , ..., Zi−1 , M00,i , M1,i , Si ) → (M00,i , M1,i , Ki−1 , Si ) →
(M01,i ⊕ Ki−1 , M00,i , M1,i , Si ). (e) follows because M01,i

5

[1] I. Csiszar and J. Korner, “Broadcast channels with conﬁdential messages,” IEEE Trans. on Info. Theory, vol. 24, no. 3, pp. 339-348, May
1978.
[2] Y. K. Chia and A. El Gamal, “3-Receiver broadcast channels with
common and conﬁdential messages,” in Proc. IEEE Int. Symp. on Info.
Theory, Seoul, Korea, Jun.-Jul. 2009, pp. 1849-1853.
[3] S. Salehkalaibar and M. R. Aref, “The capacity region of a class of
3-receiver broadcast channels with two eavesdroppers,” in Proc. IEEE
Int. Symp. on Info. Theory, St. Petersburg, Russia, Jul.-Aug. 2011, pp.
1031-1035.
[4] Y. Chen and A. J. Han Vinck, “Wiretap channel with side information,”
IEEE Trans. on Info. Theory, vol. 54, no. 1, pp. 395- 402, Jan. 2008.
[5] A. Khisti, S. N. Diggavi, and G. W. Wornell, “Secret key agreement
using asymmetry in channel state knowledge,”in Proc. IEEE Int. Symp.
on Info. Theory, Seoul, South Korea, July 2009, pp. 2286-2290.
[6] Y. K. Chia and A. El Gamal, “Wiretap channel with causal state
information,” in Proc. IEEE Int. Smyp. on Info. Theory, Austin, Texas,
June 2010, pp. 13-18.
[7] C. E. Shannon, “Channels with side information at the transmitter,” IBM
J. Res. Develop., vol. 2, pp. 289-293, 1958.
[8] E. Ardestanizadeh, M. Franceschetti, T. Javidi, and Y. H. Kim, “Wiretap
channel with rate-limited feedback,” IEEE Trans. on Info. Theory, vol.
55, no. 12, pp. 5353-5361, Dec. 2009.
[9] C. E. Shannon, “Communication theory of secrecy systems,” Bell
Systems Tech. J., vol. 28, pp. 656-715, 1949.

